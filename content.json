{"pages":[{"title":"Catagories","text":"Here is my Categories page.","link":"/catagories/index.html"},{"title":"About","text":"My name is Wan Zixin. I graduated from school of resources and environmental science, WuHan University(WHU), majoring in Geographic Information Science(GIS). I like beautiful and regular things. I like making close friends. Dreaming of becoming a self-discipline and persistence person.","link":"/about/index.html"}],"posts":[{"title":"2021 July 24th","text":"18th-23th July 2021","link":"/Gallery/2021-July-24th/"},{"title":"ArcGIS中自定义Python脚本工具","text":"ArcGIS中的ArcToolBox包含许多工具，涉及网络分析、路径分析、格式转换等诸多领域，再结合详尽的帮助文档，可以快速掌握上手一个工具的使用。当然，ArcGIS也提供自定义脚本工具，以满足用户的定制化需求。这篇文章旨在介绍ArcGIS中Python脚本工具的编写与使用，以及其中遇到的问题，以飨读者。在文章末尾给出一个自定义脚本工具的源代码，供读者参考。笔者的ArcGIS版本为10.6，自带的Python版本为2.7.14，与目前主流的python3略有差别，需留心注意。 ArcPy简介ArcPy 是以 arcgisscripting 模块为基础并继承了 arcgisscripting 功能进而构建而成的站点包。目的是为以实用高效的方式通过 Python 执行地理数据分析、数据转换、数据管理和地图自动化创建基础。在导入 ArcPy 之后，可以运行随 ArcGIS 安装的标准工具箱中的所有地理处理工具，包括有分析工具箱、制图工具箱、转换工具箱、数据管理工具箱、编辑工具箱、地理编码工具箱、线性参考工具箱、多维工具箱和空间统计工具箱。 ArcPy由一系列模块组成，包括： 模块中文名 模块名 描述 数据访问模块（Data Access） arcpy.da 数据访问模块 (arcpy.da) 是一个用于处理数据的 Python 模块。通过它可控制编辑会话、编辑操作、改进的游标支持（包括更快的性能）、表和要素类与 NumPy 数组之间相互转换的函数以及对版本化、复本、属性域和子类型工作流的支持。 制图模块（Mapping） arcpy.mapping 主要是用于操作现有地图文档 (.mxd) 和图层文件 (.lyr) 的内容。此外，还提供自动执行导出和打印的功能。Arcpy.mapping 可用于自动执行地图生产；它扩展了数据驱动页面的功能，同时，因其包含导出至 PDF 文档、创建和管理 PDF 文档的函数，而为构建完整地图册所必需。最后，可将 arcpy.mapping 脚本发布为地理处理服务，并将脚本功能提供给 Web 应用程序。 ArcGIS空间分析扩展模块（ArcGIS Spatial Analyst） arcpy.sa Spatial Analyst 模块是用于分析栅格数据的 Python 模块，该模块在进行分析时将使用 ArcGIS Spatial Analyst 扩展模块 提供的功能。借助该模块可访问 Spatial Analyst 工具箱中提供的所有地理处理工具以及其他帮助程序函数和类 ArcGIS网络分析扩展模块（ArcGIS Network Analyst） arcpy.na arcpy.na 是用于使用 ArcGIS Network Analyst 扩展模块 提供的网络分析功能的 Python 模块。通过它可访问 Network Analyst 工具箱中提供的所有地理处理工具以及允许您通过 Python 使 Network Analys 工作流自动化的其他帮助程序函数和类。 时间模块 arcpy.time arcpy.time 模块包含在 Python 中处理时间增量和时区时会用到的类、方法以及属性。 自定义工具箱和脚本工具的步骤 ArcMap中点开右侧“目录”，展开“工具箱”，右键单击“我的工具箱”，选择“新建”工具箱，为工具箱命名； 右键单击新工具箱，选择“添加”脚本，进入脚本工具编辑页面； “名称”用于系统内部处理，全英文且不能包含空格、连接线等非法字符；“标签”是脚本工具的显示名称，便于阅读；勾选“存储相对路径名”，以便制作好的工具箱分享出去可以直接使用；“脚本文件”选择对应的.py文件；最后，设置脚本中所需要的参数，并指定好类型。 编写py文件工具参数的传入比如想要编写一个按掩膜提取的脚本工具，需要输入待提取的栅格图层和作为掩膜的矢量图层，输出提取完成的栅格图层。普通.py脚本文件中，参数的传递非常容易，但是如何获取输入参数提供给ArcGIS的脚本工具呢？这是需要使用arcpy.GetParameterAsText函数，按顺序获取输入参数，并赋给特定变量以供使用。 12345import arcpyyp_road_shp = arcpy.GetParameterAsText(0)pond_tif = arcpy.GetParameterAsText(1) jsonPath = arcpy.GetParameterAsText(2) 自定义进度对话框中的消息使用arcpy.AddMessage函数向脚本工具的消息中添加自定义消息，仅需要一个字符串类型的参数做文本输出。用于自定义写入消息的四个ArcPy函数如下所示，可根据需要使用相应的函数。其中，值得注意的一点是，message需为全英文，否则单独运行无误，但作为脚本工具在ArcGIS中使用会产生意想不到的错误。 函数名 描述 AddMessage(message) 用于一般信息性消息（严重性 = 0） AddWarning(message) 用于警告消息（严重性 = 1） AddError(message) 用于错误消息（严重性 = 2） AddIDMessage(message_type, messageID, add_argument1, add_arrgument2) 用于错误和警告（由 message_type 参数确定严重性。） 添加描述信息右键单击自定义的脚本工具，选择“项目描述”，单击左上角的“编辑”，即可为脚本工具和参数添加说明信息，以便工具可读性的提高。 杨浦区洪水风险样例的脚本工具源码上海市杨浦区，路网图层与洪水图层叠加，输出road_id（道路编码），name（道路名称），level（道路洪水等级），levelType（洪水等级范围）到json文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139'''# -*- coding: utf-8 -*-'''# python version: 2.7.14# Author: Wan Zixin# Date: 2020.07.23import arcpyimport jsonimport codecsimport osdef TifBand2ToShp(pond_tif): rasterTif_band2 = arcpy.MakeRasterLayer_management(pond_tif, \"rasterTif_band2\", \"#\", band_index=\"2\") # 波段索引从1开始计 rasterTif_band2_shp_name = byproductDir+'\\\\'+os.path.basename(pond_tif).split('.')[0]+'.shp' rasterTif_band2_shp = arcpy.RasterToPolygon_conversion(rasterTif_band2, rasterTif_band2_shp_name, \"NO_SIMPLIFY\") #arcpy.AddMessage(\"Step1 tif文件band2转为shp文件已完成。\") arcpy.AddMessage(\"Step1 tif's ban2 to shapefile is done.\") return rasterTif_band2_shp_namedef InteractTwoShps(shp1,shp2,jsonPath): infos = [] interact_shp_name = byproductDir+'/'+\"myInteract_\"+ os.path.basename(shp1) interact_shp = arcpy.Intersect_analysis([shp1, shp2], interact_shp_name) # arcpy.AddMessage(\"Step2 shp文件叠加操作已完成。\") arcpy.AddMessage ('Step2 shapefile interact is done.') fields = ['road_id', 'name', 'gridcode'] with arcpy.da.SearchCursor(interact_shp, fields) as cursor: for row in cursor: info={} info[\"road_id\"]=row[0]; info[\"name\"]=row[1]; g_legend = getLegend(row[2]) info[\"level\"] = g_legend; g_code = getLevelType(g_legend) info[\"levelType\"] = g_code; infos.append(info) infos_new = [] infos_new = reviseInfos(infos); jsonData = json.dumps(infos_new, ensure_ascii = False, encoding=\"gb2312\") f = codecs.open(jsonPath, 'w',encoding='utf-8') f.write(jsonData) f.close() # arcpy.AddMessage(\"Step3 JSON文件生成已完成。JSON文件路径为： \" + jsonPath) arcpy.AddMessage(\"Step3 JSON file is created. JSON file path is \" + jsonPath)def reviseInfos(infos): # 按road_id排序 infos.sort(key=lambda x: x['road_id']) # 设置一个哨兵字典,初值为列表第一个元素 info_flag = {} info_flag = infos[0] # 定义一个新列表，作返回值 global infos_new infos_new = [] infos_new.append(info_flag) # 定义一个info_max存储road_id相等中level最大的字典元素 # info_max = {} # 从列表第二个元素开始 global i i = 1 while i &lt; len(infos): if(info_flag['road_id'] == infos[i]['road_id']): info_max = infos_new[-1] # info_max是待返回列表的最后一个元素,定义一个info_max存储road_id相等中level最大的字典元素 if(info_max['level'] &lt; infos[i]['level']): info_max = infos[i] infos_new.pop(-1) infos_new.append(info_max) else: infos_new.append(infos[i]) info_flag = infos[i] i += 1 # i_new = i # i_new += 1 # i = i_new # python2中没有自增和自减 return infos_newdef getLegend(g): if g == 255: return 0 elif g == 203: return 0.1 elif g == 167: return 0.2 elif g == 135: return 0.3 elif g == 96: return 0.4 elif g == 64: return 0.5 elif g == 36: return 1.0 elif g == 0: return 1.1 else: # print \"g的数值有误\" return Nonedef getLevelType(g_legend): if g_legend &lt; 0.1: return \"&lt;0.1\" elif g_legend &gt;= 0.1 and g_legend &lt; 0.3: return \"0.1-0.3\" elif g_legend &gt;= 0.3 and g_legend &lt;= 0.5: return \"0.3-0.5\" elif g_legend &gt;0.5: return \"&gt;0.5\" else: # print \"g_legend数值有误\" return NonebyproductDir = arcpy.GetParameterAsText(3)if not os.path.exists(byproductDir): os.mkdir(byproductDir)# byproductDir = 'E:/PondRisk/ArcPyHand/byproduct'def main(): arcpy.env.overwriteOutput = True # 允许覆盖已有文件,注意提醒用户 yp_road_shp = arcpy.GetParameterAsText(0) pond_tif = arcpy.GetParameterAsText(1) # tif数据确保包含有两个波段及以上 jsonPath = arcpy.GetParameterAsText(2) #pond_tif = 'E:/PondRisk/ArcPyHand/lib/workspace/YP_20190810000000_max.tif' #yp_road_shp = 'E:/PondRisk/ArcPyHand/lib/workspace/YP_roads.shp' #jsonPath = 'C:/Users/user/Desktop/info.json' tif_band2_shp_path = TifBand2ToShp(pond_tif) InteractTwoShps(tif_band2_shp_path, yp_road_shp,jsonPath)if __name__ == \"__main__\": main()","link":"/Item/ArcGIS%E4%B8%AD%E8%87%AA%E5%AE%9A%E4%B9%89Python%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/"},{"title":"Confidence","text":"When faced with a big challenge where potential failure seems to lurk at every corner, maybe you’ve heard this advice before: “Be more confident.” And most likely, this is what you think when you hear it: “If only it were that simple.” But what is confidence? Take the belief that you are valuable, worthwhile, and capable, also konwn as self-esteem, add in the optimism that comes when you are certain of your abilities, and then enpowered by this, act courageously to face a challenge head-on. This is confidence. It turns thoughts into actions. So where does confidence even come from? There are several factors that impact confidence. One: what you’re born with, such as your genes, which will impact things like the balance of neurochemicals in your brain. Two: how you’re treated. This includes the social pressures of your enviroment. Three: the part you have control over, the choices you make, the risks you take, and how you think about and respond to challenges and setbacks. It isn’t possible to completely untangle these three factors, but the personal choices we make certainly play a major role in confidence development. So, by keeping in mind a few practical tips, we do actually have the power to cultivate our own confidence. Tip one: a quick fix. There are a few tricks that can give you an immediate confidence boost in the short term. Picture your success when you’re beginning a difficult task, something as simple as listening to music with deep bass; it can promote feelings of power. You can even strike a powerful pose or give yourself a pep talk. Tip two: believe in your ability to improve. If you’re looking for a long term change, consider the way you think about your abilities and talents. Do you think they are fixed at birth, or that they can be developed, like a muscle? These beliefs matter because they can influence how you act when you’re faced with setbacks. If you have a fixed mindset, meaning thay you think your talents are locked in place, you might give up, assuming you’re discovered something you’re not very good at. But if you have a growth mindset and think your abilities can improve, a challenge is an opportunity to learn and grow. Neuroscience supports the growth mindset. The connections in your brain do get stronger and grow with study and practice. It alse turns out, on average, people who have a growth mindset are more successful, getting better grades and doing better in the face of challenges. Tip three: practice failure. Face it, you’re going to fail at sometimes. Everyone does. J.K. Rowling was rejected by twelve different publishers before one picked up “Harry Potter”. The Wright Brothers built on history’s failed attempts at flight, including some of their own, before designing a successful airplane. Studies show that those who fail regularly and keep trying anyway are better equipped to respond to challenges and setbacks in a constructive way. They learn how to try different strategies, ask others for advices, and perservere. So, think of the challenge you want to take on, realize it’s not going to be easy, accept that you’ll make mistakes, and be kind to yourself when you do. Give yourself a pep talk, stand up, and go for it. The excitement you’ll feel knowing that whatever the result, you’ll have gained greater knowledge and understanding. This is confidence.","link":"/Study/English/Confidence/"},{"title":"Git常用命令","text":"Git是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。本文参考廖雪峰老师的Git教程总结了Git常用命令和使用场景，便于使用中速查。廖雪峰老师的Git教程指路。 创建版本库12345678# 创建文件夹mkdir &lt;directoryname&gt; # 把某目录变成Git可以管理的仓库git init # 把文件添加到仓库git add &lt;filename&gt; # 从暂存区提交到master分支，discription是本次提交的说明git commit -m \"discription\" 时光机穿梭1234# 查看提交历史git log# 减少输出信息，提高可读性git log --pretty=oneline 123456# 回退到上一版本git reset --hard HEAD^# 命令行窗口未关闭时，回退到commit id对应的版本；版本号不必写全，写前几位即可git reset --hard &lt;commitid&gt;# 命令行窗口关闭时：查看命令历史，找到目的版本的commit id，再利用上一条命令返回目的版本git reflog HEAD 表示当前版本，HEAD^ 表示上一个版本，HEAD^^ 表示上上一个版本…… 123456789# 查看状态git status# 丢弃工作区的修改git checkout --&lt;file&gt;# 取消暂存git reset HEAD &lt;file&gt;git restore --staged &lt;file&gt;# 删除文件，删除后记得commitgit rm &lt;file&gt; 远程仓库123456# 关联我的远程库git remote add origin git@github.com:WanZixin/learngit.git# 把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令git push -u origin master# 克隆到本地库，也可用https协议，但原生ssh协议速度最快git clone git@github.com:WanZixin/gitskills.git 分支管理创建与合并分支1234567891011121314# 查看当前分支git branch# 创建分支git branch &lt;branchname&gt;# 删除分支git branch -d &lt;branchname&gt;# 切换到指定分支git switch &lt;branchname&gt; git checkout &lt;branchname&gt;# 创建并切换到指定分支git switch -c &lt;branchname&gt; git checkout -b &lt;branchname&gt;# 合并指定分支到当前分支git merge &lt;branchname&gt; 解决冲突当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。 12# 查看分支合并图git log --graph 分支管理策略通常，合并分支时，如果可能，Git会用Fast forward模式，但这种模式下，删除分支后，会丢掉分支信息。如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 12# 使用no-ff方式合并，表示禁用Fast forwardgit merge --no-ff -m \"merge with no-ff\" dev 在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 bug分支软件开发中，bug就像家常便饭一样。有了bug就需要修复，在Git中，由于分支是如此的强大，所以，每个bug都可以通过一个新的临时分支来修复，修复后，合并分支，然后将临时分支删除。 1234567891011121314# 把当前工作现场“储藏”起来，等以后恢复现场后继续工作git stash# 查看工作现场git stash list# 恢复现场后并不删除stash的内容git stash apply# 删除stash的内容git stash drop# 恢复现场的同时把stash也删除了git stash pop# 恢复到指定的stashgit stash apply stash@{0}# 复制一个特定的提交到当前分支git cherry-pick &lt;commitid&gt; feature分支软件开发中，总有无穷无尽的新的功能要不断添加进来。添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 123# feature-vulcan分支还没有被合并，如果删除，将丢失掉修改，如果要强行删除，需要使用大写的-D参数git branch -d feature-vulcangit branch -D feature-vulcan 多人协作master分支是主分支，因此要时刻与远程同步。 dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步。 bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug。 feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。 1234# 查看远程库信息git remote# 显示更详细的信息git remote -v 多人协作的工作模式： 首先，可以试图用git push origin &lt;branch-name&gt;推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！ 如果git pull提示 no tracking information ，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;。 标签管理tag是一个让人容易记住的有意义的名字，跟某个commit绑在一起。 1234567891011121314# 打一个标签，默认标签是打在最新提交的commit上的git tag &lt;tagname&gt;# 查看所有标签git tag# 指定标签信息git tag -a &lt;tagname&gt; -m \"description\"# 给指定commit添加标签 git tag &lt;tagname&gt; &lt;commitid&gt;# 删除标签git tag -d &lt;tagname&gt;# 推送标签到远程库git push origin &lt;tagname&gt;# 一次性推送全部尚未推送到远程的本地标签git push origin --tags 如果标签已经推送到远程，要删除远程标签需要两步： 1234# 先从本地删除 git tag -d &lt;tagname&gt;# 再从远程删除git push origin :refs/tags/&lt;tagname&gt; 自定义Git忽略特殊文件忽略某些文件时，需要编写 .gitignore。该 文件本身要放到版本库里，并且可以对.gitignore做版本管理！ 忽略文件的原则： 忽略操作系统自动生成的文件，比如缩略图等； 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件； 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 配置别名配置Git的时候，加上–global是针对当前用户(这台电脑的所有Git仓库)起作用的，如果不加，那只针对当前的仓库起作用。每个仓库的配置文件都放在 .git/config 文件中，其中别名在 [alias] 后面，要删除别名，把对应的行删除即可。 12# 用st表示statusgit config --global alias.st status","link":"/Study/Git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"OpenTSDB概述","text":"OpenTSDB是一个可扩展的时序数据库，可以在不丢失粒度的情况下存储和提供大量时间序列数据。常用于基础监控、[]。 查询或读取数据OpenTSDB提供了许多方法来提取、处理和分析数据。可以用CLI工具、HTTP API查询数据，并查看GnuPlot图（GnuPlot是一个命令行的交互绘图工具）。开源工具比如Grafana和Bosun也可以连接TSDB。使用 OpenTSDB 的基于标签的系统进行查询可能有点棘手，因此请通读本文档。 基本概念TSD 时间序列守护线程 Metric 指标 tag 标签 group 组 aggregation 聚合 查询参数 参数 数据类型 必需 描述 栗子 Start Time String or Integer 是 查询的起始时间，可以是绝对时间，也可以是相对时间 24h-ago End Time String or Integer 否 查询的结束时间，如果没有提供结束时间，则会使用TSD的当前时间作为结束时间 1h-ago Metric String 是 系统中指标的全称，且是大小写敏感的 sys.cpu.user Aggregation Function String 是 一个用来合并多条时间线的计算方法 sum Filter String 否 过滤标签值以减少在查询或组中选取的时间序列数量，并在各种标签上聚合 host=*,dc=lax Downsampler String 否 用于减少时间段内返回的数据点数量 1h-avg Rate String 否 用于计算结果每秒变化率 rate Functions String 否 数据处理功能，如附加过滤、时移等 highestMax(…) Expressions String 否 时间序列间的数据操作功能 (m2 / (m1 + m2)) * 100 TimesUnix格式的或人类可读的时间戳都支持。因为OpenTSDB可以以毫秒分辨率存储数据，默认情况下查询返回秒分辨率的数据以对现有的工具向后兼容。如果您每秒存储多个数据点，请确保您发出的任何查询都包含 1s-&lt;func&gt; 的采样器以读取正确的数据， 否则将发出不确定的值。 要以毫秒分辨率提取数据，请使用 /api/query 并指定 msResolution（ms 也可以，但不推荐）JSON 参数或查询字符串标志，它将绕过向下采样（除非指定）并返回 Unix 中的所有时间戳毫秒分辨率。 此外，scan命令返回写入存储的时间戳。 Filters// TODO","link":"/Study/Java/OpenTSDB/OpenTSDB%E6%A6%82%E8%BF%B0/"},{"title":"Python下GDAL和OGR的使用","text":"项目上需要实现两个功能，一个是shp文件（路网）与tif文件（积水）的相交，以获取各条道路的积水信息；一个是根据经纬度位置获取对应tif文件的像素值。某个项目上需要实现两个功能，一个是shp文件（路网）与tif文件（积水）的相交，以获取各条道路的积水信息；一个是根据经纬度位置获取对应tif文件的像素值。为了解决上述问题，首先考虑到ArcGIS Desktop自带的ArcPy，借助ArcPy可以调用标准工具箱的任意一项工具，但最大的缺点在于速度，仅仅在import语句中导入ArcPy模块，就需要花费十秒左右的时间，而且Python2.7的版本太过远古。如果仅仅是做单独脚本，或者是编写ArcGIS的脚本工具，ArcPy仍然是最好的选择。但要考虑到作为Web服务，时延太长就很不合理了。因而，选择了Python 3.8环境下的gdal和ogr，分别用于处理栅格数据和矢量数据；使用flask和flasgger，分别用于微型网络框架和Swagger-UI的使用。 GDAL和OGR的安装使用pip安装速度上很慢，使用国内镜像源速度快很多，共有两种方式在pip安装模块时使用镜像源。 临时修改。使用pip时加上-i https://pypi.tuna.tsinghua.edu.cn/simple，例如：pip install gdal -i https://pypi.tuna.tsinghua.edu.cn/simple即使用了清华的镜像源。 永久修改。Windows平台下的用户目录新建pip文件夹，再新建pip.ini配置文件，写入如下内容保存，以后的每次pip安装模块都会使用阿里云的镜像源了。 1234[global]index-url = http://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com 使用pip install gdal命令即可，因为gdal和ogr都被集成在了osgeo中，ogr也会一并下载。使用from osgeo import gdal, ogr即可导入。 GDAL和OGR的使用Python下GDAL的官方文档，地址为https://gdal.org/python，以下将本次任务中使用到的部分做个简单的记录。 栅格数据的读取1234567891011from osgeo import gdaldef readRaster(rasterPath): dataset = gdal.Open(rasterPath) #波段从1开始计数，这行语句获取栅格数据集的第二个波段 band2 = dataset.GetRasterBand(2) #获取栅格文件的仿射信息，是一个包含六个元素的数组,第三个元素和第五个元素带代表旋转信息，一般都为0 geotransform = dataset.GetGeoTransform() originX = geotransform[0] #左上角经度 originY = geotransform[3] #左上角纬度 pixelWidth = geotransform[1] #像元宽度 pixelHeight = geotransform[5] #像元高度 矢量数据的读取1234567891011from osgeo import ogrdef readShp(shpPath): driver = ogr.GetDriverByName('ESRI Shapefile') ds = driver.Open(shppath, 0) # read only layer = ds.GetLayer(0) #获取数据集的第一个图层 ds_sr = layer.GetSpatialRef() #获取数据集的空间参考 #获取图层的每一个要素与属性 for feature in layer: geomtry = feature.GetGeometryRef() FID = feature.GetField('FID') 栅格矢量化1234567891011121314151617181920212223def raster_to_shapefile(self,rasterpath): driver = ogr.GetDriverByName('ESRI Shapefile') src_dataset = gdal.Open(rasterpath) # get band2 in tif src_band2 = src_dataset.GetRasterBand(2) maskband = src_band2.GetMaskBand() #掩膜波段图层 target_sr = osr.SpatialReference() target_sr.ImportFromEPSG(4326) dst_layerName = \"byproduct/Polyginize_Stuff\" dst_dateset = driver.CreateDataSource(dst_layerName + \".shp\") dst_layer = dst_dateset.CreateLayer(dst_layerName, srs = target_sr) # DN代表地物反射率，这段代码在属性表创建了DN列，值即为波段2的值 dst_fieldName = 'DN' fd = ogr.FieldDefn(dst_fieldName, ogr.OFTInteger) dst_layer.CreateField(fd) # 第四个参数是需要将DN值写入矢量字段的索引，应该不包括FID和Shape gdal.Polygonize(src_band2, maskband, dst_layer, 0, [], callback = None) return dst_layerName 栅格数据中根据仿射信息将经纬度转换为行列号1234567891011121314151617181920def getRGBByLnglat(self,lnglat,time): maxTifpath = self.getMaxTifpathByTime(time) dataset = gdal.Open(maxTifpath) geotransform = dataset.GetGeoTransform() originX = geotransform[0] originY = geotransform[3] pixelWidth = geotransform[1] pixelHeight = geotransform[5] xOffset = int((lnglat[0]-originX)/pixelWidth) yOffset = int((lnglat[1]-originY)/pixelHeight) rgb = [] for i in range(1,4): band = dataset.GetRasterBand(i) # gridcode is a two-dimensional array with only an element gridcode = band.ReadAsArray(xOffset,yOffset,1,1) rgb.append(gridcode[0][0]) return str(rgb[0]) + ',' + str(rgb[1]) + ',' + str(rgb[2]) 矢量数据的相交Intersect在ogr中，读入一个矢量文件得到的是数据集，数据集的下一维度是图层（一般只有一个图层），图层的下一维度是要素，要素包含几何图形和属性。相交有两个维度的判断办法，一种是Layer（图层）的相交，一种是Geometry（几何图形）的相交。基于Layer的相交仅有一个函数Intersection，无论是否存在相交，返回的都是处理结果；而基于Geometry的相交则有三个函数，分别是Intersection，Intersect，Intersects，不同点在于后两个函数返回的是bool值，即只要几何图形的envelope重叠就返回True，否则返回False。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778def getDataSetFromShpPath(self, shppath): driver = ogr.GetDriverByName('ESRI Shapefile') ds = driver.Open(shppath, 0) # read only if ds is None: print(shppath + 'is wrong.') return return dsdef intersectTwoShp(roadShp,pondshp): pond_ds = getDataSetFromShpPath(pondshp) road_ds = getDataSetFromShpPath(roadShp) pond_layer = pond_ds.GetLayer(0) road_layer = road_ds.GetLayer(0) # 用于空间参考的一致性变换 src_sr = road_layer.GetSpatialRef() target_sr = pond_layer.GetSpatialRef() ct = osr.CoordinateTransformation(src_sr,target_sr) infos = [] # 构建的相交信息 i = 0 # 总循环次数 j = 0 # 相交次数 for pond_feature in pond_layer: pond_geom = pond_feature.GetGeometryRef() for road_feature in road_layer: i += 1 road_geom = road_feature.GetGeometryRef() road_geom.Transform(ct) intersect = pond_geom.Intersect(road_geom) if intersect: # 以下为提取信息，可以根据需要做替换或是修改 j += 1 info = {} road_id = road_feature.GetField('road_id') name = road_feature.GetField('name') gridCode = pond_feature.GetField('DN') g_legend = self._getLegend(gridCode) g_code = self._getLevelType(g_legend) if g_legend &lt; 0.1: continue info[\"level\"] = g_legend info[\"levelType\"] = g_code info[\"name\"] = name info[\"road_id\"] = road_id infos.append(info) # print(i,j) infos_new = _reviseInfos(infos) return infos_newdef _reviseInfos(infos): # 按road_id排序 infos.sort(key=lambda x: x['road_id']) # 设置一个哨兵字典,初值为列表第一个元素 info_flag = {} info_flag = infos[0] # 定义一个新列表，作返回值 infos_new = [] infos_new.append(info_flag) # 从列表第二个元素开始 i = 1 while i &lt; len(infos): if(info_flag['road_id'] == infos[i]['road_id']): # info_max是待返回列表的最后一个元素,定义一个info_max存储road_id相等中level最大的字典元素 info_max = infos_new[-1] if(info_max['level'] &lt; infos[i]['level']): info_max = infos[i] infos_new.pop(-1) infos_new.append(info_max) else: infos_new.append(infos[i]) info_flag = infos[i] i += 1 return infos_new 图层空间参考的修改这个部分在2.5节中有应用，在这里主要是在Geometry级别的操作，在DataSet类中有Set SpatialRef函数可以实现数据集的空间参考修改。 12345678910111213141516from osgeo import ogr,osrdef modifySR(srcShpPath, targetShpPath) road_ds = self.getDataSetFromShpPath(srcShpPath) pond_ds = self.getDataSetFromShpPath(targetShpPath) road_layer = road_ds.GetLayer(0) pond_layer = pond_ds.GetLayer(0) src_sr = road_layer.GetSpatialRef() target_sr = pond_layer.GetSpatialRef() ct = osr.CoordinateTransformation(src_sr,target_sr) # Geometry级别的修改空间参考，但图层本身并没有被修改 for feature in road_layer: geom = feature.GetGeometryReF() geom.Transform(ct) 结语最终的版本还有一些可以修改的地方，不是尽善尽美的，主要因为对gdal和ogr本身的类结构不熟悉。 在使用过程中参考了很多CSDN的博客，起了个入门的作用。如果真想要深入的使用gdal和ogr这么强大的工具，应该研究官方给出的文档，关键函数都有详细的说明，查看传入参数、返回值和函数名基本上能猜个八九不离十。另外，类图的阅读非常有必要，这可以帮助快速的掌握模块的组织架构，总的来说有所收获。 看得开心！","link":"/Item/Python%E4%B8%8BGDAL%E5%92%8COGR%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"PostgreSQL常用命令记录","text":"PostgreSQL版本是12.2，psql 是 PostgreSQL 中的一个命令行交互式客户端工具，它允许你交互地键入 SQL 命令，然后把它们发送给 PostgreSQL 服务器，再显示 SQL 或命令的结果。输入的内容允许来自一个文件，此外它还提供了一些元命令和多种类似 shell 的特性来实现书写脚本，以及对大量任务的自动化工作。约定[]表示其中的内容可选，{}和|表示需选择一个候选，…表示前面的元素可以重复。中文官方链接，地址指路。 角色登录 使用用默认超级用户postgres登录，输入psql -U postgres，再输入安装时设置的超级用户密码，回车即可登入。 假设现有拥有登录权限用户为user和数据库exampledb，则登录命令为psql -U user -d exampledb，-U参数指定登录用户，-d参数指定待操作的数据库。 假设现有数据库exampledb和登录权限的用户为user，且user正好为当前操作系统用户，此时可以省略-U参数，登录命令为psql -d exampledb。 创建角色 在超级用户登录状态下，创建新角色，CREATE ROLE name，创建名称为name的角色，没有任何权限。 在超级用户登录状态下，创建新角色，CREATE USER name，创建名称为name的角色，除了登录权限外，没有任何权限，该行命令等价于CREATE ROLE name LOGIN。 在超级用户登录状态下，创建一个新超级用户，使用CREATE ROLE name SUPERUSER。一个数据库超级用户除了登录会绕开所有的权限检查，使用超级用户操作是危险的操作，推荐用受限的角色完成大部分工作。 创建超级用户的详细命令以及对应的解释如下。 1234567891011121314151617181920CREATE ROLE name [ [ WITH ] option [ ... ] ]where option： SUPERUSER | NOSUPERUSER --该角色是否是超级用户 | CREATEDB | NOCREATEDB --该角色是否可以创建数据库 | CREATEROLE | NOCREATEROLE --该角色是否可以创建新角色 | INHERIT | NOINHERIT --该角色是否继承自其他角色 | LOGIN | NOLOGIN --该角色是否具有登录权限 | REPLICATION | NOREPLICATION --决定一个角色是否为复制角色，能以复制模式（物理复制或者逻辑复制）连接到服务器以及创建或者删除复制槽，这是非常高特权，默认为否 | BYPASSRLS | NOBYPASSRLS --是否一个角色可以绕过每一条行级安全性（RLS）策略 | CONNECTION LIMIT connlimit --如果角色能登录，这指定该角色能建立多少并发连接 | [ ENCRYPTED ] PASSWORD 'password' | PASSWORD NULL --设置角色的口令（口令只对具有LOGIN属性的角色有用，如果没有指定口令，口令将被设置为空并且该用户的口令认证总是会失败。也可以用PASSWORD NULL显式地写出一个空口令。 | VALID UNTIL 'timestamp' --设置一个日期和时间，在该时间点之后角色的口令将会失效 | IN ROLE role_name [, ...] --IN ROLE子句列出一个或多个现有的角色，新角色将被立即作为新成员加入到这些角色中 | IN GROUP role_name [, ...] --是IN ROLE的废弃写法 | ROLE role_name [, ...] --ROLE子句列出一个或者多个现有角色，它们会被自动作为成员加入到新角色中 | ADMIN role_name [, ...] --略 | USER role_name [, ...] --是ROLE子句的废弃写法 | SYSID uid --向后兼容 修改角色权限在创建角色时未指定的权限，都可以在超级用户登录状态下得以修改，比如更改角色名称，更改/移除一个角色的口令，更改一个角色的失效日期，使角色具有创建数据库的权限等等。 123456789101112131415--示例--更改一个角色的口令ALTER ROLE davide WITH PASSWORD 'hu8jmn3';--移除一个角色的口令ALTER ROLE davide WITH PASSWORD NULL;--让一个角色能够创建新的数据库：ALTER ROLE davide CREATEDB;--更改一个口令的失效日期，指定该口令应该在2020年5月4日中午（在一个比UTC快 1 小时的时区）过期ALTER ROLE davide VALID UNTIL 'May 4 12:00:00 2020 +1';--更改一个角色的名称ALTER ROLE davide RENAME TO new_davide; 完整的角色权限修改语句和参数，其中大部分与创建角色时的参数相同，含义也一致，参考地址。 删除角色由于角色可以拥有数据库对象并且能持有访问其他对象的特权，删除一个角色 常常并非一次DROP ROLE就能解决。该用户所拥有的对象必须被删除或转移给其他角色。 123ALTER TABLE bobs_table OWNER TO alice;--类似的数据完全安排给其他角色后DROP ROLE davide; 数据库创建数据库 超级用户或普通角色登录状态下，CREATE DATABASE dbname，创建数据库默认为当前登录用户所有。 超级用户或普通角色登录状态下，CREATE DATABASE dbname OWNER rolename ，创建数据库并指定数据库拥有者。 删除数据库1DROP DATABASE dbname; 表创建表1DROP TABLE tablename; 删除表1DROP TABLE tablename; 其余常用命令\\l查看已经存在的数据库 \\c dbname 进入数据库 \\d查看所有表 \\d tablename查看指定表信息 \\du查看所有角色","link":"/Study/PostgreSQL%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/"},{"title":"Spring开发","text":"什么是Spring？Spring是一个支持快速开发Java EE应用程序的框架。它提供了一系列底层容器和基础设施，并可以和大量常用的开源框架无缝集成，可以说是开发Java EE应用程序的必备。Spring最早是由Rod Johnson在他的一本书里提出的用来取代EJB的轻量级框架，随后他又开始专心开发这个基础框架，并起名为Spring Framework。 随着Spring越来越受欢迎，在Spring Framework的基础上，又诞生了Spring Boot、Spring Cloud、Spring Data、Spring Security等一系列基于Spring Framework的项目。本章我们只介绍Spring Framework，即最核心的Spring框架。 Spring Framework主要包括几个模块： 支持IoC和AOP的容器 支持JDBC和ORM的数据访问模块 支持声明式事务的模块 支持基于Servlet的MVC开发 支持基于Reactive的Web开发 以及集成JMS、JavaMail、JMX、缓存等其他模块 我们会依次介绍Spring Framework的主要功能。","link":"/Study/Java/Spring/Spring%E5%BC%80%E5%8F%91/"},{"title":"My Gallery Test","text":"my gallery test 12345678&lt;div class=\"justified-gallery\"&gt;&lt;img src=\"https://cdn.jsdelivr.net/gh/WanZixin/picture@main/20210422/大象.jpg\" alt=\"Elephant\" /&gt;&lt;img src=\"https://cdn.jsdelivr.net/gh/WanZixin/picture@main/20210422/鸟.jpg\" alt=\"Birds\" /&gt;&lt;img src=\"https://cdn.jsdelivr.net/gh/WanZixin/picture@main/20210422/猫.jpg\" alt=\"Cat\" /&gt;&lt;img src=\"https://cdn.jsdelivr.net/gh/WanZixin/picture@main/20210422/狐狸.jpg\" alt=\"Fox\" /&gt;&lt;img src=\"https://cdn.jsdelivr.net/gh/WanZixin/picture@main/20210422/马.jpg\" alt=\"Horse\" /&gt;&lt;img src=\"https://cdn.jsdelivr.net/gh/WanZixin/picture@main/20210422/豹.jpg\" alt=\"Leopard\" /&gt;&lt;/div&gt;","link":"/Gallery/gallery/"},{"title":"Cheese","text":"Cheese is milk’s leap towards immortality. Before empires and royalty, before pottery and writing, before medal tools and weapons–there was cheese. As early as 8000 BCE, the earliest Neolithic farmers living in the Fertile Crescent began a legacy of cheesemaking, almost as old as civilization itself. The rise of agriculture led to domesticated sheep and goats, which ancient farmers harvested for milk. But when left in warm conditions for several hours, that fresh milk began to sour. Its lactic acids caused proteins to coagulate, binding into soft clumps. Upon discovering this strange transformation, the farmers drained the remaining liquid–later named whey–and found the yellowish globs could be eaten fresh as a soft, spreadable meal. These clumps, or curds, became the building blocks of cheese, which would eventually be aged, pressed, ripened and whizzed into a diverse cornucopia of diary delights. The discovery of cheese gave Neolithic people an enormous survival advantage. Milk was rich with essential proteins, fats and minerals. But it also contained high quantities of lactose–a suger which is difficult to process for many ancient and modern stomachs. Cheese, however, could provide all of milk’s advantages with much less lactose. And since it can be preserved and stockpiled, these essential nutrients could be eaten throughout scarce famines and long winters. Some 7th millennium BCE pottery fragments found in Turkey still contain telltale residues of the cheese and butter they held. By the end of the Bronze Age, cheese was a standard commodity in maritime trade throughout the eastern Mediterranen. In the densely populated city-states of Mesopotamia, cheese became a staple of culinary and religous life. Some of the earliest konwn writing inludes administrative records of cheese quotas, listing a variety of cheeses for different rituals and populations across Mesopotamia. Records from nearby civilizations in Turkey also reference rennet. This animal byproduct, produced in the stomachs of certain mammals, can accelerate and control coagulation. Eventually this sophisticated cheesemaking tool spread around the globe, giving way to a wide variety of new, harder cheeses. And though some conservative food cultures rejected the diary delicacy, many more embraced cheese, and quickly added their own local flavors. Nomadic Mongolians used yak’s milk to create hard, sundried wedges of Byaslag. Egyptians enjoyed goats’ milk cottage cheese, straining the whey with reed mats. In South Asia, milk was coagulated with a variety of acids, such as lemon juice, vinegar, or yogurt and then hung to dry into loafs of paneer. This soft mild cheese could be added to curries and sauces, or simply fried as a quick vegetarian dish. The Greek produced bricks of salty brined feta cheese, alongside a harder variety similar to today’s pecorino remano. This grating cheese was produced in Sicily and used in dished all across the Mesditerranean. Under Roman rule, “dry cheese” or “caseus aridus” became an essential ration for the nearly 500,000 soldiers guarding the vast borders of the Roman Empire. And when the Western Roman Empire collapsed, cheesemaking continued to evolve in the manors that dotted the midieval European countryside. In the hundreds of Benedictine monasteries scatterd across Europe, medieval monks experimented endlessly with different types of milk, cheesemaking practices, and aging processes that led to many of today’s popular cheeses. Parmesan, Roquefort, Munster and several Swiss types were all refined and perfected by these cheesemaking clergymen. In the Alps, Swiss cheesemaking was particularly successful–producing a myriad of cow’s milk cheeses. By the end of 14th century, Alpine cheese from the Gruyere regions of Switzerland had become so profitable that a neighboring state invaded the Gruyere highlands to take control of the growing cheese trade. Cheese remained popular through the Renaissance, and the Industrial Revolution took production out of the monastery and into machinery. Today, the world produces roughly 22 billion kilograms of cheese a year, shipped and consumed around the globe. But 10,000 years after its invention, local farms are still following in the footsteps of their Neolithic ancestors, hand crafting one of humanity’s oldest favorite foods.","link":"/Study/English/cheese/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/uncategorized/hello-world/"},{"title":"为什么会有回光返照","text":"本文选自知乎答主fpspaul的作品。 大脑：各单位报告目前情况 心：机能丧失99% 肝：机能丧失99% 肺：机能丧失99% 胃：机能丧失99% 脾：机能丧失99% 肾：机能丧失99% 大脑：外界援助已无法扭转局势，肾上腺素储备还有多少？ 肾上腺：肾上腺素仅余5%且无法再制造 大脑：所有肾上腺素分配给神经系统及声带肌肉，准备给外界传达最后信息，其余各单位做好停机准备，本指令不再重复","link":"/Diary/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%9C%89%E5%9B%9E%E5%85%89%E8%BF%94%E7%85%A7/"},{"title":"使用POI替换Word模板中的关键词","text":"这里的POI不是Point Of Interest兴趣点，而是针对Microsoft Documents的开源Java API，当前最新版本是4.1.2，官网指路。Word模板格式是.docx，所以重点讨论POI中的XWPFDocument。JDK版本是JDK 14。IDE使用IntelliJ IDEA 2020.1.2。 从数据库提取信息首先，连接Oracle数据库，查看待操作表的字段，拟定sql语句在查询窗口运行查看结果。然后，导入ojdbc10.jar和fastjson*-1.2.7.*jar，编写代码连接数据库并执行查询语句，组合每一个JSONObject，构造JSONArray返回。这个JSONArray中的键值对用来替换Word模板中的关键词。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081// 连接数据库，查询的代码package ManipulateDB;import com.alibaba.fastjson.JSONArray;import com.alibaba.fastjson.JSONObject;import java.sql.*;public class OracleDB { private String url = \"jdbc:oracle:thin:@ip地址:端口号:SID\"; private String username = \"your_name\"; private String password = \"your_password\"; /** * 连接oracle数据库 * @return 返回Connection实例 */ public Connection getConnect(){ Connection connect = null; try{ //建立驱动 String driverName = \"oracle.jdbc.driver.OracleDriver\"; Class.forName(driverName); //连接 connect = DriverManager.getConnection(url, username, password); }catch (Exception e){ e.printStackTrace(); } return connect; } /** * 根据TBYBH编号查询DLTB表获取信息：编号，坐落，面积，地类编码，地类名称 * @param idStr * @return 返回一个JSONArray，包含上述信息 */ public JSONArray query(String idStr) throws Exception{ JSONArray infos = new JSONArray(); try{ Connection connect = getConnect(); Statement stmt = connect.createStatement(); String sql = \"select TBYBH,ZLDWDM,ZLDWMC,SHAPE_AREA_1,SHDLBM,SHDLMC from DLTB where TBYBH= '\"+idStr+\"'\"; ResultSet rs = stmt.executeQuery(sql); while(rs.next()){ String TBYBH = rs.getString(\"TBYBH\"); String ZLDWDM = rs.getString(\"ZLDWDM\").substring(0,12);//截取前12位 int SHAPE_AREA_1 = (int)Math.floor(rs.getInt(\"SHAPE_AREA_1\"));//保留整数位 String SHDLBM = rs.getString(\"SHDLBM\"); String SHDLMC = rs.getString(\"SHDLMC\"); String country = rs.getString(\"ZLDWMC\"); String address = this.queryAddress(ZLDWDM.substring(0,6)); address += this.queryAddress(ZLDWDM.substring(0,9)); address += country; JSONObject info = new JSONObject(); info.put(\"TBYBH\",TBYBH); info.put(\"ZLDWDM\",ZLDWDM); info.put(\"SHAPE_AREA_1\",SHAPE_AREA_1); info.put(\"SHDLBM\",SHDLBM); info.put(\"SHDLMC\",SHDLMC); info.put(\"ADDRESS\",address); infos.add(info); } // 数据库查询后一定要关闭资源，不然数据库会限制连接数目，从而中断程序 connect.close(); stmt.close(); rs.close(); }catch (SQLException e){ e.printStackTrace(); } return infos; } public static void main(String[] args) throws Exception{ OracleDB orcltool = new OracleDB(); JSONArray infos = orcltool.query(\"310117120F04318\"); System.out.println(infos); } 替换模板中的关键词POI结构说明如下，更多信息查看Components，地址指路。 名称 说明 HSSF 读写Excel .xls格式文档 XSSF 读写Excel .xlsx格式文档 HWPF 读写Word.doc格式文档 XWPF 读写Word.docx格式文档 HSLF 读写PPT.ppt格式文档 XLSF 读写PPT.pptx格式文档 本文的模板文档格式是.docx，主体是一个表格，于是遍历每一个单元格，若匹配到关键词，则删除原有文本，填入自定义文本。没错，XWPFDocument没有提供replace之类的api，只能删除原有文本再填入新文本。.docx文档实际上是一个压缩包。若加载多媒体资源，比如图片时，如果没有展示出来，可以将后缀名改为.zip再解压便可以看到内部结构，查看多媒体资源是否写入成功。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 /** * 替换对应信息 * @param docx * @param info * @return */public void replaceInTable(XWPFDocument docx,JSONObject info) throws Exception{ List&lt;XWPFTable&gt; tables = docx.getTables(); XWPFTable table = tables.get(tables.size()-1); List&lt;XWPFTableRow&gt; rows; List&lt;XWPFTableCell&gt; cells; rows = table.getRows(); for (XWPFTableRow row : rows) { cells = row.getTableCells(); for (XWPFTableCell cell : cells) { String text = cell.getText(); if(text.equals(\"TBYBH\")){ cell.removeParagraph(0); cell.setText(info.getString(\"TBYBH\")); System.out.println(\"TBYBH修改成功: \"+info.getString(\"TBYBH\")); }else if(text.equals(\"ZLDWDM\")){ cell.removeParagraph(0); cell.setText(info.getString(\"ADDRESS\")); }else if(text.equals(\"SHAPE_AREA_1\")){ cell.removeParagraph(0); cell.setText(info.getString(\"SHAPE_AREA_1\")); }else if(text.equals(\"SHDLBM\")){ cell.removeParagraph(0); cell.setText(info.getString(\"SHDLBM\")); }else if (text.equals(\"SHDLMC\")){ cell.removeParagraph(0); cell.setText(info.getString(\"SHDLMC\")); }else if(text.equals(\"picture\")){ this.addPics(cell,info.getString(\"TBYBH\")); } } } } /** * 删除cell原内容，添加图片 * @param cell * @param TBYBH * @throws Exception */ public void addPics(XWPFTableCell cell,String TBYBH)throws Exception{ cell.removeParagraph(0); XWPFParagraph paragraph = cell.addParagraph(); XWPFRun run = paragraph.createRun(); run.setText(\"现场照片：\"); run.addBreak(); String picspath = this.dirpath+\"\\\\\"+TBYBH; String[] pics = new File(picspath).list(); for(int i=0;i&lt;4 &amp;&amp; i&lt;pics.length;i++){ InputStream is = new FileInputStream(picspath+\"\\\\\"+pics[i]); if(i == 0){ run.setText(\"图一：\"); }else if(i == 1){ run.setText(\"图二：\"); }else if(i == 2){ run.addBreak(); run.setText(\"图三：\"); }else if(i == 3){ run.setText(\"图四：\"); } run.addPicture(is,XWPFDocument.PICTURE_TYPE_JPEG,pics[i], Units.toEMU(140),Units.toEMU(140)); run.setText(\" \"); is.close(); } } 合并文档一个一个word文档打印起来要点击很多次，于是选择合并为一个文档。选择使用Python的win32模块，注意导入相关依赖。待合并的word文档统一放进一个文件夹，再指定目的文档地址即可。 12345678910111213141516171819202122232425# author：EduTech# link：https://zhuanlan.zhihu.com/p/100588511# 依赖：# pip install pywin32# pip install pypiwin32import win32com.client as win32import osword = win32.gencache.EnsureDispatch('Word.Application')#启动word对象应用word.Visible = Falsepath = r'D:\\software\\doc'files = []for filename in os.listdir(path): filename = os.path.join(path,filename) files.append(filename)#新建合并后的文档output = word.Documents.Add()for file in files: output.Application.Selection.InsertFile(file)#拼接文档#获取合并后文档的内容doc = output.Range(output.Content.Start, output.Content.End)output.SaveAs('D://software//doc//result.docx') #保存output.Close() 结束语整个项目从下载IDEA开始，中间经历了数据库用户名称密码错误，破解IDEA，熟悉IDEA，下载JDK14，POI依赖包的查找，doc转docx，查阅POI官方文档，查找前人博客等一系列问题，直到生成最终的文档，总共花费了三天时间。其中有一天半的时间都卡在怎么样复制旧表格添加到文档末尾，全英文的官方文档看的我头大，越看越急躁，越静不下心来。回想起花了两三个小时看完pyshp优美的官方文档，讲的细致而且举例丰富，IDLE直接可以上手尝试，哪怕是全英文也理解的非常快。下次我学习官方文档的时候，就开着IDEA建一个项目试它的API，应该效果会好很多。 IDEA的界面做的比MyEclipse好看多了。 Word文档的结构好复杂，写一份好看的word文档要花好多时间，希望将来能流行用简单又美观的Markdown文档。 欢迎联系我347335189@qq.com。 看得开心!","link":"/Item/%E4%BD%BF%E7%94%A8POI%E6%9B%BF%E6%8D%A2Word%E6%A8%A1%E6%9D%BF%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E8%AF%8D/"},{"title":"使用高德Web服务API生成shp文件","text":"高德Web服务API向开发者提供HTTP接口，开发者可通过这些接口使用各类型的地理数据服务，返回结果支持JSON和XML格式。利用行政区域查询以获取行政区域坐标串，生成shp文件。利用搜索POI中的关键字搜索获取兴趣点的id，再将id传入https://www.amap.com/detail/get/detail?id=，获得POI的详细信息，其中包括面状POI的边界坐标串，再生成shp文件。但由于反爬机制的存在，这样的方法不可以短时间提交大量请求。还有另外一个方法AOI边界查询，在高德开放平台属于高阶服务，使用前需要申请权限。本项目开源在GitHub，地址指路。 文件说明lib文件夹，包含两个xls文件，分别是高德地图的城市编码表和POI分类编码表。 result/district_shp文件夹，用于存储生成的行政区shp文件。 result/aoi_shp文件夹，用于存储生成的aoi的shp文件。 config.ini文件，配置文件，填写高德地图web服务的key；填写要爬取的poi的类别编码；填写爬取城市的adcode。 getPoiShp.py文件，生成指定专题、指定城市的aoi的shp文件。 getDistrictShp.py文件，生成行政区划shp文件。 gcj02togps84.py文件，高德地图使用的是GCJ-02坐标系，用此py文件转换为WGS-84坐标系。 GCJ-02是由中国国家测绘局（G表示Guojia国家，C表示Cehui测绘，J表示Ju局）制订的地理信息系统的坐标系统。它是一种对经纬度数据的加密算法，即加入随机的偏差。国内出版的各种地图系统（包括电子形式），必须至少采用GCJ-02对地理位置进行首次加密。 第三方依赖 requests configparser pyshp 注意事项 result/district_shp文件夹中，分别包含有中国各省份、湖北各城市、武汉行政区的个人地理数据库。result/aoi_shp文件夹中，分别包含有武汉市高等教育院校、武汉市公园、武汉市景点的个人地理数据库。这些数据是在ArcMap中构建的数据库，一并上传，供需要的读者下载使用。 每一个shp文件写入成功后，在控制台会输出提示，注意查看。 若想研究pyshp的用法，推荐查阅pyshp的github页面，其作者的文档很详细。笔者额外加了写入.prj文件的代码。","link":"/Item/%E4%BD%BF%E7%94%A8%E9%AB%98%E5%BE%B7Web%E6%9C%8D%E5%8A%A1API%E7%94%9F%E6%88%90shp%E6%96%87%E4%BB%B6/"},{"title":"如果只剩三个小时就要出现丧尸，你会干什么","text":"本文选自知乎答主laq是只仓鼠的作品。 1. 买盐， 买糖， 买辣椒， 在屋子里塞满各种调味料。 等丧尸出来了， 我就跑过去被咬一口。 然后跳进调味料里打滚。 我要把自己腌入了味儿了！ 心里是甜的， 嘴上是辣的， 脑子是咸的， 等到了那时候， 他们不过是丧尸罢了， 而我， 会成为一只美味的丧尸。 2. 渐渐的， 我在北京夏天的阳光下被逐渐烘干。 又辣又咸又甜的我， 就像一个行走的辣条一样。 或许人类就会因此得救吧？ 丧尸都是群居动物， 本来他们走路轻， 动作慢， 叫人没法察觉，防不胜防的。 而现在不一样了， 丧尸的队伍里有了我！ 当幸存者们半夜闻见了一股子辣条味， 从梦中流着哈喇子惊醒时， 他们就知道了， 是丧尸来了。 3. 又或许人类终究逃不过这宿命呢？ 随着最后一艘飞船的升空， 人类永远离开了地球。 现在地球上只有丧尸和美味的丧尸了。 丧尸们只吃活人， 没有了人类， 丧尸们大概也会饿死吧？ 我们一开始伸着手对着天空， 发出了奇怪的喊声。 祈求从天上掉下一个血肉鲜活的人来。 接着身体被微生物腐蚀了， 肌肉撑不住了， 腿和手断开了， 我们掉入了尘土里。 4. 我想， 我或许是防腐处理最好的一只丧尸了。 高盐高糖又香辣的我， 或许能站立到一切结束的最后一刻吧。 骄阳下， 我对自己竖起了大拇指。 5. 到了那时， 也许会有什么食腐的动物跑了出来。 它们挨个啃食着在地上扭动的丧尸们， 一脸的嫌弃。 从资本家到道上的大哥， 从开豪车的权贵老爷到穿着暴露的美女， 他们都一样的恶臭， 一样的难吃。 直到啃到了我， 那只小耗子眼前一亮， 对旁边的大耗子说： “妈妈妈妈，为什么这个丧尸叔叔嘴吧是甜甜的，眼是咸咸的，肉是辣辣的，心里却是苦苦的啊？” 6. 而我， 则会用我腐朽的声带喊出最后的声音： 因为他们都是原味的， 老子可是香辣的啊！ 我的声音充满了自豪， 用以掩饰自己曾为了这个世界哭过的事实。 完。","link":"/Diary/%E5%A6%82%E6%9E%9C%E5%8F%AA%E5%89%A9%E4%B8%89%E4%B8%AA%E5%B0%8F%E6%97%B6%E5%B0%B1%E8%A6%81%E5%87%BA%E7%8E%B0%E4%B8%A7%E5%B0%B8%EF%BC%8C%E4%BD%A0%E4%BC%9A%E5%B9%B2%E4%BB%80%E4%B9%88/"},{"title":"台风项目回顾","text":"本文是使用Leaflet开发某个台风项目过程中遇到的一些问题和解决方法的记录。 Leaflet中使用复选框控制图层显示Leaflet本身有图层控制的支持，但最近用Leaflet做台风的小项目，其中一个细节是使用复选框控制图层显示与否，解决方法作如下记录。在表格中的”选择”列是对应一个台风图层的复选框，通过勾选来展示和隐藏本图层。Leaflet中的图层有其所属的leaflet_id，是为了保证图层的唯一性，但要选中复选框来操作对应的图层，显然leaflet_id帮不上什么忙了。 于是，在绘制图层时给图层绑定一个自定义的layerId。 12345var id = 202002;var lyr_point = L.circle(……);var lyr_polyline = L.polyline(……);var lyr = L.featureGroup([lyr_point,lyr_polyline]);lyr.options.layerId = id; // 给图层（组）lyr绑定自定义id,在options参数里添加 js创建复选框时，给每一个复选框绑定id，值即为对应台风的id。要展示图层时，查看当前选中复选框是否选中，若选中则根据id构造url绘制；要隐藏图层时，遍历图层组，若传入的id与某一个图层的layerId匹配，则隐藏该图层。复选框绑定的函数框架如下，这样就可以实现使用复选框控制图层了。 1234567891011function showPath(id){ if(document.getElementById(id.toString()).checked){ //这里使用id构造url，利用返回的数据绘制图层 }else{ lyrGroup.eachLayer(function (layer){ if(id == layer.options.LayersID){ lyr.removeLayer(layer); } } }} 台风风圈的绘制Leaflet中绘制台风风圈，网上有一篇博客实现的比较完整，具体思路是扩展L.Polygon类，使用SVG的path绘制。但我这里调用这个扩展类绘制的风圈不稳定，在地图缩放、拖动，窗口大小的改变都会是风圈图层消失。在浏览器中查看，发现上述操作是SVG的path里的d属性清零了，百思不得其解，于是乎放弃这个方法，改使用turf.js绘制风圈。 turf.js是浏览器和Node.js环境下的高级地理空间分析的js库，里面实现了很多常见的空间分析，比如缓冲区、点在多边形内等。我这里用lineArc函数，指定中心点、半径、起始和终止角度后，它可以绘制一段圆弧，注意这里的圆弧是由计算出来的很多点拟合而成的，并不是真正的绘制了一条圆弧。其中options参数中的step默认为64，如果想要展示效果更顺滑一点，可以选择拟合点数。 分别指定东北，东南，西南，西北四个方向上的半径长度，单位默认是kilometer，生成四段圆弧，再把四段圆弧的坐标都push进一个数组，利用lineString函数生成线要素，再利用lineToPolygon函数转换为多边形。 最后，使用L.geoJSON将风圈图层添加到地图上。实现函数贴在下方。 1234567891011121314151617181920212223242526272829303132333435363738394041// p--中心点（包含四个方向的半径）,lyr--风圈图层所添加进的图层组function drawTyphoonCircle(p,lyr){ var center = turf.point([p.longitude, p.latitude]); var r_ne,r_se,r_sw,r_nw; if(p.radius7_quad &amp;&amp; p.radius7){ r_ne = p.radius7_quad.ne; r_se = p.radius7_quad.se; r_sw = p.radius7_quad.sw; r_nw = p.radius7_quad.nw; }else{ return; } var options = {number:2048}; var arc_ne = turf.lineArc(center, r_ne, 0, 89.9,options); var arc_se = turf.lineArc(center, r_se, 90, 179.9,options); var arc_sw = turf.lineArc(center, r_sw, 180, 269.9,options); var arc_nw = turf.lineArc(center, r_nw, 270, 360.1,options); var arcs = []; arcs.push(arc_ne,arc_se,arc_sw,arc_nw); var myStyle = { \"color\": \"#ccffcc\", \"weight\": 2, \"fillColor\":\"#ccffcc\" }; var typhoonCircleCoords = []; for(var i=0;i&lt;arcs.length;i++){ var rawCoords1 = arcs[i].geometry.coordinates; for(var j=0;j&lt;rawCoords1.length;j++){ typhoonCircleCoords.push(rawCoords1[j]); } } var lineAll = turf.lineString(typhoonCircleCoords); var typhoonCirclePolygon = turf.lineToPolygon(lineAll); L.geoJSON(typhoonCirclePolygon,{style:myStyle}).addTo(lyr);} 给表格添加滚动条，设置后无效overflow-y设置为true后，要设置height为一个固定的值，比如600px。 Leaflet中加载Mapbox自定义地图使用L.tileLayer创建，url template中的username是Mapbox的注册账户的用户名。在https://studio.mapbox.com/中自定义图层的分享按钮处点击，即可看到style_id和Access Token。 1234567var mymap = L.map('map').setView([20.557212,126.402354],3.5);L.tileLayer('https://api.mapbox.com/styles/v1/{username}/{style_id}/tiles/512/{z}/{x}/{y}?access_token={accessToken}',{ username:'whitedreamer', style_id:'cjn64ahui0ycg2rq72fer5a3r', accessToken:'pk.eyJ1Ijoid2hpdGVkcmVhbWVyIiwiYSI6ImNqbjN4azFjcDAwbG0zcG52aGc3M2x0M2sifQ.CYsl1oXDVr1PWgx4z6lSeg'}).addTo(mymap); 单击表格行等同于单击行内的复选框，选中图层这个功能是问题1的改进版，需要修改原有的代码逻辑。首先，删除复选框的onclick绑定的事件，然后改写showPath函数：根据图层id（等同于checkbox的id）绘制台风路径，增加hidePath函数：根据图层id隐藏台风路径；最后，编写selectARow函数，获取所点击表格行中的复选框id，根据id判断图层是否已绘制，若未绘制则绘制该图层，若已绘制则取消绘制。 注意：selectARow函数根据id判断复选框是否被选中来判断图层是否已绘制，存在逻辑矛盾，因为点击复选框是点击就绘制，取消就取消绘制；而点击表格行是若未选中则选中后绘制，若选中了则取消选中然后取消绘制。这两个逻辑相反，无法调和，故采取上述逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253function showPath(id){ lyr_num += 1;//lyr_num是图层数量 if(lyr_num &gt; 4){ alert('Layers More Than 4.'); } var url = 'https://www.readearth.com/typhoon/'+id.toString().slice(0,4)+'/'+id+'.json'; draw(url,id); $('.badge')[0].innerHTML=lyr_num;//bootstrap徽标，显示在按钮上，展示当前选中的图层数量 ids.push(id);}function hidePath(id){ lyr.eachLayer(function (layer){ if(id == layer.options.LayersID){ lyr.removeLayer(layer); lyr_num -= 1; $('.badge')[0].innerHTML=lyr_num;//更新当前显示的图层数量 } }); ids.forEach(function(item, index) { if(item == id) { ids.splice(index, 1);//删除id数组中的对应项 } });}function selectARow(){ $('.table').on('click','tr',function(){ var td_checkbox = $(this)[0].children[3];//获取checkbox所在td var checkbox = td_checkbox.children[0];//获取checkox var id = parseInt(checkbox.id);//获取checkbox的id // flag标志行对应的图层是否已绘制，若已绘制则移除，若未绘制则绘制，默认未绘制 var layers = lyr.getLayers(); var flag = 0; if(layers.length){ lyr.eachLayer(function(layer){ if(id == layer.options.LayersID){ flag = 1; } }) } if(flag){ checkbox.checked = false; hidePath(id); }else{ checkbox.checked = true; showPath(id); } })} 一个div浮在一个div之上假设div1在底下，div2浮在上方，则css应该这么写。注意：div1与div2之间是平行关系，不是嵌套关系，但div1定义要在div2之上。 12345678#div1{ position:absolute;}#div2{ positon:relative; z-index:1/*div2的z-index大于div1的z-index即可，默认div1的z-index为0*/} Echarts绘制图表的依赖从Echarts官网下载的官方案例会引入很多文件，一般的图表，像饼图、条形图、折线图等等，只需要引入一个文件，即： 12 &lt;!-- 引入echarts.js --&gt;&lt;script type='text/javascript' src='https://cdn.bootcss.com/echarts/4.2.1-rc1/echarts.min.js'&gt;&lt;/script&gt; 推荐下载下来本地引用，在线引用略慢。","link":"/Item/%E5%8F%B0%E9%A3%8E%E9%A1%B9%E7%9B%AE%E5%9B%9E%E9%A1%BE/"},{"title":"广义天气之子","text":"早在八月七号就已立秋，八月末，三伏天快结束了。每天早上仍会感觉到有些热，但也比较温和了。回想上次在上图写日记，差不多就是一个月前。 ​ 一天下午饭后遛弯的时候发现一个缝合怪： ​ “烟花”来的时候，风雨很大，郑州地铁被淹的新闻传遍全国，所以周一那天申请了在家办公。害怕后面严重了不能出门又没有外卖，还买了两天的零食。实际上，没两天台风就过去了，零食也就剩了好久。 ​ 一个周六去静安寺，刚好碰见有人路演，唱了很多周杰伦的歌和抖音上的歌。我录了好几个视频，如果文档里可以放视频的话，下次试试看。录视频的时候，手机发热很严重，一分钟的时候，就自己结束了。然后就从静安寺一路向东走，走了有三站地铁那么长，到了外滩。我发现去了好几次外滩了，下次换其他地方散心。最好能买点衣服、鞋，吃点好吃的、没吃过的东西。 ​ 七夕那天是周六，下着小雨。中午补了一大觉，下午拿着伞出去散心。从BFC（The Bund of Finance Center）外滩金融中心，沿着黄浦江走到了外白渡桥。一路上很多对幸福的情侣。雨其实有点大的，拿着伞故意不打开，反正也好久没淋过雨了，就一路散步着走刷微信步数，再顺便拍一拍照片。 ​ 有一天晚上到半夜两点还睡不着，索性不睡了，搜了《天气之子》看。半夜也还下着小雨，忽大忽小的，和片子里的场景很相像。没预料到，看到阳菜变透明，帆高不顾一切的找阳菜的时候，我也感觉很不好受。还好导演仁慈，没有以悲剧结尾，但也还是伤感。看完的时候接近四点，但也没有困意，特别想写点当时的想法，因为不及时记录下来，等后面就没有同样的心态了。坐在电脑前一个半小时，回想着电影情节，联想着过往的记忆，在雨声中，编辑了一条公开的微博。想把自己的想法公开出去，这样才能缓解，发仅自己可见的微博就没有这样的效果。其实私心在于想让cx知道一下我的精神状态。发出去后已经是五点五十了，窗帘拉严，戴着眼罩，盖着毯子就去睡了。 ​ 韩版Heart Signal第二季也看完了，总的来说蛮好看的，就是结局不太让人满意，磕的cp没有一个成的…… ​ 这一个月工作上进度尤其缓慢。首先是在申请线上缓存环境时，被存储平台和中间件的人踢皮球。虽然他们都各有各的道理，但架构和技术方案是俊儒、阳哥、丁哥一起定的，我只是执行者。还有，公司对S1服务要求很严格。比如，S1服务不能和S2服务共用缓存集群，S1服务不得依赖S2服务。所以上周周会上，特地跟华哥提了这个问题。华哥叫我留下，又详细讨论了替代方案与服务架构。周三开会，才定下了新的替代方案。 ​ 七月底的时候其实就到打针的时间了，去仁济询问医生走医保打针是什么流程，说要影像资料、结核检测、血液里各种指标的报告单，然后得挂另一个科室的号等等很多东西。就这样，打针的时间拖了近一个月，直到这周五才打完针。随访医生检测我颈部、腰背、足跟、膝盖时，跟住院时候的医生一模一样，又是软尺又是角度盘的，测完医生告诉我说：恢复的不错嘛，看这个情况很好了。门诊医生开了进口的药，看我情况很良好，给我又约了一个半月后的门诊，也就是10.15，还嘱咐我要自己学打针。 ​ 我记得以前很爱找各种图片当壁纸，还经常换。自从去年换了手机后，发现没兴趣找壁纸了，默认壁纸从来没换过，电脑也是这样。另外，希望支付宝多来点高温补贴的红包，多来点消费券，每天抢红包贼欢乐。 ​ 后面华哥发了我一份后端应届生的培养目标，后面照这个表格，用三个月的时间把上面的每一条都做到吧，就写在博客里记录着。另外，英语的学习继续保持，算法设计的学习明天开始。 ​ 三个月后11.22前来检查完成情况。","link":"/Diary/%E5%B9%BF%E4%B9%89%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%90/"},{"title":"新浪微博移动端签到数据爬取","text":"爬取网站为新浪微博移动端，相对于PC端而言网页结构简单且限制较少，签到页不需要模拟登录。以城市为单位爬取新浪微博移动端POI下的签到微博，存入csv文件。本项目开源在GitHub，地址指路。 更新，西刺代理无法再使用，请更换其他代理。 文件说明buildip.py，爬取 西刺高匿代理 构建代理池。myemail.py，爬取完毕后发邮件给自己的邮箱。wifi.py，确保网络连接不断开（网络断开后自动重连）。crawler.py，爬虫本体。config.ini，配置文件，配置项有邮箱，wifi名称，城市名称，城市编码。 爬取信息 字段 含义 user_id 用户ID user_name 昵称 gender 性别 tweets 微博文本 textLength 微博文本长度 created_at 发布时间 source 发布端 followers_count 粉丝数 follow_count 关注数 statuses_count 历史微博数 profile_url 主页链接 pic_num 图片数 pics_url 图片链接 reposts_count 转发数 comments_count 评论数 attitudes_count 态度数 思路 爬取城市页面，例如武汉市的URL为https://m.weibo.cn/p/1001018008642010000000000，获取城市下的所有POI，写入&lt;cityName&gt;.csv文件。其实这里POI的名称和id可以直接传到下一步中，而这里生成csv文件是为了本地存储POI的信息供后一步使用。 读取上一步生成的csv文件读出POI的name和id，再构造URL爬取POI下的微博信息，例如黄鹤楼URL是https://m.weibo.cn/p/index?containerid=100101B2094655D464A3FF439C。 使用方法修改config.ini文件，email_address填写自己的邮箱，wifi填写已连接过的wifi名称，cityName填写爬取的城市名称，cityId填写城市编码。 城市编码参考新浪微博开放平台的省份城市编码表，举例如下：湖北省的省份编码为42，武汉市编码为1，则武汉市的编码为4201。值得注意的一点是：北京、上海、天津、重庆四个直辖市的编码后两位均为0，不再继续向下区分，北京市：1100，例如北京海淀区对应代码为1108，爬取不到内容。 依赖的第三方库 requests pandas configparser fake_useragent","link":"/Item/%E6%96%B0%E6%B5%AA%E5%BE%AE%E5%8D%9A%E7%A7%BB%E5%8A%A8%E7%AB%AF%E7%AD%BE%E5%88%B0%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/"},{"title":"注解","text":"本节介绍Java程序的一种特殊“注释”—-注解（Annotation）。 使用注解什么是注解？注解是放在Java源码的类、方法、字段、参数前的一种特殊的“注释”。注释会被编译器直接忽略，注解则可以被编译器打包进class文件，因此，注解是一种用作标注的“元数据”。 注解的作用从JVM的角度看，注解本身对代码逻辑没有任何影响，如何使用注解完全由工具决定。 Java的注解可以分为三类： 第一类是由编译器使用的注解，例如： @Override：让编译器检查该方法是否正确实现了覆写 @Suppress：告诉编译器忽略此处代码产生的警告 这类注解不会被编译进.class文件，它们在编译后就被编译器扔掉了。 第二类是由工具处理.class文件使用的注解，比如有些工具会在加载class的时候，对class做动态修改，实现一些特殊功能。这类注解会被编译进.class文件，但加载结束后并不会存在于内存中。这类注解只被一些底层库使用，一般我们不必自己处理。 第三类是在程序运行期能够读取的注解，它们在加载后一直存在于JVM中，这也是最常用的注解。例如，一个配置了@PostConstructor的方法会在调用构造方法后被自动调用（这是Java代码读取该注解实现的功能，JVM并不会识别该注解）。 定义一个注解时，还可以定义配置参数。配置参数包括： 所有基本类型 String 枚举类型 基本类型、String、Class以及枚举的数组 因为配置参数必须是常量，所以，上述限制保证了注解在定义时就已经确定了每个参数的值。 注解的配置参数可以有默认值，缺少某个配置参数时将使用默认值。 此外，大部分注解会有一个名为value的配置参数，对此参数赋值，可以只写常量，相当于省略了value参数。 如果只写注解，相当于全部使用默认值。举个例子。 12345678910111213public class Hello { @Check(min=0, max=100, value=55) public int n; @Check(value=99) public int p; @Check(99) // @Check(value=99) public int x; @Check public int y;} @Check就是一个注解。第一个@Check(min=0, max=100, value=55)明确定义了三个参数，第二个@Check(value=99)只定义了一个value参数，它实际上和@Check(99)是完全一样的。最后一个@Check表示所有参数都使用默认值。 定义注解Java语言使用@interface语法来定义注解，它的格式如下： 12345public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";} 注解的参数类似无参数方法，可以用default设定一个默认值（强烈推荐）。最常用的参数应当命名为value。 元注解有一些注解可以修饰其他注解，这些注解就称为元注解（meta annotation）。Java标准库已经定义了一些元注解，我们只需要使用元注解，通常不需要自己去编写元注解。 @Target最常用的元注解是@Target。使用@Target可以定义Annotation，应用于以下位置。 类或接口：ElementType.TYPE 字段：ElementType.FIELD 方法：ElementType.METHOD 构造方法：ElementType.CONSTRUCTOR 方法参数：ElementType.PARAMETER 例如，定义注解@Report用在方法上，我们必须添加一个@Target(ElementType.METHOD)： 123456@Target(ElementType.METHOD)public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";} 定义注解@Report可用在方法或字段上，可以把@Target注解参数变为数组{ElementType.METHOD, ElementType.FIELD}： 1234567@Target({ ElementType.METHOD, ElementType.FIELD})public @interface Report { ...} 实际上，@Target定义的value是ElementType[]数组，只有一个元素时，可以省略数组的写法。 @Retention@Retention定义了Annotation的生命周期。 仅编译器：RetentionPolicy.SOURCE 仅class文件：RetentionPolicy.CLASS 运行期：RetentionPolicy.RUNTIME 如果@Retention不存在，则该Annotation默认为CLASS。因为通常我们自定义的Annotation都是RUNTIME，所以务必要加上@Retention(RetentionPolicy.RUNTIME)这个元注解。 123456@Retention(RetentionPolicy.RUNTIME)public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";} @Repeatable使用@Repeatable这个元注解可以定义Annotation是否可重复。这个注解应用不是特别广泛。 123456789101112@Repeatable(Reports.class)@Target(ElementType.TYPE)public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";}@Target(ElementType.TYPE)public @interface Reports { Report[] value();} 经过@Repeatable修饰后，在某个类型声明处，就可以添加多个@Report注解。 1234@Report(type=1, level=\"debug\")@Report(type=2, level=\"warning\")public class Hello {} @Inherited使用@Inherited定义子类是否可继承父类定义的Annotation。@Inherited仅针对@Target(ElementType.TYPE)类型的annotation有效，并且仅针对class的继承，对interface的继承无效。 1234567@Inherited@Target(ElementType.TYPE)public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";} 在使用时，如果一个类用到了@Report： 123@Report(type=1)public class Person {} 则它的子类默认也定义了该注解： 12public class Student extends Person {} 如何定义Annotation第一步，用@interface定义注解： 12public @interface Report {} 第二步，添加参数、默认值，把最常用的参数定义为value()，推荐所有参数都尽量设置默认值。 12345public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";} 第三步，用元注解配置注解： 1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface Report { int type() default 0; String level() default \"info\"; String value() default \"\";} 其中，必须设置@Target和@Retention，@Retention一般设置为RUNTIME，因为我们自定义的注解通常要求在运行期读取。一般情况下，不必写@Inherited和@Repeatable。 处理注解Java的注解本身对代码逻辑没有任何影响。根据@Retention的配置： SOURCE类型的注解在编译期就被丢掉了； CLASS类型的注解仅保存在class文件中，它们不会被加载进JVM； RUNTIME类型的注解会被加载进JVM，并且在运行期可以被程序读取。 如何使用注解完全由工具决定。SOURCE类型的注解主要由编译器使用，因此我们一般只使用，不编写。CLASS类型的注解主要由底层工具库使用，涉及到class的加载，一般我们很少用到。只有RUNTIME类型的注解不但要使用，还经常需要编写。 因此，我们只讨论如何读取RUNTIME类型的注解。 注解定义后也是一种class，所有的注解都继承自java.lang.annotation.Annotation，因此，读取注解需要使用反射API。 Java提供的使用反射API读取Annotation的方法包括： 判断某个注解是否存在于Class、Field、Method或Constructor： Class.isAnnotationPresent(Class) Field.isAnnotationPresent(Class) Method.isAnnotationPresent(Class) Constructor.isAnnotationPresent(Class) 例如： 12// 判断@Report是否存在于Person类:Person.class.isAnnotationPresent(Report.class); 使用反射API读取Annotation： Class.getAnnotation(Class) Field.getAnnotation(Class) Method.getAnnotation(Class) Constructor.getAnnotation(Class) 例如： 1234// 获取Person定义的@Report注解:Report report = Person.class.getAnnotation(Report.class);int type = report.type();String level = report.level(); 使用反射API读取Annotation有两种方法。 方法一是先判断Annotation是否存在，如果存在，就直接读取。 12345Class cls = Person.class;if (cls.isAnnotationPresent(Report.class)) { Report report = cls.getAnnotation(Report.class); ...} 方法二是直接读取Annotation，如果Annotation不存在，将返回null。 12345Class cls = Person.class;Report report = cls.getAnnotation(Report.class);if (report != null) { ...} 读取方法、字段和构造方法的Annotation和Class类似。但是读取方法参数的Annotation就比较麻烦一点，因为方法参数本身可以看成一个数组，而每个参数又可以定义多个注解，所以一次性获取方法参数的所有注解就必须用一个二维数组来表示。 使用注解注解如何使用，完全由程序自己决定。例如，JUint是一个测试框架，它会自动运行所有标记为@Test的方法。 我们来看一个@Range注解，我们希望用它来定义一个String字段的规则：字段长度满足@Range的参数定义。 123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface Range { int min() default 0; int max() default 255;} 在某个JavaBean中，我们可以使用该注解： 1234567public class Person { @Range(min=1, max=20) public String name; @Range(max=10) public String city;} 但是，定义了注解，本身对程序逻辑没有任何影响。我们必须自己编写代码来使用注解。这里我们编写一个Person实例的检查方法，它可以检查Person实例的String字段长度是否满足@Range的定义。 1234567891011121314151617181920void check(Person person) throws IllegalArgumentException, ReflectiveOperationException { // 遍历所有Field: for (Field field : person.getClass().getFields()) { // 获取Field定义的@Range: Range range = field.getAnnotation(Range.class); // 如果@Range存在: if (range != null) { // 获取Field的值: Object value = field.get(person); // 如果值是String: if (value instanceof String) { String s = (String) value; // 判断值是否满足@Range的min/max: if (s.length() &lt; range.min() || s.length() &gt; range.max()) { throw new IllegalArgumentException(\"Invalid field: \" + field.getName()); } } } }} 这样一来，我们通过@Range注解，配合check()方法，就可以完成Person实例的检查。注意检查逻辑完全是我们自己编写的，JVM不会自动给注解添加任何额外的逻辑。","link":"/Study/Java/%E6%B3%A8%E8%A7%A3/"},{"title":"第一篇日记","text":"37e04ec70934a816027f912f647dad2265870e635425d04807c58056dcb3fb5118e9bd9cb4b5db46dd6d1e5131a2bb894d5eb375b0cdf49b555c98756ebba769ece6de9a9ca32a24be5da05942a41696d04e51d48297fd0f0a0cbfb4c5412f62 Hey, password is required here.","link":"/Diary/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%97%A5%E8%AE%B0/"},{"title":"JDBC编程","text":"程序运行的时候，往往需要存储数据。现代应用程序最基本，也是使用最广泛的数据存储就是关系数据库。Java为关系数据库定义了一套标准的访问接口，JDBC（Java DataBase Connctivity），本章我们介绍如何在应用程序中使用JDBC。 JDBC简介程序运行时，数据都是在内存中的。当程序终止时，通常都需要将数据保存到磁盘上，无论是保存到本地磁盘，还是通过网络保存到服务器上，最终都会将数据写入磁盘文件。如何定义数据的存储格式就是一个大问题。我们可以自定义各种保存格式。但，存储和读取都需要自己实现；不能做快速查询，只有把数据全部读取到内存中才能自己遍历，有时候数据大小远远超过了内存（比如蓝光电影，40GB的数据），根本无法全部读入内存。 为了便于程序保存和读取数据，而且能通过条件快速查询到指定的数据，就出现了数据库这种专门用于集中存储和查询的软件。 NoSQL你也许还听说过NoSQL数据库，很多NoSQL宣传其速度和规模远远超过关系数据库，所以很多同学觉得有了NoSQL是否就不需要SQL了呢？千万不要被他们忽悠了，连SQL都不明白怎么可能搞明白NoSQL呢？ 数据库类别既然我们要使用关系数据库，就必须选择一个关系数据库。目前广泛使用的关系数据库也就这么几种： 付费的商用数据库： Oracle，典型的高富帅； SQL Server，微软自家产品，Windows定制专款； DB2，IBM的产品，听起来挺高端； Sybase，曾经跟微软是好基友，后来关系破裂，现在家境惨淡。 这些数据库都是不开源而且付费的，最大的好处是花了钱出了问题可以找厂家解决，不过在Web的世界里，常常需要部署成千上万的数据库服务器，当然不能把大把大把的银子扔给厂家，所以，无论是Google、Facebook，还是国内的BAT，无一例外都选择了免费的开源数据库： MySQL，大家都在用，一般错不了； PostgreSQL，学术气息有点重，其实挺不错，但知名度没有MySQL高； sqlite，嵌入式数据库，适合桌面和移动应用。 作为一个Java工程师，选择哪个免费数据库呢？当然是MySQL。因为MySQL普及率最高，出了错，可以很容易找到解决方法。而且，围绕MySQL有一大堆监控和运维的工具，安装和使用很方便。 JDBCJDBC时Java程序访问数据库的标准接口。 使用Java程序访问数据库时，Java代码并不是直接通过TCP连接去访问数据库，而是通过JDBC接口来访问，而JDBC接口则通过JDBC驱动来实现真正对数据库的访问。 例如，我们在Java代码中如果要访问MySQL，那么必须编写代码操作JDBC接口。注意到JDBC接口是Java标准库自带的，所以可以直接编译。而具体的JDBC驱动是由数据库厂商提供的，例如，MySQL的JDBC驱动由Oracle提供。因此，访问某个具体的数据库，我们只需要引入该厂商提供的JDBC驱动，就可以通过JDBC接口来访问，这样保证了Java程序编写的是一套数据库访问代码，却可以访问各种不同的数据库，因为他们都提供了标准的JDBC驱动。 从代码来看，Java标准库自带的JDBC驱动其实就是定义了一组接口，而某个具体的JDBC驱动其实就是实现了这些接口的类。 实际上，一个MySQL的JDBC的驱动就是一个jar包，它本身也是纯Java编写的。我们自己编写的代码只需要引用Java标准库提供的java.sql包下面的相关接口，由此再间接地通过MySQL驱动的jar包通过网络访问MySQL服务器，所有复杂的网络通讯都被封装到JDBC驱动中，因此，Java程序本身只需要引入一个MySQL驱动的jar包就可以正常访问MySQL服务器。 小结使用JDBC的好处是： 各数据库厂商使用相同的接口，Java代码不需要针对不同数据库分别开发； Java程序编译期仅依赖java.sql包，不依赖具体数据库的jar包； 可随时替换底层数据库，访问数据库的Java代码基本不变。 JDBC查询JDBC是一套接口规范，它在哪呢？在Java的标准库java.sql里。接口不能直接实例化，而是必须实例化其实现类，然后通过接口引用这个实例。那么，JDBC接口的实现类在哪里？我们把某个数据库实现了JDBC接口的jar包称为JDBC驱动。 例如，我们加入MySQL的驱动，添加的Maven依赖是： 123456&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 注意到这里添加的依赖的scope是runtime，因为编译Java程序不需要MySQL的这个jar包，只有在运行期才使用。如果把scope改成compile，虽然也能正常编译，但是在IDE里写程序的时候，会多出来一大堆类似com.mysql.jdbc.Connection这样的类，非常容易与Java标准库的JDBC接口混淆，所以坚决不要设置compile。 JDBC连接使用JDBC时，我们先了解什么是Connection。Connection代表一个JDBC连接，它相当于Java程序到数据库的连接（通常是TCP连接）。打开一个Connection时，需要准备URL、用户名和口令。 URL是由数据库厂商指定的格式，例如，MySQL的URL时： 1jdbc:mysql://&lt;hostname&gt;:&lt;port&gt;/&lt;db&gt;?key1=value1&amp;key2=value2 假设数据库运行在本机localhost，端口使用标准的3306，数据库名称是learnjdbc，那么URL如下： 1jdbc:mysql://localhost:3306/learnjdbc?useSSL=false&amp;characterEncoding=utf8 后面两个参数表示不使用SSL加密，使用UTF-8作为字符编码。 要获取数据库连接，使用如下代码： 123456789// JDBC连接的URL, 不同数据库有不同的格式:String JDBC_URL = \"jdbc:mysql://localhost:3306/test\";String JDBC_USER = \"root\";String JDBC_PASSWORD = \"password\";// 获取连接:Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD);// TODO: 访问数据库...// 关闭连接:conn.close(); 核心代码时DriverManager提供的静态方法getConnection()。DriverManager会自动扫描classpath，找到所有的JDBC驱动，然后根据我们传入的URL自动挑选一个合适的驱动。 因为JDBC连接是一种昂贵的资源，使用后要及时释放。使用try(resource)来自动释放JDBC连接是一个好方法： 123try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { ...} JDBC查询获取到JDBC连接后，下一步我们就可以查询数据库了。查询数据库分以下几步： 通过Connection提供的createStatement()方法创建一个Statement对象，用于执行一个查询 执行Statement对象提供的executeQuery(\"SELECT * FROM students\")并传入SQL语句，执行查询并获得返回的结果集，使用ResultSet来引用这个结果集 反复调用ResultSet的next()方法并读取每一行结果 完整查询代码如下： 123456789101112try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { try (Statement stmt = conn.createStatement()) { try (ResultSet rs = stmt.executeQuery(\"SELECT id, grade, name, gender FROM students WHERE gender=1\")) { while (rs.next()) { long id = rs.getLong(1); // 注意：索引从1开始 long grade = rs.getLong(2); String name = rs.getString(3); int gender = rs.getInt(4); } } }} Statement和ResultSet都是需要关闭的资源，因此嵌套使用try(resource)确保及时关闭。 rs.next()用于判断是否有下一行记录，如果有，会自动把当前行移动到下一行（一开始获得的ResultSet是当前行不是第一行）。 ResultSet获取列时，索引从1开始而不是0。 必须根据SELECT的列的对应位置来调用getLong(1)，getString(2)这些方法，否则对应位置的数据类型不对，将报错。 SQL注入使用Statement拼接字符串非常容易引发SQL注入的问题，这是因为SQL参数往往是通过方法参数传入的。 我们来看一个例子：假设用户登录的验证方法如下： 12345User login(String name, String pass) { ... stmt.executeQuery(\"SELECT * FROM user WHERE login='\" + name + \"' AND pass='\" + pass + \"'\"); ...} 其中，参数name和pass通常都是Web页面输入后由程序接收到的。 如果用户的输入是程序期待的值，就可以拼出正确的SQL。例如：name = \"bob\"，pass = \"1234\"： 1SELECT * FROM user WHERE login='bob' AND pass='1234' 但是，如果用户的输入是一个精心构造的字符串，就可以拼出意想不到的SQL，这个SQL也是正确的，但它查询的条件不是程序设计的意图。例如：name = \"bob' OR pass=\", pass = \" OR pass='\"： 1SELECT * FROM user WHERE login='bob' OR pass=' AND pass=' OR pass='' 这个SQL语句执行的时候，根本不用判断口令是否正确，这样一来，登录就形同虚设。 要避免SQL注入攻击，一个办法是针对所有字符串参数进行转义，但是转义很麻烦，而且需要在任何使用SQL的地方增加转义代码。 还有一个办法就是使用PreparedStatement。使用PreparedStatement可以完全避免SQL注入的问题，因为PreparedStatement始终使用?作为占位符，并且把数据连同SQL本身传给数据库，这样可以保证每次传给数据库的SQL语句是相同的，只是占位符的数据不同，还能高效利用数据库本身对查询的缓存。上述登录SQL如果用PreparedStatement可以改写如下： 12345678User login(String name, String pass) { ... String sql = \"SELECT * FROM user WHERE login=? AND pass=?\"; PreparedStatement ps = conn.prepareStatement(sql); ps.setObject(1, name); ps.setObject(2, pass); ...} 所以，PreparedStatement比Statement更安全，而且更快。 使用Java操作数据库时，必须使用PreparedStatement，严禁任何通过参数拼接字符串的代码 我们把上面使用Statement的代码改为使用PreparedStatement： 1234567891011121314try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { try (PreparedStatement ps = conn.prepareStatement(\"SELECT id, grade, name, gender FROM students WHERE gender=? AND grade=?\")) { ps.setObject(1, \"M\"); // 注意：索引从1开始 ps.setObject(2, 3); try (ResultSet rs = ps.executeQuery()) { while (rs.next()) { long id = rs.getLong(\"id\"); long grade = rs.getLong(\"grade\"); String name = rs.getString(\"name\"); String gender = rs.getString(\"gender\"); } } }} 使用PreparedStatement和Statement稍有不同，必须首先调用setObject()设置每个占位符?的值，最后获取的仍然是ResultSet对象。 另外注意到从结果集读取列时，使用String类型的列名比索引要易读，而且不易出错。 注意到JDBC查询的返回值总是ResultSet，即使我们写这样的聚合查询SELECT SUM(score) FROM ...，也需要按结果集读取： 1234ResultSet rs = ...if (rs.next()) { double sum = rs.getDouble(1);} 数据类型有的童鞋可能注意到了，使用JDBC的时候，我们需要在Java数据类型和SQL数据类型之间进行转换。JDBC在java.sql.Types定义了一组常量来表示如何映射SQL数据类型，但是平时我们使用的类型通常也就以下几种： SQL数据类型 Java数据类型 BIT, BOOL boolean INTEGER int BIGINT long REAL float FLOAT, DOUBLE double CHAR, VARCHAR String DECIMAL BigDecimal DATE java.sql.Date, LocalDate TIME java.sql.Time, LocalTime 注意：只有最新的JDBC驱动才支持LocalDate和LocalTime。 JDBC更新数据库操作总结起来就4个字：增删改查，行话叫CRUD：Create，Retrieve，Update和Delete。查就是查询，上一节介绍过了，就是使用PreparedStatement进行各种SELECT，然后处理结果集。现在我们来看看如何使用JDBC进行增删改查。 插入插入操作是INSERT，即插入一条记录。通过JDBC插入，本质上也是用PreparedStatement执行一条SQL语句，不过最后不是执行executeQuery()，而是executeUpdate()。示例代码如下： 12345678910try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { try (PreparedStatement ps = conn.prepareStatement( \"INSERT INTO students (id, grade, name, gender) VALUES (?,?,?,?)\")) { ps.setObject(1, 999); // 注意：索引从1开始 ps.setObject(2, 1); // grade ps.setObject(3, \"Bob\"); // name ps.setObject(4, \"M\"); // gender int n = ps.executeUpdate(); // 1 }} 设置参数与查询是一样的，有几个?占位符就必须设置对应的参数。虽然Statement也可以执行插入操作，但我们仍然要严格遵循绝不能手动拼SQL字符串的原则，以避免安全漏洞。 当成功执行executeUpdate()后，返回值是int，表示插入的记录数量。此处总是1，因为只插入了一条记录。 插入并获取主键如果数据库的表设置了自增主键，那么执行INSERT语句时，并不需要指定主键，数据库会自动分配主键。对于使用自增主键的程序，有个额外的步骤，就是如何获取插入后自增主键的值。 要获取自增主键，不能先插入，再查询。因为两条SQL执行期间可能有别的程序也插入了同一个表。获取自增主键的正确写法是，在创建PreparedStatement的时候，指定一个RETURN_GENERATED_KEYS标志位，表示JDBC驱动必须返回插入的自增主键。示例代码如下： 123456789101112131415try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { try (PreparedStatement ps = conn.prepareStatement( \"INSERT INTO students (grade, name, gender) VALUES (?,?,?)\", Statement.RETURN_GENERATED_KEYS)) { ps.setObject(1, 1); // grade ps.setObject(2, \"Bob\"); // name ps.setObject(3, \"M\"); // gender int n = ps.executeUpdate(); // 1 try (ResultSet rs = ps.getGeneratedKeys()) { if (rs.next()) { long id = rs.getLong(1); // 注意：索引从1开始 } } }} 注意两点： 一是调用prepareStatement()时，第二个参数必须传入常量Statement.RETURN_GENERATED_KEYS，否则JDBC驱动不会返回自增主键； 二是执行executeUpdate()方法后，必须调用getGeneratedKeys()获取一个ResultSet对象，这个对象包含了数据库自动生成的主键的值，读取该对象的每一行来获取自增主键的值。如果一次插入多条记录，那么这个ResultSet对象就会有多行返回值。如果插入时有多列自增，那么ResultSet对象的每一行都会对应多个自增值（自增列不一定必须是主键）。 更新更新操作是UPDATE语句，它可以一次更新若干列的记录。 1234567try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { try (PreparedStatement ps = conn.prepareStatement(\"UPDATE students SET name=? WHERE id=?\")) { ps.setObject(1, \"Bob\"); // 注意：索引从1开始 ps.setObject(2, 999); int n = ps.executeUpdate(); // 返回更新的行数 }} executeUpdate()返回数据库实际更新的行数。返回结果可能是正数，也可能是0（表示没有任何记录更新）。 删除删除操作是DELETE语句，它可以一次删除若干列。 123456try (Connection conn = DriverManager.getConnection(JDBC_URL, JDBC_USER, JDBC_PASSWORD)) { try (PreparedStatement ps = conn.prepareStatement(\"DELETE FROM students WHERE id=?\")) { ps.setObject(1, 999); // 注意：索引从1开始 int n = ps.executeUpdate(); // 删除的行数 }} 小结使用JDBC执行INSERT，UPDATE和DELETE都可视为更新操作。更新操作使用PreparedStatement的executeUpdate()进行，返回影响的行数。 JDBC事务数据库事务（Transaction）是由若干SQL语句构成的一个操作序列。有点类似于Java的synchronized同步。数据库系统保证一个事务中的所有SQL要么全部执行成功，要么全部不执行，即数据库事务具有ACID特性： Atomicity：原子性 Consistency：一致性 Isolation：隔离性 Durability：持久性 数据库事务可以并发执行，而数据库系统从效率考虑，对事务定义了不同的隔离级别。SQL标准定义了4种隔离级别，分别对应可能出现的数据不一致的情况： Isolation Level 脏读（Dirty Read） 不可重复读（Non Repeatable Read） 幻读（Phantom Read） Read Uncommitted Yes Yes Yes Read Committed - Yes Yes Repeatable Read - - Yes Serializable - - - 对应用程序来说，数据库事务非常重要，很多运行着关键任务的应用程序，都必须依赖数据库事务保证程序的结果正常。 要在JDBC中执行事务，本质上就是如何把多条SQL包裹在一个数据库事务中执行。我们来看JDBC的事务代码： 123456789101112131415Connection conn = openConnection();try { // 关闭自动提交: conn.setAutoCommit(false); // 执行多条SQL语句: insert(); update(); delete(); // 提交事务: conn.commit();} catch (SQLException e) { // 回滚事务: conn.rollback();} finally { conn.setAutoCommit(true); conn.close();} 其中，开启事务的关键代码是conn.setAutoCommit(false)，表示关闭自动提交。提交事务的代码在执行完若干条SQL语句后，调用conn.commit()。注意，事务不总能成功，如果事务提交失败，会抛出SQL异常（也可能在执行SQL语句的时候就抛出了），此时我们必须捕获并调用conn.rollback()回滚事务。最后，在finally中通过conn.setAutoCommit(true)把Connection对象的状态恢复到初始值。 实际上，默认情况下，我们获取到Connection连接后，总是处于自动提交模式，也就是每执行一条SQL都是作为事务自动执行的，这也是为什么我们前面的更新操作总能成功的原因：因为默认有这种隐式事务。只要关闭了Connection的autoCommit，就可以在一个事务中执行多条语句，事务以commit()方法结束。 如果要设定事务的隔离级别，可以使用如下代码： 12// 设定隔离级别为READ COMMITTED:conn.setTransactionIsolation(Connection.TRANSACTION_READ_COMMITTED); 如果没有调用上述方法，那么会使用数据库的默认隔离级别。MySQL的默认隔离级别是REPEATABLE_READ。 JDBC Batch使用JDBC操作数据库的时候，经常会执行一些批量操作。 很多情况下，执行JDBC时，只有占位符参数不同，所以SQL实际上是一样的。通过一个循环来执行每个PreparedStatement虽然可行，但是性能很低。SQL数据库对SQL语句相同，但只有参数不同的若干语句可以作为batch执行，即批量执行，这种操作有特别的优化，速度远远快于循环执行每个SQL。 在JDBC代码中，我们可以利用SQL这一特性，把同一个SQL但参数不同的若干次操作合并为一个batch执行。我们以批量插入为例： 123456789101112131415try (PreparedStatement ps = conn.prepareStatement(\"INSERT INTO students (name, gender, grade, score) VALUES (?, ?, ?, ?)\")) { // 对同一个PreparedStatement反复设置参数并调用addBatch(): for (Student s : students) { ps.setString(1, s.name); ps.setBoolean(2, s.gender); ps.setInt(3, s.grade); ps.setInt(4, s.score); ps.addBatch(); // 添加到batch } // 执行batch: int[] ns = ps.executeBatch(); for (int n : ns) { System.out.println(n + \" inserted.\"); // batch中每个SQL执行的结果数量 }} 执行batch和执行一个SQL不同点在于，需要对同一个PreparedStatement反复设置参数并调用addBatch()，这样就相当于给一个SQL加上了多组参数，相当于变成了“多行”SQL。 第二个点是，调用的不是executeUpdate()，而是executeBatch()，因为我们设置了多组参数，相应地，返回结果也是多个int值，因此返回类型是int[]，循环int[]数据即可获得每组参数执行后影响的结果数量。 JDBC连接池我们在多线程一章讲到过，创建线程是一个很昂贵的操作，如果有大量的小任务要执行，并且频繁地创建和销毁线程，实际上会消耗大量的系统资源，往往创建和销毁线程所耗费的时间比执行任务的时间还长。所以，为了提高效率，可以使用线程池。 类似地，在执行JDBC的增删改查的操作时，如果每一次操作都来打开一次连接，操作，关闭连接，那么创建和销毁JDBC连接的开销就太大了。为了避免频繁地创建和销毁JDBC连接，可以通过使用连接池（Connection Pool）复用已创建好的连接。 JDBC连接池有一个标准的接口javax.sql.DataSource，注意这个类位于Java标准库中，但仅仅是接口。要使用JDBC连接池，我们必须选择一个JDBC连接池的实现。常用的JDBC连接池有： HikariCP C3P0 BoneCP Druid 目前使用最广泛的是HikariCP。我们以HikariCP为例，先添加依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;2.7.1&lt;/version&gt;&lt;/dependency&gt; 紧接着，创建一个DataSource实例，这个实例就是连接池： 12345678HikariConfig config = new HikariConfig();config.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\");config.setUsername(\"root\");config.setPassword(\"password\");config.addDataSourceProperty(\"connectionTimeout\", \"1000\"); // 连接超时：1秒config.addDataSourceProperty(\"idleTimeout\", \"60000\"); // 空闲超时：60秒config.addDataSourceProperty(\"maximumPoolSize\", \"10\"); // 最大连接数：10DataSource ds = new HikariDataSource(config); 注意，创建DataSource也是非常昂贵的操作，所以通常DataSource实例总是作为一个全局变量存储，并贯穿整个应用程序的生命周期。 有了连接池后，我们如何使用它呢？和之前的代码类似，只是获取Connection时，把DriverManager.getConnection()改为ds.getConnection()： 123try (Connection conn = ds.getConnection()) { // 在此获取连接 ...} // 在此“关闭”连接 通过连接池获取连接时，并不需要指定JDBC的相关URL、用户名、口令等信息，因为这些信息已经存储在连接池内部了。一开始，连接池内部并没有连接，所以，第一次调用ds.getConnection()，会使连接池内部先创建一个Connection，再返回给客户端使用。当我们调用conn.close()时，并不是真正的关闭连接，而是释放到连接池中，以便下次获取连接时能直接返回。 因此，连接池内部维护了若干Connection实例，如果调用ds.getConnection()，就选择一个空闲连接，并标记它为“正在使用”然后返回。如果对Connection调用close()，那么就把连接再次标记为“空闲”从而等待下次调用。这样一来，我们就通过连接池维护了少量连接，但可以频繁地执行大量的SQL语句。 通常，连接池提供了大量的参数可以配置，例如，维护的最小、最大活动连接数，指定一个连接在空闲一段时间后自动关闭等，需要根据应用程序的负载合理地配置这些参数。此外，大多数连接池都提供了详细的实时状态以便进行监控。","link":"/Study/Java/JDBC%E7%BC%96%E7%A8%8B/"},{"title":"Java快速入门","text":"为什么Java应用最广泛？从互联网到企业平台，Java是应用最广泛的编程语言，原因在于： Java是基于JVM虚拟机的跨平台语言，一次编写，到处运行； Java程序易于编写，而且有内置垃圾收集，不必考虑内存管理； Java虚拟机拥有工业级的稳定性和高度优化的性能，且经过了长时期的考验； Java拥有最广泛的开源社区支持，各种高质量组件随时可用。 Java语言常年霸占着三大市场： 互联网和企业应用，这是Java EE的长期优势和市场地位； 大数据平台，主要有Hadoop、Spark、Flink等，他们都是Java或Scala（一种运行于JVM的编程语言）开发的； Android移动平台。 这意味着Java拥有最广泛的就业市场。本章内容主要是介绍Java程序的基础知识。 1.Java简介Java介于编译型语言和解释型语言之间。 编译型语言如C、C++，代码是直接编译成机器码执行，但是不同的平台（x86、ARM等）CPU的指令集不同，因此，需要编译出每一种平台的对应机器码。解释型语言如Python、Ruby没有这个问题，可以由解释器直接加载源码然后运行，代价是运行效率太低。而Java是将代码编译为一种字节码，它类似于抽象的CPU指令，然后针对不同的平台编写虚拟机，不同平台的虚拟机负责加载字节码并执行，这样九实现了”一次编写，到处运行“。从实践的角度来看，JVM的兼容性做的非常好，低版本的Java字节码完全可以正常运行在高版本的JVM上。 随着Java的发展，SUN给Java分出了三个不同的版本。 Java SE：Standard Edition Java EE：Enterprise Edition Java ME：Micro Edition 123456789┌───────────────────────────┐│Java EE ││ ┌────────────────────┐ ││ │Java SE │ ││ │ ┌─────────────┐ │ ││ │ │ Java ME │ │ ││ │ └─────────────┘ │ ││ └────────────────────┘ │└───────────────────────────┘ 这三者又是什么关系呢？简单来说，Java SE就是标准版，包含标准的JVM和标准库，而Java EE是企业版，它在Java SE基础上添加了大量的API和库，以方便开发Web应用、数据库、消息服务等，Java EE使用的虚拟机和Java SE完全相同。 Java ME是一个针对嵌入式设备的”瘦身版“，Java SE的标准库无法在Java ME上使用，Java ME的虚拟机也是”瘦身版“。 毫无疑问，Java SE是整个Java平台的核心，而Java EE是进一步学习Web应用必须的。我们熟悉的Spring框架就是Java EE开源生态的一部分。而Java ME并没有流行起来，反而是Android成为了移动平台的标准之一。 因此推荐的Java学习路线如下： 首先要学习Java SE，掌握Java语言本身、Java核心开发技术以及Java标准库的使用。 如果继续学习Java EE，那么Spring框架、数据库开发、分布式架构就是需要学习的。 如果要学习大数据开发，那么Hadoop、Spark、Flink这些大数据平台就是需要学习的，他们都基于Java或Scala开发。 如果想要学习移动开发，那么就深入Android平台，掌握Android App开发。 无论怎么选，Java SE的核心是基础。 初学者学Java，经常听到JDK、JRE这些名词，它们到底是啥？ JDK：Java Development Kit JRE：Java Runtime Environment 简单地说，JRE就是运行Java字节码的虚拟机。但是，如果只有Java源码，要编译成Java字节码，就需要JDK，因为JDK除了包含JRE，还提供了编译器、调试器等开发工具。要学习Java开发，当然需要安装JDK了。 那JSR、JCP……又是啥？ JSR规范：Java Specification Request JCP组织：Java Community Process 为了保证Java语言的规范性，SUN公司搞了一个JSR规范，凡是想给Java平台加一个功能，比如说访问数据库的功能，大家要先创建一个JSR规范，定义好接口，这样，各个数据库厂商都按照规范写出Java驱动程序，开发者就不用担心自己写的数据库代码在MySQL上能跑，却不能跑在PostgreSQL上。所以JSR是一系列的规范，从JVM的内存模型到Web程序接口，全部都标准化了。而负责审核JSR的组织就是JCP。 一个JSR规范发布时，为了让大家有个参考，还要同时发布一个“参考实现”，以及一个“兼容性测试套件”： RI：Reference Implementation TCK：Technology Compatibility Kit 比如有人提议要搞一个基于Java开发的消息服务器，这个提议很好啊，但是光有提议还不行，得贴出真正能跑的代码，这就是RI。如果有其他人也想开发这样一个消息服务器，如何保证这些消息服务器对开发者来说接口、功能都是相同的？所以还得提供TCK。 通常来说，RI只是一个“能跑”的正确的代码，它不追求速度，所以，如果真正要选择一个Java的消息服务器，一般是没人用RI的，大家都会选择一个有竞争力的商用或开源产品。 2.Java程序基础2.1Java程序基本结构Java是面向对象的语言，一个程序的基本单位是class。 123public class Hello{//类开始 ...}//类结束 类名的要求：类名必须以英文字母开头，后接字母、数字或下划线的组合；习惯上以大写字母开头。 public是访问修饰符，表示该类是公开的。 在class内部可以定义若干方法（method）。 12345public class Hello { public static void main(String[] args) { // 方法名是main ... } // 方法定义结束} 这里的方法名是main，返回值是void，表示没有任何返回值。我们注意到public除了可以修饰类，也可以修饰方法。关键字static是另一个访问修饰符，表示这是一个静态方法。方法名也有命名规则，和类的命名规则一样，只不过首字母小写。 Java入口程序规定的方法必须是静态方法，方法名必须为main，括号内的参数必须是String数组。 在方法内部，语句才是真正执行的代码。Java的每一行语句必须以分号结束。在Java程序中，注释是给人阅读的文本，编译器会自动忽略注释。 Java有三种注释，第一种是单行注释，以双斜线开头，直到这一行的行尾结束。 1//这是单行注释 第二种是多行注释，以/*开始，以*/结束，可以有多行，类似这样： 12345/*这是注释blablabla...这也是注释*/ 还有一种特殊的多行注释，以/**开始，以*/结束，每行以*开头，类似这样： 12345/** * 可以用来自动创建文档的注释 * * @auther WanZixin */ 这种特殊的多行注释需要写在类和方法的定义处，可以用于自动创建文档。 2.2变量和数据类型在Java中，变量分为两种：基本类型的变量和引用类型的变量。在Java中，变量必须先定义后使用，在定义变量的时候，可以给它一个初始值。变量的一个重要特点是可以重新赋值。变量不但可以重新赋值，还可以赋值给其他变量。 变量基本数据类型是CPU可以直接进行运算的类型。Java定义了以下几种基本数据类型： 整数类型：byte，short，int，long 浮点数类型：float，double 字符类型：char 布尔类型：boolean 不同的数据类型占用的字节数不一样。我们看一下Java基本数据类型占用的字节数： 123456789101112131415161718192021 ┌───┐ byte │ │ └───┘ ┌───┬───┐ short │ │ │ └───┴───┘ ┌───┬───┬───┬───┐ int │ │ │ │ │ └───┴───┴───┴───┘ ┌───┬───┬───┬───┬───┬───┬───┬───┐ long │ │ │ │ │ │ │ │ │ └───┴───┴───┴───┴───┴───┴───┴───┘ ┌───┬───┬───┬───┐ float │ │ │ │ │ └───┴───┴───┴───┘ ┌───┬───┬───┬───┬───┬───┬───┬───┐double │ │ │ │ │ │ │ │ │ └───┴───┴───┴───┴───┴───┴───┴───┘ ┌───┬───┐ char │ │ │ └───┴───┘ 对于整型类型，Java只定义了带符号的整型，因此，最高位的bit表示符号位（0表示正数，1表示负数）。 浮点类型的数就是小数，因为小数用科学计数法表示的时候，小数点是可以“浮动”的。对于float类型，需要加上f后缀。浮点数可表示的范围非常大，float类型可最大表示3.4x10^38，而double类型可最大表示1.79x10^308。 布尔类型boolean只有true和false两个值，布尔类型总是关系运算的计算结果。 字符类型char表示一个字符。Java的char类型除了可表示标准的ASCII外，还可以表示一个Unicode字符。注意char类型使用单引号'，且仅有一个字符，要和双引号\"的字符串类型区分开。 除了上述基本类型的变量，剩下的都是引用类型，最常见的引用类型就是String字符串。引用类型的变量类似于C语言的指针，它内部存储一个“地址”，指向某个对象在内存的位置。 常量定义变量的时候，如果加上final修饰符，这个变量就成为了常量。常量在定义时进行初始化后就不可再次赋值，再次复制会导致编译错误。 1234final double PI = 3.14; // PI是一个常量double r = 5.0;double area = PI * r * r;PI = 300; // compile error! 根据习惯，常量名通常全部大写。常量的作用是用有意义的变量名来避免魔术数字，比如不要在代码中写3.14，而是定义一个常量。如果将来需要提高计算精度，我们只需要在常量的定义处修改，例如，改成3.1416，而不必在所有地方替换3.14。 var关键字有些时候，类型的名字太长，写起来比较麻烦。这个时候，如果想省略变量类型，可以使用var关键字。 1234//StringBuilder sb = new StringBuilder();var sb = new StringBuilder();//编译器会根据赋值语句自动推断出sb的类型，会更换成：//StringBuilder sb = new StringBuilder(); 变量的作用域范围在Java中，多行语句用{ }括起来。很多控制语句，例如条件判断和循环，都以{ }作为它们自身的范围。只要正确地嵌套这些{ }，编译器就能识别出语句块的开始和结束。而在语句块中定义的变量，它有一个作用域，就是从定义处开始，到语句块结束。超出了作用域引用这些变量，编译器会报错。 定义变量时，要遵循作用域最小化原则，尽量将变量定义在尽可能小的作用域，并且，不要重复使用变量名。 2.3整数运算Java的整数运算遵循四则运算规则，可以使用任意嵌套的小括号。四则运算规则和初等数学一致。整数的数值表示不但是精确的，而且整数运算永远是精确的，即使是除法也是精确的，因为两个整数相除只能得到结果的整数部分。求余运算使用%。特别注意：整数的除法对于除数为0时运行时将报错，但编译不会报错。 要特别注意，整数由于存在范围限制，如果计算结果超出了范围，就会产生溢出，而溢出不会出错，却会得到一个奇怪的结果。 还有一种简写的运算符，即+=，-=，*=，/=。 自增/自减， ++运算和--运算。注意++写在前面和后面计算结果是不同的，++n表示先加1再引用n，n++表示先引用n再加1。不建议把++运算混入到常规运算中，容易自己把自己搞懵了。 移位运算。可以对整数进行移位运算。对整数7左移1位将得到整数14，左移两位将得到整数28。 如果对一个负数进行右移，最高位的1不动，结果仍然是一个负数。还有一种无符号的右移运算，使用&gt;&gt;&gt;，它的特点是不管符号位，右移后高位总是补0，因此，对一个负数进行&gt;&gt;&gt;右移，它会变成正数，原因是最高位的1变成了0。 位运算。位运算是按位进行与、或、非和异或的运算。 类型自动提升。在运算过程中，如果参与运算的两个数类型不一致，那么计算结果为较大类型的整型。 也可以将结果强制转型，即将大范围的整数转型为小范围的整数。强制转型使用(类型)。 例如，将int强制转型为short。要注意，超出范围的强制转型会得到错误的结果，原因是转型时，int的两个高位字节直接被扔掉，仅保留了低位的两个字节。 2.4浮点数运算浮点数运算和整数运算相比，只能进行加减乘除这些数值计算，不能做位运算和移位运算。在计算机中，浮点数虽然表示的范围大，但是，浮点数有个非常重要的特点，就是浮点数常常无法精确表示。 因为浮点数常常无法精确表示，因此，浮点数运算会产生误差。由于浮点数存在运算误差，所以比较两个浮点数是否相等常常会出现错误的结果。正确的比较方法是判断两个浮点数之差的绝对值是否小于一个很小的数。浮点数在内存的表示方法和整数比更加复杂。Java的浮点数完全遵循IEEE-754标准，这也是绝大多数计算机平台都支持的浮点数标准表示方法。 类型提升。如果参与运算的两个数其中一个是整型，那么整型可以自动提升到浮点型。 溢出。整数运算在除数为0时会报错，而浮点数运算在除数为0时，不会报错，但会返回几个特殊值： NaN表示Not a Number Infinity表示无穷大 -Infinity表示负无穷大 强制转型。可以将浮点数强制转型为整数。在转型时，浮点数的小数部分会被丢掉。如果转型后超过了整型能表示的最大范围，将返回整型的最大值。 2.5布尔运算对于布尔类型boolean，永远只有true和false两个值。 布尔运算是一种关系运算，包括以下几类： 比较运算符：&gt;，&gt;=，&lt;，&lt;=，==，!= 与运算 &amp;&amp; 或运算 || 非运算 ! 关系运算符的优先级从高到低依次是： ! &gt;，&gt;=，&lt;，&lt;= ==，!= &amp;&amp; || 布尔运算的一个重要特点是短路运算。如果一个布尔运算的表达式能提前确定结果，则后续的计算不再执行，直接返回结果。 Java还提供一个三元运算符b ? x : y，它根据第一个布尔表达式的结果，分别返回后续两个表达式之一的计算结果。注意到三元运算b ? x : y会首先计算b，如果b为true，则只计算x，否则，只计算y。此外，x和y的类型必须相同，因为返回值不是boolean，而是x和y之一。 2.6字符和字符串在Java中，字符和字符串是两个不同的类型。 字符类型char是基本数据类型，它是character的缩写。一个char保存一个Unicode字符。因为Java在内存中总是使用Unicode表示字符，所以，一个英文字符和一个中文字符都用一个char类型表示，它们都占用两个字节。要显示一个字符的Unicode编码，只需将char类型直接赋值给int类型即可。还可以直接用转义字符\\u+Unicode编码来表示一个字符。 和char类型不同，字符串类型String是引用类型，我们用双引号\"...\"表示字符串。一个字符串可以存储0个到任意个字符。 常见的转义字符包括： \\\" 表示字符\" \\' 表示字符' \\\\ 表示字符\\ \\n 表示换行符 \\r 表示回车符 \\t 表示Tab \\u#### 表示一个Unicode编码的字符 Java编译器对字符串做了特殊照顾，可以用+连接任意字符串和其他数据类型，极大的方便了字符串的处理。如果用+连接字符串和其他数据类型，会将其他数据类型先自动转型为字符串，再连接。 如果我们要表示多行字符串，使用+连接会非常不方便。从Java 13开始，可以用\"\"\"...\"\"\"表示多行字符串。 123456String s = \"\"\" SELECT * FROM users WHERE id &gt; 100 ORDER BY name DESC \"\"\"; Java字符串还有个重要特点是不可变特性，是指字符串内容不可变。JVM在执行String s = \"hello\";时，先创建字符串\"hello\"，然后把字符串变量s指向它。在重新给s复制时，s = \"world\";时，同样的，JVM先创建字符串\"world\"，再把s指向它。原来的字符串\"hello\"还在，只是我们没法通过变量s访问它了。 引用类型的变量可以指向一个空值null，它表示不存在，即该变量不指向任何对象。 2.7数组类型数组是同一数据类型的集合。数组元素可以是值类型或引用类型，但数组本身是引用类型。 定义一个数组类型的变量，使用数组类型“类型[]”，例如，int[]。和单个基本类型变量不同，数组变量初始化必须使用new int[5]表示创建一个可容纳5个int元素的数组。 Java的数组有两个特点： 数组所有元素初始化为默认值，整形是0，浮点型是0.0，布尔型是false。 数组一旦创建，大小就不可改变。 要访问数组中的某一个元素，需要使用索引。数组索引从0开始。可以修改数组中的某一个元素，使用赋值语句。用数组变量.length获取数组大小。数组是索引类型，在使用索引访问数组元素时，如果索引超出范围，运行时会报错。也可以在定义数组时直接指定初始化的元素，这样就不必写出数组大小，而是由编译器自动推算数组大小。 123int[] ns = new int[] { 68, 79, 91, 85, 62 };//还可以进一步简写成int[] ns = { 68, 79, 91, 85, 62 }; 3.流程控制3.1输入和输出输入我们总是使用System.out.println()来向屏幕输出一些内容。println是print line的缩写，表示输出并换行。如果不想换行，可以用print()。 Java还提供了格式化输出的功能。为什么要格式化输出？因为计算机表示的数据不一定适合人阅读。格式化输出使用System.out.printf()，通过使用占位符%?，printf()可以把后面的参数格式化成指定格式。Java的格式化功能提供了多种占位符，可以把各种数据类型“格式化”成指定的字符串。 占位符 说明 %d 格式化输出整数 %x 格式化输出十六进制整数 %f 格式化输出浮点数 %e 格式化输出科学计数法表示的浮点数 %s 格式化字符串 %表示占位符。占位符本身还可以有更详细的格式化参数。更详细的格式化参数参考JDK文档java.util.Formatter。 输出和输出相比，Java的输入就要复杂得多。 我们先看一个从控制台读取一个字符串和一个整数的例子： 123456789101112import java.util.Scanner;public class Main { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); // 创建Scanner对象 System.out.print(\"Input your name: \"); // 打印提示 String name = scanner.nextLine(); // 读取一行输入并获取字符串 System.out.print(\"Input your age: \"); // 打印提示 int age = scanner.nextInt(); // 读取一行输入并获取整数 System.out.printf(\"Hi, %s, you are %d\\n\", name, age); // 格式化输出 }} 首先，我们通过import语句导入java.util.Scanner，import是导入某个类的语句，必须放到Java源代码的开头。 然后，创建Scanner对象并传入System.in。System.out代表标准输出流，而System.in代表标准输入流。直接使用System.in读取用户输入虽然是可以的，但需要更复杂的代码，而通过Scanner就可以简化后续的代码。 有了Scanner对象后，要读取用户输入的字符串，使用scanner.nextLine()，要读取用户输入的整数，使用scanner.nextInt()。Scanner会自动转换数据类型，因此不必手动转换。 3.2if判断Java中根据条件来决定是否执行某一段代码，需要使用if语句。根据if的计算结果（true还是false），JVM决定是否执行if语句块（即花括号{}包含的所有语句）。 当if语句块只有一行语句时，可以省略花括号{}。 if语句还可以编写一个else { … }，当条件判断为false时，将执行else的语句块。 还可以用多个if … else if …串联。 在串联使用多个if时，要特别注意判断顺序。 在Java中，判断值类型的变量是否相等，可以使用==运算符。但是，判断引用类型的变量是否相等，==表示“引用是否相等”，或者说，是否指向同一个对象。例如，下面的两个String类型，它们的内容是相同的，但是，分别指向不同的对象，用==判断，结果为false。要判断引用类型的变量内容是否相等，必须使用equals()方法。 3.3switch多重选择除了if语句外，还有一种条件判断，是根据某个表达式的结果，分别去执行不同的分支。 switch语句根据switch (表达式)计算的结果，跳转到匹配的case结果，然后继续执行后续语句，直到遇到break结束执行。switch的计算结果必须是整型、字符串或枚举类型。 12345678910111213141516171819public class Main { public static void main(String[] args) { int option = 1; switch (option) { case 1: System.out.println(\"Selected 1\"); break; case 2: System.out.println(\"Selected 2\"); break; case 3: System.out.println(\"Selected 3\"); break; default: System.out.println(\"Not selected\"); break; } }} 如果option的值没有匹配到任何case，那么switch语句不会执行任何语句。加一个default后，当没有匹配到任何case时，执行default。 使用switch时，注意case语句没有花括号，而且case语句具有穿透性，漏写break将导致意想不到的结果。 如果有几个case语句执行的是同一组语句块，可以这么写： 1234567891011121314151617public class Main { public static void main(String[] args) { int option = 2; switch (option) { case 1: System.out.println(\"Selected 1\"); break; case 2: case 3: System.out.println(\"Selected 2, 3\"); break; default: System.out.println(\"Not selected\"); break; } }} 使用switch语句时，只要保证有break，case的顺序不影响程序逻辑。但是仍然建议按照自然顺序排列，便于阅读。 switch语句还可以匹配字符串，字符串匹配时，是比较内容是否相等。 使用switch时，如果遗漏了break，会造成严重的逻辑错误，而且不易在源代码中发现。从Java 12开始，switch语句升级为更简单的表达式语法，使用类似模式匹配的方法，保证只会有一种路径会执行，并且不需要break语句。 1234567891011121314public class Main { public static void main(String[] args) { String fruit = \"apple\"; switch (fruit) { case \"apple\" -&gt; System.out.println(\"Selected apple\"); case \"pear\" -&gt; System.out.println(\"Selected pear\"); case \"mango\" -&gt; { System.out.println(\"Selected mango\"); System.out.println(\"Good choice!\"); } default -&gt; System.out.println(\"No fruit selected\"); } }} 注意，新语法使用-&gt;，如果有多条语句，需要用花括号括起来。 大多数时候，在switch表达式内部，我们会返回简单的值。但是，如果需要复杂的语句，我们也可以写很多语句放在花括号里，用yield返回一个值作为switch语句的返回值。 3.4while循环循环语句就是让计算机根据条件做循环计算，在条件满足时继续循环，条件不满足时退出循环。我们先看Java提供的while条件循环，它的基本用法是： 1234while(条件表达式){ 循环语句}// 执行后续代码 while循环在每次循环开始之前，首先判断条件是否成立。如果计算结果是true，就把循环体内的语句执行一遍，如果计算结果为false，那就直接跳到while循环的末尾，继续往下执行。 注意到while循环是先判断循环条件再循环，因此有可能一次循环都不做。 对于循环条件判断，以及自增变量的处理，要特别注意边界条件。 如果循环条件永远满足，那这个循环就成了死循环。死循环将导致100%的CPU占用，用户会感觉电脑运行缓慢，应避免编写死循环代码。 3.5do while循环do while循环是先执行循环，再判断条件，条件满足时继续循环，条件不满足时退出循环。 123do{ 循环语句}while(条件表达式) 可见do while循环至少会循环一次。 3.6for循环for循环的功能非常强大，它使用计数器实现循环。for循环会先初始化计数器，然后，在每次循环前检测循环条件，在每次循环后更新计数器，计数器变量通常命名为i。 for循环的用法是： 123for(初始条件:循环检测条件:循环后更新计数器){ // 执行语句} 在for循环执行之前，会先执行初始化语句，然后循环前先检测循环条件，循环后自动执行计数器更新语句。因此，和while循环相比，for循环把更新计数器的代码放到了一起，在for循环内部不再需要更新计数器。 注意for循环的初始化计数器总是被执行，并且for循环也可能循环0次。而且尽量不要在循环体内部修改计数器，容易导致莫名其妙的逻辑错误。 for循环还可以缺少初始化语句、循环语句和计数器更新语句。 for循环经常用来遍历数组，因为通过计数器可以根据索引来访问数组的每个元素。但是，很多时候，我们实际上真正要访问的是数组的每个元素的值。Java还提供了一个for each循环，它可以更简单的遍历数组。 12345678public class Main { public static void main(String[] args) { int[] ns = { 1, 4, 9, 16, 25 }; for (int n : ns) { System.out.println(n); } }} 和for循环相比，for each循环的变量n不再是计数器，而是直接对应到数组的每个元素。for each循环的写法也更简洁。但是，for each循环无法指定遍历顺序，也无法获取数组的索引。 除了数组外，for each循环能够遍历所有“可迭代”的数据类型，包括后面的List，Map等。 3.7break和continue在循环过程中，可以使用break语句跳出当前循环。break语句通常配合if语句使用。要特别注意，break语句总是跳出自己所在的那一层循环。 break会跳出当前循环，也就是整个循环都不会执行了。而continue则是提前结束本次循环，直接执行下次循环。在多层嵌套的循环中，continue语句同样是结束本次自己所在的循环。 4.数组操作4.1遍历数组为了实现for循环遍历，初始条件i=0，因为索引总是从0开始，继续循环的条件是i&lt;ns.length，因为当i=ns.length时，i已经超出了索引范围（索引范围是0~ns.length-1），每次循环后i++。 第二种方式是使用for each循环，直接迭代数组的每个元素。注意，在for(int n:ns)循环中，变量n直接拿到ns数组的元素，而不是索引。 显然for each循环更加简洁。但是，for each循环无法拿到数组的索引，因此，使用哪一种for循环，取决于我们的需要。 4.2数组排序常用的排序算法有冒泡排序、插入排序和快速排序等； Java的标准库已经内置了排序功能，我们只需要调用JDK提供的Arrays.sort()就可以排序。 对数组排序会直接修改数组本身。 4.3多维数组二维数组就是数组的数组。访问二维数组的一个元素使用array[row][col]。 要打印一个二维数组，可以使用两层嵌套的for循环，或者使用Java标准库的Arrays.deepToString()。 理论上我们能定义任意维数组，但在实际应用上，除了二维数组在某些情况下还用得上，更高维的数组很少使用。 4.4命令行参数Java程序的入口方法是main方法，而main方法可以接受一个命令行参数，它是一个String[]数组。这个命令行参数由JVM接受用户输入并传给main方法。我们可以利用接收到的命令行参数，根据不同的参数执行不同的代码。例如，实现一个-version参数，打印程序版本号。 12345678910public class Main { public static void main(String[] args) { for (String arg : args) { if (\"-version\".equals(arg)) { System.out.println(\"v 1.0\"); break; } } }} 这样，程序就可以根据传入的命令行参数做出不同的响应。","link":"/Study/Java/Java%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"},{"title":"Java核心类","text":"本节介绍Java核心类，包括字符串，StringBuilder，StringJoiner，包装类型，JavaBean，枚举，常用工具类。 字符串和编码String在Java中，String是一个引用类型，它本身也是一个class。但是Java对String有特殊处理，可以直接用\"...\"来表示一个字符串。实际上字符串在String内部是通过一个char[]数组表示的。因为String太常用了，所以Java提供了这种字符串字面量的表示方法。 Java字符串的一个重要特点是字符串不可变。 当我们想要比较两个字符串是否相同时，我们实际上想比较字符串的内容是否相同。必须用equals()方法，而不能使用==。 要忽略大小写比较，使用equalsIgnoreCase()方法。 常用字符串操作提取字串、查找、替换、大小写转换等。 使用trim()方法可以移除字符串首尾空白字符。空白字符包括空格，\\t，\\r，\\n。注意，trim()并没有改变字符串内容，而是返回了一个新字符串。另一个strip()方法也可以移除字符串首尾空白字符。它和trim()不同的是，类似中文的空格字符\\u3000也会被移除。 isEmpty()和isBlank()来判断字符串是否为空和空白字符串。 有几个占位符，后面就传入几个参数。参数类型要和占位符一致。我们经常用这个方法来格式化信息。常用的占位符有： %s：显示字符串； %d：显示整数； %x：显示十六进制整数； %f：显示浮点数。 类型转换要把任意基本类型或引用类型转换为字符串，可以使用静态方法valueOf()。 这是一个重载方法，编译器会根据参数自动选择合适的方法。要把字符串转换为其他类型，就需要根据情况。 String和char[]类型可以互相转换。 12char[] cs = \"Hello\".toCharArray(); // String -&gt; char[]String s = new String(cs); // char[] -&gt; String 从String的不变性设计可以看出，如果传入的对象有可能改变，我们需要复制而不是直接引用。 字符编码在早期的计算机系统中，为了给字符编码，美国国家标准学会（American National Standard Institute：ANSI）制定了一套英文字母、数字和常用符号的编码，它占用一个字节，编码范围从0到127，最高位始终为0，称为ASCII编码。 类似的， GB2312标准使用两个字节表示一个汉字，日文有Shift_JIS编码，韩文有EUC-KR编码，这些编码因为标准不统一，同时使用，就会产生冲突。 为了统一全球所有语言的编码，全球统一码联盟发布了Unicode编码，它把世界上主要语言都纳入同一个编码，这样，中文、日文、韩文和其他语言就不会冲突。 那我们经常使用的UTF-8又是什么编码呢？因为英文字符的Unicode编码高字节总是00，包含大量英文的文本会浪费空间，所以，出现了UTF-8编码，它是一种变长编码，用来把固定长度的Unicode编码变成1～4字节的变长编码。 UTF-8编码的另一个好处是容错能力强。如果传输过程中某些字符出错，不会影响后续字符，因为UTF-8编码依靠高字节位来确定一个字符究竟是几个字节，它经常用来作为传输编码。 StringBuilderJava编译器对String做了特殊处理，使得我们可以直接用+拼接字符串。String在拼接时总会创建新的字符串对象，然后扔掉旧的字符串。这样，绝大多数字符串都是临时对象，不但浪费内存，还影响GC效率。 为了能高效拼接字符串，Java标准库提供了StringBuilder，它是一个可变对象，可以预分配缓冲区。这样，往StringBuilder中新增字符时，不会创建新的临时对象。 StringBuilder还可以进行链式操作。 注意：对于普通字符串+操作，并不需要我们将其改写为StringBuilder，因为Java编译器在编译时就自动把多个连续的+操作编码为StringConcatFactory的操作。在运行期，StringConcatFactory会自动把字符串连接优化为数组复制或者StringBuilder操作。 你可能还听说过StringBuffer，这是Java早期的一个StringBuilder的线程安全版本，它通过同步来保证多个线程操作StringBuffer是安全的，但是同步会带来执行速度的下降。 StringJoiner用分隔符拼接数组的需求很常见，Java标准库提供了一个StringJoiner来干这个事。 12345String[] names = {\"Bob\", \"Alice\", \"Grace\"};var sj = new StringJoiner(\", \", \"Hello \", \"!\");for (String name : names) { sj.add(name);}//hello和!分别是开头和结尾 String还提供了一个静态方法join()，这个方法在内部使用了StringJoiner来拼接字符串，在不需要指定开头和结尾时，用String.join()更方便。 12String[] names = {\"Bob\", \"Alice\", \"Grace\"};var s = String.join(\", \", names); 包装类型我们已经知道，Java的数据类型分两种： 基本类型：byte，short，int，long，boolean，float，double，char 引用类型：所有class和interface类型 引用类型可以赋值为null表示空，但基本类型不能赋值为null。 那么如何把一个基本类型视为对象（引用类型）呢？ 比如，我们想要把int基本类型变成一个引用类型，我们可以定义一个Interger，它只包含一个int型的实例字段，这样就把Integer视为int的包装类型（Wrapper Class）。定义好了Interger，就可以把int和Interger相互转换。 实际上，因为包装类型非常有用，Java核心库为每种基本类型都提供了对应的包装类型。 自动装箱Java编译器可以帮助我们自动在int和Interger之间转型。 12Integer n = 100; // 编译器自动使用Integer.valueOf(int)int x = n; // 编译器自动使用Integer.intValue() 这种直接把int变为Interger的赋值写法，成为自动装箱（Auto Boxing），反过来，把Interger变为int的赋值写法，成为自动拆箱（Auto Unboxing）。 注意：自动装箱和自动拆箱只发生在编译阶段，目的是为了少写代码。装箱和拆箱会影响代码的执行效率，因为编译后的class代码是严格区分基本类型和引用类型的。并且，自动拆箱执行时可能会报NullPointerException。 不变类所有的包装类型都是不变类。因此一旦创建了Interger对象，该对象就是不变的。对两个Interger实例进行比较时要特别注意，绝不能用==比较，因为Interger是引用类型，必须用equals()比较。 在我们自己创建Interger的时候，有以下两种方法： 12Interger n = new Interger(100);//方法一Interger n = interger.valueOf(100);//方法二 方法二更好，因为方法一总是创建新的Interger实例，方法二把内部优化交给Interger的实现者来做，即使在当前版本没有优化，也有可能在下一个版本进行优化。 我们把能创建”新“对象的静态方法称为静态工厂方法。Interger.valueOf()就是静态工厂方法，它尽可能的返回缓存的实例以节省内存。 进制转换Interger类本身还提供了大量方法，例如，最常用的静态方法parseint()可以把字符串解析成一个整数。 12int x1 = Integer.parseInt(\"100\"); // 100int x2 = Integer.parseInt(\"100\", 16); // 256,因为按16进制解析 Integer还可以把整数格式化为指定进制的字符串。 Java的包装类型还定义了一些有用的静态变量。 123456789// boolean只有两个值true/false，其包装类型只需要引用Boolean提供的静态字段:Boolean t = Boolean.TRUE;Boolean f = Boolean.FALSE;// int可表示的最大/最小值:int max = Integer.MAX_VALUE; // 2147483647int min = Integer.MIN_VALUE; // -2147483648// long类型占用的bit和byte数量:int sizeOfLong = Long.SIZE; // 64 (bits)int bytesOfLong = Long.BYTES; // 8 (bytes) 最后，所有的整数和浮点数的包装类型都继承自Number，因此可以非常方便的通过包装类型获取各种基本类型。 12345678// 向上转型为Number:Number num = new Integer(999);// 获取byte, int, long, float, double:byte b = num.byteValue();int n = num.intValue();long ln = num.longValue();float f = num.floatValue();double d = num.doubleValue(); 处理无符号整型在Java中，并没有无符号整型（Unsigned）的基本数据类型。byte，short，int和long都是带符号整型，最高位是符号位。无符号整型和有符号整型的转换在Java中就需要借助包装类型的静态方法完成。例如： 12byte x = -1;byte y = Byte.toUnsignedInt(x); JavaBean在Java中，有很多class都符合这样的规范： 若干private实例字段 通过public方法来读写实例字段 如果读写方法符合以下这种命名规范： 1234//读方法public Type getXyz();//写方法public void setXyz(Type value); 那么这种class被称为JavaBean。 上面的字段是xyz，那么读写方法分别以get和set开头，并且后接大写字母开头的字段名Xyz，因此读写方法分别是getXyz()和setXyz()。boolean字段比较特殊，它的读方法一般命名为isXyz()。 我们通常把一组对应的读方法（getter）和写方法（setter）称为属性（property）。只有getter的属性称为只读属性。 属性只需要定义getter和setter方法，不一定需要对应字段。可以看出，getter和setter也是一种数据封装的方法。 JavaBean的作用JavaBean主要用来传递数据，即把一组数据组合一个JavaBean便于传输。此外，JavaBean可以方便地被IDE分析，生成读写属性的代码，主要用在图形界面的可视化设计中。 枚举JavaBean要枚举一个JavaBean的所有属性，可以直接使用Java核心库提供的Introspector。 123456BeanInfo info = Introspector.getBeanInfo(Person.class);for (PropertyDescriptor pd : info.getPropertyDescriptors()) { System.out.println(pd.getName()); System.out.println(\" \" + pd.getReadMethod()); System.out.println(\" \" + pd.getWriteMethod());} 枚举类为了让编译器能自动检查某个值在枚举的集合内，并且不同用途的枚举需要不同的类型来标记，不能混用，我们可以使用enum来定义枚举类。 123enum Weekday { SUN, MON, TUE, WED, THU, FRI, SAT;} 注意到定义枚举类是通过关键字enum实现的，我们只需要依次列举出枚举的常量名。和int定义的常量相比，使用enum定义枚举有如下好处： 首先，enum常量本身带有类型信息，即Weekday.SUN类型是Weekday，编译器会自动检查出类型错误。其次，不可能引用到非枚举的值，因为无法通过编译。最后，不同类型的枚举不能相互比较或者赋值，因为类型不符。这就使得编译器可以在编译器自动检查出所有可能的潜在错误。 enum的比较使用enum定义的枚举类型是引用类型。引用类型比较，要使用equals()方法，如果使用==比较，它比较的是两个引用类型的变量是否是同一个对象。因此，引用类型比较，要始终使用equals()方法，但enum类型可以例外。 因为enum类型的每个常量在JVM中只有一个唯一实例，所以可以直接用==比较。 enum类型通过enum定义的枚举类，和其他class有什么区别？答案是没有任何区别。enum定义的类型就是class，只不过它有以及几个特点。 定义的enum类型总是继承自java.lang.Enum，且无法被继承 只能定义出enum实例，而无法通过new操作符创建enum实例 定义的每个实例都是引用类型的唯一实例 可以将enum类型用于switch语句 因为enum是一个class，每个枚举的值都是class实例，这些实例有一些方法。 name() 返回常量名 ordinal() 返回定义的常量的顺序，从0开始计数 对枚举常量调用toString()会返回和name()一样的字符串。但是，toString()可以被覆写，而name()则不行。覆写toString()的目的是在输出时更有可读性。 纪录类使用String，Integer等类型的时候，这些类型都是不变类，一个不变类具有以下几个特点： 定义class时使用final，无法派生子类 每个字段使用final，保证创建实例后无法修改任何字段 为了保证不变类的比较，还需要正确覆写equals()和hashCode()，这样才能在集合类中正常使用。 record从Java 14开始，引入了新的Record类。我们定义Record类时，使用关键字record。 12345678910111213141516171819202122232425262728293031public record Point(int x, int y) {}//改写为classpublic final class Point extends Record { private final int x; private final int y; public Point(int x, int y) { this.x = x; this.y = y; } public int x() { return this.x; } public int y() { return this.y; } public String toString() { return String.format(\"Point[x=%s, y=%s]\", x, y); } public boolean equals(Object o) { ... } public int hashCode() { ... }} 除了用final修饰class以及每个字段外，编译器还为我们创建了构造方法，和字段名同名的方法，以及覆写toString()，equals()和hashCode()方法。换句话说，使用record关键字可以一行写出一个不变类。 和enum类似，我们自己不能直接从Record派生，只能通过record关键字由编译器实现继承。 构造方法编译器默认按照record声明的变量顺序自动创建一个构造方法，并在方法内给字段赋值。那么问题来了，如果我们要检查参数，应该怎么办？ 假设Point类的x，y不允许负数，我们就给Point的构造函数加上检查逻辑。 1234567public record Point(int x, int y) { public Point { if (x &lt; 0 || y &lt; 0) { throw new IllegalArgumentException(); } }} 注意到方法public Point{...}被称为Compact Constructor，它的目的是让我们编写出检查逻辑，编译器最终生成的构造方法如下： 123456789101112public final class Point extends Record { public Point(int x, int y) { // 这是我们编写的Compact Constructor: if (x &lt; 0 || y &lt; 0) { throw new IllegalArgumentException(); } // 这是编译器继续生成的赋值代码: this.x = x; this.y = y; } ...} 作为record的Point仍然可以添加静态方法，一般常用的静态的of()方法，用来创建Point。 12345678public record Point(int x, int y) { public static Point of() { return new Point(0, 0); } public static Point of(int x, int y) { return new Point(x, y); }} 这样我们可以写出更简洁的代码。 12var z = Point.of();var p = Point.of(123, 456); BigInteger在Java中，由CPU原生提供的整型最大范围是64位long型整数。使用long型整数可以直接通过CPU指令进行计算，速度非常快。 如果我们使用的整数范围超过了long型怎么办？这时，就只能用软件来模拟一个大整数。java.math.BigInteger就是用来表示任意大小的整数。BigInteger内部使用一个int[]数组来模拟一个非常大的整数。 和long型整数运算相比，BigInteger不会有范围限制，但缺点是速度比较慢。 Biginteger和Integer、Long一样，也是不变类，也继承自Number类，因为Number定义了几种转换为基本类型的几个方法： 转换为byte：byteValue() 转换为short：shortValue() 转换为int：intValue() 转换为long：longValue() 转换为float：floatValue() 转换为double：doubleValue() 因此，通过上述方法，可以把BigInteger转换为基本类型。如果BigInteger表示的范围超过了基本类型的范围，转换时将丢失高位信息，即结果不一定是准确的。如果需要准确的转换成基本类型，可以使用intValueExact()、longValueExact()等方法，在转换时如果超出范围，将直接抛出ArithmeticException异常。 BigDecimal和BigInteger类似，BigDecimal可以表示一个任意大小且精度完全准确的浮点数。 BigDecimal用scale()表示小数位数。如果一个BigDecimal的scale()返回负数，例如返回-2，表示这个数是整数，并且末尾有两个0。可以对一个BigDecimal设置scale，如果精度比原始值低，那么按照指定的方法进行四舍五入或者直接截断。 stripTrailingZeros()可以将一个BigDecimal格式化为一个相等的，但去掉了末尾0的BigDecimal。 对BigDecimal做加减乘，精度不会丢失，但是做除法时，存在除不尽的情况，这时必须指定精度以及如何截断。 比较BigDecimal 在比较两个BigDecimal的值是否相等时，要特别注意，使用equals()方法不但要求两个BigDecimal值相等，还要求他们的scale()相等。使用compareTo()方法来比较，它根据两个值的大小分别返回负数、正数和0，分别表示小于，大于和等于。 BigDecimal也是从Number继承的，也是不可变对象。 常用工具类Java的核心库提供了大量的现成的类供我们使用。 MathMath类是用来进行数学计算的，它提供了大量的静态方法来便于我们实现数学计算。 求绝对值，最值，计算x^y次方，e^x，以e为低的对数，三角函数，几个数学常量，生成随机数等等。 RandomRandom用来创建伪随机数。所谓伪随机数，是指只要给定一个初始的种子，产生的随机数序列是完全一样的。 要生成一个随机数，可以使用nextInt()、nextLong()、nextFloat()、nextDouble()。 我们在创建Random实例时，如果不给定种子，就使用系统当前时间戳作为种子，因此每次运行时，种子不同得到的随机数序列也就不同。如果我们创建Random实例时指定一个种子，就会得到完全相同的随机数序列。 SecureRandom有伪随机数，就有真随机数。实际上真正的真随机数只能通过量子力学原理来获取，而我们想要的是一个不可预测的安全的随机数，SecureRandom就是用来创建安全的随机数的。 SecureRandom无法指定种子，它使用RNG（random number generator）算法。JDK的SecureRandom实际上有多种不同的底层实现，有的使用安全随机种子加上伪随机数算法来产生安全的随机数，有的使用真正的随机数生成器。实际使用的时候，可以优先获取高强度的安全随机数生成器，如果没有提供，再使用普通等级的安全随机数生成器： SecureRandom的安全性是通过操作系统提供的安全的随机种子来生成随机数。这个种子是通过CPU的热噪声、读写磁盘的字节、网络流量等各种随机事件产生的“熵”。 在密码学中，安全的随机数非常重要。如果使用不安全的伪随机数，所有加密体系都将被攻破。因此，时刻牢记必须使用SecureRandom来产生安全的随机数。","link":"/Study/Java/Java%E6%A0%B8%E5%BF%83%E7%B1%BB/"},{"title":"Maven基础","text":"Maven是一个Java项目管理和构建工具，它可以定义项目结构、项目依赖，并使用统一的方式进行自动化构建，是Java项目不可缺少的工具。本章我们详细介绍如何使用Maven。 Maven介绍我们先来看看一个Java项目需要的东西。首先，我们需要确定引入哪些依赖包。其次，我们要确定项目的目录结构。例如，src目录存放Java源码，resources目录存放配置文件，bin目录存放编译后的生成的.class文件。此外，我们还需要配置环境，比如JDK的版本，编译打包流程，当前代码的版本号。最后，除了使用IDE编译外，我们还必须能通过命令行工具进行编译，才能让项目在一个独立的服务器上编译、测试、部署。 这些工作难度不大，但是非常繁琐和耗时。 Maven就是专门为Java项目打造的管理和构建工具。它的主要功能有： 提供了一套标准化的项目结构 提供了一套标准化的构建流程（编译、测试、打包、发布……） 提供了一套依赖管理机制 Maven项目结构一个使用Maven管理的普通的Java项目，它的目录结构默认如下： 12345678910a-maven-project├── pom.xml├── src│ ├── main│ │ ├── java│ │ └── resources│ └── test│ ├── java│ └── resources└── target 根目录a-maven-project是项目名，它有一个项目描述文件pom.xml，src/main/java是存放Java源码的目录，src/main/resources是存放资源文件的目录，src/test/java是存放测试源码的目录，src/test/resources是存放测试资源的目录，最后，所有编译、打包生成的文件都在target目录里。 所有的目录结构都是约定好的标准结构，千万不要随意修改目录结构。标准结构无需任何配置就可以正常使用。 我们来看一下最关键的pom.xml，它长得像下面这样： 1234567891011121314151617&lt;project ...&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itranswarp.learnjava&lt;/groupId&gt; &lt;artifactId&gt;hello&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;properties&gt; ... &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 其中，groupId类似Java的包名，通常是公司或组织的名称，artifactId类似于Java的类名，通常是项目名称，再加上version。一个Maven工程就是由groupId，artifactId和version作为唯一标识。我们在引用其他第三方库时，也是通过这三个变量确定，例如，依赖commons-logging： 12345&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 使用&lt;dependency&gt;声明一个依赖后，Maven就会自动下载这个依赖包并把它放到classpath中。 依赖管理如果我们的项目依赖第三方的jar包，例如commons logging，那么commons logging发布的jar包在哪下载？同样的，如果我们也依赖log4j，那么使用log4j需要哪些jar包？类似的依赖还包括JUnit，JavaMail。MySQL驱动等等，一个可行的方案是通过搜索引擎搜索到项目的官网，然后手动下载zip包，解压，放入classpath。但是，这个过程非常繁琐。 Maven解决了依赖管理。 例如，我们的项目依赖abc这个jar包，而abc又依赖xyz这个jar包。当我们声明了abc这个依赖时，Maven自动把abc和xyz都加入我们的项目依赖，不需要我们自己研究依赖关系。 Maven的第一个作用就是解决依赖管理。我们声明了自己的项目需要abc，Maven会自动导入abc的jar包，再判断出abc需要xyz，又会自动导入xyz的jar包，这样，最终我们的项目会依赖abc和xyz两个jar包。 我们来看一个复杂的依赖示例。 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;1.4.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 当我们声明一个spring-boot-starter-web依赖时，Maven会自动解析并判断最终需要二三十个其他的依赖。如果我们自己去手动管理这些依赖不仅耗时而且出错的概率也很大。 依赖关系Maven定义了几种依赖关系，分别是compile、test、runtime和provided。 scope 说明 示例 compile 编译时需要用到该jar包（默认） commons-logging test 编译Test时需要用到该jar包 junit runtime 编译时不需要，但运行时需要用到 mysql provided 编译时需要用到，但运行时由JDK或某个服务器提供 servlet-api 其中，默认的compile是最常用的，Maven会把这种类型的依赖直接放入classpath。 test依赖表示仅在测试时使用，正常运行时并不需要。最常用的test依赖就是JUnit。 runtime依赖表示编译时不需要，但运行时需要。最典型的runtime依赖是JDBC驱动，例如MySQL驱动。 provided依赖表示编译时需要，但运行时不需要。最典型的provided依赖是Servlet API，编译的时候需要，但是运行时，Servlet服务器内置了相关的jar，所以运行期不需要。 Maven如何知道从何处下载所需的依赖？也就是相关的jar包？答案是Maven维护了一个中央仓库，所有第三方库将自身的jar以及相关信息上传至中央仓库，Maven就可以从中央仓库把所需的依赖下载到本地。 Maven并不会每次都从中央仓库下载jar包。一旦一个jar包被下载过，就会被Maven自动缓存在本地目录，用户主目录的.m2目录，所以，除了第一次编译时需要下载需要时间会比较长，后续过程因为有本地存储，速度会快很多。 唯一ID对于某个依赖，Maven只需要3个变量即可唯一确定某个jar包： groupId：属于组织的名称，类似Java的包名； artifactId：该jar包自身的名称，类似Java的类名； version：该jar包的版本。 通过上述3个变量，即可唯一确定某个jar包。Maven通过对jar包进行PGP签名确保任何一个jar包一经发布就无法修改。修改已发布jar包的唯一方法是发布一个新版本。 注：只有以-SNAPSHOT结尾的版本号会被Maven视为开发版本，开发版本每次都会重复下载，这种SNAPSHOT版本只能用于内部私有的Maven repo，公开发布的版本不允许出现SNAPSHOT。 Maven镜像除了可以从Maven的中央仓库下载外，还可以从Maven的镜像仓库下载。如果访问Maven的中央仓库非常慢，我们可以选择一个速度较快的Maven的镜像仓库。Maven镜像仓库定期从中央仓库同步。 中国区用户可以使用阿里云提供的Maven镜像仓库。使用Maven镜像仓库需要一个配置，在用户主目录下进入.m2目录，创建一个settings.xml配置文件，内容如下： 1234567891011&lt;settings&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;name&gt;aliyun&lt;/name&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;!-- 国内推荐阿里云的Maven镜像 --&gt; &lt;url&gt;https://maven.aliyun.com/repository/central&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;/settings&gt; 配置镜像仓库后，Maven的下载速度会非常快。 搜索第三方组件如果我们要引用一个第三方组件，如何确切地获得它的groupId，artifactId和version？可以在https://search.maven.org/搜索关键字，找到对应组件后，直接复制。 命令行编译在命令行中，进入到pom.xml所在目录，输入以下命令： 1$ mvn clean package 如果一切顺利，即可在target目录下获得编译后自动打包的jar。 在IDE中使用Maven几乎所有的IDE都内置了对Maven的支持。 构建流程Maven不但有标准化的目录结构，而且还有一套标准化的构建流程，可以自动实现编译，打包，发布等等。 Lifecycle和Phase我们首先了解什么是Maven的声明周期（lifecycle）。Maven的生命周期由一系列阶段（phase）构成，以内置的生命周期default为例，它包含以下phase。 validate initialize generate-sources process-sources generate-resources process-resources compile process-classes generate-test-sources process-test-sources generate-test-resources process-test-resources test-compile process-test-classes test prepare-package package pre-integration-test integration-test post-integration-test verify install deploy 如果我们运行mvn package，Maven就会执行default生命周期，它会从开始一直运行到package这个phase为止。 validate … package 如果我们运行mvn compile，Maven也会执行default生命周期，但这次它只会运行到compile，即以下几个phase： validate … compile Maven的另一个常用生命周期是clean，它会执行3个phase： pre-clean clean （注意这个clean不是lifecycle而是phase） post-clean 所以，我们使用mvn这个命令时，后面的参数是phase，Maven自动根据生命周期运行到指定的phase。 更复杂的例子是指定多个phase，例如，运行mvn clean package，Maven先执行clean生命周期并运行到clean这个phase，然后执行default生命周期并运行到package这个phase，实际执行的phase如下： pre-clean clean （注意这个clean是phase） validate … package 在实际开发过程中，经常使用的命令有： mvn clean：清理所有生成的class和jar； mvn clean compile：先清理，再执行到compile； mvn clean test：先清理，再执行到test，因为执行test前必须执行compile，所以这里不必指定compile； mvn clean package：先清理，再执行到package。 大多数phase在执行过程中，因为我们通常没有在pom.xml中配置相关的设置，所以这些phase什么事情都不做。 经常用到的phase其实只有几个： clean：清理 compile：编译 test：运行测试 package：打包 Goal执行一个phase又会触发一个或多个goal： 执行的Phase 对应执行的Goal compile compiler:compile test compiler:testCompile surefire:test goal的命名总是abc:xyz这种形式。 其实我们类比一下就明白了： lifecycle相当于Java的package，它包含一个或多个phase； phase相当于Java的class，它包含一个或多个goal； goal相当于class的method，它其实才是真正干活的。 大多数情况下，我们只要指定phase，就默认执行这些phase默认绑定的goal，只有少数情况，我们可以直接运行一个goal，例如，启动Tomcat服务器。 1mvn tomcat:run 小结Maven通过lifecycle、phase和goal来提供标准的构建流程。 最常用的构建命令是指定phase，然后让Maven执行到指定的phase： mvn clean mvn clean compile mvn clean test mvn clean package 通常情况，我们总是执行phase默认绑定的goal，因此不必指定goal。 使用插件我们在前面介绍了Maven的lifecycle，phase和goal。使用Maven构建项目就是执行lifescycle，执行到指定的phase为止，每个phase会执行自己默认的一个或多个goal。goal是最小的任务单元。 我们以compile这个phase为例，执行： 1mvn compile Maven将执行compile这个phase，这个phase会调用compile插件执行关联的compiler:compile这个goal。 实际上，执行每个phase都是通过某个插件（plugin）执行的，Maven本身不知道如何执行compile，它只是负责找到对应的compiler插件，然后执行默认的compiler:compile这个goal来完成编译。所以，使用Maven，实际上就是配置好需要使用的插件，然后通过phase来调用它们。Maven已经内置了一些常用的标准插件： 插件名称 对应执行的phase clean clean compiler compile surefire test jar package 如果标准插件无法满足要求，我们还可以使用自定义插件。Maven通过自定义插件可以执行项目构建时需要的额外功能。使用自定义插件需要声明，例如，使用maven-shade-plugin可以创建一个可执行的jar，要使用这个插件，需要在pom.xml中声明： 1234567891011121314151617181920212223&lt;project&gt; ... &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; ... &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 自定义插件往往需要一些配置，例如，maven-shade-plugin需要指定Java程序的入口，它的配置是： 1234567&lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;mainClass&gt;com.itranswarp.learnjava.Main&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt;&lt;/configuration&gt; Maven自带的标准插件是无需声明的，只有引入其他插件才需要声明。插件的配置和用法需参考插件的官方文档。 下面列举了一些常用的插件： maven-shade-plugin：打包所有依赖包并生成可执行jar； cobertura-maven-plugin：生成单元测试覆盖率报告； findbugs-maven-plugin：对Java源码进行静态分析以找出潜在问题。 模块管理在软件开发中，把一个大项目拆分为多个模块是降低软件复杂度的有效方法。Maven可以有效的管理多个模块，我们只需要把每个模块当成一个独立的Maven项目，他们有各自独立的pom.xml。 例如，A模块的pom.xml和B模块的pom.xml高度相似，可以提取出共同的部分作为parent。注意设置&lt;packaging&gt;pom&lt;/packaging&gt;，而不是jar。因为parent本身不包含任何的Java代码，编写parent的pom.xml只是为了在各个模块里简化配置。现在我们的工程目录如下： 12345678910111213multiple-project├── pom.xml├── parent│ └── pom.xml├── module-a│ ├── pom.xml│ └── src├── module-b│ ├── pom.xml│ └── src└── module-c ├── pom.xml └── src 这样就可以大幅简化配置文件的编写。 如果模块A依赖模块B，则模块A需要模块B的jar包才能正常编译，在模块A的pom.xml中就像这样： 12345678... &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.itranswarp.learnjava&lt;/groupId&gt; &lt;artifactId&gt;module-b&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 最后，在编译的时候，需要在根目录创建一个pom.xml统一编译： 123456789101112131415161718&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itranswarp.learnjava&lt;/groupId&gt; &lt;artifactId&gt;build&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;build&lt;/name&gt; &lt;modules&gt; &lt;module&gt;parent&lt;/module&gt; &lt;module&gt;module-a&lt;/module&gt; &lt;module&gt;module-b&lt;/module&gt; &lt;module&gt;module-c&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 这样，在根目录执行mvn clean package时，Maven会根据根目录的pom.xml找到包括parent在内的4个module，一次性全部编译。 中央仓库，私有仓库和本地仓库中央仓库和私有仓库略。 本地仓库本地仓库是指把本地开发的项目“发布”在本地，这样其他项目可以通过本地仓库引用它。但是我们不推荐把自己的模块安装到Maven的本地仓库，因为每次修改某个模块的源码，都需要重新安装，非常容易出现版本不一致的情况。更好的方法是使用模块化编译，在编译的时候，告诉Maven几个模块之间存在依赖关系，需要一块编译，Maven就会自动按依赖顺序编译这些模块。 使用mvnwmvnw时Maven Wrapper的缩写。我们安装Maven时，默认情况下，系统的所有项目都会使用全局安装的这个Maven版本。但是，对某个项目来说，可能必需要使用特定版本的Maven，这时，就可以使用Maven Wrapper。它负责给这个特定的项目安装指定版本的Maven，而其他项目不受影响。 简单来说，Maven Wrapper就是给一个项目提供一个独立的、指定版本的Maven供该项目使用。 安装Maven Wrapper最简单的方式是在项目的根目录下运行安装命令： 1mvn -N io.takari:maven:0.7.6:wrapper 它会自动使用最新版本的Maven。注意0.7.6是Maven Wrapper的版本，最新的版本可以去官方网站查看。 如果要指定使用的Maven版本，使用下面的安装命令指定Maven的版本，例如3.3.3。 1mvn -N io.takari:maven:0.7.6:wrapper -Dmaven=3.3.3 安装后，查看项目结构： 12345678910111213141516my-project├── .mvn│ └── wrapper│ ├── MavenWrapperDownloader.java│ ├── maven-wrapper.jar│ └── maven-wrapper.properties├── mvnw├── mvnw.cmd├── pom.xml└── src ├── main │ ├── java │ └── resources └── test ├── java └── resources 发现多了mvnw、mvnw.cmd和.mvn目录，我们只需要把mvn命令改为mvnw就可以使用跟项目关联的Maven。例如： 1mvnw clean package Maven Wrapper的另一个作用，是把项目的mvnw、mvnw.cmd和.mvn提交到版本库中，可以使所有的开发人员使用统一的Maven版本。 发布Artifact当我们使用第三方开源库时，我们实际上是通过Maven自动下载它的jar包，并根据pom文件解析依赖，自动把相关依赖包都下载后加入到classpath。 那么，当我们自己写了一个开源库，非常希望别人也能使用时，总不能直接放个jar包的链接让别人下载吧？ 如果我们把自己的开源库放到Maven的repo中，那么，别人只需按标准引用groupId:artifactId:version，即可自动下载jar包以及相关依赖。本节我们就来介绍如何发布一个库到Maven的repo中，介绍最常用的3种方法。 以静态文件发布如果我们观察一个中央仓库的Artifact结构，例如Commons Math，它的groupId是org.apache.commons，artifactId是commons-math3，以版本3.6.1为例，发布在中央仓库的文件夹路径就是https://repo1.maven.org/maven2/org/apache/commons/commons-math3/3.6.1/，在此文件夹下，commons-math3-3.6.1.jar就是发布的jar包，commons-math3-3.6.1.pom就是它的pom.xml描述文件，commons-math3-3.6.1-sources.jar是源代码，commons-math3-3.6.1-javadoc.jar是文档。其它以.asc、.md5、.sha1结尾的文件分别是GPG签名、MD5摘要和SHA-1摘要。 我们只要按照这种目录结构组织文件，它就是一个有效的Maven仓库。 我们以一个项目为例，先创建Maven工程目录结构如下： 1234567891011how-to-become-rich├── maven-repo &lt;-- Maven本地文件仓库├── pom.xml &lt;-- 项目文件├── src│ ├── main│ │ ├── java &lt;-- 源码目录│ │ └── resources &lt;-- 资源目录│ └── test│ ├── java &lt;-- 测试源码目录│ └── resources &lt;-- 测试资源目录└── target &lt;-- 编译输出目录 在pom.xml里添加如下内容： 123456789101112131415161718192021222324252627282930313233343536373839&lt;project ...&gt; ... &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;local-repo-release&lt;/id&gt; &lt;name&gt;GitHub Release&lt;/name&gt; &lt;url&gt;file://${project.basedir}/maven-repo&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 注意到&lt;distributionManagement&gt;，它指示了发布软件包的位置，这里的&lt;url&gt;是项目根目录下的maven-repo目录，在&lt;build&gt;中定义两个插件maven-source-plugin和maven-javadoc-plugin分别用来创建源码和javadoc。如果不想发布源码，可以把对应的插件去掉。 我们直接在项目根目录下运行Maven命令mvn clean package deploy，如果一切顺利，我们就可以在maven-repo目录下找到部署后的所有文件如下： 123456789101112131415161718192021maven-repo└── com └── itranswarp └── rich └── how-to-become-rich ├── 1.0.0 │ ├── how-to-become-rich-1.0.0-javadoc.jar │ ├── how-to-become-rich-1.0.0-javadoc.jar.md5 │ ├── how-to-become-rich-1.0.0-javadoc.jar.sha1 │ ├── how-to-become-rich-1.0.0-sources.jar │ ├── how-to-become-rich-1.0.0-sources.jar.md5 │ ├── how-to-become-rich-1.0.0-sources.jar.sha1 │ ├── how-to-become-rich-1.0.0.jar │ ├── how-to-become-rich-1.0.0.jar.md5 │ ├── how-to-become-rich-1.0.0.jar.sha1 │ ├── how-to-become-rich-1.0.0.pom │ ├── how-to-become-rich-1.0.0.pom.md5 │ └── how-to-become-rich-1.0.0.pom.sha1 ├── maven-metadata.xml ├── maven-metadata.xml.md5 └── maven-metadata.xml.sha1 最后一步，把这个项目推到GitHub上，并选择Settings-GitHub Pages，选择master branch启用Pages服务。 这样，把全部内容推送至GitHub后，即可作为静态网站访问Maven的repo，它的地址是https://michaelliao.github.io/how-to-become-rich/maven-repo/。版本1.0.0对应的jar包地址是： 1https://michaelliao.github.io/how-to-become-rich/maven-repo/com/itranswarp/rich/how-to-become-rich/1.0.0/how-to-become-rich-1.0.0.jar 现在，如果其他人希望引用这个Maven包，我们可以告知如下依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.itranswarp.rich&lt;/groupId&gt; &lt;artifactId&gt;how-to-become-rich&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 但是，除了正常导入依赖外，对方还需要再添加一个&lt;repository&gt;的声明，即使用方完整的pom.xml如下： 1234567891011121314151617181920212223242526272829303132&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;example&lt;/groupId&gt; &lt;artifactId&gt;how-to-become-rich-usage&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;java.version&gt;11&lt;/java.version&gt; &lt;/properties&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;github-rich-repo&lt;/id&gt; &lt;name&gt;The Maven Repository on Github&lt;/name&gt; &lt;url&gt;https://michaelliao.github.io/how-to-become-rich/maven-repo/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.itranswarp.rich&lt;/groupId&gt; &lt;artifactId&gt;how-to-become-rich&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 在&lt;repository&gt;中，我们必须声明发布的Maven的repo地址，其中&lt;id&gt;和&lt;name&gt;可以任意填写，&lt;url&gt;填入GitHub Pages提供的地址+/maven-repo/后缀。现在，即可正常引用这个库并编写代码如下： 12Millionaire millionaire = new Millionaire();System.out.println(millionaire.howToBecomeRich()); 有的童鞋会问，为什么使用commons-logging等第三方库时，并不需要声明repo地址？这是因为这些库都是发布到Maven中央仓库的，发布到中央仓库后，不需要告诉Maven仓库地址，因为它知道中央仓库的地址默认是https://repo1.maven.org/maven2/，也可以通过~/.m2/settings.xml指定一个代理仓库地址以替代中央仓库来提高速度（参考依赖管理的Maven镜像）。 因为GitHub Pages并不会把我们发布的Maven包同步到中央仓库，所以自然使用方必须手动添加一个我们提供的仓库地址。 此外，通过GitHub Pages发布Maven repo时需要注意一点，即不要改动已发布的版本。因为Maven的仓库是不允许修改任何版本的，对一个库进行修改的唯一方法是发布一个新版本。但是通过静态文件的方式发布repo，实际上我们是可以修改jar文件的，但最好遵守规范，不要修改已发布版本。 通过Nexus发布到中央仓库此方法前期需要复杂的申请账号和项目的流程，后期需要安装调试GPG，但只要跑通流程，后续发布都只需要一行命令。 具体过程略，需要时再查看教程。","link":"/Study/Java/Maven%E5%9F%BA%E7%A1%80/"},{"title":"XML与JSON","text":"XML和JSON是两种经常在网络使用的数据格式。本章我们介绍如何使用Java读写XML和JSON。 XML简介XML是可扩展标记语言（eXtensible Markup Language）的缩写，它是一种数据表示格式，可以描述非常复杂的数据结构，常用于传输和存储数据。 XML有几个特点：一是纯文本，默认使用UTF-8编码；二是可嵌套，适合表示结构化数据。如果把XML内容存为文件，那它就是一个XML文件。此外，XML内容经常通过网络进行消息传输。 XML的结构XML有固定的结构，首行必定是&lt;?xml version=\"1.0\"?&gt;，可以加上可选编码。紧接着，如果以类似&lt;!DOCTYPE note SYSTEM \"book.dtd\"&gt;声明的是文档定义类型（DTD：Document Type Definition），DTD是可选的。接下来是XML的文档内容，一个XML文档有且仅有一个根元素，根元素可以包含任意个子元素，元素可以包含属性，例如，&lt;isbn lang=\"CN\"&gt;1234567&lt;/isbn&gt;包含一个属性lang=\"CN\"，且元素必须正确嵌套。如果是空元素，可以用&lt;tag/&gt;表示。 由于使用了&lt;，&gt;和引号等标识符，如果内容出现了特殊符号，需要使用&amp;???;表示转义。例如，Java&lt;tm&gt;必须写成： 1&lt;name&gt;Java&amp;lt;tm&amp;gt;&lt;/name&gt; 常见的特殊字符如下： 字符 表示 &lt; &lt; &gt; &gt; &amp; &amp; “ \" ‘ ' 格式正确的XML（Well Formed）是指XML的格式是正确的，可以被解析器正确读取。而合法的XML是指，不但XML格式正确，而且它的数据结构可以被DTD或者XSD验证。 DTD文档可以指定一系列规则，例如： 根元素必须是book book元素必须包含name，author等指定元素 isbn元素必须包含属性lang … 如何验证XML文件的正确性呢？最简单的方式是通过浏览器验证。可以直接把XML文件拖拽到浏览器窗口，如果格式错误，浏览器会报错。 和结构类似的HTML不同，浏览器对HTML有一定的“容错性”，缺少关闭标签也可以被解析，但XML要求严格的格式，任何没有正确嵌套的标签都会导致错误。 XML是一个技术体系，除了我们经常用到的XML文档本身外，XML还支持： DTD和XSD：验证XML结构和数据是否有效； Namespace：XML节点和属性的名字空间； XSLT：把XML转化为另一种文本； XPath：一种XML节点查询语言； … 实际上，XML的这些相关技术实现起来非常复杂，在实际应用中很少用到，通常了解一下就可以了。 使用DOM因为XML是一种树形结构的文档，它有两种标准的解析API： DOM：一次性读取XML，并在内存中表示为树形结构 SAX：以流的形式读取XML，使用事件回调 我们先来看看如何使用DOM读取XML。 DOM是Document Object Model的缩写，DOM模型就是把XML结构作为一个树形结构来处理，从根节点开始，每个节点都可以包含任意个子节点。 我们以下面的XML为例： 1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;book id=\"1\"&gt; &lt;name&gt;Java核心技术&lt;/name&gt; &lt;author&gt;Cay S. Horstmann&lt;/author&gt; &lt;isbn lang=\"CN\"&gt;1234567&lt;/isbn&gt; &lt;tags&gt; &lt;tag&gt;Java&lt;/tag&gt; &lt;tag&gt;Network&lt;/tag&gt; &lt;/tags&gt; &lt;pubDate/&gt;&lt;/book&gt; 如果解析为DOM结构，它大概长这样： 1234567891011121314151617181920 ┌─────────┐ │document │ └─────────┘ │ ▼ ┌─────────┐ │ book │ └─────────┘ │ ┌──────────┬──────────┼──────────┬──────────┐ ▼ ▼ ▼ ▼ ▼┌─────────┐┌─────────┐┌─────────┐┌─────────┐┌─────────┐│ name ││ author ││ isbn ││ tags ││ pubDate │└─────────┘└─────────┘└─────────┘└─────────┘└─────────┘ │ ┌────┴────┐ ▼ ▼ ┌───────┐ ┌───────┐ │ tag │ │ tag │ └───────┘ └───────┘ 注意到最顶层的document代表XML文档，它是真正的“根”，而&lt;book&gt;虽然是根元素，但它是document的一个子节点。 Java提供了DOM API来解析XML，它使用下面的对象来表示XML的内容： Document：代表整个XML文档； Element：代表一个XML元素； Attribute：代表一个元素的某个属性。 使用DOM API解析一个XML文档的代码如下： 1234InputStream input = Main.class.getResourceAsStream(\"/book.xml\");DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();DocumentBuilder db = dbf.newDocumentBuilder();Document doc = db.parse(input); DocumentBuilder.parse()用于解析一个XML，它可以接收InputStream，File或者URL，如果解析无误，我们将获得一个Document对象，这个对象代表了整个XML文档的树形结构，需要遍历以便读取指定元素的值： 123456789101112131415161718192021222324void printNode(Node n, int indent) { for (int i = 0; i &lt; indent; i++) { System.out.print(' '); } switch (n.getNodeType()) { case Node.DOCUMENT_NODE: // Document节点 System.out.println(\"Document: \" + n.getNodeName()); break; case Node.ELEMENT_NODE: // 元素节点 System.out.println(\"Element: \" + n.getNodeName()); break; case Node.TEXT_NODE: // 文本 System.out.println(\"Text: \" + n.getNodeName() + \" = \" + n.getNodeValue()); break; case Node.ATTRIBUTE_NODE: // 属性 System.out.println(\"Attr: \" + n.getNodeName() + \" = \" + n.getNodeValue()); break; default: // 其他 System.out.println(\"NodeType: \" + n.getNodeType() + \", NodeName: \" + n.getNodeName()); } for (Node child = n.getFirstChild(); child != null; child = child.getNextSibling()) { printNode(child, indent + 1); }} 解析结构如下： 123456789101112Document: #document Element: book Text: #text = Element: name Text: #text = Java核心技术 Text: #text = Element: author Text: #text = Cay S. Horstmann Text: #text = ... 对于DOM API解析出来的结构，我们从根节点Document出发，可以遍历所有子节点，获取所有元素、属性、文本数据，还可以包括注释，这些节点被统称为Node，每个Node都有自己的Type，根据Type来区分一个Node到底是元素，还是属性，还是文本，等等。 使用DOM API时，如果要读取某个元素的文本，需要访问它的Text类型的子节点，所以使用起来还是比较繁琐的。 小结Java提供的DOM API可以将XML解析为DOM结构，以Document对象表示； DOM可在内存中完整表示XML数据结构； DOM解析速度慢，内存占用大。 使用SAX使用DOM解析XML的优点是用起来省事，但它的主要缺点是内存占用太大。另一种解析XML的方式是SAX，SAX是Simple API for XML的缩写，它是一种基于流的解析方式，边读取XML边解析，并以时间回调的方式让调用者获取数据。因为是一边读一边解析，所以无论XML有多大，占用的内存都很小。 SAX解析会触发一系列事件： startDocument：开始读取XML文档； startElement：读取到了一个元素，例如&lt;book&gt;； characters：读取到了字符； endElement：读取到了一个结束的元素，例如&lt;/book&gt;； endDocument：读取XML文档结束。 如果我们用SAX API解析XML，Java代码如下： 1234InputStream input = Main.class.getResourceAsStream(\"/book.xml\");SAXParserFactory spf = SAXParserFactory.newInstance();SAXParser saxParser = spf.newSAXParser();saxParser.parse(input, new MyHandler()); 关键代码SAXParser.parse()除了需要传入一个InputStream外，还需要传入一个回调对象，这个对象要继承自DefaultHandler： 123456789101112131415161718192021222324252627282930313233class MyHandler extends DefaultHandler { public void startDocument() throws SAXException { print(\"start document\"); } public void endDocument() throws SAXException { print(\"end document\"); } public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException { print(\"start element:\", localName, qName); } public void endElement(String uri, String localName, String qName) throws SAXException { print(\"end element:\", localName, qName); } public void characters(char[] ch, int start, int length) throws SAXException { print(\"characters:\", new String(ch, start, length)); } public void error(SAXParseException e) throws SAXException { print(\"error:\", e); } void print(Object... objs) { for (Object obj : objs) { System.out.print(obj); System.out.print(\" \"); } System.out.println(); }} 运行SAX解析代码，可以打印出下面的结果： 1234567891011start documentstart element: bookcharacters: start element: namecharacters: Java核心技术end element: namecharacters: start element: author... 如果要读取&lt;name&gt;节点的文本，我们就必须在解析过程中根据startElement()和endElement()定位当前正在读取的节点，可以使用栈结构保存。每遇到一个startElement()入栈，每遇到一个endElement()出栈，这样，读到characters()时我们才知道读取的文本是那个节点的。可见，使用SAX API仍然比较麻烦。 使用Jackson前面我们介绍了DOM和SAX两种解析XML的标准接口，但是，二者使用起来都不直观。 我们观察XML文档的内容，发现，它完全可以对应一个定义号的JavaBean中。如果能直接从XML文档解析成一个JavaBean，那比DOM和SAX不知道容易到哪里去了。 幸运的是，一个名叫Jackson的开源第三方库可以轻松做到XML到JavaBean的转换。我们要使用Jackson，首先添加两个Maven依赖。 com.fasterxml.jackson.dataformat:jackson-dataformat-xml:2.10.1 org.codehaus.woodstox:woodstox-core-asl:4.4.1 然后，定义好JavaBean，就可以用下面几行代码解析： 12345678910InputStream input = Main.class.getResourceAsStream(\"/book.xml\");JacksonXmlModule module = new JacksonXmlModule();XmlMapper mapper = new XmlMapper(module);Book book = mapper.readValue(input, Book.class);System.out.println(book.id);System.out.println(book.name);System.out.println(book.author);System.out.println(book.isbn);System.out.println(book.tags);System.out.println(book.pubDate); 注意到XmlMapper就是我们需要创建的核心对象，可以用readValue(InputStream, Class)直接读取XML并返回一个JavaBean。运行上述代码，就可以直接从Book对象中拿到数据： 1234561Java核心技术Cay S. Horstmann1234567[Java, Network]null 如果要解析的数据格式不是Jackson内置的标准格式，那么需要编写一点额外的扩展来告诉Jackson如何自定义解析，详细请看官方文档。 使用JSON前面我们讨论了XML这种数据格式。XML的特点是功能全面，但标签繁琐，格式复杂。在Web上使用XML现在越来越少，取而代之的是JSON这种数据结构。 JSON是JavaScript Object Notation的缩写，它去除了所有JavaScript执行代码，只保留JavaScript的对象格式。一个典型的JSON如下： 12345678910{ \"id\": 1, \"name\": \"Java核心技术\", \"author\": { \"firstName\": \"Abc\", \"lastName\": \"Xyz\" }, \"isbn\": \"1234567\", \"tags\": [\"Java\", \"Network\"]} JSON作为数据传输格式，有几个显著的优点： JSON只允许使用UTF-8编码，不存在编码问题 JSON只允许使用双引号作为key，特殊字符用\\转义，格式简单 浏览器内置JSON支持，如果把数据用JSON发送给浏览器，可以用JavaScript直接处理 因此，JSON适合表示层次结构，因为它格式简单，仅支持以下几种数据类型： 键值对：{\"key\": value} 数组：[1, 2, 3] 字符串：\"abc\" 数值（整数和浮点数）：12.34 布尔值：true或false 空值：null 浏览器直接支持使用JavaScript对JSON进行读写： 12345// JSON string to JavaScript object:jsObj = JSON.parse(jsonStr);// JavaScript object to JSON string:jsonStr = JSON.stringify(jsObj); 所以，开发Web应用的时候，使用JSON作为数据传输，在浏览器端非常方便。因为JSON天生适合JavaScript处理，所以，绝大多数REST API都选择JSON作为数据传输格式。 那么，如何用Java对JSON进行读写呢？ 常用的用于解析JSON的第三方库有： Jackson Gson Fastjson … 注意到上一节提到的那个可以解析XML的浓眉大眼的Jackson也可以解析JSON！因此我们只需要引入以下Maven依赖： com.fasterxml.jackson.core:jackson-databind:2.10.0 就可以使用下面的代码解析一个JSON文件： 12345InputStream input = Main.class.getResourceAsStream(\"/book.json\");ObjectMapper mapper = new ObjectMapper();// 反序列化时忽略不存在的JavaBean属性:mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);Book book = mapper.readValue(input, Book.class); 核心代码是创建一个ObjectMapper对象。关闭DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES功能使得解析时如果JavaBean不存在该属性时解析不会报错。 把JSON解析为JavaBean的过程称为反序列化。如果把JavaBean变为JSON，那就是序列化。要实现JavaBean到JSON的序列化，只需要一行代码： 1String json = mapper.writeValueAsString(book); 要把JSON的某些值解析为特定的Java对象，例如LocalDate，也是完全可以的。例如： 1234{ \"name\": \"Java核心技术\", \"pubDate\": \"2016-09-01\"} 要解析为： 1234public class Book { public String name; public LocalDate pubDate;} 只需要引入标准的JSR 310关于JavaTime的数据格式定义至Maven： com.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.10.0 然后，在创建ObjectMapper时，注册一个新的JavaTimeModule： 1ObjectMapper mapper = new ObjectMapper().registerModule(new JavaTimeModule()); 有些时候，内置的解析规则和扩展的解析规则如果都不满足我们的需求，还可以自定义解析。 举个例子，假设Book类的isbn是一个BigInteger： 1234public class Book { public String name; public BigInteger isbn;} 但JSON数据并不是标准的整形格式： 1234{ \"name\": \"Java核心技术\", \"isbn\": \"978-7-111-54742-6\"} 直接解析，肯定报错。这时，我们需要自定义一个IsbnDeserializer，用于解析含有非数字的字符串： 1234567891011121314public class IsbnDeserializer extends JsonDeserializer&lt;BigInteger&gt; { public BigInteger deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException { // 读取原始的JSON字符串内容: String s = p.getValueAsString(); if (s != null) { try { return new BigInteger(s.replace(\"-\", \"\")); } catch (NumberFormatException e) { throw new JsonParseException(p, s, e); } } return null; }} 然后，在Book类中使用注解标注： 123456public class Book { public String name; // 表示反序列化isbn时使用自定义的IsbnDeserializer: @JsonDeserialize(using = IsbnDeserializer.class) public BigInteger isbn;} 类似的，自定义序列化时我们需要自定义一个IsbnSerializer，然后在Book类中标注@JsonSerialize(using = ...)即可。","link":"/Study/Java/XML%E4%B8%8EJSON/"},{"title":"使用AOP","text":"AOP是Aspect Oriented Programming，即面向切面编程。我们先回顾一下OOP：Object Oriented Programming，OOP作为面向对象编程的模式，获得了巨大的成功，OOP的主要功能是数据封装、继承和多态。而AOP是一种新的编程方式，它和OOP不同，OOP把系统看作多个对象的交互，AOP把系统分解为不同的关注点，或者称之为切面（Aspect）。 要理解AOP的概念，我们先用OOP举例，比如一个业务组件BookService，它有几个业务方法： createBook：添加新的Book； updateBook：修改Book； deleteBook：删除Book。 对每个业务方法，例如，createBook()，除了业务逻辑，还需要安全检查、日志记录和事务处理，它的代码像这样： 1234567891011121314public class BookService { public void createBook(Book book) { securityCheck(); Transaction tx = startTransaction(); try { // 核心业务逻辑 tx.commit(); } catch (RuntimeException e) { tx.rollback(); throw e; } log(\"created book: \" + book); }} 继续编写updateBook()，代码如下： 1234567891011121314public class BookService { public void updateBook(Book book) { securityCheck(); Transaction tx = startTransaction(); try { // 核心业务逻辑 tx.commit(); } catch (RuntimeException e) { tx.rollback(); throw e; } log(\"updated book: \" + book); }} 对于安全检查、日志、事务等代码，它们会重复出现在每个业务方法中。使用OOP，我们很难将这些四处分散的代码模块化。 考察业务模型可以发现，BookService关心的是自身的核心逻辑，但整个系统还要求关注安全检查、日志、事务等功能，这些功能实际上“横跨”多个业务方法，为了实现这些功能，不得不在每个业务方法上重复编写代码。 一种可行的方式是使用Proxy模式，将某个功能，例如，权限检查，放入Proxy中： 1234567891011121314151617181920212223242526public class SecurityCheckBookService implements BookService { private final BookService target; public SecurityCheckBookService(BookService target) { this.target = target; } public void createBook(Book book) { securityCheck(); target.createBook(book); } public void updateBook(Book book) { securityCheck(); target.updateBook(book); } public void deleteBook(Book book) { securityCheck(); target.deleteBook(book); } private void securityCheck() { ... }} 这种方式的缺点是比较麻烦，必须先抽取接口，然后，针对每个方法实现Proxy。 另一种方法是，既然SecurityCheckBookService的代码都是标准的Proxy样板代码，不如把权限检查视作一种切面（Aspect），把日志、事务也视为切面，然后，以某种自动化的方式，把切面织入到核心逻辑中，实现Proxy模式。 如果我们以AOP的视角来编写上述业务，可以依次实现： 核心逻辑，即BookService； 切面逻辑，即： 权限检查的Aspect； 日志的Aspect； 事务的Aspect。 然后，以某种方式，让框架来把上述3个Aspect以Proxy的方式“织入”到BookService中，这样一来，就不必编写复杂而冗长的Proxy模式。 AOP原理如何把切面织入到核心逻辑中？这正是AOP需要解决的问题。换句话说，如果客户端获得了BookService的引用，当调用bookService.createBook()时，如何对调用方法进行拦截，并在拦截前后进行安全检查、日志、事务等处理，就相当于完成了所有业务功能。 在Java平台上，对于AOP的织入，有3种方式： 编译期：在编译时，由编译器把切面调用编译进字节码，这种方式需要定义新的关键字并扩展编译器，AspectJ就扩展了Java编译器，使用关键字aspect来实现织入； 类加载器：在目标类被装载到JVM时，通过一个特殊的类加载器，对目标类的字节码重新“增强”； 运行期：目标对象和切面都是普通Java类，通过JVM的动态代理功能或者第三方库实现运行期动态织入。 最简单的方式是第三种，Spring的AOP实现就是基于JVM的动态代理。由于JVM的动态代理要求必须实现接口，如果一个普通类没有业务接口，就需要通过CGLIB或者Javassist这些第三方库实现。 AOP技术看上去比较神秘，但实际上，它本质就是一个动态代理，让我们把一些常用功能如权限检查、日志、事务等，从每个业务方法中剥离出来。 需要特别指出的是，AOP对于解决特定问题，例如事务管理非常有用，这是因为分散在各处的事务代码几乎是完全相同的，并且它们需要的参数（JDBC的Connection）也是固定的。另一些特定问题，如日志，就不那么容易实现，因为日志虽然简单，但打印日志的时候，经常需要捕获局部变量，如果使用AOP实现日志，我们只能输出固定格式的日志，因此，使用AOP时，必须适合特定的场景。 装配AOP我们不用关心AOP创造的“术语”，只需要理解AOP本质上只是一种代理模式的实现方式，在Spring的容器中实现AOP特别方便。 我们以UserService和MailService为例，这两个属于核心业务逻辑，现在，我们准备给UserService的每个业务方法执行前添加日志，给MailService的每个业务方法执行前后添加日志，在Spring中，需要以下步骤： 首先，我们通过Maven引入Spring对AOP的支持： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt;&lt;/dependency&gt; 上述依赖会自动引入AspectJ，使用AspectJ实现AOP比较方便，因为它的定义比较简单。 然后，我们定义一个LoggingAspect： 123456789101112131415161718@Aspect@Componentpublic class LoggingAspect { // 在执行UserService的每个方法前执行: @Before(\"execution(public * com.itranswarp.learnjava.service.UserService.*(..))\") public void doAccessCheck() { System.err.println(\"[Before] do access check...\"); } // 在执行MailService的每个方法前后执行: @Around(\"execution(public * com.itranswarp.learnjava.service.MailService.*(..))\") public Object doLogging(ProceedingJoinPoint pjp) throws Throwable { System.err.println(\"[Around] start \" + pjp.getSignature()); Object retVal = pjp.proceed(); System.err.println(\"[Around] done \" + pjp.getSignature()); return retVal; }} 观察doAccessCheck()方法，我们定义了一个@Before注解，后面的字符串是告诉AspectJ应该在何处执行该方法，这里写的意思是：执行UserService的每个public方法前执行doAccessCheck()代码。 再观察doLogging()方法，我们定义了一个@Around注解，它和@Before不同，@Around可以决定是否执行目标方法，因此，我们在doLogging()内部先打印日志，再调用方法，最后打印日志后返回结果。 在LoggingAspect类的声明处，除了用@Component表示它本身也是一个Bean外，我们再加上@Aspect注解，表示它的@Before标注的方法需要注入到UserService的每个public方法执行前，@Around标注的方法需要注入到MailService的每个public方法执行前后。 紧接着，我们需要给@Configuration类加上一个@EnableAspectJAutoProxy注解： 123456@Configuration@ComponentScan@EnableAspectJAutoProxypublic class AppConfig { ...} Spring的IoC容器看到这个注解，就会自动查找带有@Aspect的Bean，然后根据每个方法的@Before、@Around等注解把AOP注入到特定的Bean中。执行代码，我们可以看到以下输出： 12345678[Before] do access check...[Around] start void com.itranswarp.learnjava.service.MailService.sendRegistrationMail(User)Welcome, test![Around] done void com.itranswarp.learnjava.service.MailService.sendRegistrationMail(User)[Before] do access check...[Around] start void com.itranswarp.learnjava.service.MailService.sendLoginMail(User)Hi, Bob! You are logged in at 2020-02-14T23:13:52.167996+08:00[Asia/Shanghai][Around] done void com.itranswarp.learnjava.service.MailService.sendLoginMail(User) 这说明执行业务逻辑前后，确实执行了我们定义的Aspect（即LoggingAspect的方法）。 有些童鞋会问，LoggingAspect定义的方法，是如何注入到其他Bean的呢？ 其实AOP的原理非常简单。我们以LoggingAspect.doAccessCheck()为例，要把它注入到UserService的每个public方法中，最简单的方法是编写一个子类，并持有原始实例的引用： 1234567891011121314151617181920212223public UserServiceAopProxy extends UserService { private UserService target; private LoggingAspect aspect; public UserServiceAopProxy(UserService target, LoggingAspect aspect) { this.target = target; this.aspect = aspect; } public User login(String email, String password) { // 先执行Aspect的代码: aspect.doAccessCheck(); // 再执行UserService的逻辑: return target.login(email, password); } public User register(String email, String password, String name) { aspect.doAccessCheck(); return target.register(email, password, name); } ...} 这些都是Spring容器启动时为我们自动创建的注入了Aspect的子类，它取代了原始的UserService（原始的UserService实例作为内部变量隐藏在UserServiceAopProxy中）。如果我们打印从Spring容器获取的UserService实例类型，它类似UserService$$EnhancerBySpringCGLIB$$1f44e01c，实际上是Spring使用CGLIB动态创建的子类，但对于调用方来说，感觉不到任何区别。 Spring对接口类型使用JDK动态代理，对普通类使用CGLIB创建子类。如果一个Bean的class是final，Spring将无法为其创建子类。 可见，虽然Spring容器内部实现AOP的逻辑比较复杂（需要使用AspectJ解析注解，并通过CGLIB实现代理类），但我们使用AOP非常简单，一共需要三步： 定义执行方法，并在方法上通过AspectJ的注解告诉Spring应该在何处调用此方法； 标记@Component和@Aspect； 在@Configuration类上标注@EnableAspectJAutoProxy。 至于AspectJ的注入语法则比较复杂，请参考Spring文档。 Spring也提供其他方法来装配AOP，但都没有使用AspectJ注解的方式来得简洁明了，所以我们不再作介绍。 拦截器类型顾名思义，拦截器有以下类型： @Before：这种拦截器先执行拦截代码，再执行目标代码。如果拦截器抛异常，那么目标代码就不执行了； @After：这种拦截器先执行目标代码，再执行拦截器代码。无论目标代码是否抛异常，拦截器代码都会执行； @AfterReturning：和@After不同的是，只有当目标代码正常返回时，才执行拦截器代码； @AfterThrowing：和@After不同的是，只有当目标代码抛出了异常时，才执行拦截器代码； @Around：能完全控制目标代码是否执行，并可以在执行前后、抛异常后执行任意拦截代码，可以说是包含了上面所有功能。 使用注解装配AOP上一节我们讲解了使用AspectJ的注解，并配合一个复杂的execution(* xxx.Xyz.*(..))语法来定义应该如何装配AOP。 在实际项目中，这种写法其实很少使用。假设你写了一个SecurityAspect： 1@Aspect@Componentpublic class SecurityAspect { @Before(\"execution(public * com.itranswarp.learnjava.service.*.*(..))\") public void check() { if (SecurityContext.getCurrentUser() == null) { throw new RuntimeException(\"check failed\"); } }} 基本能实现无差别全覆盖，即某个包下面的所有Bean的所有方法都会被这个check()方法拦截。 还有的童鞋喜欢用方法名前缀进行拦截： 1@Around(\"execution(public * update*(..))\")public Object doLogging(ProceedingJoinPoint pjp) throws Throwable { // 对update开头的方法切换数据源: String old = setCurrentDataSource(\"master\"); Object retVal = pjp.proceed(); restoreCurrentDataSource(old); return retVal;} 这种非精准打击误伤面更大，因为从方法前缀区分是否是数据库操作是非常不可取的。 我们在使用AOP时，要注意到虽然Spring容器可以把指定的方法通过AOP规则装配到指定的Bean的指定方法前后，但是，如果自动装配时，因为不恰当的范围，容易导致意想不到的结果，即很多不需要AOP代理的Bean也被自动代理了，并且，后续新增的Bean，如果不清楚现有的AOP装配规则，容易被强迫装配。 使用AOP时，被装配的Bean最好自己能清清楚楚地知道自己被安排了。例如，Spring提供的@Transactional就是一个非常好的例子。如果我们自己写的Bean希望在一个数据库事务中被调用，就标注上@Transactional： 1@Componentpublic class UserService { // 有事务: @Transactional public User createUser(String name) { ... } // 无事务: public boolean isValidName(String name) { ... } // 有事务: @Transactional public void updateUser(User user) { ... }} 或者直接在class级别注解，表示“所有public方法都被安排了”： 1@Component@Transactionalpublic class UserService { ...} 通过@Transactional，某个方法是否启用了事务就一清二楚了。因此，装配AOP的时候，使用注解是最好的方式。 我们以一个实际例子演示如何使用注解实现AOP装配。为了监控应用程序的性能，我们定义一个性能监控的注解： 1@Target(METHOD)@Retention(RUNTIME)public @interface MetricTime { String value();} 在需要被监控的关键方法上标注该注解： 1@Componentpublic class UserService { // 监控register()方法性能: @MetricTime(\"register\") public User register(String email, String password, String name) { ... } ...} 然后，我们定义MetricAspect： 1@Aspect@Componentpublic class MetricAspect { @Around(\"@annotation(metricTime)\") public Object metric(ProceedingJoinPoint joinPoint, MetricTime metricTime) throws Throwable { String name = metricTime.value(); long start = System.currentTimeMillis(); try { return joinPoint.proceed(); } finally { long t = System.currentTimeMillis() - start; // 写入日志或发送至JMX: System.err.println(\"[Metrics] \" + name + \": \" + t + \"ms\"); } }} 注意metric()方法标注了@Around(\"@annotation(metricTime)\")，它的意思是，符合条件的目标方法是带有@MetricTime注解的方法，因为metric()方法参数类型是MetricTime（注意参数名是metricTime不是MetricTime），我们通过它获取性能监控的名称。 有了@MetricTime注解，再配合MetricAspect，任何Bean，只要方法标注了@MetricTime注解，就可以自动实现性能监控。运行代码，输出结果如下： 1Welcome, Bob![Metrics] register: 16ms AOP避坑指南例如，UserService的初始化在UserService$$EnhancerBySpringCGLIB中并未执行，原因是，没必要初始化proxy的成员变量，因为proxy的目的是代理方法。 1234public class UserService { public final ZoneId zoneId = ZoneId.systemDefault(); public UserService() {}} 实际上，成员变量的初始化是在构造方法中完成的，这样才是编译器实际编译的代码。 1234567public class UserService { public final ZoneId zoneId; public UserService() { super(); // 构造方法的第一行代码总是调用super() zoneId = ZoneId.systemDefault(); // 继续初始化成员变量 }} 然而，对于Spring通过CGLIB动态创建的UserService$$EnhancerBySpringCGLIB代理类，它的构造方法中，并未调用super()，因此，从父类继承的成员变量，包括final类型的成员变量，统统没有初始化。 那Java语言规定，任何类的构造方法，第一行必须调用super()，如果没有，编译器也会自动加上，怎么Spring的CGLIB就可以搞特殊？ 这是因为自动加super()的功能是Java编译器实现的，它发现你没加，就自动给加上，发现你加错了，就报编译错误。但实际上，如果直接构造字节码，一个类的构造方法中，不一定非要调用super()。Spring使用CGLIB构造的Proxy类，是直接生成字节码，并没有源码-编译-字节码这个步骤。因此，Spring通过CGLIB创建的代理类，不会初始化代理类自身继承的任何成员变量，包括final类型的成员变量！ 那么，启动了AOP后，应该如何解决这个问题呢？ 很简单，只需要把直接访问字段的代码，改为通过方法访问。 1234567891011@Componentpublic class MailService { @Autowired UserService userService; public String sendMail() { // 不要直接访问UserService的字段: ZoneId zoneId = userService.getZoneId(); ... }} 此时，无论注入的UserService是原始实例还是代理实例，getZoneId()都能正常工作，因为代理类会覆写getZoneId()方法，并将其委托给原始实例。 但如果我们添加一个public final的方法： 1234567@Componentpublic class UserService { ... public final ZoneId getFinalZoneId() { return zoneId; }} 在MailService中调用getFinalZoneId()时，又会出现NullPointerException。这是因为，代理类无法覆写final方法（这一点绕不开JVM的ClassLoader检查），该方法返回的是代理类的zoneId字段，即null。 因此，正确使用AOP，我们需要一个避坑指南： 访问被注入的Bean时，总是调用方法而非直接访问字段； 编写Bean时，如果可能会被代理，就不要编写public final方法。 这样才能保证有没有AOP，代码都能正常工作。 思考为什么Spring刻意不初始化Proxy继承的字段？ 如果一个Bean不允许任何AOP代理，应该怎么做来“保护”自己在运行期不会被代理？","link":"/Study/Java/Spring/%E4%BD%BF%E7%94%A8AOP/"},{"title":"加密与安全","text":"在计算机系统中，什么是加密与安全呢？举个例子，假设Bob要给Alice发一封邮件，在邮件传送过程中，黑客可能会窃取到邮件的内容，所以要防窃听。黑客还可能会篡改邮件的内容，Alice还要能识别出邮件有没有被篡改。最后，黑客可能假冒Bob给Alice发邮件，Alice必须能识别出伪造的邮件。 所以应对潜在的威胁，必须做到以下三点： 防窃听 防篡改 防伪造 计算机加密技术就是为了实现上述目标，而现代计算机密码学理论是建立在严格的数学理论基础上的，密码学已经逐渐发展为一门科学。对于绝大多数的开发者来说，设计一个安全的加密算法非常困难，验证一个加密算法是否安全更加困难，当前被认为安全的加密算法仅仅是迄今为止尚未被攻破的。因此，要编写安全的计算机程序，我们要做到： 不要自己设计山寨的加密算法 不要自己实现已有的加密算法 不要自己修改已有的加密算法 本章我们会介绍最常用的加密算法，以及如何通过Java代码实现。 编码算法最简单的编码是直接给每个字符指定一个若干字节表示的整数，复杂一点的编码就需要根据一个已有的编码推算出来。比如UTF-8编码是一种不定长的编码，但可以从给定字符的Unicode编码推算出来。 URL编码URL编码是浏览器发送数据给服务器时使用的编码，它通常附加在URL的参数部分，例如https://www.baidu.com/s?wd=%E4%B8%AD%E6%96%87。之所以需要URL编码，是出于兼容性考虑，很多服务器只识别ASCII字符。 但如果URL中包含中文、日文这些非ASCII字符怎么办？不要紧，URL编码有一套规则： 如果字符是AZ，az，0~`9以及-、_、.、*`，则保持不变； 如果是其他字符，先转换为UTF-8编码，然后对每个字节以%XX表示。 例如：字符中的UTF-8编码是0xe4b8ad，因此，它的URL编码是%E4%B8%AD。URL编码总是大写。 Java标准库提供了一个URLEncoder类来对任意字符串进行URL编码。 和标准的URL编码稍有不同，URLEncoder把空格字符编码成+，而现在的URL编码标准要求空格被编码为%20，不过，服务器都可以处理这两种情况。 如果服务器收到URL编码的字符串，就可以对其进行解码，还原成原始字符串。Java标准库的URLDecoder就可以解码。 要特别注意：URL编码是编码算法，不是加密算法。URL编码的目的是把任意文本数据编码为%前缀表示的文本，编码后的文本仅包含AZ，az，0~`9，-，_，.，*和%`，便于浏览器和服务器处理。 Base64编码URL编码是对字符进行编码，表示成%xx的形式，而Base64编码是对二进制数据进行编码，表示成文本格式。 Base64编码可以把任意长度的二进制数据变为纯文本，且只包含AZ、az、0~`9、+、/、=`这些字符。它的原理是把3字节的二进制数据按6bit一组，用4个int整数表示，然后查表，把int整数用索引对应到字符，得到编码后的字符串。 因为6位整数的范围总是063，所以，能用64个字符表示：字符AZ对应索引025，字符az对应索引2651，字符09对应索引52~`61，最后两个索引62、63分别用字符+和/`表示。 在Java中，二进制数据就是byte[]数组。Java标准库提供了Base64来对byte[]数组进行编解码。要对Base64解码，仍然用Base64这个类。 有的童鞋会问：如果输入的byte[]数组长度不是3的整数倍肿么办？这种情况下，需要对输入的末尾补一个或两个0x00，编码后，在结尾加一个=表示补充了1个0x00，加两个=表示补充了2个0x00，解码的时候，去掉末尾补充的一个或两个0x00即可。 实际上，因为编码后的长度加上=总是4的倍数，所以即使不加=也可以计算出原始输入的byte[]。Base64编码的时候可以用withoutPadding()去掉=，解码出来的结果是一样的。 因为标准的Base64编码会出现+、/和=，所以不适合把Base64编码后的字符串放到URL中。一种针对URL的Base64编码可以在URL中使用的Base64编码，它仅仅是把+变成-，/变成_。 Base64编码的目的是把二进制数据变成文本格式，这样在很多文本中就可以处理二进制数据。例如，电子邮件协议就是文本协议，如果要在电子邮件中添加一个二进制文件，就可以用Base64编码，然后以文本的形式传送。 Base64编码的缺点是传输效率会降低，因为它把原始数据的长度增加了1/3。 和URL编码一样，Base64编码是一种编码算法，不是加密算法。 如果把Base64的64个字符编码表换成32个、48个或者58个，就可以使用Base32编码，Base48编码和Base58编码。字符越少，编码的效率就会越低。 哈希算法哈希算法（Hash）又称摘要算法（Digest），它的作用是：对任意一组输入数据进行计算，得到一个固定长度的输出概要。哈希算法最重要的特点是： 相同的输入一定得到相同的输出 不同的输入大概率得到不同的输出 哈希算法的目的是为了验证原始数据是否被篡改。Java字符串的hashCode()就是一个哈希算法，它的输入是任意字符串，输出是固定的4字节int整数。 123\"hello\".hashCode(); // 0x5e918d2\"hello, java\".hashCode(); // 0x7a9d88e8\"hello, bob\".hashCode(); // 0xa0dbae2f 两个相同的字符串永远会计算出相同的hashCode，否则基于hashCode定位的HashMap就无法正常工作。这也是为什么我们自定义一个class覆写equals()方法时，必须正确覆写hashCode()方法。 哈希碰撞哈希碰撞是指，两个不同的输入得到了相同的输出。碰撞能不能避免呢？答案是不能，因为输出字节的长度是固定的。String的hashCode()输出是4字节的整数，最多只有4294967296种输出，但输入的数据长度是不固定的，有无数种输入。 碰撞不可怕，我们担心的是碰撞的概率，因为碰撞概率的高低关系到哈希算法的安全性。一个安全的哈希算法必须满足： 碰撞概率低 不能猜测输出 不能猜测输出是指，输入的任何一个bit的变化会造成输出完全不同，这样就很难从输出反推输入（只能依靠暴力穷举），否则哈希算法就很不安全。 常用的哈希算法有： 算法 输出长度（位） 输出长度（字节） MD5 128 bits 16 bytes SHA-1 160 bits 20 bytes RipeMD-160 160 bits 20 bytes SHA-256 256 bits 32 bytes SHA-512 512 bits 64 bytes 根据碰撞概率，哈希算法的输出长度越长，就越难产生碰撞，也就越安全。 Java标准库提供了常用的哈希算法，并且有一套统一的接口。我们以MD5算法为例，看看如何对输入计算哈希： 12345678910111213import java.math.BigInteger;import java.security.MessageDigest;public class Main { public static void main(String[] args) throws Exception { // 创建一个MessageDigest实例: MessageDigest md = MessageDigest.getInstance(\"MD5\"); // 反复调用update输入数据: md.update(\"Hello\".getBytes(\"UTF-8\")); md.update(\"World\".getBytes(\"UTF-8\")); byte[] result = md.digest(); // 16 bytes: 68e109f0f40ca72a15e05cc22786f8e6 System.out.println(new BigInteger(1, result).toString(16)); }} 使用MessageDigest时，我们首先根据哈希算法获取一个MessageDigest实例，然后，反复调用update(byte[])输入数据。当输入结束后，调用digest()方法获得byte[]数组表示的摘要，最后，把它转换为十六进制的字符串。 运行上述代码，可以得到输入HelloWorld的MD5是68e109f0f40ca72a15e05cc22786f8e6。 哈希算法的用途因为相同的输入永远会得到相同的输出，因此，如果输入被修改了，得到的输出就会不同。我们在网站上下载软件的时候，经常看到下载页显示的哈希。如何判断下载到本地的软件是原始的、未经篡改的文件？我们只需要自己计算一下本地文件的哈希值，再与官网公开的哈希值对比，如果相同，说明文件下载正确，否则，说明文件已被篡改。 哈希算法的另一个重要用途是存储用户口令。如果直接将用户的原始口令存放到数据库中，会产生极大的安全风险： 数据库管理员能够看到用户明文口令； 数据库数据一旦泄漏，黑客即可获取用户明文口令。 不存储用户的原始口令，那么如何对用户进行认证？ 方法是存储用户口令的哈希，例如，MD5。 在用户输入原始口令后，系统计算用户输入的原始口令的MD5并与数据库存储的MD5对比，如果一致，说明口令正确，否则，口令错误。 因此，数据库存储用户名和口令的表内容应该像下面这样： username password bob f30aa7a662c728b7407c54ae6bfd27d1 alice 25d55ad283aa400af464c76d713c07ad tim bed128365216c019988915ed3add75fb 这样一来，数据库管理员看不到用户的原始口令。即使数据库泄漏，黑客也无法拿到用户的原始口令。想要拿到用户的原始口令，必须用暴力穷举的方法，一个口令一个口令地试，直到某个口令计算的MD5恰好等于指定值。 使用哈希口令时，还要注意防止彩虹表攻击。 什么是彩虹表呢？上面讲到了，如果只拿到MD5，从MD5反推明文口令，只能使用暴力穷举的方法。 然而黑客并不笨，暴力穷举会消耗大量的算力和时间。但是，如果有一个预先计算好的常用口令和它们的MD5的对照表： 常用口令 MD5 hello123 f30aa7a662c728b7407c54ae6bfd27d1 12345678 25d55ad283aa400af464c76d713c07ad passw0rd bed128365216c019988915ed3add75fb 19700101 570da6d5277a646f6552b8832012f5dc … … 20201231 6879c0ae9117b50074ce0a0d4c843060 这个表就是彩虹表。如果用户使用了常用口令，黑客从MD5一下就能反查到原始口令： bob的MD5：f30aa7a662c728b7407c54ae6bfd27d1，原始口令：hello123； alice的MD5：25d55ad283aa400af464c76d713c07ad，原始口令：12345678； tim的MD5：bed128365216c019988915ed3add75fb，原始口令：passw0rd。 这就是为什么不要使用常用密码，以及不要使用生日作为密码的原因。 即使用户使用了常用口令，我们也可以采取措施来抵御彩虹表攻击，方法是对每个口令额外添加随机数，这个方法称之为加盐（salt）： 1digest = md5(salt+inputPassword) 经过加盐处理的数据库表，内容如下： username salt password bob H1r0a a5022319ff4c56955e22a74abcc2c210 alice 7$p2w e5de688c99e961ed6e560b972dab8b6a tim z5Sk9 1eee304b92dc0d105904e7ab58fd2f64 加盐的目的在于使黑客的彩虹表失效，即使用户使用常用口令，也无法从MD5反推原始口令。 SHA-1SHA-1也是一种哈希算法，它的输出是160 bits，即20字节。SHA-1是由美国国家安全局开发的，SHA算法实际上是一个系列，包括SHA-0（已废弃）、SHA-1、SHA-256、SHA-512等。 在Java中使用SHA-1，和MD5完全一样，只需要把算法名称改为\"SHA-1\"。类似的，计算SHA-256，我们需要传入名称\"SHA-256\"，计算SHA-512，我们需要传入名称\"SHA-512\"。Java标准库支持的所有哈希算法可以在这里查到。 BouncyCastleJava标准库提供了一系列常用的哈希算法。但如果我们要用某种算法，Java标准库没有提供怎么办？自己写一个难度很大，所以我们找一个现成的第三方库直接使用。BouncyCastle就是一个提供了很多哈希算法和加密算法的第三方库。 我们来看一下如何使用BouncyCastle。 首先，我们把BouncyCastle提供的jar包放到classpath中。这个jar包是bcprov-jdk15on-xxx.jar，可以从官方网站下载。Java标准库的java.security包提供了一种标准机制，允许第三方提供商无缝接入。 我们要使用BouncyCastle提供的RipeMD160算法，需要先把BouncyCastle注册一下： 1234567891011public class Main { public static void main(String[] args) throws Exception { // 注册BouncyCastle: Security.addProvider(new BouncyCastleProvider()); // 按名称正常调用: MessageDigest md = MessageDigest.getInstance(\"RipeMD160\"); md.update(\"HelloWorld\".getBytes(\"UTF-8\")); byte[] result = md.digest(); System.out.println(new BigInteger(1, result).toString(16)); }} 其中，注册BouncyCastle是通过下面的语句实现的： 1Security.addProvider(new BouncyCastleProvider()); 注册只需要在启动时进行一次，后续就可以使用BouncyCastle提供的所有哈希算法和加密算法。 Hmac算法在前面讲到哈希算法时，我们说，存储用户的哈希口令时，要加盐存储，目的就在于抵御彩虹表攻击。 我们回顾一下哈希算法： 1digest = hash(input) 正是因为相同的输入会产生相同的输出，我们加盐的目的就在于，使得输入有所变化： 1digest = hash(salt + input) 这个salt可以看作是一个额外的“认证码”，同样的输入，不同的认证码，会产生不同的输出。因此，要验证输出的哈希，必须同时提供“认证码”。 Hmac算法就是一种基于密钥的消息认证码算法，它的全称是Hash-based Message Authentication Code，是一种更安全的消息摘要算法。 Hmac算法总是和某种哈希算法配合起来用的。例如，我们使用MD5算法，对应的就是HmacMD5算法，它相当于“加盐”的MD5： 1HmacMD5 ≈ md5(secure_random_key, input) 因此，HmacMD5可以看作带有一个安全的key的MD5。使用HmacMD5而不是用MD5加salt，有如下好处： HmacMD5使用的key长度是64字节，更安全； Hmac是标准算法，同样适用于SHA-1等其他哈希算法； Hmac输出和原有的哈希算法长度一致。 可见，Hmac本质上就是把key混入摘要的算法。验证此哈希时，除了原始的输入数据，还要提供key。 为了保证安全，我们不会自己指定key，而是通过Java标准库的KeyGenerator生成一个安全的随机的key。下面是使用HmacMD5的代码： 1import java.math.BigInteger;import javax.crypto.*;public class Main { public static void main(String[] args) throws Exception { KeyGenerator keyGen = KeyGenerator.getInstance(\"HmacMD5\"); SecretKey key = keyGen.generateKey(); // 打印随机生成的key: byte[] skey = key.getEncoded(); System.out.println(new BigInteger(1, skey).toString(16)); Mac mac = Mac.getInstance(\"HmacMD5\"); mac.init(key); mac.update(\"HelloWorld\".getBytes(\"UTF-8\")); byte[] result = mac.doFinal(); System.out.println(new BigInteger(1, result).toString(16)); }} 和MD5相比，使用HmacMD5的步骤是： 通过名称HmacMD5获取KeyGenerator实例； 通过KeyGenerator创建一个SecretKey实例； 通过名称HmacMD5获取Mac实例； 用SecretKey初始化Mac实例； 对Mac实例反复调用update(byte[])输入数据； 调用Mac实例的doFinal()获取最终的哈希值。 有了Hmac计算的哈希和SecretKey，我们想要验证怎么办？这时，SecretKey不能从KeyGenerator生成，而是从一个byte[]数组恢复。 恢复SecretKey的语句就是new SecretKeySpec(hkey, \"HmacMD5\")。 对称加密算法对称加密算法就是传统的用一个密码进行加密和解密。从程序的角度看，所谓加密就是这样一个函数，它接受密码和明文，然后输出密文。 1secret = encrypt(key, message); 而解密则正相反，它接受密码和密文，然后输出明文。 1plain = decrypt(key, secret); 在软件开发中，常用的对称加密算法有： 算法 密钥长度 工作模式 填充模式 DES 56/64 ECB/CBC/PCBC/CTR/… NoPadding/PKCS5Padding/… AES 128/192/256 ECB/CBC/PCBC/CTR/… NoPadding/PKCS5Padding/PKCS7Padding/… IDEA 128 ECB PKCS5Padding/PKCS7Padding/… 密钥长度直接决定加密强度，而工作模式和填充模式可以看成对称加密算法的参数和格式选择。Java标准库提供的算法实现并不包括所有的工作模式和所有的填充模式，但是通常我们只需要挑选常用的使用就可以了。 最后注意，DES算法由于密钥过短，可以在短时间内被暴力破解，现在已经不安全了。 使用AES加密AES是目前应用最广泛的加密算法。 Java标准库提供的对称加密接口非常简单，使用时按以下步骤编写代码： 根据算法名称/工作模式/填充模式获取Cipher实例； 根据算法名称初始化一个SecretKey实例，密钥必须是指定长度； 使用SerectKey初始化Cipher实例，并设置加密或解密模式； 传入明文或密文，获得密文或明文。 ECB模式是最简单的AES加密模式，它只需要一个固定长度的密钥，固定的明文会产生固定的密文，这种一对一的加密方式会导致安全性降低。更好的办法是通过CBC模式，它需要一个随机数作为IV参数，这样，对于同一份明文，每次生成的密文都不同。 在CBC模式下，需要一个随机生成的16字节IV参数，必须使用SecureRandom生成。因为多了一个IvParameterSpec实例，因此，初始化方法需要调用Cipher的一个重载方法并传入IvParameterSpec。 观察输出，可以发现每次生成的IV不同，密文也不同。 口令加密算法上一节我们讲的AES加密，细心的童鞋可能会发现，密钥长度是固定的128/192/256位，而不是我们用WinZip/WinRAR那样，随便输入几位都可以。 这是因为对称加密算法决定了口令必须是固定长度，然后对明文进行分块加密。又因为安全需求，口令长度往往都是128位以上，即至少16个字符。 但是我们平时使用的加密软件，输入6位、8位都可以，难道加密方式不一样？ 实际上用户输入的口令并不能直接作为AES的密钥进行加密（除非长度恰好是128/192/256位），并且用户输入的口令一般都有规律，安全性远远不如安全随机数产生的随机口令。因此，用户输入的口令，通常还需要使用PBE算法，采用随机数杂凑计算出真正的密钥，再进行加密。 PBE就是Password Based Encryption的缩写，它的作用如下： 1key = generate(userPassword, secureRandomPassword); PBE的作用就是把用户输入的口令和一个安全随机的口令采用杂凑后计算出真正的密钥。以AES密钥为例，我们让用户输入一个口令，然后生成一个随机数，通过PBE算法计算出真正的AES口令，再进行加密，代码如下： 1public class Main { public static void main(String[] args) throws Exception { // 把BouncyCastle作为Provider添加到java.security: Security.addProvider(new BouncyCastleProvider()); // 原文: String message = \"Hello, world!\"; // 加密口令: String password = \"hello12345\"; // 16 bytes随机Salt: byte[] salt = SecureRandom.getInstanceStrong().generateSeed(16); System.out.printf(\"salt: %032x\\n\", new BigInteger(1, salt)); // 加密: byte[] data = message.getBytes(\"UTF-8\"); byte[] encrypted = encrypt(password, salt, data); System.out.println(\"encrypted: \" + Base64.getEncoder().encodeToString(encrypted)); // 解密: byte[] decrypted = decrypt(password, salt, encrypted); System.out.println(\"decrypted: \" + new String(decrypted, \"UTF-8\")); } // 加密: public static byte[] encrypt(String password, byte[] salt, byte[] input) throws GeneralSecurityException { PBEKeySpec keySpec = new PBEKeySpec(password.toCharArray()); SecretKeyFactory skeyFactory = SecretKeyFactory.getInstance(\"PBEwithSHA1and128bitAES-CBC-BC\"); SecretKey skey = skeyFactory.generateSecret(keySpec); PBEParameterSpec pbeps = new PBEParameterSpec(salt, 1000); Cipher cipher = Cipher.getInstance(\"PBEwithSHA1and128bitAES-CBC-BC\"); cipher.init(Cipher.ENCRYPT_MODE, skey, pbeps); return cipher.doFinal(input); } // 解密: public static byte[] decrypt(String password, byte[] salt, byte[] input) throws GeneralSecurityException { PBEKeySpec keySpec = new PBEKeySpec(password.toCharArray()); SecretKeyFactory skeyFactory = SecretKeyFactory.getInstance(\"PBEwithSHA1and128bitAES-CBC-BC\"); SecretKey skey = skeyFactory.generateSecret(keySpec); PBEParameterSpec pbeps = new PBEParameterSpec(salt, 1000); Cipher cipher = Cipher.getInstance(\"PBEwithSHA1and128bitAES-CBC-BC\"); cipher.init(Cipher.DECRYPT_MODE, skey, pbeps); return cipher.doFinal(input); }} 使用PBE时，我们还需要引入BouncyCastle，并指定算法是PBEwithSHA1and128bitAES-CBC-BC。观察代码，实际上真正的AES密钥是调用Cipher的init()方法时同时传入SecretKey和PBEParameterSpec实现的。在创建PBEParameterSpec的时候，我们还指定了循环次数1000，循环次数越多，暴力破解需要的计算量就越大。 如果我们把salt和循环次数固定，就得到了一个通用的“口令”加密软件。如果我们把随机生成的salt存储在U盘，就得到了一个“口令”加USB Key的加密软件，它的好处在于，即使用户使用了一个非常弱的口令，没有USB Key仍然无法解密，因为USB Key存储的随机数密钥安全性非常高。 小结PBE算法通过用户口令和安全的随机salt计算出Key，然后再进行加密； Key通过口令和安全的随机salt计算得出，大大提高了安全性； PBE算法内部使用的仍然是标准对称加密算法（例如AES）。 密钥交换算法对称加密算法解决了数据加密的问题。我们以AES加密为例，在现实世界中，小明要向路人甲发送一个加密文件，他可以先生成一个AES密钥，对文件进行加密，然后把加密文件发送给对方。因为对方要解密，就必须需要小明生成的密钥。 现在问题来了：如何传递密钥？ 在不安全的信道上传递加密文件是没有问题的，因为黑客拿到加密文件没有用。但是，如何如何在不安全的信道上安全地传输密钥？ 要解决这个问题，密钥交换算法即DH算法：Diffie-Hellman算法应运而生。 DH算法解决了密钥在双方不直接传递密钥的情况下完成密钥交换，这个神奇的交换原理完全由数学理论支持。 我们来看DH算法交换密钥的步骤。假设甲乙双方需要传递密钥，他们之间可以这么做： 甲首选选择一个素数p，例如509，底数g，任选，例如5，随机数a，例如123，然后计算A=g^a mod p，结果是215，然后，甲发送p＝509，g=5，A=215给乙； 乙方收到后，也选择一个随机数b，例如，456，然后计算B=g^b mod p，结果是181，乙再同时计算s=A^b mod p，结果是121； 乙把计算的B=181发给甲，甲计算s＝B^a mod p的余数，计算结果与乙算出的结果一样，都是121。 所以最终双方协商出的密钥s是121。注意到这个密钥s并没有在网络上传输。而通过网络传输的p，g，A和B是无法推算出s的，因为实际算法选择的素数是非常大的。 所以更确切的说，DH算法是一个密钥协商算法，双方最终协商出一个共同的密钥，而这个密钥不会通过网络传输。如果我们把a看成甲的私钥，A看成甲的公钥，b看成乙的私钥，B看成乙的公钥，DH算法的本质就是双方各自生成自己的私钥和公钥，私钥仅对自己可见，然后交换公钥，并根据自己的私钥和对方的公钥，生成最终的密钥secretKey，DH算法通过数学定律保证了双方各自计算出的secretKey是相同的。 但是DH算法并没有解决中间人攻击，即甲乙双方不能确保与自己通信的是否真是对方。消除中间人攻击需要其他方法。 非对称加密算法从DH算法我们可以看到，公钥-私钥组成的密钥对是非常有用的加密方式，因为公钥是可以公开的，而私钥是完全保密的，由此奠定了非对称加密的基础。 非对称加密就是加密和解密使用的不是相同的密钥，只有同一个公钥、密钥对才能正常加解密。 如果小明要加密一个文件发送给小红，他应该首先向小红索取她的公钥，然后，他用小红的公钥加密，把加密文件发送给小红，此文件只能由小红的私钥解开，因为小红的私钥在她自己手里，所以，除了小红，没有任何人能解开此文件。 非对称加密的典型算法就是RSA算法，是三个哥们一起发明的，RSA取自它们名字的首字母。 非对称加密相比对称加密的显著优点在于，对称加密需要协商密钥，而非对称加密可以安全地公开各自的公钥，在N个人之间通信的时候：使用非对称加密只需要N个密钥对，每个人只管理自己的密钥对。而使用对称加密需要则需要N*(N-1)/2个密钥，因此每个人需要管理N-1个密钥，密钥管理难度大，而且非常容易泄漏。 所以，在实际应用的时候，非对称加密总是和对称加密一起使用。假设小明需要给小红需要传输加密文件，他俩首先交换了各自的公钥，然后： 小明生成一个随机的AES口令，然后用小红的公钥通过RSA加密这个口令，并发给小红； 小红用自己的RSA私钥解密得到AES口令； 双方使用这个共享的AES口令用AES加密通信。 可见非对称加密实际上应用在第一步，即加密“AES口令”。这也是我们在浏览器中常用的HTTPS协议的做法，即浏览器和服务器先通过RSA交换AES口令，接下来双方通信实际上采用的是速度较快的AES对称加密，而不是缓慢的RSA非对称加密。 以RSA算法为例，它的密钥有256/512/1024/2048/4096等不同的长度。长度越长，密码强度越大，当然计算速度也越慢。 如果修改待加密的byte[]数据的大小，可以发现，使用512bit的RSA加密时，明文长度不能超过53字节，使用1024bit的RSA加密时，明文长度不能超过117字节，这也是为什么使用RSA的时候，总是配合AES一起使用，即用AES加密任意长度的明文，用RSA加密AES口令。 此外，只使用非对称加密算法不能防止中间人攻击。 签名算法我们使用非对称加密算法的时候，对于一个公钥-私钥对，通常是用公钥加密，私钥解密。 如果使用私钥加密，公钥解密是否可行呢？实际上是完全可行的。 不过我们再仔细想一想，私钥是保密的，而公钥是公开的，用私钥加密，那相当于所有人都可以用公钥解密。这个加密有什么意义？ 这个加密的意义在于，如果小明用自己的私钥加密了一条消息，比如小明喜欢小红，然后他公开了加密消息，由于任何人都可以用小明的公钥解密，从而使得任何人都可以确认小明喜欢小红这条消息肯定是小明发出的，其他人不能伪造这个消息，小明也不能抵赖这条消息不是自己写的。 因此，私钥加密得到的密文实际上就是数字签名，要验证这个签名是否正确，只能用私钥持有者的公钥进行解密验证。使用数字签名的目的是为了确认某个信息确实是由某个发送方发送的，任何人都不可能伪造消息，并且，发送方也不能抵赖。 在实际应用的时候，签名实际上并不是针对原始消息，而是针对原始消息的哈希进行签名，即： 1signature = encrypt(privateKey, sha256(message)) 对签名进行验证实际上就是用公钥解密： 1hash = decrypt(publicKey, signature) 然后把解密后的哈希与原始消息的哈希进行对比。 因为用户总是使用自己的私钥进行签名，所以，私钥就相当于用户身份。而公钥用来给外部验证用户身份。 常用数字签名算法有： MD5withRSA SHA1withRSA SHA256withRSA 它们实际上就是指定某种哈希算法进行RSA签名的方式。 DSA签名除了RSA可以签名外，还可以使用DSA算法进行签名。DSA是Digital Signature Algorithm的缩写，它使用ElGamal数字签名算法。 DSA只能配合SHA使用，常用的算法有： SHA1withDSA SHA256withDSA SHA512withDSA 和RSA数字签名相比，DSA的优点是更快。 ECDSA算法椭圆曲线签名算法ECDSA：Elliptic Curve Digital Signature Algorithm也是一种常用的签名算法，它的特点是可以从私钥推出公钥。比特币的签名算法就采用了ECDSA算法，使用标准椭圆曲线secp256k1。BouncyCastle提供了ECDSA的完整实现。 数字证书我们知道，摘要算法用来确保数据没有被篡改，非对称加密算法可以对数据进行加解密，签名算法可以确保数据完整性和抗否认性，把这些算法集合到一起，并搞一套完善的标准，这就是数字证书。 因此，数字证书就是集合了多种密码学算法，用于实现数据加解密、身份认证、签名等多种功能的一种安全标准。 数字证书可以防止中间人攻击，因为它采用链式签名认证，即通过根证书（Root CA）去签名下一级证书，这样层层签名，直到最终的用户证书。而Root CA证书内置于操作系统中，所以，任何经过CA认证的数字证书都可以对其本身进行校验，确保证书本身不是伪造的。 我们在上网时常用的HTTPS协议就是数字证书的应用。浏览器会自动验证证书的有效性。 以HTTPS协议为例，浏览器和服务器建立安全连接的步骤如下： 浏览器向服务器发起请求，服务器向浏览器发送自己的数字证书； 浏览器用操作系统内置的Root CA来验证服务器的证书是否有效，如果有效，就使用该证书加密一个随机的AES口令并发送给服务器； 服务器用自己的私钥解密获得AES口令，并在后续通讯中使用AES加密。 上述流程只是一种最常见的单向验证。如果服务器还要验证客户端，那么客户端也需要把自己的证书发送给服务器验证，这种场景常见于网银等。 注意：数字证书存储的是公钥，以及相关的证书链和算法信息。私钥必须严格保密，如果数字证书对应的私钥泄漏，就会造成严重的安全威胁。如果CA证书的私钥泄漏，那么该CA证书签发的所有证书将不可信。数字证书服务商DigiNotar就发生过私钥泄漏导致公司破产的事故。","link":"/Study/Java/%E5%8A%A0%E5%AF%86%E4%B8%8E%E5%AE%89%E5%85%A8/"},{"title":"单元测试","text":"本节我们介绍Java平台最常用的测试框架JUnit，并详细介绍如何编写单元测试。 编写JUnit单元测试大部分情况是我们编写好了实现代码，需要对已有的代码进行测试。要测试一个方法，一个很自然的想法是编写一个main()方法，然后运行一些测试代码。不过，使用main()方法测试有很多缺点：一是只能有一个main()方法，不能把测试代码分离；二是没有打印出测试结果和期望结果，例如，expected: 3628800, but actual: 123456；三是很难编写一组通用的测试代码。 因此，我们需要一种测试框架，帮助我们编写测试。 JUnitJUnit是一个开源的Java语言的单元测试框架，专门针对Java开发，使用最广泛。JUnit是事实上的单元测试的标准框架，任何Java开发者都应当学习并使用JUnit编写单元测试。 使用JUnit编写单元测试的好处在于，我们可以非常简单地组织测试代码，并随时运行它们，JUnit就会给出成功的测试和失败的测试，还可以生成测试报告，不仅包含测试的成功率，还可以统计测试的代码覆盖率，即被测试的代码本身有多少经过了测试。对于高质量的代码来说，测试覆盖率应该在80%以上。 几乎所有的IDE都集成了JUnit，这样我们就可以直接在IDE中编写并运行JUnit测试。 假定我们编写了一个计算阶乘的类，它只有一个静态方法来计算阶乘： 123456789public class Factorial { public static long fact(long n) { long r = 1; for (long i = 1; i &lt;= n; i++) { r = r * i; } return r; }} 我们来看一下FactorialTest.java的内容： 12345678910111213141516package xxx;import static org.junit.jupiter.api.Assertions.*;import org.junit.jupiter.api.Test;public class FactorialTest { @Test void testFact() { assertEquals(1, Factorial.fact(1)); assertEquals(2, Factorial.fact(2)); assertEquals(6, Factorial.fact(3)); assertEquals(3628800, Factorial.fact(10)); assertEquals(2432902008176640000L, Factorial.fact(20)); }} 核心测试方法加上@Test注解，这是JUnit要求的，它会把带有@Test的方法识别为测试方法。在测试方法内部，我们用assertEquals(1, Factorial.fact(1))表示期望Factorial.fact(1)返回1。assertEquals(expected, actual)是最常用的测试方法，它在Assertion类中定义。Assertion还定义了其他断言方法，例如： assertTrue(): 期待结果为true assertFalse(): 期待结果为false assertNotNull(): 期待结果为非null assertArrayEquals(): 期待结果为数组并与期望数组每个元素的值均相等 … 运行单元测试非常简单，选中FactorialTest.java文件，右键点击，Run As JUnit Test，IDE会自动运行这个测试，并显示结果。如果结果与预期不符，assertEquals()会抛出异常，我们就会得到一个测试失败的结果。在Failure Trace中，JUnit会告诉我们详细的错误结果。 12org.opentest4j.AssertionFailedError: expected: &lt;3628800&gt; but was: &lt;362880&gt;... 第一行的失败信息的意思是期待结果3628800，但是实际返回362880，此时，我们要么修正实现代码，要么修正测试代码，直到测试通过为止。 使用浮点数时，由于浮点数无法精确的进行比较，因此，我们需要调用assertEquals(double expected, double actual, double delta)这个重载方法，指定一个误差值： 1assertEquals(0.1, Math.abs(1 - 9 / 10.0), 0.0000001); 单元测试的好处单元测试可以确保单个方法按照正确预期运行，如果修改了某个方法的代码，只需确保其对应的单元测试通过，即可认为改动正确。此外，测试代码本身可以作为示例代码，用来演示如何调用该方法。 使用JUnit进行单元测试，我们可以使用断言（Assertion）来测试期望结果，可以方便地组织和运行测试，并方便的查看测试结果。另外，JUnit既可以直接在IDE中运行，也可以方便的集成到Maven这些自动化工具中运行。 在编写单元测试的时候，我们要遵循一定的规范： 一是单元测试代码本身必须非常简单，能一下看明白，绝不能再为测试代码编写测试； 二是每个单元测试应当互相独立，不依赖运行的顺序； 三是测试时不但要覆盖常用测试用例，还要特别注意测试边界条件，例如输入为0，null，空白字符串\" \"等情况。 使用Fixture在一个单元测试中，我们经常编写多个@Test方法，来分组、分类对目标代码进行测试。在测试的时候，我们经常遇到一个对象需要初始化，测试完可能还需要清理的情况。如果每个@Test方法都写一遍这样的重复代码，显然比较麻烦。JUint提供了编写测试前准备、测试后清理的固定代码，我们称之为Fixture。 这个类的功能很简单，但是测试的时候，我们要先初始化对象，我们不必在每个测试方法中都写上初始化代码，而是通过@BeforeEach来初始化，通过@AfterEach来清理资源： 12345678910111213141516171819202122232425262728public class CalculatorTest { Calculator calculator; @BeforeEach public void setUp() { this.calculator = new Calculator(); } @AfterEach public void tearDown() { this.calculator = null; } @Test void testAdd() { assertEquals(100, this.calculator.add(100)); assertEquals(150, this.calculator.add(50)); assertEquals(130, this.calculator.add(-20)); } @Test void testSub() { assertEquals(-100, this.calculator.sub(100)); assertEquals(-150, this.calculator.sub(50)); assertEquals(-130, this.calculator.sub(-20)); }} 在CalculatorTest测试中，有两个标记为@BeforeEach和@AfterEach的方法，它们会在运行每个@Test方法前后自动运行。 上面的测试代码在JUnit中运行顺序如下： 123456for (Method testMethod : findTestMethods(CalculatorTest.class)) { var test = new CalculatorTest(); // 创建Test实例 invokeBeforeEach(test); invokeTestMethod(test, testMethod); invokeAfterEach(test);} 可见，@BeforeEach和@AfterEach会“环绕”在每个@Test方法前后。 还有一些资源初始化和清理可能更加繁琐，而且会耗费较长时间，例如初始化数据库。JUnit还提供了@BeforeAll和@AfterAll，它们在运行所有@Test前后运行。顺序如下： 12345678invokeBeforeAll(CalculatorTest.class);for (Method testMethod : findTestMethods(CalculatorTest.class)) { var test = new CalculatorTest(); // 创建Test实例 invokeBeforeEach(test); invokeTestMethod(test, testMethod); invokeAfterEach(test);}invokeAfterAll(CalculatorTest.class); 因为@BeforeAll和@AfterAll在所有@Test方法运行前后仅运行一次，因此，他们只能初始化静态变量。例如： 12345678910111213public class DatabaseTest { static Database db; @BeforeAll public static void initDatabase() { db = createDb(...); } @AfterAll public static void dropDatabase() { ... }} 事实上，@BeforeAll和@AfterAll也只能标注在静态方法上。 因此，我们总结出编写Fixture的套路如下： 对于实例变量，在@BeforeEach中初始化，在@AfterEach中清理，它们在各个@Test方法中互不影响，因为是不同的实例； 对于静态变量，在@BeforeAll中初始化，在@AfterAll中清理，它们在各个@Test方法中均是唯一实例，会影响各个@Test方法。 大多数情况下，使用@BeforeEach和@AfterEach就足够了。只有某些测试资源初始化耗费时间太长，以至于我们不得不尽量“复用”时才会用到@BeforeAll和@AfterAll。 最后，注意到每次运行一个@Test方法前，JUnit首先创建一个XxxTest实例，因此，每个@Test方法内部的成员变量都是独立的，不能也无法把成员变量的状态从一个@Test方法带到另一个@Test方法。 异常测试在Java程序中，异常处理是非常重要的。我们自己编写的方法，也经常抛出异常。对于可能抛出异常进行测试，本身就是测试的重要环节。因此，在编写JUnit测试时，除了正常的输入输出，我们还要特定针对可能导致异常的情况进行测试。 我们仍然用Factorial举例： 1public class Factorial { public static long fact(long n) { if (n &lt; 0) { throw new IllegalArgumentException(); } long r = 1; for (long i = 1; i &lt;= n; i++) { r = r * i; } return r; }} 在方法入口，我们增加了对参数n的检查，如果为负数，则直接抛出IllegalArgumentException。 现在，我们希望对异常进行测试。在JUnit测试中，我们可以编写一个@Test方法专门测试异常： 1@Testvoid testNegative() { assertThrows(IllegalArgumentException.class, new Executable() { @Override public void execute() throws Throwable { Factorial.fact(-1); } });} JUnit提供assertThrows()来期望捕获一个指定的异常。第二个参数Executable封装了我们要执行的会产生异常的代码。当我们执行Factorial.fact(-1)时，必定抛出IllegalArgumentException。assertThrows()在捕获到指定异常时表示通过测试，未捕获到异常，或者捕获到的异常类型不对，均表示测试失败。 有些同学可能觉得编写一个Executable的匿名类太繁琐了，实际上，Java 8开始引入了函数式编程，所有单方法接口都可以简写如下： 1@Testvoid testNegative() { assertThrows(IllegalArgumentException.class, () -&gt; { Factorial.fact(-1); });} 上述奇怪的-&gt;语法就是函数式接口的实现代码，我们会在后面详细介绍。现在，我们只需要通过这种固定的代码编写能抛出异常的语句即可。 条件测试在运行测试的时候，有时我们需要排除某些@Test方法，不要让它运行。这时，我们就可以给他标记一个@Disable： 1@Disabled@Testvoid testBug101() { // 这个测试不会运行} 为什么我们不直接注释掉@Test，而是加一个@Disable呢？这是因为注释掉@Test，JUnit就不知道这是一个测试方法，而加上@Disable，JUnit仍然识别出这是个测试方法，只是暂时不运行，他会在测试结果中显示： 1Tests run: 68, Failures: 2, Errors: 0, Skipped: 5 类似@Disable这种注解就称为条件测试，JUnit根据不同的条件注解，决定是否运行当前的@Test方法。 我们来看一个例子： 1public class Config { public String getConfigFile(String filename) { String os = System.getProperty(\"os.name\").toLowerCase(); if (os.contains(\"win\")) { return \"C:\\\\\" + filename; } if (os.contains(\"mac\") || os.contains(\"linux\") || os.contains(\"unix\")) { return \"/usr/local/\" + filename; } throw new UnsupportedOperationException(); }} 我们想要测试getConfigFile()这个方法，但是在Windows上跑，和在Linux上跑的代码路径不同，因此，针对两个系统的测试方法，其中一个只能在Windows上跑，另一个只能在Mac/Linux上跑： 1@Testvoid testWindows() { assertEquals(\"C:\\\\test.ini\", config.getConfigFile(\"test.ini\"));}@Testvoid testLinuxAndMac() { assertEquals(\"/usr/local/test.cfg\", config.getConfigFile(\"test.cfg\"));} 因此，我们给两个测试方法分别加上条件如下： 1@Test@EnabledOnOs(OS.WINDOWS)void testWindows() { assertEquals(\"C:\\\\test.ini\", config.getConfigFile(\"test.ini\"));}@Test@EnabledOnOs({ OS.LINUX, OS.MAC })void testLinuxAndMac() { assertEquals(\"/usr/local/test.cfg\", config.getConfigFile(\"test.cfg\"));} @EnableOnOs就是一个条件测试判断。 不在Windows平台执行的测试，可以加上@DisableOnOs(OS.WINDOWS)。 只能在Java 9及更高版本执行的测试，可以加上@DisableOnJre(JRE.JAVA_8)。 只能在64位操作系统上执行的测试，可以用@EnableIfSystemProperty判断。 需要传入环境变量DEBUG=true才能执行的测试，可以用@EnableIfEnvironmentVariable。 1@Test@EnabledIfEnvironmentVariable(named = \"DEBUG\", matches = \"true\")void testOnlyOnDebugMode() { // TODO: this test is only run on DEBUG=true} 当我们在JUnit中运行所有的测试的时候，JUnit会给出执行的结果。在IDE中，我们很容易地看到没有执行的测试。 参数化测试如果待测试的输入和输出是一组数据：可以把测试数据组织起来，用不同的测试数据调用相同的测试方法。参数化测试和普通测试不同的地方在于，一个测试方法需要至少接受一个参数，然后，传入一组参数反复运行。 JUnit提供了一个@ParameterizedTest注解，用来进行参数化测试。 假设我们想对Math.abs()进行测试，先用一组正数进行测试： 1@ParameterizedTest@ValueSource(ints = { 0, 1, 5, 100 })void testAbs(int x) { assertEquals(x, Math.abs(x));} 再用一组负数进行测试： 1@ParameterizedTest@ValueSource(ints = { -1, -5, -100 })void testAbsNegative(int x) { assertEquals(-x, Math.abs(x));} 注意到参数化测试的注解是@ParameterizedTest，而不是普通的@Test。 实际的测试场景往往没有那么简单。 假设我们自己编写了一个StringUtils.capitalize()方法，它会把字符串的第一个字母变为大写，后续字母变为小写： 1public class StringUtils { public static String capitalize(String s) { if (s.length() == 0) { return s; } return Character.toUpperCase(s.charAt(0)) + s.substring(1).toLowerCase(); }} 要用参数化测试的方法来测试，我们不但要给出输入，还要给出预期输出。因此，测试方法至少需要接收两个参数： 1@ParameterizedTestvoid testCapitalize(String input, String result) { assertEquals(result, StringUtils.capitalize(input));} 现在问题来了：参数如何传入？ 最简单的方法是通过@MethodSource注解，它允许我们编写一个同名的静态方法来提供测试参数： 1@ParameterizedTest@MethodSourcevoid testCapitalize(String input, String result) { assertEquals(result, StringUtils.capitalize(input));}static List&lt;Arguments&gt; testCapitalize() { return List.of( // arguments: Arguments.arguments(\"abc\", \"Abc\"), // Arguments.arguments(\"APPLE\", \"Apple\"), // Arguments.arguments(\"gooD\", \"Good\"));} 上面的代码很容易理解：静态方法testCapitalize()返回了一组测试参数，每个参数都包含两个String，正好作为测试方法的两个参数传入。如果静态方法和测试方法的名称不同，@MethodSource也允许指定方法名，但使用默认同名方法最简便。 另一种传入测试参数的方法是使用@CsvSource，它的每一个字符串表示一行，一行包含的若干参数用,分隔，因此，上述测试又可以改写如下： 1@ParameterizedTest@CsvSource({ \"abc, Abc\", \"APPLE, Apple\", \"gooD, Good\" })void testCapitalize(String input, String result) { assertEquals(result, StringUtils.capitalize(input));} 如果有成百上千的测试输入，那么，直接写@CsvSource就很不方便。这个时候，我们可以把测试数据提到一个独立的CSV文件中，然后标注上@CsvFileSource： 1@ParameterizedTest@CsvFileSource(resources = { \"/test-capitalize.csv\" })void testCapitalizeUsingCsvFile(String input, String result) { assertEquals(result, StringUtils.capitalize(input));} JUnit只在classpath中查找指定的CSV文件，因此，test-capitalize.csv这个文件要放到test目录下，内容如下： 1apple, AppleHELLO, HelloJUnit, JunitreSource, Resource","link":"/Study/Java/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"title":"反射","text":"什么是反射？反射就是Reflection，Java的反射是指程序在运行期可以拿到一个对象的所有信息。反射是为了解决在运行期，对某个实例一无所知的情况下，如何调用其方法。正常情况下，如果我们要调用一个对象的方法，或者访问一个对象的字段，通常会传入对象实例。 Class类除了int等基本类型外，Java的其他类型全部都是class（包括interface）。仔细思考我们可以得出结论：class的本质是数据类型（Type）。无继承关系的数据类型无法赋值： 12Number n = new Double(123.456); // OKString s = new Double(123.456); // compile error! 而class是由JVM在执行过程中动态加载的。JVM在第一次读取到一种class类型时，将其加载到内存。每加载一种class，JVM就为其创建一个Class类型的实例，并关联起来。注意，这里的Class类型是一个名叫Class的class。它长这样： 123public final class Class{ private Class(){};} 以String类为例，当JVM加载String类时，它首先读取String.class类到内存，然后为String类创建一个Class实例并关联起来。 1Class cls = new Class(String); 这个Class实例是JVM内部创建的，如果我们查看JDK源码，可以发现Class类的构造方法是private，只有JVM能创建Class实例，我们自己的Java程序是无法创建Class实例的。 所以，JVM持有的每个Class实例都指向一个数据类型（class或interface）。一个Class实例包含了该class的所有信息。 12345678910111213141516171819202122232425262728293031┌───────────────────────────┐│ Class Instance │──────&gt; String├───────────────────────────┤│name = \"java.lang.String\" │└───────────────────────────┘┌───────────────────────────┐│ Class Instance │──────&gt; Random├───────────────────────────┤│name = \"java.util.Random\" │└───────────────────────────┘┌───────────────────────────┐│ Class Instance │──────&gt; Runnable├───────────────────────────┤│name = \"java.lang.Runnable\"│└───────────────────────────┘┌───────────────────────────┐│ Class Instance │──────&gt; String├───────────────────────────┤│name = \"java.lang.String\" │├───────────────────────────┤│package = \"java.lang\" │├───────────────────────────┤│super = \"java.lang.Object\" │├───────────────────────────┤│interface = CharSequence...│├───────────────────────────┤│field = value[],hash,... │├───────────────────────────┤│method = indexOf()... │└───────────────────────────┘ 由于JVM为每个加载的class创建了对应的Class实例，并在实例中保存了该class的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段等，因此，如果获取了某个Class实例，我们就可以通过这个Class实例获取到对应的class的所有信息。 这种通过Class实例获取class信息的方法称为反射（Reflection）。 如何获取一个class的Class实例？有三个方法： 方法一：直接通过一个class的静态变量class获取 1Class cls = String.class; 方法二：如果我们有一个实例变量，可以通过该实例变量提供的getClass()方法获取。 12String s = \"Hello\";Class cls = s.getClass(); 方法三：如果知道一个class的完整类名，可以通过Class.forName()获取。 1Class cls = Class.forName(\"java.lang.String\"); 因为Class实例在JVM中是唯一的，所以上述方法获取的Class实例是同一个实例。 注意一下Class实例比较和instanceof的差别。用instanceof不但匹配指定的类型，还匹配指定的子类。而用==判断class实例可以精确地判断数据类型，但不能作为子类型比较。 通常情况下，我们应该用instanceof判断数据类型，因为面向抽象编程的时候，我们不关心具体的子类型。只有在需要精确判断一个类型是不是某个class时，我们才使用==判断class实例。 因为反射的目的是为了获取某个实例的信息。因此，当我们拿到某个Object实例时，我们可以通过反射获取该Object的class信息。 注意到数组也是一种Class，例如String[]，而且不同于String.class，它的类名是[Ljava.lang.String。此外，JVM为每一种基本类型如int也创建了Class，通过int.class访问。 如果获取到一个Class实例，我们就可以通过该Class实例来创建对应类型的实例： 1234// 获取String的Class实例:Class cls = String.class;// 创建一个String实例:String s = (String) cls.newInstance(); 上述代码相当于new String()。通过Class.newInstance()可以创建类实例，它的局限是：只能调用public的无参数构造方法。带参数的构造方法，或者非public的构造方法都无法通过Class.newInstance()被调用。 动态加载JVM在执行Java程序时，并不是一次性把所有用到的class全部加载到内存，而是第一次需要用到class时才加载。 1234567891011// Main.javapublic class Main { public static void main(String[] args) { if (args.length &gt; 0) { create(args[0]); } } static void create(String name) { Person p = new Person(name); }} 当执行Main.java时，由于用到了Main，因此，JVM首先会把Main.class加载到内存。然而，并不会加载Person.class，除非程序执行到create()方法，JVM发现需要加载Person类时，才会首次加载Person.class。如果没有执行create()方法，那么Person.class根本就不会被加载。 这就是JVM动态加载class的特性。 动态加载class的特性对于Java程序非常重要。利用JVM动态加载class的特性，我们才能在运行期根据条件加载不同的实现类。例如，Commons Logging总是优先使用Log4j，只有当Log4j不存在时，才使用JDK的logging。利用JVM的动态加载特性，大致的实现代码如下： 12345678910111213141516// Commons Logging优先使用Log4j:LogFactory factory = null;if (isClassPresent(\"org.apache.logging.log4j.Logger\")) { factory = createLog4j();} else { factory = createJdkLog();}boolean isClassPresent(String name) { try { Class.forName(name); return true; } catch (Exception e) { return false; }} 这就是为什么我们只需要把Log4j的jar包放到classpath中，Commons Logging就会自动使用Log4j的原因。 访问字段我们先看看如何通过Class实例获取字段信息。Class类提供了以下几个方法来获取字段： Field getField(name)：根据字段名获取某个public的field（包括父类） Field getDeclaredField(name)：根据字段名获取当前类的某个field（不包括父类） Field[] getFields()：获取所有public的field（包括父类） Field[] getDeclaredFields()：获取当前类的所有field（不包括父类） 123456789101112131415161718public class Main { public static void main(String[] args) throws Exception { Class stdClass = Student.class; // 获取public字段\"score\": System.out.println(stdClass.getField(\"score\")); // 获取继承的public字段\"name\": System.out.println(stdClass.getField(\"name\")); // 获取private字段\"grade\": System.out.println(stdClass.getDeclaredField(\"grade\")); }}class Student extends Person { public int score; private int grade;}class Person { public String name;} 上述代码首先获取获取Student的Class实例，然后分别获取public字段、继承的public字段以及private字段，打印出的Field类似： 123public int Student.scorepublic java.lang.String Person.nameprivate int Student.grade 一个Field对象包含了一个字段的所有信息。 getName()，返回字段名称，例如，“name” getType()，返回字段类型，也是一个Class实例，例如，String.class getModifiers()，返回字段的修饰符，它是一个int，不同的bit代表不同的含义 以String类的value字段为例，我们用反射获取该字段的信息，代码如下： 12345678910111213public final class String { private final byte[] value;}Field f = String.class.getDeclaredField(\"value\");f.getName(); // \"value\"f.getType(); // class [B 表示byte[]类型int m = f.getModifiers();Modifier.isFinal(m); // trueModifier.isPublic(m); // falseModifier.isProtected(m); // falseModifier.isPrivate(m); // trueModifier.isStatic(m); // false 获取字段值利用反射拿到字段的一个Field实例，我们还可以拿到一个实例对应的该字段的值。 例如，对于一个Person实例，我们可以先拿到name字段对应的Field，再获取这个实例的name字段的值。 123456789101112131415public class Main { public static void main(String[] args) throws Exception { Object p = new Person(\"Xiao Ming\"); Class c = p.getClass(); Field f = c.getDeclaredField(\"name\"); Object value = f.get(p); System.out.println(value); // \"Xiao Ming\" }}class Person { private String name; public Person(String name) { this.name = name; }} 上述代码先获取Class实例，再获取Field实例，然后用Field.get(Object)获取指定实例的指定字段值。运行代码，如果不出意外，会得到一个IllegalAccessException，这是因为name被定义为一个private字段，正常情况下，Main类无法访问Person类的private字段。要修复错误，可以将private改为public，或者，在调用Object value = f.get(p);前，先写一句：f.setAccessible(true);。调用Field.setAccessible(true)的意思是，别管这个字段是不是public，一律允许访问。 有同学会问：如果使用反射可以获取private字段的值，那么类的封装还有什么意义？ 答案是正常情况下，我们总是通过p.name来访问Person的name字段，编译器会根据public、protected和private决定是否允许访问字段，这样就达到了数据封装的目的。 而反射是一种非常规的用法，使用反射，首先代码非常繁琐，其次，它更多地是给工具或底层框架来使用，目的是在不知道目标实例任何信息的情况下，获取特定字段的值。此外，setAccessible(true)可能会失败。如果JVM运行期存在SecurityManager，那么它会根据规则进行检查，有可能阻止setAccessible(true)。例如，某个SecurityManager可能不允许对java和javax开头的package的类调用setAccessible(true)，这样可以保证JVM核心库的安全。 设置字段值通过Field实例既然可以获取到指定实例的字段值，自然也可以设置字段的值。设置字段值是通过Field.set(Object, Object)实现的，第一个Object参数是指定的实例，第二个Object参数是待修改的值。 同样的，修改非public字段，需要首先调用setAccessible(true)。 调用方法我们已经通过Class实例获取所有Field对象，同样的，可以通过Class实例获取所有的Method信息。Class类提供了以下几个方法来获取Method： Method getMethod(name, Class…)：获取某个public的Method（包括父类） Method getDeclaredMethod(name, Class…)：获取当前类的某个Method（不包括父类） Method[] getMethods()：获取所有public的Method（包括父类） Method[] getDeclaredMethods()：获取当前类的所有Method（不包括父类） 我们来看一下实例代码： 123456789101112131415161718192021222324public class Main { public static void main(String[] args) throws Exception { Class stdClass = Student.class; // 获取public方法getScore，参数为String: System.out.println(stdClass.getMethod(\"getScore\", String.class)); // 获取继承的public方法getName，无参数: System.out.println(stdClass.getMethod(\"getName\")); // 获取private方法getGrade，参数为int: System.out.println(stdClass.getDeclaredMethod(\"getGrade\", int.class)); }}class Student extends Person { public int getScore(String type) { return 99; } private int getGrade(int year) { return 1; }}class Person { public String getName() { return \"Person\"; }} 上述代码首先获取Student的Class实例，然后分别获取public方法、继承的public方法以及private方法，打印出来的Method类似： 123public int Student.getScore(java.lang.String)public java.lang.String Person.getName()private int Student.getGrade(int) 一个Method对象包含一个方法的所有信息： getName()：返回方法名称，例如：”getScore”； getReturnType()：返回方法返回值类型，也是一个Class实例，例如：String.class； getParameterTypes()：返回方法的参数类型，是一个Class数组，例如：{String.class, int.class}； getModifiers()：返回方法的修饰符，它是一个int，不同的bit表示不同的含义。 调用方法当我们获取到一个Method对象时，就可以对它进行调用。以下面的代码为例： 12String s = \"Hello world\";String r = s.substring(6); // \"world\" 如果用反射来调用substring方法，需要以下代码： 123456789101112public class Main { public static void main(String[] args) throws Exception { // String对象: String s = \"Hello world\"; // 获取String substring(int)方法，参数为int: Method m = String.class.getMethod(\"substring\", int.class); // 在s对象上调用该方法并获取结果: String r = (String) m.invoke(s, 6); // 打印调用结果: System.out.println(r); }} 对Method实例调用invoke就相当于调用该方法，invoke的第一个参数是对象实例，即在哪个实例上调用该方法，后面的可变参数要与方法参数一致，否则将报错。 调用静态方法如果获取到的Method表示一个静态方法，调用静态方法时，由于无需指定实例对象，所以invoke方法传入的第一个参数永远为null。我们以Integer.parseInt(String)为例： 12345678910public class Main { public static void main(String[] args) throws Exception { // 获取Integer.parseInt(String)方法，参数为String: Method m = Integer.class.getMethod(\"parseInt\", String.class); // 调用该静态方法并获取结果: Integer n = (Integer) m.invoke(null, \"12345\"); // 打印调用结果: System.out.println(n); }} 调用非public方法和Field类似，对于非public方法，我们虽然可以通过Class.getDeclaredMethod()获取该方法实例，但直接对其调用将得到一个IllegalAccessException。为了调用非public方法，我们通过Method.setAccessible(true)允许其调用： 123456789101112131415public class Main { public static void main(String[] args) throws Exception { Person p = new Person(); Method m = p.getClass().getDeclaredMethod(\"setName\", String.class); m.setAccessible(true); m.invoke(p, \"Bob\"); System.out.println(p.name); }}class Person { String name; private void setName(String name) { this.name = name; }} 此外，setAccessible(true)可能会失败。如果JVM运行期存在SecurityManager，那么它会根据规则进行检查，有可能阻止setAccessible(true)。例如，某个SecurityManager可能不允许对java和javax开头的package的类调用setAccessible(true)，这样可以保证JVM核心库的安全。 多态我们来考察这样一种情况：一个Person类定义了hello()方法，并且它的子类Student也覆写了hello()方法，那么从Person.class获取的Method，作用于Student实例时，调用方法到底是哪个？测试一下发现，使用反射调用方法时，仍然遵循多态原则：即总是调用实际类型的覆写方法。 调用构造方法我们通常使用new操作符创建新的实例。如果通过反射来创建新的实例，可以调用Class提供的newInstance()方法。 1Person p = Person.class.newInstance(); 调用Class.newInstance()的局限是，它只能调用该类的public无参数构造方法。如果构造方法带有参数，或者不是public，就无法直接通过Class.newInstance()来调用。 为了调用任意的构造方法，Java的反射API提供了Constructor对象，它包含一个构造方法的所有信息，可以创建一个实例。Constructor对象和Method对象非常像，不同之处仅在于它是一个构造方法，并且调用结果总是返回实例。 通过Class实例获取Constructor的方法如下： getConstructor(Class…)：获取某个public的Constructor； getDeclaredConstructor(Class…)：获取某个Constructor； getConstructors()：获取所有public的Constructor； getDeclaredConstructors()：获取所有Constructor。 注意，Constructor总是当前类定义的构造方法，和父类无关，因此不存在多态的问题。 调用非public的Constructor时，必须首先通过setAccessible(true)设置允许访问。setAccessible(true)可能会失败。 获取继承关系获取父类的class。 12345678910public class Main { public static void main(String[] args) throws Exception { Class i = Integer.class; Class n = i.getSuperclass(); System.out.println(n); Class o = n.getSuperclass(); System.out.println(o); System.out.println(o.getSuperclass()); }} 运行上述代码，可以看到，Integer的父类类型是Number，Number的父类是Object，Object的父类是null。除Object外，其他任何非interface的Class都必定存在一个父类类型。 获取interface由于一个类可能实现一个或多个接口，通过Class我们就可以查询到实现的接口类型。例如，查询Integer实现的接口： 123456789public class Main { public static void main(String[] args) throws Exception { Class s = Integer.class; Class[] is = s.getInterfaces(); for (Class i : is) { System.out.println(i); } }} 注意，getInterfaces()只返回当前类直接实现的接口类型，并不包括其父类实现的接口类型。 此外，对所有interface的Class调用getSuperclass()返回的是null，获取接口的父接口要用getInterfaces()。如果一个类没有实现任何interface，那么getInterfaces()返回空数组。 继承关系当我们判断一个实例是否是某个类型时，正常情况下使用instanceof操作符。如果是两个Class实例，要判断一个向上转型是否成立，可以调用isAssignableFrom()。 12345678// Integer i = ?Integer.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Integer// Number n = ?Number.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Number// Object o = ?Object.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Object// Integer i = ?Integer.class.isAssignableFrom(Number.class); // false，因为Number不能赋值给Integer 动态代理我们先定义了接口Hello，但是我们并不去编写实现类，而是直接通过JDK提供的一个Proxy.newProxyInstance()创建了一个Hello接口对象。这种没有实现类但是在运行期动态创建了一个接口对象的方式，我们称为动态代码。JDK提供的动态创建接口对象的方式，就叫动态代理。 1234567891011121314151617181920212223public class Main { public static void main(String[] args) { InvocationHandler handler = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method); if (method.getName().equals(\"morning\")) { System.out.println(\"Good morning, \" + args[0]); } return null; } }; Hello hello = (Hello) Proxy.newProxyInstance( Hello.class.getClassLoader(), // 传入ClassLoader new Class[] { Hello.class }, // 传入要实现的接口 handler); // 传入处理调用方法的InvocationHandler hello.morning(\"Bob\"); }}interface Hello { void morning(String name);} 在运行期动态创建一个interface实例的方法如下： 定义一个InvocationHandler实例，它负责实现接口的方法调用； 通过Proxy.newProxyInstance()创建interface实例，它需要3个参数： 使用的ClassLoader，通常就是接口类的ClassLoader； 需要实现的接口数组，至少需要传入一个接口进去； 用来处理接口方法调用的InvocationHandler实例。 将返回的Object强制转型为接口。 动态代理实际上是JVM在运行期动态创建class字节码并加载的过程。 这一节看的有点模棱两可，后面这篇文章讲的比较清楚，但也就不再总结这篇文章的大意了，需要的时候再拿过来翻翻看https://www.jianshu.com/p/95970b089360。","link":"/Study/Java/%E5%8F%8D%E5%B0%84/"},{"title":"异常处理","text":"程序运行的时候，经常会发生各种错误。本章我们讨论如何在Java程序中处理各种异常情况。 Java的异常一个健壮的程序必须能处理各种各样的错误。所谓错误，就是程序调用某个函数的时候，如果失败了就代表出错了。调用方如何获知调用失败的信息？有两种方法： 方法一：约定返回错误码。因为使用int类型的错误码，想要处理就非常麻烦。这种方法常见于底层C函数。 方法二：在语言层面提供一个异常处理机制。Java内置了一套异常处理机制，总是使用异常来表示错误。异常是一种class，因此它本身带有类型信息。异常可以在任何地方抛出，但只需要在上层捕获，这样就和方法调用分离了。 123456789101112try { String s = processFile(“C:\\\\test.txt”); // ok:} catch (FileNotFoundException e) { // file not found:} catch (SecurityException e) { // no read permission:} catch (IOException e) { // io error:} catch (Exception e) { // other error:} 从继承关系可知，Throwable是异常体系的根，它继承自Object。Throwable有两个体系：Error和Exception，Error表示严重的错误，程序对此一般无能为力，比如： OutOfMemoryError：内存耗尽 NoClassDefFoundError：无法加载某个类 StackOverflowError：栈溢出 而Exception则是运行时的错误，它可以被捕获并处理。某些异常是应用程序逻辑处理的一部分，应该捕获并处理，例如： NumberFormatException：数值类型的格式错误 FileNotFoundException：未找到文件 SocketException：读取网络失败 还有一些异常是程序逻辑编写不对造成的，应该修复程序本身。例如： NullPointerException：对某个null对象调用方法或字段 IndexOutOfBoundsException：数组索引越界 Exception又分为两大类：RuntimeException以及它的子类，非RuntimeException（包括IOException、ReflectiveOperationException等等）。 Java规定： 必须捕获的异常，包括Exception及其子类，但不包括RuntimeException及其子类，这种类型的异常称为Checked Exception。 不需要捕获的异常，包括Error及其子类，RuntimeException及其子类。 捕获异常捕获异常使用try...catch语句，把可能发生异常的代码放到try{...}中，然后使用catch捕获对应的Exception及其子类。 1234567891011121314151617public class Main { public static void main(String[] args) { byte[] bs = toGBK(\"中文\"); System.out.println(Arrays.toString(bs)); } static byte[] toGBK(String s) { try { // 用指定编码转换String为byte[]: return s.getBytes(\"GBK\"); } catch (UnsupportedEncodingException e) { // 如果系统不支持GBK编码，会捕获到UnsupportedEncodingException: System.out.println(e); // 打印异常信息 return s.getBytes(); // 尝试使用用默认编码 } }} 如果我们不捕获UnsupportEncodingException，编译器会报错，报错信息类似于：unreported exception UnsupportedEncodingException; must be caught or declared to be thrown，并且准确地指出需要捕获的语句是return s.getBytes(\"GBK\");。意思是说，像UnsupportedEncodingException这样的Checked Exception，必须被捕获。 这是因为String.getBytes(String)方法定义是： 123public byte[] getBytes(String charsetName) throws UnsupportedEncodingException { ...} 于是我们知道，在方法定义的时候，使用throw xxx表示该方法可能抛出的异常类型。调用方在调用时，必须强制捕获这些异常，否则编译器会报错。 在toGBK()方法中，因为调用了String.getBytes(String)方法，就必须捕获UnsupportedEncodingException。我们也可以不捕获它，而是在方法定义处使用throws表示toGBK()方法可能会抛出UnsupportedEncodingException，就可以让toGBK()方法通过编译器检查。 只要是方法声明的Checked Exception，不在调用层捕获，也必须在更高的调用层捕获。所有未捕获的异常，最终也必须在main()方法中捕获，这也是最后捕获Exception的机会。 如果是测试代码，上面的写法就略嫌麻烦。如果不想写任何try代码，可以直接把main()方法定义为throws Exception。因为main()方法声明了可能抛出Exception，也就声明了可能抛出的所有Exception，因此在内部就无需捕获了。代价就是一旦发生异常，程序会立刻退出。 还有一些同学喜欢捕获异常后不处理，这种方式是非常不好的，即使什么也做不了，也要把异常都记下来。所有异常都可以调用printStackTrace()方法打印异常栈，这是一个简单快速打印异常栈的方法。 多catch语句可以使用多个catch语句，每个catch分别捕获对应的Exception及其子类。JVM在捕获到异常后，会从上到下匹配catch语句，匹配到某个catch后，执行catch代码块，然后不在继续匹配。简单地说就是，多个catch语句只有一个能被执行。 因此，存在多个catch语句时，catch的顺序非常重要，子类必须写在前面。 finally语句无论是否有异常发生，我们都希望执行一些语句，例如清理工作，怎么写？ Java的try…catch机制还提供了finally语句，finally语句块保证有无错误都会执行。 finally有以下几个特点： finally语句不是必须的 finally总是最后执行 如果没有发生异常，就正常执行try语句块，然后执行finally。如果发生了异常，就中断执行try语句块，然后跳转执行匹配的catch语句块，最后执行finally。可见，finally用来保证一些代码必须执行。 某些情况下，例如方法声明了可能抛出的异常，可以没有catch，只使用try…finally结构。 捕获多种异常如果某些异常的处理逻辑相同，但是异常本身不存在继承关系，那么就得编写多条catch子句。但也可以用|把处理逻辑相同的异常合并到一起，就像这样。 1234567891011public static void main(String[] args) { try { process1(); process2(); process3(); } catch (IOException | NumberFormatException e) { // IOException或NumberFormatException System.out.println(\"Bad input\"); } catch (Exception e) { System.out.println(\"Unknown error\"); }} 抛出异常异常的传播当某个方法抛出了异常时，如果当前方法没有捕获异常，异常就会被抛到上层调用方法，直到遇到某个try…catch被捕获为止。 抛出异常当发生错误时，例如，用户输入了非法的字符，我们就可以抛出异常。如何抛出异常？分两步： 创建某个Exception类 用throw语句抛出 123456void process2(String s) { if (s==null) { NullPointerException e = new NullPointerException(); throw e; }} 实际上，绝大部分抛出异常的代码都会合并写到一行： 12345void process2(String s) { if (s==null) { throw new NullPointerException(); }} 如果一个方法捕获了某个异常后，又在catch子句中抛出新的异常，就相当于把抛出的异常类型“转换”了。 为了能追踪到完整的异常栈，在构造异常时，把原始的Exception实例传进去，新的Exception就可以持有原始Exception信息。 有了完整的异常栈的信息，我们才能快速定位并修复代码的问题。捕获到异常并再次抛出时，一定要留住原始异常，否则很难定位第一案发现场！ 在代码中获取原始异常可以使用Throwable.getCause()方法，如果返回null，说明已经是“根异常”了。 异常屏蔽如果在执行finally语句时抛出异常，那么catch语句的异常还能否继续抛出？finally抛出异常后，原来在catch中准备抛出的异常就“消失”了，因为只能抛出一个异常，没有被抛出的异常称为“被屏蔽”的异常（Suppressed Exception）。 在极少数情况下，我们需要获知所有的异常。如何保存所有的异常信息？方法是先用origin变量保存原始异常，然后调用Throwable.addSuppressed()，把原始异常添加进来，最后在finally抛出。 1234567891011121314151617public class Main { public static void main(String[] args) throws Exception { Exception origin = null; try { System.out.println(Integer.parseInt(\"abc\")); } catch (Exception e) { origin = e; throw e; } finally { Exception e = new IllegalArgumentException(); if (origin != null) { e.addSuppressed(origin); } throw e; } }} 当catch和finally都抛出了异常时，虽然catch的异常被屏蔽了，但是finally抛出的异常仍然包含了它。 绝大多数情况下，在finally中不要抛出异常，通常不需要关心Suppressed Exception。 提问时贴出异常异常打印的栈信息是找出问题的关键，许多初学者提问时只贴代码不贴异常，相当于只报案不给线索，福尔摩斯也无能为力。还有同学只贴部分异常信息，最关键的Caused by: xxx给省略了，这都属于不正确的提问方式，得改。 自定义异常Java标准库定义的常用异常包括： 1234567891011121314151617181920212223242526272829Exception│├─ RuntimeException│ ││ ├─ NullPointerException│ ││ ├─ IndexOutOfBoundsException│ ││ ├─ SecurityException│ ││ └─ IllegalArgumentException│ ││ └─ NumberFormatException│├─ IOException│ ││ ├─ UnsupportedCharsetException│ ││ ├─ FileNotFoundException│ ││ └─ SocketException│├─ ParseException│├─ GeneralSecurityException│├─ SQLException│└─ TimeoutException 当我们在代码中需要抛出异常时，尽量使用JDK已定义的异常类型。 在一个大型项目中，可以自定义新的异常类型，但是保持一个合理的异常继承体系是非常重要的。 一个常见的做法是自定义一个BaseException作为根异常，然后派生出各种业务类型的异常。BaseExcption需要从一个合适的Exception派生，通常建议从RuntimeException派生。 12public class BaseException extends RuntimeException{} 其他业务类型的异常就可以从BaseException派生。 1234567public class UserNotFoundException extends BaseException {}public class LoginFailedException extends BaseException {}... 自定义的BaseException应该提供多个构造方法。 1234567891011121314151617public class BaseException extends RuntimeException { public BaseException() { super(); } public BaseException(String message, Throwable cause) { super(message, cause); } public BaseException(String message) { super(message); } public BaseException(Throwable cause) { super(cause); }} 这样，抛出异常的时候，就可以选择合适的构造方法。 NullPointerException在所有的RuntimeException异常中，Java程序员最熟悉的恐怕就是NullPointerException了。NullPointerException俗称NPE，即空指针异常。如果一个对象是null，调用其方法或访问其字段就会产生NullPointerException，这个异常通常是由JVM抛出的。 指针这个概念实际上源自C语言，Java语言中并无指针。我们定义的变量实际上是引用，Null Pointer更确切地说是Null Reference，不过两者区别不大。 处理NullPointerException首先，必须明确，NullPointerException是一种代码逻辑错误，遇到NullPointerException，遵循原则是早暴露，早修复，严禁使用catch来隐藏这种编码错误。 好的编码习惯可以极大地降低NullPointerException的产生，例如，成员变量在定义时初始化： 123public class Person { private String name = \"\";} 使用空字符串\"\"而不是默认的null可避免很多NullPointerException，编写业务逻辑时，用空字符串\"\"表示未填写比null安全得多。 定位NullPointerException如果产生了NullPointerException，例如，调用a.b.c.x()时产生了NullPointerException，原因可能是： a是null a.b是null a.b.c是null 确定到底是哪个对象是null以前只能打印这样的日志： 123System.out.println(a);System.out.println(a.b);System.out.println(a.b.c); 从Java 14开始，如果产生了NullPointerException，JVM可以给出详细的信息告诉我们null对象到底是谁。 使用断言断言（Assertion）是一种调试程序的方式。在Java中，使用assert关键字来实现断言。先看一个栗子： 12345public static void main(String[] args) { double x = Math.abs(-123.45); assert x &gt;= 0; System.out.println(x);} 语句assert x &gt;= 0;即为断言，断言条件x &gt;= 0预期为true。如果计算结果为false，则断言失败，抛出AssertionError。 使用assert语句时，还可以添加一个可选的断言消息：assert x &gt;= 0 : \"x must &gt;= 0\";。这样，断言失败的时候，AssertionError会带上消息x must &gt;= 0，更加便于调试。 Java断言的特点是：断言失败时会抛出AssertionError，导致程序结束退出。因此，断言不能用于可恢复的程序错误，只应用于开发和测试阶段。 JVM默认关闭断言指令，即遇到assert语句就自动忽略了。要执行assert语句，必须给Java虚拟机传递-enableassertions（简写为-ea）参数启用断言。 还可以有选择地对特定地类启用断言，命令行参数是：-ea:com.itranswarp.sample.Main，表示只对com.itranswarp.sample.Main这个类启用断言。 或者对特定地包启用断言，命令行参数是：-ea:com.itranswarp.sample...（注意结尾有3个.），表示对com.itranswarp.sample这个包启动断言。 实际开发中，很少使用断言。更好的方法是编写单元测试，后续我们会讲解JUnit的使用。 使用JDK Logging什么是日志？日志就是Logging，它的目的是为了取代System.out.println()。输出日志，而不是用System.out.println()，有以下几个好处： 可以设置输出样式，避免每次都写\"Error: \"+var 可以设置输出级别，禁止某些级别输出。例如，只输出错误日志。 可以被重定向到文件，这样可以在程序运行结束后查看日志 可以按包名控制日志级别，只输出某些包打的日志 … Java标准库内置了日志包java.util.logging，我们可以直接用。使用日志最大的好处是，它自动打印了时间、调用类、调用方法等很多有用的信息。 JDK的Logging定义了七个日志级别，从严重到普通： SEVERE WARNING INFO CONFIG FINE FINER FINEST 默认级别是INFO，因此INFO级别以下的日志不会被打印出来。使用日志级别的好处在于，调整级别就可以屏蔽掉很多调试相关的日志输出。 使用Java标准库内置的Logging有以下局限： Logging系统在JVM启动时读取配置文件并完成初始化，一旦开始运行main()方法，就无法修改配置 配置不太方便，需要在JVM启动时传递参数-Djava.util.logging.config.file=&lt;config-file-name&gt;。 因此，Java标准库内置的Logging使用并不是很广泛。更方便的日志系统我们稍后介绍。 使用Commons Logging和Java标准库提供的日志不同，Commons Logging是一个第三方日志库，它是由Apache创建的日志模块。 Commons Logging的特点是，它可以通过配置文件指定挂接的日志系统。默认情况下，Commons Logging自动搜索并使用Log4j（Log4j是另一个流行的日志系统），如果没有找到Log4j，再使用JDK Logging。 使用Commons Logging只需要和两个类打交道，并且只有两步： 通过LogFactory获取Log类的实例 使用Log实例的方法打日志 Commons Logging定义了6个日志级别： FATAL ERROR WARNING INFO DEBUG TRACE 默认级别是INFO。 使用Commons Logging时，如果在静态方法中引用Log，通常直接定义一个静态变量。在实例方法中引用Log，通常定义一个实例变量。 12345678910111213141516171819202122// 在静态方法中引用Log:public class Main { static final Log log = LogFactory.getLog(Main.class); static void foo() { log.info(\"foo\"); }}// 在实例方法中引用Log:public class Person { protected final Log log = LogFactory.getLog(getClass()); void foo() { log.info(\"foo\"); }}// 在子类中使用父类实例化的log:public class Student extends Person { void bar() { log.info(\"bar\"); }} 注意到实例变量log的获取方式是LogFactory.getLog(getClass())，虽然也可以用LogFactory.getLog(Person.class)，但是前一种方式有个非常大的好处，就是子类可以直接使用该log实例。 由于Java类的动态特性，子类获取的log字段实际上相当于LogFactory.getLog(Student.class)，但却是从父类继承而来，并且无需改动代码。 此外，Commons Logging的日志方法，例如info()，除了标准的info(String)，还提供了一个非常有用的重载方法：info(String, Throwable)，这使得记录异常更加简单。 使用Log4j前面介绍了Commons Logging，可以作为“日志接口”来使用，而真正的“日志实现”可以使用Log4j。Log4j是一种非常流行的日志框架。Log4j是一个组件化设计的日志系统，它的架构大致如下： 12345678910111213log.info(\"User signed in.\"); │ │ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ├──&gt;│ Appender │───&gt;│ Filter │───&gt;│ Layout │───&gt;│ Console │ │ └──────────┘ └──────────┘ └──────────┘ └──────────┘ │ │ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ├──&gt;│ Appender │───&gt;│ Filter │───&gt;│ Layout │───&gt;│ File │ │ └──────────┘ └──────────┘ └──────────┘ └──────────┘ │ │ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ └──&gt;│ Appender │───&gt;│ Filter │───&gt;│ Layout │───&gt;│ Socket │ └──────────┘ └──────────┘ └──────────┘ └──────────┘ 当我们用Log4j输出一条日志时，Log4j自动通过不同的Appender把同一条日志输出到不同的目的地。例如： console：输出到屏幕 file：输出到文件 socket：通过网络输出到远程计算机 jdbc：输出到数据库 在输出日志的过程中，通过Filter来过滤哪些log需要被输出，哪些log不需要被输出。例如，仅输出ERROR级别的日志。 最后通过Layout来格式化日志信息，例如，自动添加日期、时间、方法名称等。 上述结构虽然复杂，但我们在实际使用时，并不需要关心Log4j的API，而是通过配置文件来配置它。以XML配置为例，使用Log4j时，我们把一个log4j2.xml文件放到classpath下就可以让Log4j读取配置文件并按照我们的配置来输出日志。下面是一个配置文件的例子。 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Configuration&gt; &lt;Properties&gt; &lt;!-- 定义日志格式 --&gt; &lt;Property name=\"log.pattern\"&gt;%d{MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36}%n%msg%n%n&lt;/Property&gt; &lt;!-- 定义文件名变量 --&gt; &lt;Property name=\"file.err.filename\"&gt;log/err.log&lt;/Property&gt; &lt;Property name=\"file.err.pattern\"&gt;log/err.%i.log.gz&lt;/Property&gt; &lt;/Properties&gt; &lt;!-- 定义Appender，即目的地 --&gt; &lt;Appenders&gt; &lt;!-- 定义输出到屏幕 --&gt; &lt;Console name=\"console\" target=\"SYSTEM_OUT\"&gt; &lt;!-- 日志格式引用上面定义的log.pattern --&gt; &lt;PatternLayout pattern=\"${log.pattern}\" /&gt; &lt;/Console&gt; &lt;!-- 定义输出到文件,文件名引用上面定义的file.err.filename --&gt; &lt;RollingFile name=\"err\" bufferedIO=\"true\" fileName=\"${file.err.filename}\" filePattern=\"${file.err.pattern}\"&gt; &lt;PatternLayout pattern=\"${log.pattern}\" /&gt; &lt;Policies&gt; &lt;!-- 根据文件大小自动切割日志 --&gt; &lt;SizeBasedTriggeringPolicy size=\"1 MB\" /&gt; &lt;/Policies&gt; &lt;!-- 保留最近10份 --&gt; &lt;DefaultRolloverStrategy max=\"10\" /&gt; &lt;/RollingFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=\"info\"&gt; &lt;!-- 对info级别的日志，输出到console --&gt; &lt;AppenderRef ref=\"console\" level=\"info\" /&gt; &lt;!-- 对error级别的日志，输出到err，即上面定义的RollingFile --&gt; &lt;AppenderRef ref=\"err\" level=\"error\" /&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 虽然配置Log4j比较繁琐，但一旦配置完成，使用起来就非常方便。对上面的配置文件，凡是INFO级别的日志，会自动输出到屏幕，而ERROR级别的日志，不但会输出到屏幕，还会同时输出到文件。并且，一旦日志文件达到指定大小（1MB），Log4j就会自动切割新的日志文件，并最多保留10份。 在开发阶段，始终使用Commons Logging接口来写入日志，并且开发阶段无需引入Log4j。如果需要把日志写入文件， 只需要把正确的配置文件和Log4j相关的jar包放入classpath，就可以自动把日志切换成使用Log4j写入，无需修改任何代码。 使用SLF4J和Logback前面介绍了Commons Logging和Log4j这一对好基友，一个负责充当日志API，一个负责实现日志底层，搭配使用非常方便开发。有的童鞋可能还听说过SLF4J和Logback。SLF4J类似于Commons Logging，也是一个日志接口，而Logback类似于Log4j，是一个日志的实现。 为什么有了Commons Logging和Log4j，又会蹦出来SLF4J和Logback？这是因为Java有着非常悠久的开源历史，不但OpenJDK本身是开源的，而且我们用到的第三方库，几乎全部都是开源的。开源生态丰富的一个特定就是，同一个功能，可以找到若干种互相竞争的开源库。因为对Commons Logging的接口不满意，有人就搞了SLF4J。因为对Log4j的性能不满意，有人就搞了Logback。 我们先来看看SLF4J对Commons Logging的接口有何改进。在Commons Logging中，我们要打印日志，有时候得这么写： 123int score = 99;p.setScore(score);log.info(\"Set score \" + score + \" for Person \" + p.getName() + \" ok.\"); 拼字符串是一个非常麻烦的事，所以SLF4J的日志接口改成了这样： 123int score = 99;p.setScore(score);logger.info(\"Set score {} for Person {} ok.\", score, p.getName()); 我们靠猜也能猜出来，SLF4J的日志接口传入的是一个带占位符的字符串，用后面的变量自动替换占位符，看起来更自然。 如何使用SLF4J呢？它的接口实际上和Commons Logging几乎一模一样。对比一下二者的接口。 Commons Logging SLF4J org.apache.commons.logging.Log org.slf4j.Logger org.apache.commons.logging.LogFactory org.slf4j.LoggerFactory 和Log4j类似，我们仍然需要一个Logback的配置文件，把logback.xml放到classpath下，配置如下： 12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;file&gt;log/output.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\"&gt; &lt;fileNamePattern&gt;log/output.log.%i&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;1MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt;&lt;/configuration&gt; 从目前的趋势来看，越来越多的开源项目从Commons Logging加Log4j转向了SLF4J加Logback。","link":"/Study/Java/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"},{"title":"日期与时间","text":"日期和时间是计算机处理的重要数据，绝大部分程序的运行都要和时间打交道。本节我们将详细讲解Java程序如何正确处理日期和时间。 基本概念日期是指某一天，它不是连续变化的，而应该被看作离散的。而时间有两种概念，一种是不带日期的时间，例如12:30:59；另一种是带日期的时间，例如2021-5-13 10:09:01，只有这种带日期的时间能唯一地确定某个时刻，不带日期的时间是无法确定一个唯一时刻的。 本地时间当我们说当前时刻是2021年5月13日早上10:10时，我们说的实际上是本地时间，在国内就是北京时间。在这个时刻，如果地球上不同地方的人们同时看一眼手表，他们各自的本地时间是不同的。 所以，不同的时区，在同一时刻，本地时间是不同的。全球一共分为24个时区，伦敦所在的时区称为标准时区，其他地区按东/西偏移的小时区分，北京所在的时区是东八区。 时区因为光靠本地时间还无法唯一确定一个准确的时刻，所以我们还需要给本地时间加上一个时区。 时区有好几种表达方式。一种是以GMT或UTC加时区偏移表示，例如：GMT+08:00或者UTC+08:00表示东八区。GMT和UTC可以认为基本是等价的，只是UTC使用更精确的原子钟计时，每隔几年会有一个闰秒，我们在开发程序时可以忽略两者的误差，因为计算机的时钟在联网时会自动与时间服务器同步时间。 另一种是缩写，例如CST表示China Standard Time，也就是中国标准时间，但是CST也可以表示美国中部时间Central Standard Time USA，因此，缩写容易产生误差，我们尽量不要使用缩写。 最后一种是以洲/城市表示，例如Asia/Shanghai，表示上海所在地的时区。要注意，城市名称不是任意的城市，而是由国际标准组织规定的城市。 因为有时区的存在，东八区的2019年11月20日早上8:15，和西五区的2019年11月19日晚上19:15，他们的时刻是相同的。时刻相同的意思就是，分别在两个时区的两个人，如果在这一刻通电话，他们各自报出自己手表的时间，虽然本地时间是不同的，但是这两个时间表示的时刻是相同的。 夏令时所谓夏令时，就是夏天开始的时候，把时间往后拨一个小时，夏天结束的时候，再把时间往前拨一个小时。我们国家实行过一段夏令时，1992年就废除了，但是矫情的美国人现在还在使用，所以时间换算更加复杂。 因为涉及到夏令时，相同的时区，如果表示的方式不同，转换出的时间是不同的。我们举个栗子： 对于2019-11-20和2019-6-20两个日期来说，假设北京人在纽约： 如果以GMT或者UTC作为时区，无论日期是多少，时间都是19:00 如果以国家／城市表示，例如America／NewYork，虽然纽约也在西五区，但是，因为夏令时的存在，在不同的日期，GMT时间和纽约时间可能是不一样的 实行夏令时的不同地区，进入和退出夏令时的时间很可能是不同的。同一个地区，根据历史上是否实行过夏令时，标准时间在不同年份换算成当地时间也是不同的。因此，计算夏令时，没有统一的公式，必须按照一组给定的规则来算，并且，该规则要定期更新。计算夏令时请使用标准库提供的相关类，不要试图自己计算夏令时。 本地化在计算机中，通常使用Locale表示一个国家或地区的日期、时间、数字、货币等格式。Locale由语言_国家的字母缩写构成，例如zh_CN表示中文+中国，en_US表示英文+美国。语言使用小写，国家使用大写。 对于日期来说，不同的Locale，例如中国和美国的表示方式如下： zh_CN：2016-11-30 en_US：11/30/2016 计算机用Locale在日期、时间、货币和字符串之间进行转换。一个电商网站会根据用户所在的Locale对用户显示相应格式的内容。 小结在编写日期和时间的程序前，我们要准确理解日期、时间和时刻的概念。 由于存在本地时间，我们需要理解时区的概念，并且必须牢记由于夏令时的存在，同一地区用GMT/UTC和城市表示的时区可能导致时间不同。 计算机通过Locale来针对当地用户习惯格式化日期、时间、数字、货币等。 Date和Calender在理解日期和时间的表示方式之前，我们先要理解数据的存储和展示。 当我们定义一个整型变量并赋值时： 1int n = 123400; 编译器会把上述字符串（程序源码就是一个字符串）编译成字节码。在程序的运行期，变量n指向的内存实际上是一个4字节区域： 123┌──┬──┬──┬──┐│00│01│e2│08│└──┴──┴──┴──┘ 注意到计算机内存除了二进制的0/1外没有其他任何格式。 当我们用System.out.println(n)打印这个整数的时候，实际上println()这个方法在内部把int类型转换成String类型，然后打印出字符串123400。 1234567int n = 123400;// 123400System.out.println(n);// 1e208System.out.println(Integer.toHexString(n));// $123,400.00System.out.println(NumberFormat.getCurrencyInstance(Locale.US).format(n)); 由此可见，整数123400只是数据的存储格式，而我们打印的各种各样字符串，是数据的展示格式。展示格式有多种形式，但本质上它就是一个转换方法。 理解了数据的存储和展示，我们回头看看以下几种日期和时间： 2019-11-20 0:15:01 GMT+00:00 2019年11月20日8:15:01 11/19/2019 19:15:01 America/New_York 它们实际上是数据的展示格式，分别按英国时区、中国时区、纽约时区对同一个时刻进行展示。而这个“同一个时刻”在计算机中存储的本质上只是一个整数，我们称它为Epoch Time。Epoch Time是计算从1970年1月1日零点（格林威治时区／GMT+00:00）到现在所经历的秒数，例如：1574208900表示从从1970年1月1日零点GMT时区到该时刻一共经历了1574208900秒。分别换算成伦敦，北京，纽约时间分别是： 1231574208900 = 北京时间2019-11-20 8:15:00 = 伦敦时间2019-11-20 0:15:00 = 纽约时间2019-11-19 19:15:00 因此，在计算机中只需要存储一个整数1574208900表示某一个时刻。当需要显示为某一地区的当地时间时，我们就把它格式化为一个字符串。 Epoch Time又称为时间戳，在不同的编程语言中，会有几种存储方式： 以秒为单位的整数：1574208900，缺点是精度只能到秒； 以毫秒为单位的整数：1574208900123，最后3位表示毫秒数； 以秒为单位的浮点数：1574208900.123，小数点后面表示零点几秒。 而在Java程序中，时间戳通常是用long类型的毫秒数，即： 1long t = 1574208900123L; 转换成北京时间就是2019-11-20T8:15:00.123。要获取当前时间戳，可以使用System.currentTimeMillis()，这是Java程序获取时间戳最常用的方法。 标准库API我们再来看一下Java标准库提供的API。Java标准库有两套处理日期和时间的API： 一套定义在java.util这个包里面，主要包括Date、Calendar和TimeZone这几个类； 一套新的API是在Java 8引入的，定义在java.time这个包里面，主要包括LocalDateTime、ZonedDateTime、ZoneId等。 为什么会有新旧两套API呢？因为历史遗留原因，旧的API存在很多问题，所以引入了新的API。 那么我们能不能跳过旧的API直接用新的API呢？如果涉及到遗留代码就不行，因为很多遗留代码仍然使用旧的API，所以目前仍然需要对旧的API有一定了解，很多时候还需要在新旧两种对象之间进行转换。 本节我们快速讲解旧API的常用类型和方法。 Datejava.util.Date是用于表示一个日期和时间的对象，注意与java.sql.Date区分，后者用在数据库中。如果观察Date的源码，可以发现它实际上存储了一个long类型的以毫秒表示的时间戳。 我们来看看Date的基本用法： 1234567891011// 获取当前时间:Date date = new Date();System.out.println(date.getYear() + 1900); // 必须加上1900System.out.println(date.getMonth() + 1); // 0~11，必须加上1System.out.println(date.getDate()); // 1~31，不能加1// 转换为String:System.out.println(date.toString());// 转换为GMT时区:System.out.println(date.toGMTString());// 转换为本地时区:System.out.println(date.toLocaleString()); 注意getYear()返回的年份必须加上1900，getMonth()返回的月份是011分别表示112月，所以要加1，而getDate()返回的日期范围是1~`31`，又不能加1。 打印本地时区表示的日期和时间时，不同的计算机可能会有不同的结果。如果我们想要针对用户的偏好精确地控制日期和时间的格式，就可以使用SimpleDateFormat对一个Date进行转换。它用预定义的字符串表示格式化： yyyy：年 MM：月 dd: 日 HH: 小时 mm: 分钟 ss: 秒 1234// 获取当前时间:Date date = new Date();var sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");System.out.println(sdf.format(date)); Date对象有几个严重的问题：它不能转换时区，除了toGMTString()可以按GMT+0:00输出外，Date总是以当前计算机系统的默认时区为基础进行输出。此外，我们也很难对日期和时间进行加减，计算两个日期相差多少天，计算某个月第一个星期一的日期等。 CalenderCalendar可以用于获取并设置年、月、日、时、分、秒，它和Date比，主要多了一个可以做简单的日期和时间运算的功能。 我们来看Calendar的基本用法： 1234567891011// 获取当前时间:Calendar c = Calendar.getInstance();int y = c.get(Calendar.YEAR);int m = 1 + c.get(Calendar.MONTH);int d = c.get(Calendar.DAY_OF_MONTH);int w = c.get(Calendar.DAY_OF_WEEK);int hh = c.get(Calendar.HOUR_OF_DAY);int mm = c.get(Calendar.MINUTE);int ss = c.get(Calendar.SECOND);int ms = c.get(Calendar.MILLISECOND);System.out.println(y + \"-\" + m + \"-\" + d + \" \" + w + \" \" + hh + \":\" + mm + \":\" + ss + \".\" + ms); 注意到Calendar获取年月日这些信息变成了get(int field)，返回的年份不必转换，返回的月份仍然要加1，返回的星期要特别注意，1~`7`分别表示周日，周一，……，周六。 Calendar只有一种方式获取，即Calendar.getInstance()，而且一获取到就是当前时间。如果我们想给它设置成特定的一个日期和时间，就必须先清除所有字段： 1// 当前时间:Calendar c = Calendar.getInstance();// 清除所有:c.clear();// 设置2019年:c.set(Calendar.YEAR, 2019);// 设置9月:注意8表示9月:c.set(Calendar.MONTH, 8);// 设置2日:c.set(Calendar.DATE, 2);// 设置时间:c.set(Calendar.HOUR_OF_DAY, 21);c.set(Calendar.MINUTE, 22);c.set(Calendar.SECOND, 23);// 2019-09-02 21:22:23System.out.println(new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(c.getTime())); 利用Calendar.getTime()可以将一个Calendar对象转换成Date对象，然后就可以用SimpleDateFormat进行格式化了。 TimeZone利用Calendar进行时区转换的步骤是： 清除所有字段； 设定指定时区； 设定日期和时间； 创建SimpleDateFormat并设定目标时区； 格式化获取的Date对象（注意Date对象无时区信息，时区信息存储在SimpleDateFormat中）。 因此，本质上时区转换只能通过SimpleDateFormat在显示的时候完成。 Calendar也可以对日期和时间进行简单的加减，这里就不贴代码了。 LocalDateTime从Java 8开始，java.time包提供了新的日期和时间API，主要涉及的类型有： 本地日期和时间：LocalDateTime，LocalDate，LocalTime 带时区的日期和时间：ZonedDateTime 时刻：Instant 时区：ZoneId，ZoneOffset 时间间隔：Duration 以及一套新的用于取代SimpleDataFormat的格式化类型DateTimeFormatter。和旧的API相比，新API严格区分了时刻、本地日期、本地时间和带时区的日期时间，并且，对时间和日期运算更加方便。此外，新API修正了旧API不合理的常量设计： Month用1～12表示1月到12月 Week的范围用1～7表示周一到周日 最后，新API的类型几乎全部是不变类型，可以放心使用不必担心被修改。 我们首先来看看最常用的LocalDateTime，它表示一个本地日期和时间。 1LocalDate d = LocalDate.now(); // 当前日期LocalTime t = LocalTime.now(); // 当前时间LocalDateTime dt = LocalDateTime.now(); // 当前日期和时间System.out.println(d); // 严格按照ISO 8601格式打印System.out.println(t); // 严格按照ISO 8601格式打印System.out.println(dt); // 严格按照ISO 8601格式打 本地日期和时间通过now()获取到的总是以当前默认时区返回的，和旧API不同，LocalDateTime、LocalDate、LocalTime默认严格按照ISO 8601规定的日期和时间格式进行打印。 反过来，通过制定的日期和时间创建LocalDateTime可以通过of()方法。 1// 指定日期和时间:LocalDate d2 = LocalDate.of(2019, 11, 30); // 2019-11-30, 注意11=11月LocalTime t2 = LocalTime.of(15, 16, 17); // 15:16:17LocalDateTime dt2 = LocalDateTime.of(2019, 11, 30, 15, 16, 17);LocalDateTime dt3 = LocalDateTime.of(d2, t2); 因为严格按照ISO 8601的格式，因此，将字符串转换为LocalDateTime就可以传入标准格式。 1LocalDateTime dt = LocalDateTime.parse(\"2019-11-19T15:16:17\");LocalDate d = LocalDate.parse(\"2019-11-19\");LocalTime t = LocalTime.parse(\"15:16:17\"); 注意ISO 8601规定的日期和时间分隔符是T。标准格式如下： 日期：yyyy-MM-dd 时间：HH:mm:ss 带毫秒的时间：HH:mm:ss.SSS 日期和时间：yyyy-MM-dd’T’HH:mm:ss 带毫秒的日期和时间：yyyy-MM-dd’T’HH:mm:ss.SSS DateTimeFormatter如果要自定义输出格式，或者要把一个非ISO 8601格式的字符串解析成LocalDateTime，可以使用新的DateTimeFormatter。 1// 自定义格式化:DateTimeFormatter dtf = DateTimeFormatter.ofPattern(\"yyyy/MM/dd HH:mm:ss\");System.out.println(dtf.format(LocalDateTime.now()));// 用自定义格式解析:LocalDateTime dt2 = LocalDateTime.parse(\"2019/11/30 15:16:17\", dtf);System.out.println(dt2); LocalDateTime提供了对日期和时间进行加减的非常简单的链式调用。 1LocalDateTime dt = LocalDateTime.of(2019, 10, 26, 20, 30, 59);System.out.println(dt);// 加5天减3小时:LocalDateTime dt2 = dt.plusDays(5).minusHours(3);System.out.println(dt2); // 2019-10-31T17:30:59// 减1月:LocalDateTime dt3 = dt2.minusMonths(1);System.out.println(dt3); // 2019-09-30T17:30:59 注意到月份加减会自动调用日期，例如从2019-10-31减去1个月得到的结果是2019-09-30，因为9月没有31日。 对日期和时间进行调整则使用withXxx()方法，例如：withHour(15)会把10:11:12变为15:11:12： 调整年：withYear() 调整月：withMonth() 调整日：withDayOfMonth() 调整时：withHour() 调整分：withMinute() 调整秒：withSecond() 实际上，LocalDateTime还有一个通用的with()方法允许我们做更复杂的运算。对于计算某个月第一个周日这样的问题，新的API可以轻松完成。 要判断两个LocalDateTime的先后，可以使用isBefore()，isAfter()方法，对于LocalDate和LocalTime类似。 注意到LocalDateTime无法与时间戳进行转换，因为它没有时区，无法确定某一时刻。后面我们介绍的ZonedDateTime相当于LocalDateTime加时区的组合，它具有时区，可以与long表示的时间戳进行转换。 Duration和PeriodDuration表示两个时刻之间的时间间隔，Period表示两个日期之间的天数。 1LocalDateTime start = LocalDateTime.of(2019, 11, 19, 8, 15, 0);LocalDateTime end = LocalDateTime.of(2020, 1, 9, 19, 25, 30);Duration d = Duration.between(start, end);System.out.println(d); // PT1235H10M30SPeriod p = LocalDate.of(2019, 11, 19).until(LocalDate.of(2020, 1, 9));System.out.println(p); // P1M21D 注意到两个LocalDateTime之间的差值使用Duration表示，类似PT1235H10M30S，表示1235小时10分钟30秒。两个LocalDate之间的差值用Period表示，类似P1M21D，表示1个月21天。 Duration和Period的表示方法也符合ISO 8601的格式，它以P...T...的形式表示，P...T之间表示日期间隔，T后面表示时间间隔。如果是PT...的格式表示仅有时间间隔。利用ofXxx()或者parse()方法也可以直接创建Duration： 1Duration d1 = Duration.ofHours(10); // 10 hoursDuration d2 = Duration.parse(\"P1DT2H3M\"); // 1 day, 2 hours, 3 minutes ZonedDateTimeLocalDateTime总是表示本地日期和时间，要表示一个带时区的日期和时间，我们就需要ZonedDateTime。可以简单的把ZonedDateTime理解为LocalDateTime加ZoneId。ZoneId是java.time引入的新的时区类，注意和旧的java.util.TimeZone区分。 要创建一个ZonedDateTime对象，有以下几种方法，一种是通过now()方法返回当前时间。 1ZonedDateTime zbj = ZonedDateTime.now(); // 默认时区ZonedDateTime zny = ZonedDateTime.now(ZoneId.of(\"America/New_York\")); // 用指定时区获取当前时间System.out.println(zbj); // 2021-05-18T02:25:36.529532212Z[Etc/UTC]System.out.println(zny); // 2021-05-17T22:25:36.531996198-04:00[America/New_York] 另一种方式是通过给一个LocalDateTime附加一个ZoneId，就可以变成ZonedDateTime。 1LocalDateTime ldt = LocalDateTime.of(2019, 9, 15, 15, 16, 17);ZonedDateTime zbj = ldt.atZone(ZoneId.systemDefault());ZonedDateTime zny = ldt.atZone(ZoneId.of(\"America/New_York\"));System.out.println(zbj); // 2019-09-15T15:16:17Z[Etc/UTC]System.out.println(zny); // 2019-09-15T15:16:17-04:00[America/New_York] 以这种方式创建的ZonedDateTime，它的日期和时间与LocalDateTime相同，但附加的时区不同，因此是两个不同的时刻。 时区转换要转换时区，首先我们需要有一个ZonedDateTime对象，然后，通过withZoneSameInstant()将关联时区转换到另一个时区，转换后日期和时间都会相应调整。 1// 以中国时区获取当前时间:ZonedDateTime zbj = ZonedDateTime.now(ZoneId.of(\"Asia/Shanghai\"));// 转换为纽约时间:ZonedDateTime zny = zbj.withZoneSameInstant(ZoneId.of(\"America/New_York\"));System.out.println(zbj); // 2021-05-18T10:31:08.109980611+08:00[Asia/Shanghai]System.out.println(zny); // 2021-05-17T22:31:08.109980611-04:00[America/New_York] 要特别注意，由于夏令时的存在，时区转换时不同日期转换的结果很可能是不同的。涉及到时区时，千万不要自己计算时差，否则难以正确处理夏令时。 有了ZonedDateTime，将其转换为本地时间就非常简单了。转换为LocalDateTime，直接丢弃了时区信息。 1ZonedDateTime zdt = ...LocalDateTime ldt = zdt.toLocalDateTime(); DateTimeFormatter使用旧的Date对象时，我们用SimpleDateFormat进行格式化显示。使用新的LocalDateTime或ZonedLocalDateTime时，我们要进行格式化显示，就要使用DateTimeFormatter。 和SimpleDateFormat不同的是，DateTimeFormatter不但是不变对象，它还是线程安全的。线程的概念我们会在后面涉及到。现在我们只需要记住：因为SimpleDateFormat不是线程安全的，使用的时候，只能在方法内部创建新的局部变量。而DateTimeFormatter可以只创建一个实例，到处引用。 创建DateTimeFormatter时，我们仍然通过传入格式化字符串实现： 1DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm\"); 格式化字符串的使用方式与SimpleDateFormat完全一致。 另一种创建DateTimeFormatter的方法是，传入格式化字符串时，同时指定Locale： 1DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"E, yyyy-MMMM-dd HH:mm\", Locale.US); 这种方式可以按照Locale默认习惯格式化。我们来看实际效果。 1ZonedDateTime zdt = ZonedDateTime.now();var formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd'T'HH:mm ZZZZ\");System.out.println(formatter.format(zdt)); // 2021-05-18T02:37 GMTvar zhFormatter = DateTimeFormatter.ofPattern(\"yyyy MMM dd EE HH:mm\", Locale.CHINA);System.out.println(zhFormatter.format(zdt)); // 2021 5月 18 周二 02:37var usFormatter = DateTimeFormatter.ofPattern(\"E, MMMM/dd/yyyy HH:mm\", Locale.US);System.out.println(usFormatter.format(zdt)); // Tue, May/18/2021 02:37 当我们直接调用System.out.println()对一个ZonedDateTime或者LocalDateTime实例进行打印的时候，实际上，调用的是它们的toString()方法，默认的toString()方法显示的字符串就是按照ISO 8601格式显示的，我们可以通过DateTimeFormatter预定义的几个静态变量来引用： 1var ldt = LocalDateTime.now();System.out.println(DateTimeFormatter.ISO_DATE.format(ldt)); // 2019-09-15System.out.println(DateTimeFormatter.ISO_DATE_TIME.format(ldt)); // 2019-09-15T23:16:51.56217 小结对ZonedDateTime或LocalDateTime进行格式化，需要使用DateTimeFormmter类。 DateTimeFormatter可以通过格式化字符串和Locale对日期和字符串进行定制化输出。 Instant我们讲过，计算机存储的当前时间本质上是一个不断递增的整数。Java提供的System.currentTimeMillis()返回的就是以毫秒表示的当前时间戳。这个当前时间戳在java.time中以Instant类型表示，我们用Instant.now()获取当前时间戳，效果与System.currentTimeMillis()类似。Instant表示高精度时间戳。 实际上，Instant内部只有两个核心字段： 1public final class Instant implements ...{ private final long seconds; private final int nanos;} 一个是以秒为单位的时间戳，一个是更精确的纳秒精度。它和System.currentTimeMillis()返回的long相比，只是多了更精确的纳秒。 即然Instant就是时间戳，那么，给它附加上一个时区，就可以创建出ZonedDateTime。 可见，对于某一个时间戳，给它关联上制定的ZoneId，就得到了ZonedDateTime，继而可以获得对应时区的LocalDateTime。所以，LocalDateTime，ZoneId，Instant，ZonedDateTime和long都可以互相转换。转换的时候，只需要留意long类型的单位是秒还是毫秒就行了。 最佳实践由于Java提供了新旧两套日期和时间的API，除非涉及到遗留代码，否则我们应该坚持使用新的API。如果需要与遗留代码打交道，如何在新旧API之间互相转换呢？ 旧API转新API如果要把旧的Date和Calendar转换为新API对象，可以通过toInstant()方法转换为Instant对象，再继续转换为ZonedDateTime。 1234// Date -&gt; Instant:Instant ins1 = new Date().toInstant();// Calendar -&gt; Instant -&gt; ZonedDateTime:Calendar calendar = Calendar.getInstance();Instant ins2 = calendar.toInstant();ZonedDateTime zdt = ins2.atZone(calendar.getTimeZone().toZoneId()); 从上面的代码还可以看到，旧的TimeZone提供了一个toZoneId()，可以把自己变成新的ZoneId。 新API转旧API如果要把新的ZonedDateTime转换为旧的API对象，只能借助long型时间戳做一个中转。 123456// ZonedDateTime -&gt; long:ZonedDateTime zdt = ZonedDateTime.now();long ts = zdt.toEpochSecond() * 1000;// long -&gt; Date:Date date = new Date(ts);// long -&gt; Calendar:Calendar calendar = Calendar.getInstance();calendar.clear();calendar.setTimeZone(TimeZone.getTimeZone(zdt.getZone().getId()));calendar.setTimeInMillis(zdt.toEpochSecond() * 1000); 从上面的代码可以看到，新的ZoneId转换为旧的TimeZone，需要借助ZoneId.getId()返回的String完成。 在数据库中存储日期和时间除了旧的java.util.Date，我们还可以找到另一个java.sql.Date，它继承自java.util.Date，但会自动忽略所有时间相关的信息。这个奇葩的设计原因要追溯到数据库的日期与时间类型。 在数据库中，也存在几种日期和时间类型： DATETIME：表示日期和时间 DATE：仅表示日期 TIME：仅表示时间 TIMESTAMP：和DATETIME类似，但是数据库在创建或者更新记录的时候同时修改TIMESTAMP 在使用Java程序操作数据库时，我们需要把数据库类型与Java类型映射起来。下表是数据库类型与Java新旧API的映射关系： 数据库 对应Java类（旧） 对应Java类（新） DATETIME java.util.Date LocalDateTime DATE java.sql.Date LocalDate TIME java.sql.Time LocalTime TIMESTAMP java.sql.Timestamp LocalDateTime 实际上，在数据库中，我们需要存储的最常用的是时刻（Instant），因为有了时刻信息，就可以根据用户自己选择的时区显示正确的本地时间。所以，最好的方法是直接用长整数long表示，在数据库中存储为BIGINT类型。 通过存储一个long型时间戳，我们可以编写一个timestampToString()方法，非常简单地为不同用户以不同的偏好来显示不同的本地时间。 1static String timestampToString(long epochMilli, Locale lo, String zoneId) { Instant ins = Instant.ofEpochMilli(epochMilli); DateTimeFormatter f = DateTimeFormatter.ofLocalizedDateTime(FormatStyle.MEDIUM, FormatStyle.SHORT); return f.withLocale(lo).format(ZonedDateTime.ofInstant(ins, ZoneId.of(zoneId))); } 小结处理日期和时间时，尽量使用新的java.time包。 在数据库中存储时间戳时，尽量使用long型时间戳，它具有省空间、效率高、不依赖数据库的优点。","link":"/Study/Java/%E6%97%A5%E6%9C%9F%E4%B8%8E%E6%97%B6%E9%97%B4/"},{"title":"正则表达式","text":"正则表达式是一种用来匹配字符串强有力的武器。Java内置了强大的正则表达式的支持。本章我们会详细介绍如何在Java程序中使用正则表达式。 正则表达式简介在了解正则表达式之前，我们先看几个非常常见的问题： 如何判断字符串是否是有效的电话号码？例如：010-1234567，123ABC456，13510001000等； 如何判断字符串是否是有效的电子邮件地址？例如：test@example.com，test#example等； 如何判断字符串是否是有效的时间？例如：12:34，09:60，99:99等。 一种直观的想法是通过程序判断，这种方法需要为每种用例创建规则，然后用代码实现。下面是判断手机号的代码： 1234567891011121314boolean isValidMobileNumber(String s) { // 是否是11位？ if (s.length() != 11) { return false; } // 每一位都是0~9： for (int i=0; i&lt;s.length(); i++) { char c = s.charAt(i); if (c &lt; '0' || c &gt; '9') { return false; } } return true;} 上述代码仅仅做了非常粗略的判断，并未考虑首位数字不能为0等更详细的情况。 除了判断手机号，我们还需要判断电子邮件地址、电话、邮编等等： boolean isValidMobileNumber(String s) { … } boolean isValidEmail(String s) { … } boolean isValidPhoneNumber(String s) { … } boolean isValidZipCode(String s) { … } … 为每一种判断逻辑编写代码实在是太繁琐了。有没有更简单的方法？ 有！用正则表达式。 正则表达式可以用字符串来描述规则，并用来匹配字符串。例如，判断手机号，我们用正则表达式\\d{11}： 123boolean isValidMobileNumber(String s) { return s.matches(\"\\\\d{11}\");} 使用正则表达式的好处有哪些呢？一个正则表达式就是一个描述规则的字符串，所以，只需要编写正确的规则，我们就可以让正则表达式引擎去判断目标字符串是否符合规则。 正则表达式是一套标准，它可以用于任何语言。Java标准库java.util.regex包内置了正则表达式引擎，在Java程序中使用正则表达式非常简单。 举个例子：要判断用户输入的年份是否是20##年，我们先写出规则如下： 一共有4个字符，分别是：2，0，0~9任意数字，0~9任意数字。 对应的正则表达式就是：20\\d\\d，其中\\d表示任意一个数字。 把正则表达式转换为Java字符串就变成了20\\\\d\\\\d，注意Java字符串用\\\\表示\\。 最后，用正则表达式匹配一个字符串的代码如下： 1234567public class Main { public static void main(String[] args) { String regex = \"20\\\\d\\\\d\"; System.out.println(\"2019\".matches(regex)); // true System.out.println(\"2100\".matches(regex)); // false }} 匹配规则正则表达式的匹配规则是从左到右按规则匹配。我们首先来看如何使用正则表达式来做精确匹配。 对于正则表达式abc来说，它只能精确地匹配字符串\"abc\"，不能匹配\"ab\"，\"Abc\"，\"abcd\"等其他任何字符串。 如果正则表达式有特殊字符，那就需要用\\转义。例如，正则表达式a\\&amp;c，其中\\&amp;是用来匹配特殊字符&amp;的，它能精确匹配字符串\"a&amp;c\"，但不能匹配\"ac\"、\"a-c\"、\"a&amp;&amp;c\"等。 要注意正则表达式在Java代码中也是一个字符串，所以，对于正则表达式a\\&amp;c来说，对应的Java字符串是\"a\\\\&amp;c\"，因为\\也是Java字符串的转义字符，两个\\\\实际上表示的是一个\\。 1String re2 = \"a\\\\&amp;c\"; // 对应的正则是a\\&amp;c 如果想匹配非ASCII字符，例如中文，那就用\\u####的十六进制表示，例如：a\\u548cc匹配字符串\"a和c\"，中文字符和的Unicode编码是548c。 匹配任意字符精确匹配实际上用处不大，因为我们直接用String.equals()就可以做到。大多数情况下，我们想要的匹配规则更多的是模糊匹配。我们可以用.匹配任意一个字符。 例如，正则表达式a.c中间的.可以匹配一个任意字符，例如，下面的字符串都可以被匹配： \"abc\"，因为.可以匹配字符b； \"a&amp;c\"，因为.可以匹配字符&amp;； \"acc\"，因为.可以匹配字符c。 但它不能匹配\"ac\"、\"a&amp;&amp;c\"，因为.匹配一个字符且仅限一个字符。 匹配数字如果我们只想匹配0~`9之间的数字，可以用\\d匹配。例如，正则表达式00\\d`可以匹配： \"007\"，因为\\d可以匹配字符7； \"008\"，因为\\d可以匹配字符8。 它不能匹配\"00A\"，\"0077\"，因为\\d仅限单个数字字符。 匹配常用字符用\\w可以匹配一个字母、数字或下划线，w的意思是word。例如，java\\w可以匹配： \"javac\"，因为\\w可以匹配英文字符c； \"java9\"，因为\\w可以匹配数字字符9；。 \"java_\"，因为\\w可以匹配下划线_。 它不能匹配\"java#\"，\"java \"，因为\\w不能匹配#、空格等字符。 匹配空格字符用\\s可以匹配一个空格字符，注意空格字符不但包括空格 ，还包括tab字符（在Java中用\\t表示）。例如，a\\sc可以匹配： \"a c\"，因为\\s可以匹配空格字符 ； \"a c\"，因为\\s可以匹配tab字符\\t。 它不能匹配\"ac\"，\"abc\"等。 匹配非数字用\\d可以匹配一个数字，而\\D可以匹配一个非数字。例如，00\\D可以匹配： \"00A\"，因为\\D可以匹配非数字字符A； \"00#\"，因为\\D可以匹配非数字字符#。 00\\d可以匹配的字符串\"007\"，\"008\"等，00\\D是不能匹配的。 类似的，\\W可以匹配\\w不能匹配的字符，\\S可以匹配\\s不能匹配的字符，这几个正好是反着来的。 重复匹配我们用\\d可以匹配一个数字，例如，A\\d可以匹配\"A0\"，\"A1\"，如果要匹配多个数字，比如\"A380\"，怎么办？修饰符*可以匹配任意个字符，包括0个字符。我们用A\\d*可以匹配： A：因为\\d*可以匹配0个数字； A0：因为\\d*可以匹配1个数字0； A380：因为\\d*可以匹配多个数字380。 修饰符+至少可以匹配至少一个字符。我们用A\\d+可以匹配： A0：因为\\d+可以匹配1个数字0； A380：因为\\d+可以匹配多个数字380。 但它无法匹配\"A\"，因为修饰符+要求至少一个字符。 修饰符?可以匹配0个或1个字符。我们用A\\d?可以匹配： A：因为\\d?可以匹配0个数字； A0：因为\\d?可以匹配1个数字0。 但它无法匹配\"A33\"，因为修饰符?超过1个字符就不能匹配了。 如果我们想精确指定n个字符怎么办？用修饰符{n}就可以。我们用A\\d{3}可以匹配： A380：因为\\d{3}可以匹配3个数字380。 如果我们想匹配n~m个字符怎么办？用修饰符{n,m}就可以。我们用A\\d{3,5}可以匹配： A380：因为\\d{3,5}可以匹配3个数字380； A3800：因为\\d{3,5}可以匹配4个数字3800； A38000：因为\\d{3,5}可以匹配5个数字38000。 如果没有上限，那么修饰符{n,}就可以匹配至少n个字符。 小结单个字符的匹配规则如下： 正则表达式 规则 可以匹配 A 指定字符 A \\u548c 指定Unicode字符 和 . 任意字符 a，b，&amp;，0 \\d 数字0~9 0~`9` \\w 大小写字母，数字和下划线 az，AZ，0~`9，_` \\s 空格、Tab键 空格，Tab \\D 非数字 a，A，&amp;，_，…… \\W 非\\w &amp;，@，中，…… \\S 非\\s a，A，&amp;，_，…… 多个字符的匹配规则如下： 正则表达式 规则 可以匹配 A* 任意个数字符 空，A，AA，AAA，…… A+ 至少1个字符 A，AA，AAA，…… A? 0个或1个字符 空，A A{3} 指定个数字符 AAA A{2,3} 指定范围个数字符 AA，AAA A{2,} 至少n个字符 AA，AAA，AAAA，…… A{0,3} 最多n个字符 空，A，AA，AAA 复杂匹配规则匹配开头和结尾我们用^表示开头，$表示结尾。例如^A\\d{3}$，可以匹配\"A001\"、\"A380\"。 匹配指定范围如果我们规定一个7～8位数字的电话号码不能以0开头，应该怎么写匹配规则呢？\\d{7,8} 是不行的，因为第一个\\d可以匹配到0。 使用[...]可以匹配范围内的字符，例如[123456789]可以匹配1~`9，这样就可以写出上述电话号码的规则：[123456789]\\d{6,7}。把所有的字符列出来太麻烦，还有一种写法，[1-9]`就可以。 要匹配大小写不限的十六进制数，比如1A2b3c，我们可以这样写：[0-9a-fA-F]，它表示一共可以匹配以下任意范围的字符： 0-9：字符0~`9`； a-f：字符a~`f`； A-F：字符A~`F`。 如果要匹配6位十六进制数，前面介绍的{n}仍然可以继续配合使用：[0-9a-fA-F]{6}。 [...]还有一种排除法，即不包含指定范围的字符。假定我们要匹配任意字符，但不包括数字，可以写[^1-9]{3}： 可以匹配\"ABC\"，因为不包含字符1~`9`； 可以匹配\"A00\"，因为不包含字符1~`9`； 不能匹配\"A01\"，因为包含字符1； 不能匹配\"A05\"，因为包含字符5。 或规则匹配用|连接的两个正则规则是或规则，例如，AB|CD表示可以匹配AB或CD。 使用括号我们想要匹配字符串learn java、learn php和learn go怎么办？一个最简单的规则是learn\\sjava|learn\\sphp|learn\\sgo，但是这个规则太复杂了，可以把公共部分提出来，然后用(...)把子规则括起来表示成learn\\s(java|php|go)。 小结复杂匹配规则主要有： 正则表达式 规则 可以匹配 ^ 开头 字符串开头 $ 结尾 字符串结束 [ABC] […]内任意字符 A，B，C [A-F0-9xy] 指定范围的字符 A，……，F，0，……，9，x，y [^A-F] 指定范围外的任意字符 非A~`F` AB|CD|EF AB或CD或EF AB，CD，EF 分组匹配我们前面讲到的(...)可以用来把一个子规则括起来，这样写learn\\s(java|php|go)就可以更方便地匹配长字符串了。实际上，(...)还有一个重要作用，就是分组匹配。 我们来看一下如何用正则匹配区号-电话号这个规则，利用前面的知识： 1\\d{3,4}-\\d{6,8} 虽然这个正则匹配规则很简单，但是往往匹配成功后，下一步是提取区号和电话号，分别存入数据库。于是问题来了：如何提取匹配的子串？ 当然可以用String提供的indexOf()和substring()这些方法，但它们从正则匹配的字符串中提取子串没有通用性。正确的方法是用(...)先把要提取的规则分组，把上述正则表达式变为： 1(\\d{3,4})-{\\d{6,8}} 那么匹配后，如何按括号提取子串呢？ 现在我们没法用String.matches()这样简单的判断方法了，必须引入java.util.regex，用Pattern对象匹配，匹配后获得一个Matcher对象，如果匹配成功，就可以直接从Matcher.group(index)返回子串。 1234567891011121314import java.util.regex.*;public static void main(String[] args) { Pattern p = Pattern.compile(\"(\\\\d{3,4})\\\\-(\\\\d{7,8})\"); Matcher m = p.matcher(\"010-12345678\"); if (m.matches()) { String g1 = m.group(1); String g2 = m.group(2); System.out.println(g1); System.out.println(g2); } else { System.out.println(\"匹配失败!\"); }} 要特别注意，Matcher.group(index)方法的参数用1表示第一个子串，2表示第二个子串。如果我们传入0，会得到什么呢？答案是整个正则匹配到的字符串。 Pattern我们在前面的代码中用到的正则表达式代码是String.matches()方法，而我们在分组提取的代码中用的是java.util.regex包里面的Pattern类和Matcher类。实际上这两种代码本质上是一样的，因为String.matches()方法内部调用的就是Pattern和Matcher类的方法。 但是反复使用String.matches()对同一个正则表达式进行多次匹配效率较低，因为每次都会创建出一样的Pattern对象。完全可以先创建出一个Pattern对象，然后反复使用，就可以实现编译一次，多次匹配。 使用Matcher时，必须首先调用matches()判断是否匹配成功，成功后，才能调用group()提取子串。利用提取子串的功能，我们很容易地就获得了区号和电话号两部分字符串。 非贪婪匹配介绍非贪婪匹配之前，我们先看一个简单的问题。给定一个字符串表示的数字，判断该数字末尾0的个数。例如： \"123000\"：3个0 \"10100\"：2个0 \"1001\"：0个0 可以很容易地写出该正则表达式：(\\d+)(0*)。我们期望的分组匹配结果是： input \\d+ 0* 123000 “123” “000” 10100 “101” “00” 1001 “1001” “” 但实际上的分组匹配结果是： input \\d+ 0* 123000 “123000” “” 10100 “10100” “” 1001 “1001” “” 仔细观察上述结果，实际上它是完全合理的，因为\\d+确实可以匹配一个及以上的数字字符。这是因为正则表达式默认使用贪婪匹配：任何一个正则，它总是尽可能多地向后匹配。所以，\\d+总是会把后面的0包含进来。 要让\\d+尽量少匹配，让0*尽量多匹配，我们就必须让\\d+使用非贪婪匹配。在规则\\d+后面加个?即可表示非贪婪匹配。改写后的正则表达式为(\\d+?)(0*)。 因此，给定一个规则，加上?后就变成了非贪婪匹配。 我们再来看个例子。我们再来看这个正则表达式(\\d??)(9*)，注意\\d?表示匹配0个或1个数字，后面第二个?表示非贪婪匹配，因此，给定字符串\"9999\"，匹配到的两个子串分别是\"\"和\"9999\"，因为对于\\d?来说，可以匹配1个9，也可以匹配0个9，但是因为后面的?表示非贪婪匹配，它就会尽可能少的匹配，结果是匹配了0个9。 搜索和替换分割字符串使用正则表达式分割字符串可以实现更灵活的功能。String.split()方法传入的正是正则表达式。如果我们想让用户输入一组标签，然后把标签提取出来，因为用户的输入往往是不规范的，这时，使用合适的正则表达式，就可以消除多个空格、混合,和;这些不规范的输入，直接提取出规范的字符串。 搜索字符串我们来看一个例子。 12345678910111213import java.util.regex.*;public class Main { public static void main(String[] args) { String s = \"the quick brown fox jumps over the lazy dog.\"; Pattern p = Pattern.compile(\"\\\\wo\\\\w\"); Matcher m = p.matcher(s); while (m.find()) { String sub = s.substring(m.start(), m.end()); System.out.println(sub); } }} 我们获取到Matcher对象后，不需要调用matches()方法（因为匹配整个串肯定返回false），而是反复调用find()方法，在整个串中搜索能匹配上\\\\wo\\\\w规则的子串，并打印出来。这种方式比String.indexOf()要灵活得多，因为我们搜索的规则是3个字符：中间必须是o，前后两个必须是字符[A-Za-z0-9_]。 替换字符串使用正则表达式替换字符串可以直接调用String.replaceAll()，它的第一个参数是正则表达式，第二个参数是待替换的字符串。 1public class Main { public static void main(String[] args) { String s = \"The quick\\t\\t brown fox jumps over the lazy dog.\"; String r = s.replaceAll(\"\\\\s+\", \" \"); // \\s匹配空格字符和tab字符，把不规范的连续空格分隔的句子变成了规范的句子 System.out.println(r); // \"The quick brown fox jumps over the lazy dog.\" }} 反向引用如果我们要把搜索到的指定字符串按规则替换，比如前后各加一个&lt;b&gt;xxxx&lt;/b&gt;，这个时候，使用replaceAll()的时候，我们传入的第二个参数可以使用$1、$2来反向引用匹配到的子串。 1public class Main { public static void main(String[] args) { String s = \"the quick brown fox jumps over the lazy dog.\"; String r = s.replaceAll(\"\\\\s([a-z]{4})\\\\s\", \" &lt;b&gt;$1&lt;/b&gt; \"); System.out.println(r);// the quick brown fox jumps &lt;b&gt;over&lt;/b&gt; the &lt;b&gt;lazy&lt;/b&gt; dog. }} 它实际上把任何4字符单词的前后用&lt;b&gt;xxxx&lt;/b&gt;括起来。实现替换的关键是&lt;b&gt;$1&lt;/b&gt;，它用匹配的分组子串([a-z]{4})替换了$1。","link":"/Study/Java/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"泛型","text":"泛型是一种代码模板，可以用一套代码套用各种类型。本节我们详细讨论Java的泛型编程。 什么是泛型在介绍什么是泛型之前，我们先观察Java标准库提供的ArrayList，它可以看作“可变长度”的数组，因为用起来比数组更方便。 实际上ArrayList内部就是一个Object[]数组，配合存储一个当前分配的长度，就可以充当可变长度的数组。但如果用上述ArrayList存储String类型，会有两个缺点： 需要强制转型 不方便，易出错 1234ArrayList list = new ArrayList();list.add(\"Hello\");// 获取到Object，必须强制转型为String:String first = (String) list.get(0); 因为容易误转型，所以很容易出现ClassCastException。要解决上述问题，我们可以为String单独编写一种ArrayList： 1234567public class StringArrayList { private String[] array; private int size; public void add(String e) {...} public void remove(int index) {...} public String get(int index) {...}} 这样一来，存入的必须是String，取出的也一定是String，不需要强制转型，因为编译器会强制检查放入的类型。暂时解决了上述问题。 但新的问题又出现了，如果要存储Integer，还需要为Integer单独编写一种ArrayList，实际上，还需要为其他所有class单独编写一种ArrayList。这是不可能的，JDK的class就有上千个。 为了解决新的问题，我们必须把ArrayList变成一种模板：ArrayList&lt;T&gt;，代码如下： 1234567public class ArrayList&lt;T&gt; { private T[] array; private int size; public void add(T e) {...} public void remove(int index) {...} public T get(int index) {...}} T可以是任何class。这样一来，我们就实现了，编写一次模板，可以创建任意类型的ArrayList。 123456// 创建可以存储String的ArrayList:ArrayList&lt;String&gt; strList = new ArrayList&lt;String&gt;();// 创建可以存储Float的ArrayList:ArrayList&lt;Float&gt; floatList = new ArrayList&lt;Float&gt;();// 创建可以存储Person的ArrayList:ArrayList&lt;Person&gt; personList = new ArrayList&lt;Person&gt;(); 因此，泛型就是定义一种模板，然后在代码中为用到的类创建对应的ArrayList&lt;类型&gt;，由编译器针对类型做检查。这样一来，即实现了编写一次，万能匹配，又通过编译器保证了类型安全。 向上转型在Java标准库中的ArrayList&lt;T&gt;实现了List&lt;T&gt;接口，它可以向上转型为List&lt;T&gt;。要特别注意，不能把ArrayList&lt;Integer&gt;向上转型为ArrayList&lt;Number&gt;或List&lt;Number&gt;。 我们把一个ArrayList&lt;Integer&gt;转型为ArrayList&lt;Number&gt;类型后，这个ArrayList&lt;Number&gt;就可以接受Float类型，因为Float是Number的子类。但是，ArrayList&lt;Number&gt;实际上和ArrayList&lt;Integer&gt;是同一个对象，也就是ArrayList&lt;Integer&gt;类型，它不可能接受Float类型， 所以在获取Integer的时候将产生ClassCastException。 实际上，编译器为了避免这种错误，根本就不允许把ArrayList&lt;Integer&gt;转型为ArrayList&lt;Number&gt;。 注意泛型的继承关系：可以把ArrayList&lt;Integer&gt;向上转型为List&lt;Integer&gt;（T不能变！），但不能把ArrayList&lt;Integer&gt;向上转型为ArrayList&lt;Number&gt;（T不能变成父类）。 使用泛型使用ArrayList时，如果不定义泛型类型，泛型类型实际上就是Object。此时，只能把&lt;T&gt;当Object使用，没有发挥泛型的优势。 当我们定义泛型类型&lt;String&gt;后，List&lt;T&gt;的泛型接口变为强类型List&lt;String&gt;。当我们定义泛型类型&lt;Number&gt;后，List&lt;T&gt;的泛型接口变为强类型List&lt;Number&gt;。编译器如果能自动推断出泛型类型，就可以省略后面的泛型类型。编译器看到泛型类型List&lt;Number&gt;就可以自动推断出后面的ArrayList&lt;T&gt;的泛型类型必须是ArrayList&lt;Number&gt;。 1234List&lt;String&gt; strlist = new ArrayList&lt;String&gt;();List&lt;Number&gt; numlist = new ArrayList&lt;Number&gt;();// 可以省略后面的Number，编译器可以自动推断泛型类型：List&lt;Number&gt; numlist2 = new ArrayList&lt;&gt;(); 泛型接口还可以在接口中使用泛型。例如，Arrays.sort(Object[])可以对任意数组进行排序，但待排序的元素必须实现Comparable&lt;T&gt;这个泛型接口。可以直接对String数组进行排序，因为String本身已经实现了Comparable&lt;String&gt;接口。 12345678public interface Comparable&lt;T&gt; { /** * 返回负数: 当前实例比参数o小 * 返回0: 当前实例与参数o相等 * 返回正数: 当前实例比参数o大 */ int compareTo(T o);} 12345678910111213141516171819202122232425262728// sortimport java.util.Arrays;public class Main { public static void main(String[] args) { Person[] ps = new Person[] { new Person(\"Bob\", 61), new Person(\"Alice\", 88), new Person(\"Lily\", 75), }; Arrays.sort(ps); System.out.println(Arrays.toString(ps)); }}class Person implements Comparable&lt;Person&gt; { String name; int score; Person(String name, int score) { this.name = name; this.score = score; } public int compareTo(Person other) {//也可以修改逻辑，按score从高到低排序 return this.name.compareTo(other.name); } public String toString() { return this.name + \",\" + this.score; }} 编写泛型编写泛型类比普通类要复杂。通常来说，泛型类一般用在集合类，例如ArrayList&lt;T&gt;，我们很少需要编写泛型类。如果我们确实需要编写一个泛型类，那么应该怎么编写呢？ 首先，按照某种类型，例如String，来编写类。然后标记所有的特定类型，这里是String。最后把特定类型String替换为T，并声明&lt;T&gt;。熟练之后可以直接从T开始编写。 1234567891011121314151617181920212223242526272829public class Pair { private String first; private String last; public Pair(String first, String last) { this.first = first; this.last = last; } public String getFirst() { return first; } public String getLast() { return last; }}public class Pair&lt;T&gt; { private T first; private T last; public Pair(T first, T last) { this.first = first; this.last = last; } public T getFirst() { return first; } public T getLast() { return last; }} 静态方法编写泛型类时，要特别注意，泛型类型&lt;T&gt;不能用于静态方法。例如： 123456789101112131415public class Pair&lt;T&gt; { private T first; private T last; public Pair(T first, T last) { this.first = first; this.last = last; } public T getFirst() { ... } public T getLast() { ... } // 对静态方法使用&lt;T&gt;: public static Pair&lt;T&gt; create(T first, T last) { return new Pair&lt;T&gt;(first, last); }} 上述代码会导致编译错误，我们无法在静态方法creat()的方法参数和返回类型上使用泛型类型T。对于静态方法，我们可以单独改写为泛型方法，只需要使用另一个类型就好了。这样才能清楚地将静态方法的泛型类型和实例类型的泛型类型区分开。 普通的方法是通过类的实例来调用的，创建实例的过程调用了构造方法，也就是说对象已经知道这个时候类上面定义的的具体类型了；而静态方法不需要对象实例来调用，所以也就不知道的具体类型，虚拟机不允许这种情况发生，所以编译的时候就报错了。 或者说静态方法由于随着类的加载而加载，不能访问类的泛型（因为在创建对象的时候才确定），因此必须定义自己的泛型类型。 1234// 静态泛型方法应该使用其他类型区分:public static &lt;K&gt; Pair&lt;K&gt; create(K first, K last) { return new Pair&lt;K&gt;(first, last);} 多个泛型类型泛型还可以定义多种类型。例如，我们希望Pair不总是存储两个类型一样的对象，就可以使用类型&lt;T, K&gt;。 12345678910public class Pair&lt;T, K&gt; { private T first; private K last; public Pair(T first, K last) { this.first = first; this.last = last; } public T getFirst() { ... } public K getLast() { ... }} 使用的时候，需要指出两种类型：Pair&lt;String, Integer&gt; p = new Pair&lt;&gt;(\"test\", 123);。 Java标准库的Map&lt;K, V&gt;就是使用两种泛型类型的例子。它对Key使用一种类型，对Value使用另一种类型。 擦拭法泛型是一种类似“模板代码”的技术，不同语言的泛型实现方式不一定相同。Java语言的泛型实现方法是擦拭法（Type Erasure）。所谓擦拭法，是指虚拟机对泛型其实一无所知，所有的工作都是编译器做的。 编译器把类型&lt;T&gt;视为Object 编译器根据&lt;T&gt;实现安全的强制转型 所以，Java的泛型是由编译器在编译时实行的，编译器内部永远把所有类型&lt;T&gt;视为Object处理，但是，在需要转型的时候，编译器会根据T的类型自动为我们实现安全地强制转型。了解了Java泛型的实现方法，我们就知道了Java泛型的局限。 局限一：&lt;T&gt;不能是基本类型，因为实际类型是Object，Object类型无法持有基本类型。 局限二：无法取得带泛型的Class，换句话说，所有泛型实例无论T的类型是什么，getClass()返回同一个Class实例，因为它们编译后全都是Pair&lt;Object&gt;。 局限三：无法判断带泛型的类型。原因同局限二。 1234Pair&lt;Integer&gt; p = new Pair&lt;&gt;(123, 456);// Compile error:if (p instanceof Pair&lt;String&gt;) {} 局限四：不能实例化T类型。 123456789101112public class Pair&lt;T&gt; { private T first; private T last; public Pair() { // Compile error: // 因为擦拭后，下面两句分别变为first = new Object();last = new Object(); // 这样一来，创建new Pair&lt;String&gt;()和new Pair&lt;Integer&gt;()就全部变成了Object // 编译器会阻止这种类型不对的代码 first = new T(); last = new T(); }} 要实例化T类型，我们必须借助额外的Class&lt;T&gt;参数，借助Class&lt;T&gt;参数并通过反射来实例化T类型，使用的时候，也必须传入Class&lt;T&gt;。 12345678910public class Pair&lt;T&gt; { private T first; private T last; public Pair(Class&lt;T&gt; clazz) { first = clazz.newInstance(); last = clazz.newInstance(); }}Pair&lt;String&gt; pair = new Pair&lt;&gt;(String.class);//因为传入了Class&lt;String&gt;的实例，所以我们借助String.class就可以实例化String类型。 不恰当的覆写方法有时候，一个看似正确定义的方法会无法通过编译，比如： 12345public class Pair&lt;T&gt; { public boolean equals(T t) { return this == t; }} 这是因为，定义的equals(T t)方法实际上会被擦拭成equals(Object t)，而这个方法是继承自Object的，编译器会阻止一个实际会变成覆写的泛型方法的定义。换个方法名，比如same，避开Object.equals(Object)的冲突就可以成功编译。 泛型继承一个类可以继承自一个泛型类。例如：父类的类型是Pair&lt;Integer&gt;，子类的类型是IntPair，可以这么继承： 12public class IntPair extends Pair&lt;Integer&gt; {} 使用的时候，因为子类IntPair并没有泛型继承，所以正常使用即可。 1IntPair ip = new IntPair(1, 2); 前面讲了，我们无法获取Pair&lt;T&gt;的T类型，即给定一个变量Pair&lt;Integer&gt; p，无法从p中获取到Integer类型。但是，在父类是泛型类型的情况下，编译器就必须把类型T保存到子类的class文件中，不然编译器就不知道IntPair只能存取Integer这种类型。 在继承了泛型类型的情况下，子类可以获取父类的泛型类型。代码较为复杂，这里就不贴了。 小结Java的泛型是采用擦拭法实现的； 擦拭法决定了泛型&lt;T&gt;： 不能是基本类型，例如：int； 不能获取带泛型类型的Class，例如：Pair&lt;String&gt;.class； 不能判断带泛型类型的类型，例如：x instanceof Pair&lt;String&gt;； 不能实例化T类型，例如：new T()。 泛型方法要防止重复定义方法，例如：public boolean equals(T obj)； 子类可以获取父类的泛型类型&lt;T&gt;。 extends通配符我们前面已经讲到泛型的继承关系：Pair&lt;Integer&gt;不是Pair&lt;Number&gt;的子类。假设我们定义了Pair&lt;T&gt;，然后又针对Pair&lt;Number&gt;类型写了一个静态方法，它接受的参数类型是Pair&lt;Number&gt;。 12345678public class Pair&lt;T&gt; { ... }public class PairHelper { static int add(Pair&lt;Number&gt; p) { Number first = p.getFirst(); Number last = p.getLast(); return first.intValue() + last.intValue(); }} 上述代码是可以正常编译的，使用的时候，我们传入： 1int sum = PairHelper.add(new Pair&lt;Number&gt;(1, 2)); 注意，传入的类型是Pair&lt;Number&gt;，实际参数类型是&lt;Integer, Integer&gt;。既然实际参数是Integer类型，试试传入Pair&lt;Integer&gt;。 直接运行会得到一个编译错误，原因很明显，因为Pair&lt;Integer&gt;不是Pair&lt;Number&gt;的子类，因此add(Pair&lt;Number&gt;)不接受参数类型Pair&lt;Integer&gt;。但是从add()方法的代码可知，传入Pair&lt;Integer&gt;完全符合内部代码的类型规范，因为语句： 12Number first = p.getFirst();Number last = p.getLast(); 实际类型是Integer，引用类型是Number，没有问题。问题在于方法参数类型定死了只能传入Pair&lt;Number&gt;。 有没有办法使得方法参数接受Pair&lt;Integer&gt;？办法是有的，这就是使用Pair&lt;? extends Number&gt;使得方法接受所有泛型类型为Number及其子类的Pair类型。 12345static int add(Pair&lt;? extends Number&gt; p) { Number first = p.getFirst(); Number last = p.getLast(); return first.intValue() + last.intValue();} 这样一来，给方法传入Pair&lt;Integer&gt;类型时，它符合参数Pair&lt;? extends Number&gt;类型。这种使用&lt;? extends Number&gt;的泛型定义称之为上界通配符（Upper Bounds Wildcards），即把泛型类型T的上界限定在Number了。 除了可以传入Pair&lt;Integer&gt;类型，我们还可以传入Pair&lt;Double&gt;类型，Pair&lt;BigDecimal&gt;类型等等，因为Double和BigDecimal都是Number的子类。 &lt;? extends Number&gt;通配符的一个重要限制：方法参数签名无法传递任何Number的子类型。这里唯一的例外是可以给方法参数传入null。 1234567static int add(Pair&lt;? extends Number&gt; p) { Number first = p.getFirst(); Number last = p.getLast(); p.setFirst(new Integer(first.intValue() + 100));// p.setLast(new Integer(last.intValue() + 100));// return p.getFirst().intValue() + p.getFirst().intValue();} extends通配符的作用使用extends通配符只能读，不能写。 使用extends限定T类型在定义泛型类型Pair&lt;T&gt;的时候，也可以使用extends通配符来限定T的类型。因为Number、Integer和Double都符合&lt;T extends Number&gt;。而非Number类型将无法通过编译。 123456public class Pair&lt;T extends Number&gt; { ... }Pair&lt;Number&gt; p1 = null;Pair&lt;Integer&gt; p2 = new Pair&lt;&gt;(1, 2);Pair&lt;Double&gt; p3 = null;Pair&lt;String&gt; p1 = null; // compile error!Pair&lt;Object&gt; p2 = null; // compile error! 小结使用类似&lt;? extends Number&gt;通配符作为方法参数时表示： 方法内部可以调用获取Number引用的方法，例如：Number n = obj.getFirst();； 方法内部无法调用传入Number引用的方法（null除外），例如：obj.setFirst(Number n);。 即一句话总结：使用extends通配符表示可以读，不能写。 使用类似&lt;T extends Number&gt;定义泛型类时表示： 泛型类型限定为Number以及Number的子类。 super通配符使用&lt;? super Integer&gt;通配符表示： 允许调用set(? super Integer)方法传入Integer的引用； 不允许调用get()方法获得Integer的引用。 唯一例外是可以获取Object的引用：Object o = p.getFirst()。 换句话说，使用&lt;? super Integer&gt;通配符作为方法参数，表示方法内部代码对于参数只能写，不能读。 对比extends和super通配符作为方法参数，&lt;? extends T&gt;类型和&lt;? super T&gt;类型的区别在于： &lt;? extends T&gt;允许调用读方法T get()获取T的引用，但不允许调用写方法set(T)传入T的引用（传入null除外） &lt;? super T&gt;允许调用写方法set(T)传入T的引用，但不允许调用读方法T get()获取T的引用（获取Object除外） 一个是允许读不允许写，一个是允许写不允许读。 先记住上面的结论，我们来看Java标准库的Collections类定义的copy()方法： 123456789public class Collections { // 把src的每个元素复制到dest中: public static &lt;T&gt; void copy(List&lt;? super T&gt; dest, List&lt;? extends T&gt; src) { for (int i=0; i&lt;src.size(); i++) { T t = src.get(i); dest.add(t); } }} 它的作用是把每一个List的每个元素依次添加到另一个List。它的第一个参数是List&lt;? super T&gt;，表示目标List，第二个参数List&lt;? extends T&gt;，表示要复制的List。我们可以简单地用for循环实现复制。在for循环中，我们可以看到，对于类型&lt;? extends T&gt;的变量src，我们可以安全地获取类型T的引用，而对于类型&lt;? super T&gt;的变量dest，我们可以安全地传入T的引用。 这个copy()方法的定义就完美地展示了extends和super的意图： copy()方法内部不会读取dest，因为不能调用dest.get()来获取T的引用； copy()方法内部也不会修改src，因为不能调用src.add(T)。 这是由编译器检查来实现的。如果在方法代码中意外修改了src，或者意外读取了dest，就会导致一个编译错误。 这个copy()方法的另一个好处是可以安全地把一个List&lt;Integer&gt;添加到List&lt;Number&gt;，但是反过来无法添加。 这些都是通过super和extends通配符，并由编译器强制检查实现的。 PECS原则何时使用extends，何时使用super？为了便于记忆，我们可以用PECS原则：Producer Extends Consumer Super。 即：如果需要返回T，它是生产者（Producer），要使用extends通配符；如果需要写入T，它是消费者（Consumer），要使用super通配符。 无限定通配符实际上，Java的泛型还允许使用无限定通配符（Unbounded Wildcard Type），即只定义一个?： 12void sample(Pair&lt;?&gt; p) {} 因为&lt;?&gt;通配符既没有extends，也没有super，因此： 不允许调用set(T)方法并传入引用（null除外）； 不允许调用T get()方法并获取T引用（只能获取Object引用）。 换句话说，既不能读，也不能写，那只能做一些null判断： 123static boolean isNull(Pair&lt;?&gt; p) { return p.getFirst() == null || p.getLast() == null;} 大多数情况下，可以引入泛型参数&lt;T&gt;消除&lt;?&gt;通配符： 123static &lt;T&gt; boolean isNull(Pair&lt;T&gt; p) { return p.getFirst() == null || p.getLast() == null;} &lt;?&gt;通配符有一个独特的特点，就是：Pair&lt;?&gt;是所有Pair&lt;T&gt;的超类。 泛型和反射Java的部分反射API也是泛型。例如，Class&lt;T&gt;就是泛型。 1234567// compile warning:Class clazz = String.class;String str = (String) clazz.newInstance();// no warning:Class&lt;String&gt; clazz = String.class;String str = clazz.newInstance(); 调用Class的getSuperclass()方法返回的Class类型是Class&lt;? super T&gt;： 1Class&lt;? super String&gt; sup = String.class.getSuperclass(); 构造方法Constructor&lt;T&gt;也是泛型： 123Class&lt;Integer&gt; clazz = Integer.class;Constructor&lt;Integer&gt; cons = clazz.getConstructor(int.class);Integer i = cons.newInstance(123); 我们可以声明带泛型的数组，但不能用new操作符创建带泛型的数组。必须通过强制转型实现带泛型的数组。 12345Pair&lt;String&gt;[] ps = null; // okPair&lt;String&gt;[] ps = new Pair&lt;String&gt;[2]; // compile error!@SuppressWarnings(\"unchecked\")Pair&lt;String&gt;[] ps = (Pair&lt;String&gt;[]) new Pair[2]; 使用泛型数组要特别小心，因为数组实际上在运行期没有泛型，编译器可以强制检查变量ps，因为它的类型是泛型数组。但是，编译器不会检查变量arr，因为它不是泛型数组。因为这两个变量实际上指向同一个数组，所以，操作arr可能导致从ps获取元素时报错，例如，以下代码演示了不安全地使用带泛型的数组： 123456789Pair[] arr = new Pair[2];Pair&lt;String&gt;[] ps = (Pair&lt;String&gt;[]) arr;ps[0] = new Pair&lt;String&gt;(\"a\", \"b\");arr[1] = new Pair&lt;Integer&gt;(1, 2);// ClassCastException:Pair&lt;String&gt; p = ps[1];String s = p.getFirst(); 要安全地使用泛型数组，必须扔掉arr的引用，由于拿不到原始数组的引用，就只能对泛型数组ps进行操作，这种操作就是安全的。 12@SuppressWarnings(\"unchecked\")Pair&lt;String&gt;[] ps = (Pair&lt;String&gt;[]) new Pair[2]; 带泛型的数组实际上是编译器的类型擦除，所以我们不能直接创建泛型数组T[]，因为擦拭后代码变成Object[]。必须借助Class&lt;T&gt;来创建泛型数组。 12345678910// compile error:public class Abc&lt;T&gt; { T[] createArray() { return new T[5]; }}T[] createArray(Class&lt;T&gt; cls) { return (T[]) Array.newInstance(cls, 5);} 我们还可以利用可变参数创建泛型数组T[]： 123456789public class ArrayHelper { @SafeVarargs static &lt;T&gt; T[] asArray(T... objs) { return objs; }}String[] ss = ArrayHelper.asArray(\"a\", \"b\", \"c\");Integer[] ns = ArrayHelper.asArray(1, 2, 3); 谨慎使用泛型可变参数1234567891011121314151617public class Main { public static void main(String[] args) { String[] arr = asArray(\"one\", \"two\", \"three\"); System.out.println(Arrays.toString(arr)); // ClassCastException: String[] firstTwo = pickTwo(\"one\", \"two\", \"three\"); System.out.println(Arrays.toString(firstTwo)); } static &lt;K&gt; K[] pickTwo(K k1, K k2, K k3) { return asArray(k1, k2); } static &lt;T&gt; T[] asArray(T... objs) { return objs; }} 直接调用asArray(T...)似乎没有问题，但是在另一个方法中，我们返回一个泛型数组就会产生ClassCastException，原因还是因为擦拭法，在pickTwo()方法内部，编译器无法检测K[]的正确类型，因此返回了Object[]。如果仔细观察，可以发现编译器对所有可变泛型参数都会发出警告，除非确认完全没有问题，才可以用@SafeVarargs消除警告。如果在方法内部创建了泛型数组，最好不要将它返回给外部使用。","link":"/Study/Java/%E6%B3%9B%E5%9E%8B/"},{"title":"面向对象基础","text":"面向对象编程，是一种通过对象的方式，把现实世界映射到计算机模型的一种编程方法。在本章，我们将讨论面向对象的基本概念（类，实例，方法等）、面向对象的实现方式（继承，多态）、Java语言提供的机制（package，class path，jar）以及Java标准库提供的核心类（字符串、包装类型、JavaBean、枚举、常用工具类等）。通过本章的学习，完全可以理解并掌握面向对象的基本思想。 现实世界中，我们定义了“人”这种抽象概念，而具体的人则是“小明”、“小红”、“小军”等一个个具体的人。所以，“人”可以定义为一个类（class），而具体的人则是实例（instance）。同样的，“书”也是一种抽象的概念，所以它是类，而《Java核心技术》、《Java编程思想》、《Java学习笔记》则是实例。 所以只要理解了class和instance的概念，基本上就明白了什么是面向对象编程。class是一种对象模板，而instance是对象实例。 在Java中，创建一个类，例如： 1234class Person { public String name; public int age;} 一个class可以包含多个字段（field），字段用来描述一个类的特征。上面的Person类，我们定义了两个字段，一个String类型的字段name，一个int类型的字段age。因此，通过class把一组数据汇集到一个对象上，实现了数据封装。 public是用来修饰字段的，它表示这个字段可以被外部访问。 定义了class，只是定义了对象模板，而要根据对象模板创建出真正的对象实例，必须用new操作符。new操作符可以创建一个实例，然后我们要定义一个引用类型的变量来指向这个实例。 1Person ming = new Person(); 上述代码创建了一个Person类型的实例，并通过变量ming指向它。new Person()是创建Person实例，Person ming是定义Person类型的变量ming，指向刚创建的Person实例。有了这个指向实例的变量，我们就可以通过这个变量来操作实例，访问实例变量用变量.字段。 1234567ming.name = \"Xiao Ming\"; // 对字段name赋值ming.age = 12; // 对字段age赋值System.out.println(ming.name); // 访问字段namePerson hong = new Person();hong.name = \"Xiao Hong\";hong.age = 15; 上述两个变量分别指向两个不同的实例，两个instance拥有class定义的name和age字段，且各自都有一份独立的数据，互不干扰。 方法一个class可以包含多个field，但是直接把field用public暴露给外部可能会破坏封装性，直接操作field也容易造成逻辑混乱。为了避免外部代码直接访问field，我们可以用private修饰field，拒绝外部访问。 把field从public改成private，外部代码不能访问这些field，那我们定义这些field有什么用？怎么才能给它赋值？怎么才能读取它的值？ 所以我们使用方法（method）来让外部代码可以间接修改field。 1234567891011121314151617181920212223242526272829303132public class Main { public static void main(String[] args) { Person ming = new Person(); ming.setName(\"Xiao Ming\"); // 设置name ming.setAge(12); // 设置age System.out.println(ming.getName() + \", \" + ming.getAge()); }}class Person { private String name; private int age; public String getName() { return this.name; } public void setName(String name) { this.name = name; } public int getAge() { return this.age; } public void setAge(int age) { if (age &lt; 0 || age &gt; 100) { throw new IllegalArgumentException(\"invalid age value\"); } this.age = age; }} 虽然外部代码不能直接修改private字段，但是，外部代码可以调用方法setName()和setAge()来间接修改private字段。在方法内部，我们就有机会检查参数的合理性。比如，setAge()就会检查传入的参数，若参数超出了范围就会报错。这样，外部代码就没有任何机会把age设置成不合理的值。 所以，一个class通过定义method，就可以给外部代码暴露一些操作的接口，同时内部保证逻辑一致性。 调用方法的语法是实例变量.方法名(参数); 。 有public方法，自然就有private方法。和private字段一样，private方法不允许外部调用，那我们定义private方法有什么用？ 定义private方法的理由是内部方法是可以调用private方法的。 1234567891011121314151617class Person { private String name; private int birth; public void setBirth(int birth) { this.birth = birth; } public int getAge() { return calcAge(2019); // 调用private方法 } // private方法: private int calcAge(int currentYear) { return currentYear - this.birth; }} 上述代码中，calcAge()是一个private方法，外部代码无法调用，但是内部方法getAge()可以调用它。 我们还注意到，这个Person类只定义了birth字段，没有定义age字段，获取age时，通过方法getAge()返回的是一个实时计算的值，并非存储在某个字段的值。这说明方法可以封装一个类的对外接口，调用方不需要知道也不关心Person实例在内部到底有没有age字段。 在方法内部，可以使用一个隐含的变量this，它始终指向当前实例。因此，通过this.field就可以访问当前实例字段。如果没有命名冲突，可以忽略this。 123456class Person { private String name; public String getName() { return name; // 相当于this.name }} 但是如果有局部变量和字段重名，那么局部变量优先级更高，就必须加上this。 123456class Person { private String name; public void setName(String name) { this.name = name; // 前面的this不可少，少了就变成局部变量name了 }} 方法参数方法可以包含0个或任意个参数，方法参数用于接受传递给方法的变量值。调用方法时必须严格按照参数的定义一一传递。 可变参数可变参数用类型…定义，可变参数相当于数组类型。 12345678910111213class Group { private String[] names; public void setNames(String... names) { this.names = names; }}// 调用时可以这么写Group g = new Group();g.setNames(\"Xiao Ming\", \"Xiao Hong\", \"Xiao Jun\"); // 传入3个Stringg.setNames(\"Xiao Ming\", \"Xiao Hong\"); // 传入2个Stringg.setNames(\"Xiao Ming\"); // 传入1个Stringg.setNames(); // 传入0个String 完全可以把可变参数改写为String[]类型。但是，调用方需要自己先构造String[]，比较麻烦。 12Group g = new Group();g.setNames(new String[] {\"Xiao Ming\", \"Xiao Hong\", \"Xiao Jun\"}); // 传入1个String[] 参数绑定调用方把参数传递给实例方法时，调用时传递的值会按参数位置一一绑定。基本类型参数的传递，是调用方值的复制。双方各自的后续修改，互不影响。引用类型参数的传递，调用方的变量和接收方的参数变量，指向的是同一个对象。双方任意一方对这个对象的修改，都会影响对方（因为指向同一个对象嘛）。 构造方法创建实例的时候，我们经常需要同时初始化这个实例的字段。创建实例的时候，实际上是通过构造方法来初始化实例的。由于构造方法是如此特殊，所以构造方法的名称就是类名。构造方法的参数没有限制，在方法内部，也可以编写任意语句。但是，和普通方法相比，构造方法没有返回值（也没有void），调用构造方法，必须用new操作符。 默认构造方法是不是任何class都有构造方法？是的。如果一个class没有定义构造方法，编译器会自动为我们生成一个默认构造方法，它没有参数，也没有执行语句。如果我们自定义了一个构造方法，那么编译器就不再自动创建默认构造方法。如果既要能使用带参数的构造方法，又想保留不带参数的构造方法，那么只有把两个构造方法都定义出来。 没有在构造方法中初始化字段时，引用类型的字段默认是null，数值类型的字段用默认值，int类型默认值是0，布尔类型默认值是false。 既对字段进行初始化，又在构造方法中对字段进行初始化。当我们创建对象的时候，得到的对象实例，字段的初始值是啥？ 在Java中，创建对象实例的时候，先初始化字段，再按构造方法的代码初始化。 多构造方法可以定义多个构造方法，在通过new操作符调用时，编译器通过构造方法的参数数量、位置和类型自动区分。 一个构造方法可以调用其他构造方法，这样做的目的是便于代码复用。调用其他构造方法的语法是this(…)。 1234567891011121314class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } public Person(String name) { this(name, 18); // 调用另一个构造方法Person(String, int) } public Person() { this(\"Unnamed\"); // 调用另一个构造方法Person(String) }} 方法重载在一个类中，我们可以定义多个方法。如果有一系列方法，它们的功能都是类似的，只有参数有所不同，那么，可以把这一组方法名做成同名方法。这种方法名相同，但各自的参数不同，称为方法重载（Overload）。方法重载的目的是，功能类似的方法使用同一名字，更容易记住，因此，调用起来更简单。 举个例子，String类提供了多个重载方法indexOf()，可以查找子串： int indexOf(int ch)：根据字符的Unicode码查找； int indexOf(String str)：根据字符串查找； int indexOf(int ch, int fromIndex)：根据字符查找，但指定起始位置； int indexOf(String str, int fromIndex)根据字符串查找，但指定起始位置。 继承继承是面向对象编程中非常强大的一种机制，它首先可以复用代码。当我们让Student从Person继承时，Student就获得了Person的所有功能，我们只需要为Student编写新增的功能。Java使用extends关键字来实现继承。 12345678910111213141516class Person { private String name; private int age; public String getName() {...} public void setName(String name) {...} public int getAge() {...} public void setAge(int age) {...}}class Student extends Person { // 不要重复name和age字段/方法, // 只需要定义新增score字段/方法: private int score; public int getScore() { … } public void setScore(int score) { … }} 注意到我们在定义Person的时候，没有写extends。在Java中，没有明确写extends的类，编译器会自动加上extends Object。所以，任何类，除了Object，都会继承自某个类。 Java只允许一个class继承自一个类，因此，一个类有且仅有一个父类。只有Object特殊，它没有父类。 protected继承有个特点，子类无法访问父类的private字段，这就使得继承的作用被削弱了。为了让子类可以访问父类的字段，我们把private改成protected，protected修饰的字段可以被子类访问。 因此，protected关键字可以把字段和方法权限控制在继承树内部，protected字段和方法可以被其子类，以及子类的子类所访问。 supersuper关键字表示父类。子类引用父类的字段，可以用field.fieldName。实际上，这里使用super.name，或者this.name，或者name，效果都是一样的。编译器会自动定位到父类的name字段。 12345678910111213141516class Person { protected String name; protected int age; public Person(String name, int age) { this.name = name; this.age = age; }}class Student extends Person { protected int score; public Student(String name, int age, int score) { //super(); // 自动调用父类的构造方法，但父类并没有无参构造函数，因此编译失败。解决方法是调用父类存在的某个构造方法。 super(name, age); this.score = score; }} 在Java中，任何class的构造方法，第一行语句必须是调用父类的构造方法。如果没有明确地调用父类的构造方法，编译器会帮我们自动加一句super()。父类没有默认的构造方法，子类就必须显式调用super()，并给出参数以便让编译器定位到父类的一个合适的构造方法。 这里还顺带引出了另一个问题：即子类不会继承任何父类的构造方法。子类默认的构造方法是编译器自动生成的，不是继承的。 阻止继承正常情况下，只要某个class没有final修饰符，那么任何类都可以从该class继承。 向上转型这种把一个子类类型安全的变为父类类型的赋值，被称为向上转型（upcasting）。 向下转型和向上转型相反，如果把一个父类类型强制转型为子类类型，就是向下转型（downcasting）。不能把父类变为子类，因为子类功能比父类多，多的功能无法凭空变出来。因此，向下转型很可能会失败。失败的时候，JVM会报ClassCastException。 为了避免向下转型出错，Java提供了instanceof操作符，先判断一个实例究竟是不是某种类型。 12345Person p = new Student();if (p instanceof Student) { // 只有判断成功才会向下转型: Student s = (Student) p; // 一定会成功} 区分继承和组合在使用继承时，我们要注意逻辑一致性。继承是is关系，组合是has关系。比如，Student继承自Book，这在逻辑上是不通的，Student不是Book，是持有Book。 多态在继承关系中，子类如果定义了一个与父类方法签名完全相同的方法，被称为覆写（Override）。Override和Overload不同的是，如果方法签名如果不同，就是Overload，Overload方法是一个新方法；如果方法签名相同，并且返回值也相同，就是Override。 在Java中，方法名相同，方法参数相同，但方法返回值不同，也是不同的方法。在Java程序中，出现这种情况，编译器会报错。 加上@Override可以让编译器帮助检查是否进行了正确的覆写。希望进行覆写，但是不小心写错了方法签名，编译器会报错。但是@Override不是必需的。 Java的实例方法调用是基于运行时的实际类型的动态调用，而非变量的声明类型。这个非常重要的特性在面向对象编程中称之为多态。多态是指，针对某个类型的方法调用，其真正执行的方法取决于运行时期实际类型的方法。 覆写Object方法因为所有的class最终都继承自Object，而Object定义了几个重要的方法： toString()：把instance输出为String； equals()：判断两个instance是否逻辑相等； hashCode()：计算一个instance的哈希值。 在必要的情况下，我们可以覆写Object的这几个方法。 调用super在子类的覆写方法中，如果要调用父类的被覆写的方法，可以通过super来调用。 final继承允许子类覆写父类的方法。如果一个父类不允许子类对它的某个方法覆写，可以把该方法标记为final。用final标识的方法不能被Override。 对于一个类的实例字段，同样可以用final修饰。用final修饰的字段在初始化后不能被修改。 如果一个类不希望任何其他类继承自它，那么可以把这个类本身标记为final。用final修饰的类不能被继承。 抽象类如果父类的方法本身不需要实现任何功能，仅仅是为了定义方法签名，目的是让子类覆写它，那么可以把父类的方法声明为抽象方法。 把一个方法声明为abstract，表示它是一个抽象方法，本身没有任何实现方法的语句。因为这个抽象方法本身无法执行，所以其所在的类也无法被实例化。编译器会告诉我们，无法编译Person类，因为它包含抽象方法。必须把Person类本身也声明为abstract，才能正确编译它。 123abstract class Person { public abstract void run();} 无法实例化的抽象类有什么用？因为抽象类本身被设计成只能用于被继承，因此，抽象类可以强迫子类实现其定义的抽象方法，否则编译会报错。因此，抽象方法实际上相当于定义了“规范”。 面向抽象编程这种尽量引用高层类型，避免引用实际子类型的方式，称之为面向抽象编程。 面向抽象编程的本质就是： 上层代码只定义规范（例如：abstract class Person）； 不需要子类就可以实现业务逻辑（正常编译）； 具体的业务逻辑由不同的子类实现，调用者并不关心。 接口在抽象类中，抽象方法本质上是定义接口规范，即规定高层类的接口，从而保证所有子类都有相同的接口实现，这样多态就能发挥威力。如果一个抽象类没有字段，所有方法全部是抽象方法，就可以把该抽象类改写为接口interface。 在Java中，使用interface可以声明一个接口： 1234interface Person { void run(); String getName();} 所谓interface，就是比抽象类还要抽象的纯抽象接口，因为它连字段都不能有。因为接口定义的所有方法默认都是public abstract的，所以这两个修饰符不需要写出来（写不写效果都一样）。当一个具体的class去实现一个interface时，需要使用implements关键字。 我们知道，在Java中，一个类只能继承自另一个类，不能从多个类继承。但是，一个类可以实现多个interface。 1234class Student implements Person, Hello { // 实现了两个interface ...} 接口继承一个interface可以继承自另一个interface。interface继承自interface使用extends，相当于扩展了接口的方法。 继承关系合理设计interface和abstract class的继承关系，可以充分复用代码。一般来说，公共逻辑适合放在abstract class中，具体逻辑放到各个子类，而接口层次代表抽象程度。 在使用的时候，实例化的对象永远只能是某个具体的子类，但总是通过接口引用它，因为接口比抽象类更抽象。 default方法default方法的目的是，当我们需要给接口新增一个方法时，会涉及到修改全部子类。如果新增的是default方法，那么子类就不必全部修改，只需要在需要覆写的地方去覆写新增方法。 default方法和抽象类的普通方法是有所不同的。因为interface没有字段，default方法无法访问字段，而抽象类的普通方法可以访问实例字段。 静态字段和静态方法在class中定义的字段，我们称之为实例字段。实例字段的特点是，每个实例都有独立的字段，各个实例的同名字段互不影响。还有一种字段，使用static修饰的字段，成为静态字段。实例字段在每个实例中都有自己的一个独立“空间”，但是静态字段只有一个共享“空间”，所有实例都会共享该字段。 对于静态字段，无论修改哪个实例的静态字段，效果都是一样的：所有实例的静态字段都被修改了，原因是静态字段并不属于实例。 虽然实例可以访问静态字段，但是它们指向的其实都是Person class的静态字段。所以，所有实例共享一个静态字段。 因此，不推荐用实例变量.静态字段去访问静态字段，因为在Java程序中，实例对象并没有静态字段。在代码中，实例对象能访问静态字段只是因为编译器可以根据实例类型自动转换为类名.静态字段来访问静态对象。 推荐用类名来访问静态字段。可以把静态字段理解为描述class本身的字段（非实例字段）。 有静态字段，就有静态方法。用static修饰的方法称为静态方法。调用实例方法必须通过一个实例变量，而调用静态方法则不需要实例变量，通过类名就可以调用。静态方法类似其它编程语言的函数。 因为静态方法属于class而不属于实例，因此，静态方法内部，无法访问this变量，也无法访问实例字段，它只能访问静态字段。通过实例变量也可以调用静态方法，但这只是编译器自动帮我们把实例改写成类名而已。通常情况下，通过实例变量访问静态字段和静态方法，会得到一个编译警告。静态方法经常用于工具类。静态方法也经常用于辅助方法。注意到Java程序的入口main()也是静态方法。 接口的静态字段interface是一个纯抽象类，所以它不能定义实例字段。但是，interface可以有静态字段，且必须为final类型。编译器会自动把该字段变为public static final类型。 包在Java中，我们用package来解决名字冲突。 Java定义了一种名字空间，称之为package包。一个类总是属于一个包的，类名只是简写，真正的完整类名是包名.类名。 JVM执行的时候只看完整类名，因此只要包名不同，类就不同。 要特别注意，包没有父子关系 。java.util和java.util.zip是不同的包，两者没有任何继承关系。 包作用域位于同一个包的类，可以访问包作用域的字段和方法。不用public、protected、private修饰的字段和方法就是包作用域。 import在一个class中，我们总会引用其他的class。第一种方法，直接写出完整类名。第二种方法是用import语句，然后写简单类名。在写import的时候，可以使用*，表示把这个包下面的所有class都导入进来。还有一种import static的语法，它可以导入可以导入一个类的静态字段和静态方法。 Java编译器最终编译出的.class文件只使用完整类名，因此，在代码中，当编译器遇到一个class名称时： 如果是完整类名，就直接根据完整类名查找这个class； 如果是简单类名，按下面的顺序依次查找： 查找当前package是否存在这个class； 查找import的包是否包含这个class； 查找java.lang包是否包含这个class。 如果按照上面的规则还无法确定类名，则编译报错。 编写class的时候，编译器会自动帮我们做两个import动作： 默认自动import当前package的其他class； 默认自动import java.lang.*。 如果有两个class名称相同，那么只能import其中一个，另一个必须写完整类名。为了避免名字冲突，我们需要确定唯一的包名。推荐的做法是使用倒置的域名来确保唯一性。要注意不要和java.lang包的类重名，即自己的类不要使用这些名字，String，System，Runtime。也要注意不要和JDK同名。 作用域定义为public的class、interface可以被其他任何类访问： 定义为private的field、method无法被其他类访问。 private访问权限被限定在class的内部，而且与方法声明顺序无关。推荐把private方法放到后面，因为public方法定义了类对外提供的功能，阅读代码的时候，应该先关注public方法。由于Java支持嵌套类，如果一个类内部还定义了嵌套类，那么，嵌套类拥有访问private的权限： protected作用于继承关系。定义为protected的字段和方法可以被子类访问，以及子类的子类。 包作用域是指一个类允许访问同一个package的没有public、private修饰的class，以及没有public、protected、private修饰的字段和方法。 在方法内部定义的变量称为局部变量，局部变量作用域从变量声明处开始到对应的块结束。方法参数也是局部变量。使用局部变量时，应该尽可能把局部变量的作用域缩小，尽可能延后声明局部变量。 final字段。用final修饰class可以阻止被继承。用final修饰method可以阻止被子类覆写。用final修饰field可以阻止被重新赋值。用final修饰局部变量可以阻止被重新赋值。 如果不确定是否需要public，就不声明为public，即尽可能少地暴露对外的字段和方法。 把方法定义为package权限有助于测试，因为测试类和被测试类只要位于同一个package，测试代码就可以访问被测试类的package权限方法。 一个.java文件只能包含一个public类，但可以包含多个非public类。如果有public类，文件名必须和public类的名字相同。 内部类如果一个类定义在另一个类的内部，这个类就是Inner Class。它与普通类有个最大的不同，就是Inner Class的实例不能单独存在，必须依附于一个Outer Class的实例。 Inner Class和普通Class相比，除了能引用Outer实例外，还有一个额外的“特权”，就是可以修改Outer Class的private字段，因为Inner Class的作用域在Outer Class内部，所以能访问Outer Class的private字段和方法。 还有一种定义Inner Class的方法，它不需要在Outer Class中明确地定义这个Class，而是在方法内部，通过匿名类（Anonymous Class）来定义。 匿名类和Inner Class一样，可以访问Outer Class的private字段和方法。之所以我们要定义匿名类，是因为在这里我们通常不关心类名，比直接定义Inner Class可以少写很多代码。 除了接口外，匿名类也完全可以继承自普通类。 用static修饰的内部类和Inner Class有很大的不同，它不再依附于Outer的实例，而是一个完全独立的类，因此无法引用Outer.this，但它可以访问Outer的private静态字段和静态方法。如果把静态内部类（Static Nested Class）移到Outer之外，就失去了访问private的权限。 classpath和jarclasspathclasspath是JVM用到的一个环境变量，它用来指示JVM如何搜索class。因为Java是编译型语言，源码文件是.java，而编译后的.class文件才是真正可以被JVM执行的字节码。因此，JVM需要知道，如果要加载一个abc.xyz.Hello的类，应该去哪搜索对应的Hello.class文件。所以，classpath就是一组目录的集合，它设置的搜索路径与操作系统相关。 classpath的设定方法有两种： 在系统环境变量中设置classpath环境变量，不推荐； 在启动JVM时设置classpath变量，推荐。 我们强烈不推荐在系统环境变量中设置classpath，那样会污染整个系统环境。在启动JVM时设置classpath才是推荐的做法。实际上就是给java命令传入-classpath或-cp参数。没有设置系统环境变量，也没有传入-cp参数，那么JVM默认的classpath为.，即当前目录。 在IDE中运行Java程序，IDE自动传入的-cp参数是当前工程的bin目录和引入的jar包。 jar包如果有很多.class文件，散落在各层目录中，肯定不便于管理。如果能把目录打一个包，变成一个文件，就方便多了。jar包就是用来干这个事的，它可以把package组织的目录层级，以及各个目录下的所有文件（包括.class文件和其他文件）都打成一个jar文件，这样一来，无论是备份，还是发给客户，就简单多了。如果我们要执行一个jar包的class，就可以把jar包放到classpath中。 这样JVM会自动在hello.jar文件里去搜索某个类。 那么问题来了：如何创建jar包？因为jar包就是zip包，所以，直接在资源管理器中，找到正确的目录，点击右键，在弹出的快捷菜单中选择“发送到”，“压缩(zipped)文件夹”，就制作了一个zip文件。然后，把后缀从.zip改为.jar，一个jar包就创建成功。 jar包还可以包含一个特殊的/META-INF/MANIFEST.MF文件，MANIFEST.MF是纯文本，可以指定Main-Class和其它信息。JVM会自动读取这个MANIFEST.MF文件，如果存在Main-Class，我们就不必在命令行指定启动的类名，而是用更方便的命令java -jar hello.jar。 jar包还可以包含其它jar包，这个时候，就需要在MANIFEST.MF文件里配置classpath了。在大型项目中，不可能手动编写MANIFEST.MF文件，再手动创建zip包。Java社区提供了大量的开源构建工具，例如Maven，可以非常方便地创建jar包。 模块从Java 9开始，JDK又引入了模块（Module）。jar只是用于存放class的容器，它并不关心class之间的依赖。从Java 9开始引入的模块，主要是为了解决“依赖”这个问题。如果a.jar必须依赖另一个b.jar才能运行，那我们应该给a.jar加点说明啥的，让程序在编译和运行的时候能自动定位到b.jar，这种自带“依赖关系”的class容器就是模块。 从Java 9开始，原有的Java标准库已经由一个单一巨大的rt.jar分拆成了几十个模块，这些模块以.jmod扩展名标识，可以在$JAVA_HOME/jmods目录下找到它们。 这些.jmod文件每一个都是一个模块，模块名就是文件名。例如：模块java.base对应的文件就是java.base.jmod。模块之间的依赖关系已经被写入到模块内的module-info.class文件了。所有的模块都直接或间接地依赖java.base模块，只有java.base模块不依赖任何模块，它可以被看作是“根模块”，好比所有的类都是从Object直接或间接继承而来。 把一堆class封装为jar仅仅是一个打包的过程，而把一堆class封装为模块则不但需要打包，还需要写入依赖关系，并且还可以包含二进制代码（通常是JNI扩展）。此外，模块支持多版本，即在同一个模块中可以为不同的JVM提供不同的版本。 在src目录下多了一个module-info.java这个文件，这就是模块的描述文件。在这个模块中，它长这样： 1234module hello.world { requires java.base; // 可不写，任何模块都会自动引入java.base requires java.xml;} 其中，module是关键字，后面的hello.world是模块的名称，它的命名规范与包一致。花括号的requires xxx;表示这个模块需要引用的其他模块名。除了java.base可以被自动引入外，这里我们引入了一个java.xml的模块。当我们使用模块声明了依赖关系后，才能使用引入的模块。 可以用JDK提供的命令行工具来编译并创建模块。运行模块。打包JRE。运行Java程序的时候，实际上我们用到的JDK模块，并没有那么多。不需要的模块，完全可以删除。 过去发布一个Java应用程序，要运行它，必须下载一个完整的JRE，再运行jar包。而完整的JRE块头很大，有100多M。怎么给JRE瘦身呢？现在，JRE自身的标准库已经分拆成了模块，只需要带上程序用到的模块，其他的模块就可以被裁剪掉。怎么裁剪JRE呢？并不是说把系统安装的JRE给删掉部分模块，而是“复制”一份JRE，但只带上用到的模块。 要分发我们自己的Java应用程序，只需要把这个jre目录打个包给对方发过去，对方直接运行上述命令即可，既不用下载安装JDK，也不用知道如何配置我们自己的模块，极大地方便了分发和部署。 访问权限。class的这些访问权限只在一个模块内有效，模块和模块之间，例如，a模块要访问b模块的某个class，必要条件是b模块明确地导出了可以访问的包。模块进一步隔离了代码的访问权限。","link":"/Study/Java/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%9F%BA%E7%A1%80/"},{"title":"IO","text":"I/O是指Input/Output，即输入和输出。以内存为中心，Input指从外部读入数据到内存，例如把文件从磁盘读取到内存，从网络读取数据到内存等等；Output指把数据从内存输出到外部，例如，把数据从内存写入到文件，把数据从内存输出到网络等等。为什么要把数据读到内存才能处理这些数据？因为代码是在内存中运行的，数据也必须读到内存，最终的表示方式无非是byte数组，字符串等，都必须存放在内存里。 从Java代码来看，输入实际上就是从外部，例如，硬盘上的某个文件，把内容读到内存，并且以Java提供的某种数据类型表示，例如，byte[]，String，这样后续代码才能处理这些数据。因为内存有“易失性”，所以必须把处理后的数据以某种方式输出，例如，写入到文件。Output实际上就是把Java表示的数据格式，例如，byte[]，String等输出到某个地方。 IO流IO流是一种顺序读写数据的模式，它的特点是单向流动。数据类似自来水一样在水管中流动，所以我们把它称为IO流。 InputStream/OutputStreamIO流以byte（字节）为最小单位，因此也称为字节流。例如，我们要从磁盘读入一个文件，包含6个字节，就相当于读入了6个字节的数据。这6个字节是按顺序读入的，所以是输入字节流。反过来，我们把6个字节从内存写入磁盘文件，就是输出字节流。在Java中，InputStream代表输入字节流，OutputStream代表输出字节流，这是最基本的两种IO流。 Reader/Writer如果我们需要读写的是字符，并且字符不全是单字节表示的ASCII字符，那么，按照char来读写显然更方便，这种流称为字符流。Java提供了Reader和Writer表示字符流，字符流传输的最小数据单位是char。例如，我们把char[]数组Hi你好这4个字符用Writer字符流写入文件，并且使用UTF-8编码，得到的最终文件内容是8个字节，英文字符H和i各占一个字节，中文字符你好各占3个字节。 12340x480x690xe4bda00xe5a5bd 反过来，我们用Reader读取以UTF-8编码的这8个字节，会从Reader中得到Hi你好这4个字符。 因此，Reader和Writer本质上是一个能自动编码解码的InputStream和OutputStream。 使用Reader，数据源虽然是字节，但我们读入的数据都是char类型的字符，原因是Reader内部把读入的byte做了解码，转换成了char。使用InputStream，我们读入的数据和原始二进制数据一模一样，是byte[]数组，但是我们可以自己把二进制byte[]数组按照某种编码转换成字符串。究竟使用Reader还是InputStream，要取决于具体的使用场景。如果数据源不是文本，就只能使用InputStream，如果数据源是文本，使用Reader更方便一些。Writer和OutputStream是类似的。 同步和异步同步IO是指，读写IO时代码必须等待数据返回后才继续执行后续代码，它的优点是代码编写简单，缺点是CPU执行效率低。而异步IO是指，读写IO时仅发出请求，然后立刻执行后续代码，它的优点是CPU执行效率高，缺点是代码编写复杂。 Java标准库的包java.io提供了同步IO，而java.nio则是异步IO。上面我们讨论的InputStream、OutputStream、Reader和Writer都是同步IO的抽象类，对应的具体实现类，以文件为例，有FileInputStream、FileOutputSteam、FileReader和FileWriter。 本节我们只讨论Java的同步IO，即输入/输出流的IO模型。 File对象在计算机系统中，文件是非常重要的存储方式。Java的标准库java.io提供了File对象来操作文件和目录。 要构造一个File对象，需要传入文件路径，既可以传入绝对路径，也可以传入相对路径。绝对路径是以根目录开头的完整路径，例如： 1File f = new File(\"C:\\\\Windows\\\\notepad.exe\"); 传入相对路径时，相对路径前面加上当前目录就是绝对路径。可以用.来表示当前路径，..用来表示上级目录。 1234// 假设当前目录是C:\\DocsFile f1 = new File(\"sub\\\\javac\"); // 绝对路径是C:\\Docs\\sub\\javacFile f3 = new File(\".\\\\sub\\\\javac\"); // 绝对路径是C:\\Docs\\sub\\javacFile f3 = new File(\"..\\\\sub\\\\javac\"); // 绝对路径是C:\\sub\\javac File对象有3种形式表示的路径，一种是getPath()，返回构造方法传入的路径，一种是getAbsolutePath()，返回绝对路径，一种是getCanonicalPath()，它和绝对路径相似，但返回的是规范路径。 什么是规范路径呢？例如，绝对路径可以表示成C:\\Windows\\System32\\..\\notepad.exe，而规范路径就是把.和..转换成标准的绝对路径后的路径：C:\\Windows\\notepad.exe。Windows和Linux的路径分隔符不同，File对象有一个静态变量用于表示当前平台的系统分隔符。 1System.out.println(File.separator); // 根据当前平台打印\"\\\"或\"/\" 文件和目录File对象既可以表示文件，也可以表示目录。特别要注意的是，构造一个File对象，即使传入的文件或目录不存在，代码也不会出错，因为构造一个File对象，并不会导致任何磁盘操作。只有当我们调用File对象的某些方法时，才真正进行磁盘操作。例如，调用isFile()判断一个File对象是否是一个已存在的文件，调用isDirectory()判断该File对象是否是一个已存在的目录。 用File对象获取到一个文件时，还可以进一步判断文件的权限和大小： boolean canRead()：是否可读； boolean canWrite()：是否可写； boolean canExecute()：是否可执行； long length()：文件字节大小。 对目录而言，是否可执行表示能否列出它包含的文件和子目录。 创建和删除文件当File对象表示一个文件时，可以通过createNewFile()创建一个新文件，用delete()删除该文件。 有时候，程序需要读取一些临时文件，File对象提供了createTempFile()来创建一个临时文件，以及deleteOnExit()在JVM退出时自动删除该文件。 12File f = File.createTempFile(\"tmp-\", \".txt\"); // 提供临时文件的前缀和后缀f.deleteOnExit(); // JVM退出时自动删除 遍历文件和目录当File对象表示一个目录时，可以使用list()和listFiles()列出目录下的文件和子目录名。ListFiles()提供了一系列重载方法，可以过滤不想要的文件和目录。 123456789101112131415161718192021public static void main(String[] args) throws IOException { File f = new File(\"C:\\\\Windows\"); File[] fs1 = f.listFiles(); // 列出所有文件和子目录 printFiles(fs1); File[] fs2 = f.listFiles(new FilenameFilter() { // 仅列出.exe文件 public boolean accept(File dir, String name) { return name.endsWith(\".exe\"); // 返回true表示接受该文件 } }); printFiles(fs2);}static void printFiles(File[] files) { System.out.println(\"==========\"); if (files != null) { for (File f : files) { System.out.println(f); } } System.out.println(\"==========\");} 和文件操作类似，File对象如果表示一个目录，可以通过以下方法创建和删除目录： boolean mkdir()：创建当前File对象表示的目录 boolean mkdirs()：创建当前File对象表示的目录，并在必要时将不存在的父目录也创建出来 boolean delete()：删除当前File对象表示的目录，当前目录必须为空才能删除成功 PathJava标准库还提供了一个Path对象，它位于java.nio.file包。Path对象和File对象类似，但操作更加简单。 12345678910111213141516171819202122232425import java.io.*;import java.nio.file.*;public class Main { public static void main(String[] args) throws IOException { Path p1 = Paths.get(\".\", \"project\", \"study\"); // 构造一个Path对象 System.out.println(p1); Path p2 = p1.toAbsolutePath(); // 转换为绝对路径 System.out.println(p2); Path p3 = p2.normalize(); // 转换为规范路径 System.out.println(p3); File f = p3.toFile(); // 转换为File对象 System.out.println(f); for (Path p : Paths.get(\"..\").toAbsolutePath()) { // 可以直接遍历Path System.out.println(\" \" + p); } }}/*打印出来以下内容*/./project/study/app/./project/study/app/project/study/app/project/study app .. 如果需要对目录进行复杂的拼接、遍历等操作，使用Path对象更方便。 InputStreamInputStream就是Java标准库提供的最基本的输入流。它位于java.io这个包里。java.io包提供了所有同步IO的功能。要特别注意的一点是，InputStream并不是一个接口，而是一个抽象类，它是所有输入流的超类。这个抽象类定义的一个最重要的方法是int read()，签名如下： 1public abstract int read() throws IOException; 这个方法会读取输入流的下一个字节，并返回字节表示的int值（0~255）。如果已读到末尾，返回-1表示不能继续读取了。 FileInputStream是InputStream的一个子类。顾名思义，FileInputStream就是从文件流种读取数据。下面的代码演示了如何完整的读取一个FileInputStream的所有字节： 123456789101112public void readFile() throws IOException { // 创建一个FileInputStream对象: InputStream input = new FileInputStream(\"src/readme.txt\"); for (;;) { int n = input.read(); // 反复调用read()方法，直到返回-1 if (n == -1) { break; } System.out.println(n); // 打印byte的值 } input.close(); // 关闭流} 在计算机中，类似文件、网络端口这些资源，都是由操作系统统一管理的。应用程序在运行的过程中，如果打开了一个文件进行读写，完成后要及时的关闭，以便让操作系统把资源释放掉，否则，应用程序占用的资源会越来越多，不但白白占用内存，还会影响其他应用程序的运行。 InputStream和OutputStream都是通过close()方法来关闭流。关闭流就会释放对应的底层资源。 我们还注意到在读取或写入IO流的过程中，可能会发生错误，例如，文件不存在导致无法读取，没有写权限导致写入失败等等。这些底层错误由Java虚拟机自动封装成IOException异常并抛出。因此，所有与IO操作相关的代码都必须正确处理IOException。 仔细观察上面的代码，会发现一个潜在的问题：如果读取过程发生了IO错误，InputStream就没法正确的关闭，资源也就没法及时释放。因此，需要用try…finally来保证InputStream在无论是否发生IO错误的时候都能正确地关闭： 123456789101112public void readFile() throws IOException { InputStream input = null; try { input = new FileInputStream(\"src/readme.txt\"); int n; while ((n = input.read()) != -1) { // 利用while同时读取并判断 System.out.println(n); } } finally { if (input != null) { input.close(); } }} 用try…finally来编写上述代码会感觉比较复杂，更好的写法是利用Java 7引入的新的try(resource)的语法，只需要编写try语句，让编译器自动为我们关闭资源。推荐的写法如下： 12345678public void readFile() throws IOException { try (InputStream input = new FileInputStream(\"src/readme.txt\")) { int n; while ((n = input.read()) != -1) { System.out.println(n); } } // 编译器在此自动为我们写入finally并调用close()} 实际上，编译器并不会特别地为InputStream加上自动关闭。编译器只看try(resource = ...)中的对象是否实现了java.lang.AutoCloseable接口，如果实现了，就自动加上finally语句并调用close()方法。InputStream和OutputStream都实现了这个接口，因此，都可以用在try(resource)中。 缓冲在读取流的时候，一次读取一个字节并不是最高效的方法。很多流支持一次性读取多个字节到缓冲区，对于文件和网络流来说，利用缓冲区一次性读取多个字节效率往往要高很多。InputStream提供了两个重载方法来支持读取多个字节： int read(byte[] b)，读取若干字节并填充到byte[]数组，返回读取的字节数 int read(byte[] b, int off, int len)，指定byte[]数组的偏移量和最大填充数 利用上述方法一次性读取多个字节时，需要先定义一个byte[]数组作为缓冲区，read()方法会尽可能多地读取字节到缓冲区，但不会超过缓冲区大小。read()方法的返回值不再是字节的int值，而是返回实际读取了多少个字节，如果返回-1，表示没有更多的数据了。利用缓冲区一次读取多个字节的代码如下： 12345678910public void readFile() throws IOException { try (InputStream input = new FileInputStream(\"src/readme.txt\")) { // 定义1000个字节大小的缓冲区: byte[] buffer = new byte[1000]; int n; while ((n = input.read(buffer)) != -1) { // 读取到缓冲区 System.out.println(\"read \" + n + \" bytes.\"); } }} 阻塞在调用InputStream的read()方法读取数据时，我们说read()方法是阻塞（Blocking）的。它的意思是，对于下面的代码： 123int n;n = input.read(); // 必须等待read()方法返回才能执行下一行代码int m = n; 执行到第二行代码时，必须等read()方法返回后才能继续。因为读取IO流相比执行普通代码，速度会慢很多，因此，无法确定read()方法调用到底要花费多少时间。 InputStream实现类用FileInputStream可以从文件获取输入流，这是InputStream常用的一个实现类。此外，ByteArrayInputStream可以在内存中模拟一个InputStream。ByteArrayInputStream实际上是把一个byte[]数组在内存中变成一个InputStream，虽然实际应用不多，但测试的时候，可以用它来构造一个InputStream。 OutputStream和InputStream相反，OutputStream是Java标准库提供的最基本的输出流。OutputStream也是抽象类，它是所有输出流的超类。这个抽象类定义的一个重要方法就是void write(int b)，签名如下： 1public abstract void write(int b) throws IOException; 这个方法会写入一个字节到输出流，要注意的是，虽然传入的是int参数，但只会写入一个字节，即只写入int表示低8位表示字节的部分，相当于b &amp; 0xff。 和InputStream类似，OutputStream也提供了close()方法关闭输出流，以便释放系统资源。要特别注意：OutputStream还提供了一个flush()方法，它的目的是将缓冲区的内容真正输出到目的地。为什么要有flush()？因为向磁盘、网络写入数据的时候，出于效率的考虑，操作系统并不是输出一个字节就立刻写入到文件或者发送到网络，而是把输出的字节先放到内存的一个缓冲区里（本质上就是一个byte[]数组），等到缓冲区写满了，再一次性写入文件或者网络。对于很多IO设备来说，一次写1个字节和一次写1000个字节，花费的时间几乎是一样的，所以OutputStream有个flush()方法，能强制把缓冲区内容输出。 通常情况下，我们不需要调用这个flush()方法，因为缓冲区写满后OutputStream会自动调用它，并且，在调用close()方法关闭OutputStream之前，也会自动调用flush()方法。 但是，在某些情况下，我们必须手动调用flush()方法。 举个栗子： 小明正在开发一款在线聊天软件，当用户输入一句话后，就通过OutputStream的write()方法写入网络流。小明测试的时候发现，发送方输入后，接收方根本收不到任何信息，怎么肥四？ 原因就在于写入网络流是先写入内存缓冲区，等缓冲区满了才会一次性发送到网络。如果缓冲区大小是4K，则发送方要敲几千个字符后，操作系统才会把缓冲区的内容发送出去，这个时候，接收方会一次性收到大量消息。 解决办法就是每输入一句话后，立刻调用flush()，不管当前缓冲区是否已满，强迫操作系统把缓冲区的内容立刻发送出去。 实际上，InputStream也有缓冲区。例如，从FileInputStream读取一个字节时，操作系统往往会一次性读取若干字节到缓冲区，并维护一个指针指向未读的缓冲区。然后，每次我们调用int read()读取下一个字节时，可以直接返回缓冲区的下一字节，避免每次读一个字节都导致IO操作。当缓冲区全部读完后继续调用read()，则会出发操作系统的下一次读取并再次填满缓冲区。 FileOutputStream我们以FileOutputStream为例，演示如何将若干个字节写入文件流： 123456789public void writeFile() throws IOException { OutputStream output = new FileOutputStream(\"out/readme.txt\"); output.write(72); // H output.write(101); // e output.write(108); // l output.write(108); // l output.write(111); // o output.close();} 每次写入一个字节非常麻烦，更常见的方法是一次性写入若干字节。这是，可以用OutputStream提供的重载方法void write(byte[])来实现： 12345public void writeFile() throws IOException { OutputStream output = new FileOutputStream(\"out/readme.txt\"); output.write(\"Hello\".getBytes(\"UTF-8\")); // Hello output.close();} 和InputStream一样，上述代码没有考虑到在发生异常的情况下如何正确地关闭资源。写入过程也会经常发生IO错误，例如，磁盘已满，无权限写入等等。我们需要用try(resource)来保证OutputStream在无论是否发生IO错误的时候都能够正确地关闭： 12345public void writeFile() throws IOException { try (OutputStream output = new FileOutputStream(\"out/readme.txt\")) { output.write(\"Hello\".getBytes(\"UTF-8\")); // Hello } // 编译器在此自动为我们写入finally并调用close()} 阻塞OutputStream的write()方法也是阻塞的。 OutputStream实现类用FileOutputStream可以从文件获取输出流，这是OutputStream常用的一个实现类。此外，ByteArrayOutputStream可以在内存中模拟一个OutputStream。ByteArrayOutputStream实际上是把一个byte[]数组在内存中变成一个OutputStream，虽然实际应用不多，但测试的时候，可以用它来构造一个OutputStream。 同时操作多个AutoCloseable资源时，在try(resource) { ... }语句中可以同时写出多个资源，用;隔开。例如，同时读写两个文件： 123456// 读取input.txt，写入output.txt:try (InputStream input = new FileInputStream(\"input.txt\"); OutputStream output = new FileOutputStream(\"output.txt\")){ input.transferTo(output); // transferTo的作用是?} Filter模式Java的IO标准库提供的InputStream根据来源可以包括： FileInputStream，从文件读取数据，是最终数据源 ServletInputStream，从HTTP请求读取数据，是最终数据源 Socket.getInputStream()，从TCP连接读取数据，是最终数据源 … 直接使用继承，为各种InputStream附加更多功能，根本无法控制代码的复杂度，很快就会失控。为了解决依赖继承会导致子类数量失控的问题，JDK首先讲InputStream分为两大类： 一类是直接提供数据的基础InputStream： FileInputStream ByteArrayInputStream ServletInputStream … 一类是提供附加功能的InputStream： BufferedInputStream，缓冲 DigestInputStream，计算签名 CipherInputStream，加密/解密 … 当我们需要给一个基本的InputStream附加各种功能时，我们先确定这个能提供数据源的InputStream，因为我们需要的数据总得来自某个地方，例如，FileInputStream，数据来自文件： 1InputStream file = new FileInputStream(\"test.gz\"); 紧接着，我们希望FileInputStream能提供缓冲的功能来提高读取效率，因此我们用BufferedInputStream包装这个InputStream，得到的包装类型是BufferedInputStream，但它仍然被视为一个InputStream： 1InputStream buffered = new BufferedInputStream(file); 最后，假设该文件已经用gzip压缩，我们希望直接读取解压缩的内容，就可以再包装一个GZIPInputStream： 1InputStream gzip = new GZIPInputStream(buffered); 无论我们包装多少次，得到的对象始终是InputStream，我们直接用InputStream来引用它，就可以正确读取。 上述这种通过一个“基础”组件再叠加各种“附加”功能组件的模式，称之为Filter模式（或者装饰器模式：Decorator）。它可以让我们通过少量的类来实现各种功能的组合： 12345678910111213141516 ┌─────────────┐ │ InputStream │ └─────────────┘ ▲ ▲┌────────────────────┐ │ │ ┌─────────────────┐│ FileInputStream │─┤ └─│FilterInputStream│└────────────────────┘ │ └─────────────────┘┌────────────────────┐ │ ▲ ┌───────────────────┐│ByteArrayInputStream│─┤ ├─│BufferedInputStream│└────────────────────┘ │ │ └───────────────────┘┌────────────────────┐ │ │ ┌───────────────────┐│ ServletInputStream │─┘ ├─│ DataInputStream │└────────────────────┘ │ └───────────────────┘ │ ┌───────────────────┐ └─│CheckedInputStream │ └───────────────────┘ 类似的，OutputStream也是以这种模式来提供各种功能： 12345678910111213141516 ┌─────────────┐ │OutputStream │ └─────────────┘ ▲ ▲┌─────────────────────┐ │ │ ┌──────────────────┐│ FileOutputStream │─┤ └─│FilterOutputStream│└─────────────────────┘ │ └──────────────────┘┌─────────────────────┐ │ ▲ ┌────────────────────┐│ByteArrayOutputStream│─┤ ├─│BufferedOutputStream│└─────────────────────┘ │ │ └────────────────────┘┌─────────────────────┐ │ │ ┌────────────────────┐│ ServletOutputStream │─┘ ├─│ DataOutputStream │└─────────────────────┘ │ └────────────────────┘ │ ┌────────────────────┐ └─│CheckedOutputStream │ └────────────────────┘ 编写FilterInputStream我们也可以自己编写FilterInputStream，以便可以把自己的FilterInputStream“叠加”到任何一个InputStream中。下面的例子演示了如何编写一个CountInputStream，它的作用是对输入的字节计数。 123456789101112131415161718192021222324252627282930313233343536373839404142import java.io.*;public class Main { public static void main(String[] args) throws IOException { byte[] data = \"hello, world!\".getBytes(\"UTF-8\"); try (CountInputStream input = new CountInputStream(new ByteArrayInputStream(data))) { int n; while ((n = input.read()) != -1) { System.out.println((char)n); } System.out.println(\"Total read \" + input.getBytesRead() + \" bytes\"); } }}class CountInputStream extends FilterInputStream { private int count = 0; CountInputStream(InputStream in) { super(in); } public int getBytesRead() { return this.count; } public int read() throws IOException { int n = in.read(); if (n != -1) { this.count ++; } return n; } public int read(byte[] b, int off, int len) throws IOException { int n = in.read(b, off, len); if (n != -1) { this.count += n; } return n; }} 注意到在叠加多个FilterInputStream，我们只需要持有最外层的InputStream，并且，当最外层的InputStream关闭时（在try(resource)块的结束处自动关闭），内层的InputStream的close()方法也会被自动调用，并最终调用到最核心的“基础”InputStream，因此不存在资源泄露。 小结Java的IO标准库使用Filter模式为InputStream和OutputStream增加功能： 可以把一个InputStream和任意个FilterInputStream组合； 可以把一个OutputStream和任意个FilterOutputStream组合。 Filter模式可以在运行期动态增加功能。 操作ZipZipInputStream是一种FilterInputStream，它可以直接读取zip包的内容。另一个JarInputStream是从ZipInputStream派生，它增加的主要功能是直接读取jar文件里面的MANIFEST.MF文件。因为本质上jar包就是zip包，只是额外附加了一些固定的描述文件。 1234567891011121314151617181920212223┌───────────────────┐│ InputStream │└───────────────────┘ ▲ │┌───────────────────┐│ FilterInputStream │└───────────────────┘ ▲ │┌───────────────────┐│InflaterInputStream│└───────────────────┘ ▲ │┌───────────────────┐│ ZipInputStream │└───────────────────┘ ▲ │┌───────────────────┐│ JarInputStream │└───────────────────┘ 读取zip包我们来看看ZipInputStream的基本用法。我们要创建一个ZipInputStream，通常是传入一个FileInputStream作为数据源，然后，循环调用getNextEntry()，直到返回null，表示zip流结束。 一个ZipEntry表示一个压缩文件或目录，如果是压缩文件，我们就用read()方法不断读取，直到返回-1： 123456789101112try (ZipInputStream zip = new ZipInputStream(new FileInputStream(...))) { ZipEntry entry = null; while ((entry = zip.getNextEntry()) != null) { String name = entry.getName(); if (!entry.isDirectory()) { int n; while ((n = zip.read()) != -1) { ... } } }} 写入zip包ZipOutputStream是一种FilterOutputStream，它可以直接写入内容到zip包，可以把多份数据写入zip包。我们要先创建一个ZipOutputStream，通常是包装一个FileOutputStream，然后，每写入一个文件前，先调用putNextEntry()，然后用write()写入byte[]数据，写入完毕后调用closeEntry()结束这个文件的打包。 12345678try (ZipOutputStream zip = new ZipOutputStream(new FileOutputStream(...))) { File[] files = ... for (File file : files) { zip.putNextEntry(new ZipEntry(file.getName())); zip.write(getFileDataAsBytes(file)); zip.closeEntry(); }} 上面的代码没有考虑文件的目录结构。如果要实现目录层次结构，new ZipEntry(name)传入的name要用相对路径。 读取classpath资源很多Java程序启动的时候，都需要读取配置文件。例如，从一个.properties文件读取配置。这就需要在磁盘的某一目录创建相应的文件。Linux和Windows的路径又不一致。因此，从磁盘的固定目录读取配置文件，不是一个好办法。那有没有路径无关的读取文件方式呢？ 我们知道，Java存放.class的目录或jar包也可以包含其他任意类型的文件，例如： 配置文件，例如.properties； 图片文件，例如.jpg； 文本文件，例如.txt，.csv； … 从classpath读取文件就可以避免不同环境下路径文件不一致的问题。 在classpath中的资源文件，路径总是以/开头，我们先获取当前的Class对象，然后调用getResourceAsStream()就可以从classpath读取任意的资源文件。调用getResourceAsStream()需要特别注意的一点是，如果资源文件不存在，它将返回null。因此，我们需要检查返回的InputStream是否为null，如果为null，表示资源文件在classpath中没有找到： 12345try (InputStream input = getClass().getResourceAsStream(\"/default.properties\")) { if (input != null) { // TODO: }} 如果我们把默认的配置放到jar包里，再从外部文件系统读取一个可选的配置文件，就可以做到既有默认的配置文件，又可以让用户自己修改配置。这样读取配置，应用程序的启动就更加灵活。 123Properties props = new Properties();props.load(inputStreamFromClassPath(\"/default.properties\"));props.load(inputStreamFromFile(\"./conf.properties\")); 序列化序列化是指把一个Java对象变成二进制内容，本质上就是一个byte[]数组。为什么要把Java对象序列化？因为序列化后可以把byte[]保存到文件中，或者把byte[]通过网络传输到远程，这样，就相当于把Java对象存储到文件或者通过网络传输出去了。 有序列化就有反序列化，即把一个二进制内容（也就是byte[]数组）变回Java对象。有了反序列化，保存到文件中的byte[]数组又可以变回Java对象，或者从网络上读取byte[]并把它变为Java对象。 我们来看看如何把一个Java对象序列化。 一个Java对象要能序列化，必须实现一个特殊的java.io.Serializable接口，它的定义如下： 123public interface Serializable{ } Serializable接口没有定义任何方法，它是一个空接口。我们把这样的空接口称为标记接口（Marker Interface），实现了标记接口的类仅仅是给自身贴了个标记，并没有增加任何方法。 序列化把一个Java对象变为byte[]数组，需要使用ObjectOutputStream。它负责把一个Java对象写入一个字节流： 1234567891011121314151617import java.io.*;import java.util.Arrays;public class Main { public static void main(String[] args) throws IOException { ByteArrayOutputStream buffer = new ByteArrayOutputStream(); try (ObjectOutputStream output = new ObjectOutputStream(buffer)) { // 写入int: output.writeInt(12345); // 写入String: output.writeUTF(\"Hello\"); // 写入Object: output.writeObject(Double.valueOf(123.456)); } System.out.println(Arrays.toString(buffer.toByteArray())); }} ObjectOutputStream既可以写入基本类型，如int，boolean，也可以写入String（以UTF-8编码），还可以写入实现了Serializable接口的Object。因为写入Object时需要大量的类型信息，所以写入的内容很大。 反序列化和ObjectOutputStream相反，ObjectInputStream负责从一个字节流读取Java对象： 12345try (ObjectInputStream input = new ObjectInputStream(...)) { int n = input.readInt(); String s = input.readUTF(); Double d = (Double) input.readObject();} 除了能读取基本类型和String类型外，调用readObject()可以直接返回一个Object对象。要把它变成一个特定类型，必须强制转型。readObject()可能抛出的异常有： ClassNotFoundException，没有找到对应的Class InvalidClassException，Class不匹配 对于ClassNotFoundException，这种情况常见于一台电脑上的Java程序把一个Java对象，例如，Person对象序列化以后，通过网络传给另一台电脑上的另一个Java程序，但是这台电脑的Java程序并没有定义Person类，所以无法反序列化。 对于InvalidClassException，这种情况常见于序列化的Person对象定义了一个int类型的age字段，但是反序列化时，Person类定义的age字段被改成了long类型，所以导致class不兼容。 为了避免这种class定义变动导致的不兼容，Java的序列化允许class定义一个特殊的serialVersionUID静态变量，用于标识Java类的序列化“版本”，通常可以由IDE自动生成。如果增加或修改了字段，可以改变serialVersionUID的值，这样就能自动阻止不匹配的class版本。 123public class Person implements Serializable { private static final long serialVersionUID = 2709425275741743919L;} 反序列化时，由JVM直接构造出Java对象，不调用构造方法，构造方法内部的代码，在反序列化时根本不可能执行。 安全性因为Java的序列化机制可以导致一个实例能直接从byte[]数组创建，而不经过构造方法，因此，它存在一定的安全隐患。一个精心构造的byte[]数组被反序列化后可以执行特定的Java代码，从而导致严重的安全漏洞。 实际上，Java本身提供的基于对象的序列化和反序列化机制既存在安全性问题，也存在兼容性问题。更好的序列化方法是通过JSON这样通用的数据结构来实现，只输出基本类型和String的内容，而不存储任何与代码相关的信息。 Java的序列化机制仅适用于Java，如果需要与其他语言交换数据，必须使用通用的序列化方法，例如JSON。 ReaderReader是Java的IO库提供的另一个输入流接口。和InputStream的区别是，InputStream是一个字节流，即以byte为单位读取，而Reader是一个字符流，即以char为单位读取。 java.io.Reader是所有字符输入流的超类，它最主要的方法是： 1public int read() throws IOException; 这个方法读取字符流的下一个字符，并返回字符表示的int，范围是0~65535。如果已读到末尾，返回-1。 FileReaderFileReader是Reader的一个子类，它可以打开文件并获取Reader。下面的代码演示了如何完整地读取一个FileReader的所有字符： 123456789101112public void readFile() throws IOException { // 创建一个FileReader对象: Reader reader = new FileReader(\"src/readme.txt\"); // 字符编码是??? for (;;) { int n = reader.read(); // 反复调用read()方法，直到返回-1 if (n == -1) { break; } System.out.println((char)n); // 打印char } reader.close(); // 关闭流} 如果我们读取一个纯ASCII编码的文本文件，上述代码工作是没有问题的。但如果文件中包含中文，就会出现乱码，因为FileReader默认的编码与系统相关，例如，Windows系统的默认编码可能是GBK，打开一个UTF-8编码的文本文件就会出现乱码。 要避免乱码问题，我们需要在创建FileReader时指定编码： 1Reader reader = new FileReader(\"src/readme.txt\", StandardCharsets.UTF_8); 和InputStream一样，Reader也是一种资源，需要保证出错的时候也能正确关闭，所以我们需要用try(resource)来保证Reader在无论有没有IO错误的时候都能正确关闭： 123try (Reader reader = new FileReader(\"src/readme.txt\", StandardCharsets.UTF_8) { // TODO} Reader还提供了一次性读取若干字符并填充到char[]数组的方法： 1public int read(char[] c) throws IOException 它返回实际读入的字符个数，最大不超过char[]数组的长度，返回-1表示流结束。利用这个方法，我们可以先设置一个缓冲区，然后，每次尽可能地填充缓冲区： 123456789public void readFile() throws IOException { try (Reader reader = new FileReader(\"src/readme.txt\", StandardCharsets.UTF_8)) { char[] buffer = new char[1000]; int n; while ((n = reader.read(buffer)) != -1) { System.out.println(\"read \" + n + \" chars.\"); } }} CharArrayReaderCharArrayReader可以在内存中模拟一个Reader，它的作用实际上是把一个char[]数组变成一个Reader，这和ByteArrayInputStream非常类似： 12try (Reader reader = new CharArrayReader(\"Hello\".toCharArray())) {} StringReaderStringReader可以直接把String作为数据源，它和CharArrayReader几乎一样： 12try (Reader reader = new StringReader(\"Hello\")) {} InputStreamReaderReader和InputStream有什么关系？ 除了特殊的CharArrayReader和StringReader，普通的Reader实际上是基于InputStream构造的，因为Reader需要从InputStream中读入字节流（byte），然后，根据编码设置，再转换为char就可以实现字符流。如果我们查看FileReader的源码，它在内部实际上持有一个FileInputStream。 既然Reader本质上是一个基于InputStream的byte到char的转换器，那么，如果我们已经有一个InputStream，想把它转换为Reader，是完全可行的。InputStreamReader就是这样一个转换器，它可以把任何InputStream转换为Reader。示例代码如下： 1234// 持有InputStream:InputStream input = new FileInputStream(\"src/readme.txt\");// 变换为Reader:Reader reader = new InputStreamReader(input, \"UTF-8\"); 构造InputStreamReader时，我们需要传入InputStream，还需要指定编码，就可以得到一个Reader对象。上述代码可以通过try (resource)更简洁地改写如下： 123try (Reader reader = new InputStreamReader(new FileInputStream(\"src/readme.txt\"), \"UTF-8\")) { // TODO:} 上述代码实际上就是FileReader的一种实现方式。使用try (resource)结构时，当我们关闭Reader时，它会在内部自动调用InputStream的close()方法，所以，只需要关闭最外层的Reader对象即可。 PrintStream和PrintWriterPrintStream是一种FilterOutputStream，它在OutputStream的接口上，额外提供了一些写入各种数据类型的方法。 写入int：print(int) 写入boolean：print(boolean) 写入String：print(String) 写入Object：print(Object)，实际上相当于print(object.toString()) … 以及对应的一组println()方法，它会自动加上换行符。我们经常使用的System.out.println()实际上就是使用PrintStream打印各种数据，其中System.out是系统默认提供的PrintStream，表示标准输出。 123System.out.print(12345); // 输出12345System.out.print(new Object()); // 输出类似java.lang.Object@3c7a835aSystem.out.println(\"Hello\"); // 输出Hello并换行 System.err是系统默认提供的标准错误输出。 PrintStream和OutputStream相比，除了添加了一组print()/println()方法，可以打印各种数据类型。此外，它还有一个额外优点，就是不会抛出IOException，这样我们在编写代码时，就不必捕获IOException。 PrintWriterPrintStream输出的总是byte数据，而PrintWriter则是扩展了Writer接口，它的print()/println()方法总是输出char数据，两者的使用方法几乎一模一样。 使用Files从Java 7开始，提供了Files和Paths这两个工具类，能极大的方便我们读写文件。虽然Files和Paths是java.nio包里面的类，但他俩封装了很多读写文件的简单方法。 例如，我们要把一个文件的全部内容读取为一个byte[]，可以这么写： 1byte[] data = Files.readAllBytes(Paths.get(\"/path/to/file.txt\")); 如果是文本文件，可以把一个文件的所有内容全部读取为String： 123456// 默认使用UTF-8编码读取:String content1 = Files.readString(Paths.get(\"/path/to/file.txt\"));// 可指定编码:String content2 = Files.readString(Paths.get(\"/path/to/file.txt\"), StandardCharsets.ISO_8859_1);// 按行读取并返回每行内容:List&lt;String&gt; lines = Files.readAllLines(Paths.get(\"/path/to/file.txt\")); 写入文件也非常方便： 12345678// 写入二进制文件:byte[] data = ...Files.write(Paths.get(\"/path/to/file.txt\"), data);// 写入文本并指定编码:Files.writeString(Paths.get(\"/path/to/file.txt\"), \"文本内容...\", StandardCharsets.ISO_8859_1);// 按行写入文本:List&lt;String&gt; lines = ...Files.write(Paths.get(\"/path/to/file.txt\"), lines); 此外，Files工具类还有copy()，delete()，exists()，move()等快捷方法操作文件和目录。 最后要特别注意的是，Files提供的读写方法，受内存限制，只能读写小文件，例如配置文件等，不可一次读如几个G的大文件。读写大型文件仍然要使用文件流，每次只读写一部分文件内容。","link":"/Study/Java/IO/"},{"title":"IoC容器","text":"在学习Spring框架时，我们遇到的第一个也是最核心的概念就是容器。什么是容器？ 容器是一种为某个特定组件的运行提供必要支持的一个软件环境。例如，Tomcat就是一个Servlet容器，它可以为Servlet的运行提供运行环境。类似Docker这样的软件也是一个容器，它提供了必要的Linux环境以便运行一个特定的Linux进程。 通常来说，使用容器运行组件，除了提供一个组件的运行环境之外，容器还提供了许多底层服务。例如，Servlet容器底层实现了TCP链接，解析HTTP协议等非常复杂的任务，如果没有容器来提供这些服务，我们就无法编写像Servlet这样代码简单、功能强大的组件。早起的Java EE服务器提供的EJB容器最重要的功能就是通过声明式事务服务，使得EJB组件的开发人员不必编写冗长的事务处理代码，所以极大的简化了事务处理。 Spring的核心就是提供了一个IoC容器，它可以管理所有轻量级的JavaBean组件，提供的底层服务包括组件的生命周期管理、配置和组装服务、AOP支持，以及建立在AOP基础上的声明式服务等。本节我们介绍的IoC容器，主要介绍Spring容器如何对组件进行声明周期管理和配置组装服务。 IoC原理IoC全称是Inversion of Control，直译为控制反转。在理解IoC之前，我们先看看通常的Java组件是如何协作的。 我们假定一个在线书店，通过BookService获取书籍，为了从数据库查询书籍，BookService持有一个DataSource；为了实例化一个HikariDataSource，又不得不实例化一个HikariConfig。现在我们继续编写UserService获取用户，因为UserService也要访问数据库，因此我们不得不也实例化一个HikariDataSource。在处理用户购买的CartServlet中，我们需要实例化UserService和BookService。类似的，在购买历史HistoryServlet中，也需要实例化UserService和BookService。 上述每个组件都采用了一种简单的通过new创建实例并持有的方式。仔细观察，会发现以下缺点： 实例化一个组件其实很难。例如，BookService和UserService要创建HikariDataSource，实际上需要读取配置，才能先实例化HikariConfig，再实例化HikariDataSource。 没有必要让BookService和UserService分别创建DataSource实例，完全可以共享同一个DataSource，但谁负责创建DataSource，谁负责获取其他组件已经创建的DataSource，不好处理。类似的，CartServlet和HistoryServlet也应当共享BookService实例和UserService实例，但也不好处理。 很多组件需要销毁以便释放资源，例如DataSource，但如果该组件被多个组件共享，如何确保它的使用方都已经全部被销毁？ 随着更多组件被引入，例如书籍评论，需要共享的组件写起来会更困难，这些组件的依赖关系会越来越复杂。 测试某个组件，例如BookService，是复杂的，因为必须要在真实的数据库环境下执行。 从上面的例子可以看出，如果一个系统有大量的组件，其生命周期和相互之间的依赖关系如果由组件自身来维护，不但大大增加了系统的复杂度，而且会导致组件之间极为紧密的耦合，继而给测试和维护带来了极大的困难。 因此，核心问题是： 谁负责创建组件？ 谁负责根据依赖关系组装组件？ 销毁时，如何按依赖顺序正确销毁？ 解决这一问题的核心方案就是IoC。 传统的应用程序中，控制权在程序本身，程序的控制流程完全由开发者控制。例如：CartServlet创建了BookService，在创建BookService的过程中，又创建了DataSource组件。这种模式的缺点是，一个组件如果要使用另一个组件，必须先知道如何正确地创建它。 在IoC模式下，控制权发生了反转，即从应用程序转移到IoC容器，所有组件不再由应用程序自己创建和配置，而是由IoC容器负责，这样，应用程序只需要直接使用已经创建好并且配置好的组件。为了能让组件在IoC容器中被“装配”出来，需要某种“注入”机制。例如，BookService自己并不会创建DataSource，而是等待外部通过setDataSource()方法来注入一个DataSource。 不直接new一个DataSource，而是注入一个DataSource，这个小小的改动虽然简单，却带来了一系列好处： BookService不再关心如何创建DataSource，因此不必编写数据库配置之类的代码 DataSource实例被注入到BookService，同样也可以注入到UserService，因此共享一个组件非常简单 测试BookService更容易，因为注入的是DataSource，可以使用内存数据库，而不是真实的MySQL配置 因此，IoC又称为依赖注入（DI：Dependency Injection），它解决了一个最主要的问题：将组件的创建+配置和组件的使用相分离，并且由IoC容器负责管理组件的生命周期。 因为IoC容器要负责实例化所有的组件，因此有必要告诉容器如何创建组件，以及各组件的依赖关系。一种最简单的配置是通过XML文件来实现的，例如： 123456789&lt;beans&gt; &lt;bean id=\"dataSource\" class=\"HikariDataSource\" /&gt; &lt;bean id=\"bookService\" class=\"BookService\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt; &lt;bean id=\"userService\" class=\"UserService\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt;&lt;/beans&gt; 上述XML配置文件指示IoC容器创建3个JavaBean组件，并把id为dataSource的组件通过属性dataSource注入到另外两个组件中。 在Spring的IoC容器中，我们把所有的组件统称为JavaBean，即配置一个组件就是配置一个Bean。 依赖注入方式我们从上面的代码可以看到，依赖注入可以通过set()方法实现。但依赖注入也可以通过构造方法实现。 很多Java类都具有带参数的构造方法，如果我们把BookService改造为通过构造方法注入，那么实现代码如下： 1234567public class BookService { private DataSource dataSource; public BookService(DataSource dataSource) { this.dataSource = dataSource; }} Spring的IoC容器同时支持属性注入和构造方法注入，并允许混合使用。 无侵入容器在设计上，Spring的IoC容器是一个高度可扩展的无侵入容器。所谓无侵入，是指应用程序的组件无需实现Spring的特定接口，或者说，组件根本不知道自己在Spring的容器中运行。这种无侵入的设计有以下好处： 应用程序组件既可以在Spring的IoC容器中运行，也可以自己编写代码自行组装配置； 测试的时候并不依赖Spring容器，可单独进行测试，大大提高了开发效率。 装配Bean上一节我们讨论了为什么要使用Spring的IoC容器，那么到底如何使用IoC容器呢？装配好的Bean又如何使用？ 我们看一个具体的用户注册登录的例子，下面是他的工程结构。首先，我们用Maven创建工程并引入spring-context依赖。 123456789101112131415spring-ioc-appcontext├── pom.xml└── src └── main ├── java │ └── com │ └── itranswarp │ └── learnjava │ ├── Main.java │ └── service │ ├── MailService.java │ ├── User.java │ └── UserService.java └── resources └── application.xml 先编写一个MailService，用于在用户登录和注册成功后发送邮件通知。再编写一个UserService，实现用户登录和注册。 12345678public class MailService{...}public class UserService{ private MailService mailService; public void setMailService(MailService mailService){ this.mailService = mailService; } ...} 注意到UserService通过setMailService()注入了一个MailService。 然后，我们要编写一个特定的application.xml配置文件，告诉Sring的IoC容器应该如何创建并组装Bean。 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"userService\" class=\"com.itranswarp.learnjava.service.UserService\"&gt; &lt;property name=\"mailService\" ref=\"mailService\" /&gt; &lt;/bean&gt; &lt;bean id=\"mailService\" class=\"com.itranswarp.learnjava.service.MailService\" /&gt;&lt;/beans&gt; 注意观察上述配置文件，其中与XML Schema相关的部分格式是固定的，我们只关注两个&lt;bean ...&gt;的配置。 每个&lt;bean ...&gt;都有一个id标识，相当于Bean的唯一ID； 在userServiceBean中，通过&lt;property name=\"...\" ref=\"...\" /&gt;注入了另一个Bean； Bean的顺序不重要，Spring根据依赖关系会自动正确初始化。 把上述XML配置文件用Java代码写出来，就像这样： 123UserService userService = new UserService();MailService mailService = new MailService();userService.setMailService(mailService); 只不过Spring容器是通过读取XML文件后使用反射完成的。 如果注入的不是Bean，而是boolean、int、String这样的数据类型，则通过value注入，例如，创建一个HikariDataSource： 1234567&lt;bean id=\"dataSource\" class=\"com.zaxxer.hikari.HikariDataSource\"&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/test\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"password\" /&gt; &lt;property name=\"maximumPoolSize\" value=\"10\" /&gt; &lt;property name=\"autoCommit\" value=\"true\" /&gt;&lt;/bean&gt; 最后一步，我们需要创建一个Spring的IoC容器实例，然后加载配置文件，让Spring容器为我们创建并装配好配置文件中指定的所有Bean，这只需要一行代码： 1ApplicationContext context = new ClassPathXmlApplicationContext(\"application.xml\"); 接下来，我们就可以从Spring容器中取出装配好的Bean，然后使用它。 1234// 获取Bean:UserService userService = context.getBean(UserService.class);// 正常调用:User user = userService.login(\"bob@example.com\", \"password\"); 完整的main()方法如下： 12345678public class Main { public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\"application.xml\"); UserService userService = context.getBean(UserService.class); User user = userService.login(\"bob@example.com\", \"password\"); System.out.println(user.getName()); }} ApplicationContext我们从创建Spring容器的代码： 1ApplicationContext context = new ClassPathXmlApplicationContext(\"application.xml\"); 可以看到，Spring容器就是ApplicationContext，它是一个接口，有很多实现类，这里我们选择ClassPathXmlApplicationContext，表示它会自动从classpath中查找指定的XML配置文件。 获得了ApplicationContext的实例，就获得了IoC容器的引用。从ApplicationContext中我们可以根据Bean的ID获取Bean，但更多的时候我们根据Bean的类型获取Bean的引用： 1UserService userService = context.getBean(UserService.class); Spring还提供另一种IoC容器叫BeanFactory，使用方式和ApplicationContext类似： 12BeanFactory factory = new XmlBeanFactory(new ClassPathResource(\"application.xml\"));MailService mailService = factory.getBean(MailService.class); BeanFactory和ApplicationContext的区别在于，BeanFactory的实现是按需创建，即第一次获取Bean时才创建这个Bean，而ApplicationContext会一次性创建所有的Bean。实际上，ApplicationContext接口是从BeanFactory接口继承而来的，并且，ApplicationContext提供了一些额外的功能，包括国际化支持、事件和通知机制等。通常情况下，我们总是使用ApplicationContext，很少会考虑使用BeanFactory。 使用Annotation配置使用Spring的IoC容器，实际上就是通过类似XML这样的配置文件，把我们自己的Bean的依赖关系描述出来，然后让容器来创建和装配Bean。一旦容器初始化完毕，我们就直接从容器中获取Bean使用他们。 使用XML配置的优点是所有的Bean都能一目了然地列出来了，并通过配置注入能直观的看到每个Bean的依赖。它的缺点是写起来非常繁琐，每增加一个组件，就必须把新的Bean配置到XML中。 有没有其他更简洁的配置方式呢？ 有的。我们可以使用Annotation配置，可以完全不需要XML，让Spring自动扫描Bean并组装它们。 我们把上一节的示例改造一下。先删除XML配置文件，然后给UserService和MailService添加几个注解。首先，给MailService添加一个@Component注解。 1@Componentpublic class MailService { ...} 这个@Component注解就相当于定义了一个Bean，它有一个可选的名称，默认是mailService，即小写开头的类名。然后，我们给UserService添加一个@Component注解和@Autowired注解。 1@Componentpublic class UserService { @Autowired MailService mailService; ...} 使用@Autowired就相当于把指定类型的Bean注入到指定的字段中。和XML配置相比，@Autowired大幅简化了注入，因为它不但可以写在set()方法上，还可以直接写在字段上，甚至可以写在构造方法中。 1@Componentpublic class UserService { MailService mailService; public UserService(@Autowired MailService mailService) { this.mailService = mailService; } ...} 我们一般把@Autowired写在字段上，通常使用package权限的字段，便于测试。 最后编写一个AppConfig类启动容器： 1@Configuration@ComponentScanpublic class AppConfig { public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); UserService userService = context.getBean(UserService.class); User user = userService.login(\"bob@example.com\", \"password\"); System.out.println(user.getName()); }} 除了main()方法外，AppConfig标注了@Configuration，表示它是一个配置类，因为我们创建ApplicationContext时， 1ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); 使用的实现类是AnnotationConfigApplicationContext，必须传入一个标注了@Configuration的类名。 此外，AppConfig还标注了@ComponentScan，它告诉容器，自动搜索当前类所在的包以及子包，把所有标注为@Component的Bean自动创建出来，并根据@Autowired进行装配。 整个工程的结构如下： 1spring-ioc-annoconfig├── pom.xml└── src └── main └── java └── com └── itranswarp └── learnjava ├── AppConfig.java └── service ├── MailService.java ├── User.java └── UserService.java 使用Annotation配合自动扫描能大幅简化Spring的配置，我们只需要保证： 每个Bean被标注为@Component并正确使用@Autowired注入 配置类被标注为@Configuration和@ComponentScan 所有Bean均在指定包以及子包内 使用@ComponentScan非常方便，但是我们也要特别注意包的层次结构。通常来说，启动配置AppConfig位于自定义的顶层包，其他Bean按类别放入子包。 思考如果我们想给UserService注入HikariDataSource，但是这个类位于com.zaxxer.hikari包中，并且HikariDataSource也不可能有@Component注解，如何告诉IoC容器创建并配置HikariDataSource？或者换个说法，如何创建并配置一个第三方Bean？ 定制BeanScope对于Spring容器来说，当我们把一个Bean标记为@Component，它就会自动为我们创建一个单例（Singleton），即容器初始化时创建Bean，容器关闭前销毁Bean。在容器运行期间，我们调用getBean(Class)获取到的Bean总是同一个实例。 还有一种Bean，我们每次调用getBean(Class)，容器都会返回一个新的实例，这种Bean称为Prototype（原型），它的生命周期显然和Singleton不同。声明一个Prototype的Bean时，需要添加一个额外的@Scope注解。 1@Component@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) // @Scope(\"prototype\")public class MailSession { ...} 注入List有些时候，我们会有一系列接口相同，不同实现类的Bean。例如，注册用户时，我们要对email、password和name这3个变量进行验证。为了便于扩展，我们先定义验证接口： 1public interface Validator { void validate(String email, String password, String name);} 然后，分别使用3个Validator对用户参数进行验证： 1@Componentpublic class EmailValidator implements Validator { public void validate(String email, String password, String name) { if (!email.matches(\"^[a-z0-9]+\\\\@[a-z0-9]+\\\\.[a-z]{2,10}$\")) { throw new IllegalArgumentException(\"invalid email: \" + email); } }}@Componentpublic class PasswordValidator implements Validator { public void validate(String email, String password, String name) { if (!password.matches(\"^.{6,20}$\")) { throw new IllegalArgumentException(\"invalid password\"); } }}@Componentpublic class NameValidator implements Validator { public void validate(String email, String password, String name) { if (name == null || name.isBlank() || name.length() &gt; 20) { throw new IllegalArgumentException(\"invalid name: \" + name); } }} 最后，我们通过一个Validators作为入口进行验证： 1@Componentpublic class Validators { @Autowired List&lt;Validator&gt; validators; public void validate(String email, String password, String name) { for (var validator : this.validators) { validator.validate(email, password, name); } }} 注意到Validators被注入了一个List&lt;Validator&gt;，Spring会自动把所有类型为Validator的Bean装配为一个List注入进来，这样一来，我们每新增一个Validator类型，就自动被Spring装配到Validators中了，非常方便。 因为Spring是通过扫描classpath获取到所有的Bean，而List是有序的，要指定List中Bean的顺序，可以加上@Order注解。 1@Component@Order(1)public class EmailValidator implements Validator { ...}@Component@Order(2)public class PasswordValidator implements Validator { ...}@Component@Order(3)public class NameValidator implements Validator { ...} 可选注入默认情况下，当我们标记了一个@Autowired后，Spring如果没有找到对应类型的Bean，它会抛出NoSuchBeanDefinitionException异常。 可以给@Autowired增加一个required = false的参数： 1@Componentpublic class MailService { @Autowired(required = false) ZoneId zoneId = ZoneId.systemDefault(); ...} 这个参数告诉Spring容器，如果找到一个类型为ZoneId的Bean，就注入，如果找不到，就忽略。 这种方式非常适合有定义就使用定义，没有就使用默认值的情况。 创建第三方Bean如果一个Bean不在我们自己的package管理之内，例如ZoneId，如何创建它？ 答案是我们自己在@Configuration类中编写一个Java方法创建并返回它，注意给方法标记一个@Bean注解： 1@Configuration@ComponentScanpublic class AppConfig { // 创建一个Bean: @Bean ZoneId createZoneId() { return ZoneId.of(\"Z\"); }} Spring对标记为@Bean的方法只调用一次，因此返回的Bean仍然是单例。 初始化和销毁有些时候，一个Bean在注入必要的依赖后，需要进行初始化（监听消息等）。在容器关闭时，有时候还需要清理资源（关闭连接池等）。我们通常会定义一个init()方法进行初始化，定义一个shutdown()方法进行清理，然后，引入JSR-250定义的Annotation： 1&lt;dependency&gt; &lt;groupId&gt;javax.annotation&lt;/groupId&gt; &lt;artifactId&gt;javax.annotation-api&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 在Bean的初始化和清理方法上标记@PostConstruct和@PreDestroy： 1@Componentpublic class MailService { @Autowired(required = false) ZoneId zoneId = ZoneId.systemDefault(); @PostConstruct public void init() { System.out.println(\"Init mail service with zoneId = \" + this.zoneId); } @PreDestroy public void shutdown() { System.out.println(\"Shutdown mail service\"); }} Spring容器会对上述Bean做如下初始化流程： 调用构造方法创建MailService实例； 根据@Autowired进行注入； 调用标记有@PostConstruct的init()方法进行初始化。 而销毁时，容器会首先调用标记有@PreDestroy的shutdown()方法。 Spring只根据Annotation查找无参数方法，对方法名不作要求。 使用别名默认情况下，对一种类型的Bean，容器只创建一个实例。但有些时候，我们需要对一种类型的Bean创建多个实例。例如，同时连接多个数据库，就必须创建多个DataSource实例。 如果我们在@Configuration类中创建了多个同类型的Bean： 1@Configuration@ComponentScanpublic class AppConfig { @Bean ZoneId createZoneOfZ() { return ZoneId.of(\"Z\"); } @Bean ZoneId createZoneOfUTC8() { return ZoneId.of(\"UTC+08:00\"); }} Spring会报NoUniqueBeanDefinitionException异常，意思是出现了重复的Bean定义。 这个时候，需要给每个Bean添加不同的名字： 1@Configuration@ComponentScanpublic class AppConfig { @Bean(\"z\") ZoneId createZoneOfZ() { return ZoneId.of(\"Z\"); } @Bean @Qualifier(\"utc8\") ZoneId createZoneOfUTC8() { return ZoneId.of(\"UTC+08:00\"); }} 可以用@Bean(\"name\")指定别名，也可以用@Bean+@Qualifier(\"name\")指定别名。 存在多个同类型的Bean时，注入ZoneId又会报错： 1NoUniqueBeanDefinitionException: No qualifying bean of type 'java.time.ZoneId' available: expected single matching bean but found 2 意思是期待找到唯一的ZoneId类型Bean，但是找到两。因此，注入时，要指定Bean的名称： 1@Componentpublic class MailService { @Autowired(required = false) @Qualifier(\"z\") // 指定注入名称为\"z\"的ZoneId ZoneId zoneId = ZoneId.systemDefault(); ...} 还有一种方法是把其中某个Bean指定为@Primary： 1@Configuration@ComponentScanpublic class AppConfig { @Bean @Primary // 指定为主要Bean @Qualifier(\"z\") ZoneId createZoneOfZ() { return ZoneId.of(\"Z\"); } @Bean @Qualifier(\"utc8\") ZoneId createZoneOfUTC8() { return ZoneId.of(\"UTC+08:00\"); }} 这样，在注入时，如果没有指出Bean的名字，Spring会注入标记有@Primary的Bean。这种方式也很常用。例如，对于主从两个数据源，通常将主数据源定义为@Primary： 1@Configuration@ComponentScanpublic class AppConfig { @Bean @Primary DataSource createMasterDataSource() { ... } @Bean @Qualifier(\"slave\") DataSource createSlaveDataSource() { ... }} 其他Bean默认注入的就是主数据源。如果要注入从数据源，那么只需要指定名称即可。 使用FactoryBean我们在设计模式的工厂方法中讲到，很多时候，可以通过工厂模式创建对象。Spring也提供了工厂模式，允许定义一个工厂，然后由工厂创建真正的Bean。 用工厂模式创建Bean需要实现FactoryBean接口。我们观察下面的代码： 1@Componentpublic class ZoneIdFactoryBean implements FactoryBean&lt;ZoneId&gt; { String zone = \"Z\"; @Override public ZoneId getObject() throws Exception { return ZoneId.of(zone); } @Override public Class&lt;?&gt; getObjectType() { return ZoneId.class; }} 当一个Bean实现了FactoryBean接口后，Spring会先实例化这个工厂，然后调用getObject()创建真正的Bean。getObjectType()可以指定创建的Bean的类型，因为指定类型不一定与实际类型一致，可以是接口或抽象类。 因此，如果定义了一个FactoryBean，要注意Spring创建的Bean实际上是这个FactoryBean的getObject()方法返回的Bean。为了和普通Bean区分，我们通常都以XxxFactoryBean命名。 使用Resource在Java程序中，我们经常会读取配置文件、资源文件等。使用Spring容器时，我们也可以把“文件”注入进来，方便程序读取。 例如，AppService需要读取logo.txt这个文件，通常情况下，我们需要写很多繁琐的代码，主要是为了定位文件，打开InputStream。 Spring提供了一个org.springframework.core.io.Resource（注意不是javax.annotation.Resource），它可以像String、int一样使用@Value注入： 1@Componentpublic class AppService { @Value(\"classpath:/logo.txt\") private Resource resource; private String logo; @PostConstruct public void init() throws IOException { try (var reader = new BufferedReader( new InputStreamReader(resource.getInputStream(), StandardCharsets.UTF_8))) { this.logo = reader.lines().collect(Collectors.joining(\"\\n\")); } }} 注入Resource最常用的方式是通过classpath，即类似classpath:/logo.txt表示在classpath中搜索logo.txt文件，然后，我们直接调用Resource.getInputStream()就可以获取到输入流，避免了自己搜索文件的代码。 也可以直接指定文件的路径，例如： 1@Value(\"file:/path/to/logo.txt\")private Resource resource; 但使用classpath是最简单的方式。上述工程结构如下： 1spring-ioc-resource├── pom.xml└── src └── main ├── java │ └── com │ └── itranswarp │ └── learnjava │ ├── AppConfig.java │ └── AppService.java └── resources └── logo.txt 使用Maven的标准目录结构，所有资源文件放入src/main/resources即可。 注入配置在开发应用程序时，经常需要读取配置文件。最常用的配置方法是以key=value的形式写在.properties文件中。 例如，MailService根据配置的app.zone=Asia/Shanghai来决定使用哪个时区。要读取配置文件，我们可以使用上一节讲到的Resource来读取位于classpath下的一个app.properties文件。但是，这样仍然比较繁琐。 Spring容器还提供了一个更简单的@PropertySource来自动读取配置文件。我们只需要在@Configuration配置类上再添加一个注解： 1@Configuration@ComponentScan@PropertySource(\"app.properties\") // 表示读取classpath的app.propertiespublic class AppConfig { @Value(\"${app.zone:Z}\") String zoneId; @Bean ZoneId createZoneId() { return ZoneId.of(zoneId); }} Spring容器看到@PropertySource(\"app.properties\")注解后，自动读取这个配置文件，然后，我们使用@Value正常注入： 1@Value(\"${app.zone:Z}\")String zoneId; 注意注入的字符串语法，它的格式如下： \"${app.zone}\"表示读取key为app.zone的value，如果key不存在，启动将报错； \"${app.zone:Z}\"表示读取key为app.zone的value，但如果key不存在，就使用默认值Z。 这样一来，我们就可以根据app.zone的配置来创建ZoneId。 还可以把注入的注解写到方法参数中： 1@BeanZoneId createZoneId(@Value(\"${app.zone:Z}\") String zoneId) { return ZoneId.of(zoneId);} 可见，先使用@PropertySource读取配置文件，然后通过@Value以${key:defaultValue}的形式注入，可以极大地简化读取配置的麻烦。 另一种注入配置的方式是先通过一个简单的JavaBean持有所有的配置，例如，一个SmtpConfig： 1@Componentpublic class SmtpConfig { @Value(\"${smtp.host}\") private String host; @Value(\"${smtp.port:25}\") private int port; public String getHost() { return host; } public int getPort() { return port; }} 然后，在需要读取的地方，使用#{smtpConfig.host}注入： 1@Componentpublic class MailService { @Value(\"#{smtpConfig.host}\") private String smtpHost; @Value(\"#{smtpConfig.port}\") private int smtpPort;} 注意观察#{}这种注入语法，它和${key}不同的是，#{}表示从JavaBean读取属性。\"#{smtpConfig.host}\"的意思是，从名称为smtpConfig的Bean读取host属性，即调用getHost()方法。一个Class名为SmtpConfig的Bean，它在Spring容器中的默认名称就是smtpConfig，除非用@Qualifier指定了名称。 使用一个独立的JavaBean持有所有属性，然后在其他Bean中以#{bean.property}注入的好处是，多个Bean都可以引用同一个Bean的某个属性。例如，如果SmtpConfig决定从数据库中读取相关配置项，那么MailService注入的@Value(\"#{smtpConfig.host}\")仍然可以不修改正常运行。 使用条件装配开发应用程序时，我们会使用开发环境，例如，使用内存数据库以便快速启动。而运行在生产环境时，我们会使用生产环境，例如，使用MySQL数据库。如果应用程序可以根据自身的环境做一些适配，无疑会更加灵活。 Spring为应用程序准备了Profile这一概念，用来表示不同的环境。例如，我们分别定义开发、测试和生产这3个环境： native test production 创建某个Bean时，Spring容器可以根据注解@Profile来决定是否创建。例如，以下配置： 1@Configuration@ComponentScanpublic class AppConfig { @Bean @Profile(\"!test\") ZoneId createZoneId() { return ZoneId.systemDefault(); } @Bean @Profile(\"test\") ZoneId createZoneIdForTest() { return ZoneId.of(\"America/New_York\"); }} 如果当前的Profile设置为test，则Spring容器会调用createZoneIdForTest()创建ZoneId，否则，调用createZoneId()创建ZoneId。注意到@Profile(\"!test\")表示非test环境。 在运行程序时，加上JVM参数-Dspring.profiles.active=test就可以指定以test环境启动。 实际上，Spring允许指定多个Profile，例如： 1-Dspring.profiles.active=test,master 可以表示test环境，并使用master分支代码。 要满足多个Profile条件，可以这样写： 1@Bean@Profile({ \"test\", \"master\" }) // 同时满足test和masterZoneId createZoneId() { ...} 使用Conditional除了根据@Profile条件来决定是否创建某个Bean外，Spring还可以根据@Conditional决定是否创建某个Bean。 例如，我们对SmtpMailService添加如下注解： 1@Component@Conditional(OnSmtpEnvCondition.class)public class SmtpMailService implements MailService { ...} 它的意思是，如果满足OnSmtpEnvCondition的条件，才会创建SmtpMailService这个Bean。OnSmtpEnvCondition的条件是什么呢？我们看一下代码： 1public class OnSmtpEnvCondition implements Condition { public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { return \"true\".equalsIgnoreCase(System.getenv(\"smtp\")); }} 因此，OnSmtpEnvCondition的条件是存在环境变量smtp，值为true。这样，我们就可以通过环境变量来控制是否创建SmtpMailService。 Spring只提供了@Conditional注解，具体判断逻辑还需要我们自己实现。Spring Boot提供了更多使用起来更简单的条件注解，例如，如果配置文件中存在app.smtp=true，则创建MailService： 1@Component@ConditionalOnProperty(name=\"app.smtp\", havingValue=\"true\")public class MailService { ...} 如果当前classpath中存在类javax.mail.Transport，则创建MailService： 1@Component@ConditionalOnClass(name = \"javax.mail.Transport\")public class MailService { ...} 后续我们会介绍Spring Boot的条件装配。我们以文件存储为例，假设我们需要保存用户上传的头像，并返回存储路径，在本地开发运行时，我们总是存储到文件： 1@Component@ConditionalOnProperty(name = \"app.storage\", havingValue = \"file\", matchIfMissing = true)public class FileUploader implements Uploader { ...} 在生产环境运行时，我们会把文件存储到类似AWS S3上： 1@Component@ConditionalOnProperty(name = \"app.storage\", havingValue = \"s3\")public class S3Uploader implements Uploader { ...} 其他需要存储的服务则注入Uploader： 1@Componentpublic class UserImageService { @Autowired Uploader uploader;} 当应用程序检测到配置文件存在app.storage=s3时，自动使用S3Uploader，如果存在配置app.storage=file，或者配置app.storage不存在，则使用FileUploader。 可见，使用条件注解，能更灵活地装配Bean。","link":"/Study/Java/Spring/IoC%E5%AE%B9%E5%99%A8/"},{"title":"函数式编程","text":"本章我们介绍Java的函数式编程。 我们先看看什么是函数。函数是一种最基本的任务，一个大型程序就是一个顶层函数调用若干底层函数，这些被调用的函数又可以调用其他函数，即大任务被一层层拆解并执行。所以，函数就是面向过程程序设计的基本单元。 Java不支持单独定义函数，但可以把静态方式视为独立的函数，把实例方法视为自带this参数的函数。而函数式编程（Functional Programming），虽然也可以归结到面向过程的程序设计，但其思想更接近数学计算。 我们首先要搞明白计算机（Computer）和计算（Compute）的概念。 在计算机的层次上，CPU执行的是加减乘除的指令代码，以及各种条件判断和跳转指令，所以，汇编语言是最贴近计算机的语言。 而计算则指数学意义上的计算，越是抽象的计算，离计算机硬件越远。 对应到编程语言，就是越低级的语言，越贴近计算机，抽象程度低，执行效率高，比如C语言；越高级的语言，越贴近计算，抽象程度高，执行效率低，比如Lisp语言。 函数式编程就是一种抽象程度很高的编程范式，纯粹的函数式编程语言编写的函数没有变量，因此，任意一个函数，只要输入是确定的，输出就是确定的，这种纯函数我们称之为没有副作用。而允许使用变量的程序设计语言，由于函数内部的变量状态不确定，同样的输入，可能得到不同的输出，因此，这种函数是有副作用的。 函数式编程的一个特点就是，允许把函数本身作为参数传入另一个函数，还允许返回一个函数！ 函数式编程最早是数学家阿隆佐·邱奇研究的一套函数变换逻辑，又称Lambda Calculus（λ-Calculus），所以也经常把函数式编程称为Lambda计算。 Java平台从Java 8开始，支持函数式编程。 Lamda基础在Java程序中，我们经常遇到一大堆单方法接口，即一个接口只定义了一个方法： Comparator Runnable Callable 以Comparator为例，我们想要调用Arrays.sort()时，可以传入一个Comparator实例，以匿名类方式编写如下： 123456String[] array = ...Arrays.sort(array, new Comparator&lt;String&gt;() { public int compare(String s1, String s2) { return s1.compareTo(s2); }}); 上述写法非常繁琐。从Java 8开始，我们可以用Lambda表达式替换单方法接口。改写代码如下： 12345678910import java.util.Arrays;public class Main { public static void main(String[] args) { String[] array = new String[] { \"Apple\", \"Orange\", \"Banana\", \"Lemon\" }; Arrays.sort(array, (s1, s2) -&gt; { return s1.compareTo(s2); }); System.out.println(String.join(\", \", array)); }} 观察Lamda表达式的写法，它只需要写出方法定义： 123(s1, s2) -&gt; { return s1.compareTo(s2);} 其中，参数是(s1, s2)，参数类型可以省略，因为编译器可以自动推断出String类型。-&gt;{...}表示方法体，所有代码写在内部即可。Lamda表达式没有class定义，因此写法非常简洁。如果只有一行return xxx;的代码，还可以使用更简单的方法： 1Arrays.sort(array, (s1, s2) -&gt; s1.compareTo(s2)); 返回值类型，也是由编译器自动推断的，这里推断的返回值是int，因此，只要返回int，编译器就不会报错。 FunctionalInterface我们把定义了单方法的接口称之为FunctionalInterface，用注解@FunctionalInterface标记。例如，Callable接口： 1234@FunctionalInterfacepublic interface Callable&lt;V&gt; { V call() throws Exception;} 再来看Comparator接口： 12345678910111213141516@FunctionalInterfacepublic interface Comparator&lt;T&gt; { int compare(T o1, T o2); boolean equals(Object obj); default Comparator&lt;T&gt; reversed() { return Collections.reverseOrder(this); } default Comparator&lt;T&gt; thenComparing(Comparator&lt;? super T&gt; other) { ... } ...} 虽然Comparator接口有很多方法，但只有一个抽象方法int compare(T o1, T o2)，其他的方法都是default方法或static方法。另外注意到boolean equals(Object obj)是Object定义的方法，不算在接口方法内。因此，Comparator也是一个FunctionalInterface。 小结单方法接口被称为FunctionalInterface。接收FunctionalInterface作为参数的时候，可以把实例化的匿名类改写为Lambda表达式，能大大简化代码。Lambda表达式的参数和返回值均可由编译器自动推断。 方法引用使用Lambda表达式，我们就可以不必编写FunctionalInterface接口的实现类，从而简化代码： 123Arrays.sort(array, (s1, s2) -&gt; { return s1.compareTo(s2);}); 实际上，除了Lambda表达式，我们还可以直接传入方法引用。 123456789101112import java.util.Arrays;public class Main { public static void main(String[] args) { String[] array = new String[] { \"Apple\", \"Orange\", \"Banana\", \"Lemon\" }; Arrays.sort(array, Main::cmp); System.out.println(String.join(\", \", array)); } static int cmp(String s1, String s2) { return s1.compareTo(s2); }} 上述代码在Arrays.sort()中传入了静态方法cmp的引用，用Main::cmp表示。 因为Comparator&lt;String&gt;接口定义的方法是int compare(String, String)，和静态方法int cmp(String, String)相比，除了方法名外，方法参数一致，返回类型相同，因此，我们说两者的方法签名一致，可以直接把方法名作为Lambda表达式传入。 在这里，方法签名只看参数类型和返回类型，不看方法名称，也不看类的继承关系。 我们再看看如何引用实例方法，我们把代码改写如下： 12345678import java.util.Arrays;public class Main { public static void main(String[] args) { String[] array = new String[] { \"Apple\", \"Orange\", \"Banana\", \"Lemon\" }; Arrays.sort(array, String::compareTo); System.out.println(String.join(\", \", array)); }} 不但可以编译通过，而且运行结果也是一样的，这说明String.compareTo()方法也符合Lamda定义。观察String.compareTo()的方法定义： 12345public final class String { public int compareTo(String o) { ... }} 这个方法的签名只有一个参数，为什么和int Comparator&lt;String&gt;.compare(String, String)能匹配呢？ 因为实例方法有一个隐含的this参数，String类的compareTo()方法在实际调用时，第一个隐含参数总是传入this，相当于静态方法： 1public static int compareTo(this, String o); 所以，String.compareTo()方法也可以作为方法引用传入。 构造方法引用除了静态方法和实例方法，我们还可以引用构造方法。 我们来看一个例子：如果要把一个List&lt;String&gt;转换为List&lt;Person&gt;，应该怎么办？ 123456789class Person { String name; public Person(String name) { this.name = name; }}List&lt;String&gt; names = List.of(\"Bob\", \"Alice\", \"Tim\");List&lt;Person&gt; persons = ??? 传统的做法是先定义一个ArrayList&lt;Person&gt;，然后用for循环填充这个List： 12345List&lt;String&gt; names = List.of(\"Bob\", \"Alice\", \"Tim\");List&lt;Person&gt; persons = new ArrayList&lt;&gt;();for (String name : names) { persons.add(new Person(name));} 要更简单地实现String到Person的转换，我们可以引用Person的构造方法： 1234567891011121314151617181920// 引用构造方法import java.util.*;import java.util.stream.*;public class Main { public static void main(String[] args) { List&lt;String&gt; names = List.of(\"Bob\", \"Alice\", \"Tim\"); List&lt;Person&gt; persons = names.stream().map(Person::new).collect(Collectors.toList()); System.out.println(persons); }}class Person { String name; public Person(String name) { this.name = name; } public String toString() { return \"Person:\" + this.name; }} 后面我们会讲到Stream的map()方法。现在我们看到，这里的map()需要传入的FunctionalInterface的定义是： 1234@FunctionalInterfacepublic interface Function&lt;T, R&gt; { R apply(T t);} 把泛型对应上就是方法签名Person apply(String)，即传入参数String，返回类型Person。而Person类的构造方法恰好满足这个条件，因为构造方法的参数是String，而构造方法虽然没有return语句，但它会隐式地返回this实例，类型就是Person，因此，此处可以引用构造方法。构造方法的引用写法是类名::new，因此，此处传入Person::new。 小结FunctionalInterface允许传入： 接口的实现类（传统写法，代码较繁琐） Lambda表达式（只需列出参数名，由编译器推断类型） 符合方法签名的静态方法 符合方法签名的实例方法（实例类型被看做第一个参数类型） 符合方法签名的构造方法（实例类型被看做返回类型） FunctionalInterface不强制继承关系，不需要方法名称相同，只要求方法参数（类型和数量）与方法返回类型相同，即认为方法签名相同。 使用Stream从Java 8开始，不但引入了Lamda表达式，还引入了一个全新的流式API：Stream API。它位于java.util.stream包中。 注意，这个Stream不同于java.io中的InputStream和OutputStream，它代表的是任意Java对象的序列，二者对比如下： java.io java.util.stream 存储 顺序读写的byte或char 顺序输出的任意Java对象实例 用途 序列化至文件或网络 内存计算／业务逻辑 注意，这个Stream和List也不一样，List存储的每个元素都是已经存储在内存中的某个Java对象，而Stream输出的元素可能并没有预先存储到内存中，而是实时计算出来的。换句话说，List的用途是操作一组已存在的Java对象，而Stream实现的是惰性计算，二者对比如下： java.util.List java.util.stream 元素 已分配并存储在内存 可能未分配，实时计算 用途 操作一组已存在的Java对象 惰性计算 Stream看上去不太好理解，但我们来举个例子。 如果我们要表示一个全体自然数的集合，显然，用List是不可能写出来的，因为自然数是无限的，内存再大也没法放到List中： 1List&lt;BigInteger&gt; list = ??? // 全体自然数? 但是，用Stream可以做到。写法如下： 1Stream&lt;BigInteger&gt; naturals = createNaturalStream(); // 全体自然数 我们先不考虑createNaturalStream()这个方法是如何实现的，我们看看如何使用这个Stream。 首先，我们可以对每个自然数做一个平方，这样我们就把这个Stream转换成了另一个Stream： 12Stream&lt;BigInteger&gt; naturals = createNaturalStream(); // 全体自然数Stream&lt;BigInteger&gt; streamNxN = naturals.map(n -&gt; n.multiply(n)); // 全体自然数的平方 因为这个streamNxN也有无限多个元素，要打印它，必须首先把无限多个元素变成有限个元素，可以用limit()方法截取前100个元素，最后用forEach()处理每个元素，这样，我们就打印出了前100个自然数的平方： 1234Stream&lt;BigInteger&gt; naturals = createNaturalStream();naturals.map(n -&gt; n.multiply(n)) // 1, 4, 9, 16, 25... .limit(100) .forEach(System.out::println); 我们总结一下Stream的特点：它可以“存储”有限个或无限个元素。这里的存储打了个引号，是因为元素有可能已经全部存储在内存中，也有可能是根据需要实时计算出来的。 Stream的另一个特点是，一个Stream可以轻易地转换为另一个Stream，而不是修改原Stream本身。 最后，真正的计算通常发生在最后结果的获取，也就是惰性计算。 1234Stream&lt;BigInteger&gt; naturals = createNaturalStream(); // 不计算Stream&lt;BigInteger&gt; s2 = naturals.map(BigInteger::multiply); // 不计算Stream&lt;BigInteger&gt; s3 = s2.limit(100); // 不计算s3.forEach(System.out::println); // 计算 惰性计算的特点是：一个Stream转换为另一个Stream时，实际上只存储了转换规则，并没有任何计算发生。 例如，创建一个全体自然数的Stream，不会进行计算，把它转换为上述s2这个Stream，也不会进行计算。再把s2这个无限Stream转换为s3这个有限的Stream，也不会进行计算。只有最后，调用forEach确实需要Stream输出的元素时，才进行计算。我们通常把Stream的操作写成链式操作，代码更简洁： 1234createNaturalStream() .map(BigInteger::multiply) .limit(100) .forEach(System.out::println); 因此，Stream API的基本用法就是：创建一个Stream，然后做若干次转换，最后调用一个求值方法获取真正计算的结果： 12345int result = createNaturalStream() // 创建Stream .filter(n -&gt; n % 2 == 0) // 任意个转换 .map(n -&gt; n * n) // 任意个转换 .limit(100) // 任意个转换 .sum(); // 最终计算结果 Stream API的特点是： Stream API提供了一套新的流式处理的抽象序列； Stream API支持函数式编程和链式操作； Stream可以表示无限序列，并且大多数情况下是惰性求值的。 创建Stream创建Stream有很多种方法。 Stream.of()创建Stream最简单的方式是直接用Stream.of()静态方法，传入可变参数即创建了一个能输出确定元素的Stream。 123456789import java.util.stream.Stream;public class Main { public static void main(String[] args) { Stream&lt;String&gt; stream = Stream.of(\"A\", \"B\", \"C\", \"D\"); // forEach()方法相当于内部循环调用， // 可传入符合Consumer接口的void accept(T t)的方法引用： stream.forEach(System.out::println); }} 虽然这种方式没什么实际用途，但测试的时候很方便。 基于数组或Collection第二种创建Stream的方法是基于一个数组或者Collection，这样该Stream输出的元素就是数组或者Collection持有的元素： 12345678910import java.util.*;import java.util.stream.*;public class Main { public static void main(String[] args) { Stream&lt;String&gt; stream1 = Arrays.stream(new String[] { \"A\", \"B\", \"C\" }); Stream&lt;String&gt; stream2 = List.of(\"X\", \"Y\", \"Z\").stream(); stream1.forEach(System.out::println); stream2.forEach(System.out::println); }} 把数组变成Stream使用Arrays.stream()方法。对于Collection（List、Set、Queue等），直接调用stream()方法就可以获得Stream。 上述创建Stream的方法都是把一个现有的序列变为Stream，它的元素是固定的。 基于Supplier创建Stream还可以通过Stream.generate()方法，它需要传入一个Supplier对象： 1Stream&lt;String&gt; s = Stream.generate(Supplier&lt;String&gt; sp); 基于Supplier创建的Stream会不断调用Supplier.get()方法来不断产生下一个元素，这种Stream保存的不是元素，而是算法，它可以用来表示无限序列。 例如，我们编写一个能不断生成自然数的Supplier，它的代码非常简单，每次调用get()方法，就生成下一个自然数： 1234567891011121314151617import java.util.function.*;import java.util.stream.*;public class Main { public static void main(String[] args) { Stream&lt;Integer&gt; natual = Stream.generate(new NatualSupplier()); // 注意：无限序列必须先变成有限序列再打印: natual.limit(20).forEach(System.out::println); }}class NatualSupplier implements Supplier&lt;Integer&gt; { int n = 0; public Integer get() { n++; return n; }} 上述代码我们用一个Supplier&lt;Integer&gt;模拟了一个无限序列（当然受int范围限制不是真的无限大）。如果用List表示，即便在int范围内，也会占用巨大的内存，而Stream几乎不占用空间，因为每个元素都是实时计算出来的，用的时候再算。 对于无限序列，如果直接调用forEach()或者count()这些最终求值操作，会进入死循环，因为永远无法计算完这个序列，所以正确的方法是先把无限序列变成有限序列，例如，用limit()方法可以截取前面若干个元素，这样就变成了一个有限序列，对这个有限序列调用forEach()或者count()操作就没有问题。 其他方法创建Stream的第三种方法是通过一些API提供的接口，直接获得Stream。 例如，Files类的lines()方法可以把一个文件变成一个Stream，每个元素代表文件的一行内容： 123try (Stream&lt;String&gt; lines = Files.lines(Paths.get(\"/path/to/file.txt\"))) { ...} 此方法对于按行遍历文本文件十分有用。 另外，正则表达式的Pattern对象有一个splitAsStream()方法，可以直接把一个长字符串分割成Stream序列而不是数组： 123Pattern p = Pattern.compile(\"\\\\s+\");Stream&lt;String&gt; s = p.splitAsStream(\"The quick brown fox jumps over the lazy dog\");s.forEach(System.out::println); 基本类型因为Java的范型不支持基本类型，所以我们无法用Stream&lt;int&gt;这样的类型，会发生编译错误。为了保存int，只能使用Stream&lt;Integer&gt;，但这样会产生频繁的装箱、拆箱操作。为了提高效率，Java标准库提供了IntStream、LongStream和DoubleStream这三种使用基本类型的Stream，它们的使用方法和范型Stream没有大的区别，设计这三个Stream的目的是提高运行效率： 1234// 将int[]数组变为IntStream:IntStream is = Arrays.stream(new int[] { 1, 2, 3 });// 将Stream&lt;String&gt;转换为LongStream:LongStream ls = List.of(\"1\", \"2\", \"3\").stream().mapToLong(Long::parseLong); 使用mapStream.map()是Stream最常用的一个转换方法，它把一个Stream转换为另一个Stream。所谓map操作，就是把一种操作运算，映射到一个序列的每一个元素上。 例如，对x计算它的平方，可以使用函数f(x) = x * x。我们把这个函数映射到一个序列1，2，3，4，5上，就得到了另一个序列1，4，9，16，25。 可见，map操作把一个Stream的每个元素一一对应到应用了目标函数的结果上。 12Stream&lt;Integer&gt; s = Stream.of(1, 2, 3, 4, 5);Stream&lt;Integer&gt; s2 = s.map(n -&gt; n * n); 如果我们查看Stream的源码，会发现map()方法接收的对象是Function接口对象。Function接口定义了一个apply()方法，负责把一个T类型转换为R类型。 1&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper); 其中，Function的定义是： 12345@FunctionalInterfacepublic interface Function&lt;T, R&gt; { // 将T类型转换为R: R apply(T t);} 利用map()，不但能完成数学计算，对于字符串操作，以及任何Java对象都是非常有用的。例如： 1234567891011import java.util.*;import java.util.stream.*;public class Main { public static void main(String[] args) { List.of(\" Apple \", \" pear \", \" ORANGE\", \" BaNaNa \") .stream() .map(String::trim) // 去空格 .map(String::toLowerCase) // 变小写 .forEach(System.out::println); // 打印 }} 通过若干步map转换，可以写出逻辑简单、清晰的代码。 使用filterStream.filter()是Stream的另一个常用转换方法。所谓fliter操作，就是对一个Stream的所有元素一一测试，不满足条件的就被过滤掉了，剩下满足条件的元素就构成了一个新的Stream。 例如，我们对1，2，3，4，5这个Stream调用filter()，传入的测试函数f(x) = x % 2 != 0用来判断元素是否是奇数，这样就过滤掉偶数，只剩下奇数，因此我们得到了另一个序列1，3，5。 使用IntStream写出上述逻辑，代码如下： 12345678import java.util.stream.IntStream;public class Main { public static void main(String[] args) { IntStream.of(1, 2, 3, 4, 5, 6, 7, 8, 9) .filter(n -&gt; n % 2 != 0) .forEach(System.out::println); }} filter()方法接收的对象是Predicate接口对象，它定义了一个test()方法，负责判断元素是否符合条件。 12345@FunctionalInterfacepublic interface Predicate&lt;T&gt; { // 判断元素t是否符合条件: boolean test(T t);} filter()除了常用于数值外，也可应用于任何Java对象。例如，从一组给定的LocalDate中过滤掉工作日，以便得到休息日。 使用reducemap()和filter()都是Stream的转换方法，而Stream.reduce()则是Stream的一个聚合方法，他可以把一个Stream的所有元素按照聚合函数聚合成一个结果。 reduce()方法传入的对象是BinaryOperator接口，它定义了一个apply()方法，负责把上次累加的结果和本次的元素进行运算，并返回累加的结果。 12345@FunctionalInterfacepublic interface BinaryOperator&lt;T&gt; { // Bi操作：两个输入，一个输出 T apply(T t, T u);} 我们来看一个简单的聚合方法： 1int sum = Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9).reduce(0, (acc, n) -&gt; acc + n); 上述代码看上去不好理解，我们用for循环改写一下： 12345Stream&lt;Integer&gt; stream = ...int sum = 0;for (n : stream) { sum = (sum, n) -&gt; sum + n;} 可见，reduce()操作首先初始化结果为指定值（这里是0），紧接着，reduce()对每个元素调用(acc, n) -&gt; acc + n，其中，acc是上次计算的结果。 因此，实际上这个reduce()操作是求和。 如果去掉初始值，我们会得到一个Optional&lt;Integer&gt;。 1234Optional&lt;Integer&gt; opt = stream.reduce((acc, n) -&gt; acc + n);if (opt.isPresent()) { System.out.println(opt.get());} 这是因为Stream的元素有可能是0个，这样就没法调用reduce()聚合函数了，因此返回Optional对象，需要进一步判断结果是否存在。 利用reduce()，我们可以把求和改成求积，代码也十分简单。注意，计算求积时，初始值设为1。 1234567import java.util.stream.*;public class Main { public static void main(String[] args) { int s = Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9).reduce(1, (acc, n) -&gt; acc * n); System.out.println(s); // 362880 }} 除了可以对数值进行累积计算外，灵活运用reduce()也可以对Java对象进行操作。下面的代码演示了如何将配置文件的每一行配置通过map()和reduce()聚合成一个Map&lt;String, String&gt;。 12345678910111213141516171819202122import java.util.*;public class Main { public static void main(String[] args) { // 按行读取配置文件: List&lt;String&gt; props = List.of(\"profile=native\", \"debug=true\", \"logging=warn\", \"interval=500\"); Map&lt;String, String&gt; map = props.stream() // 把k=v转换为Map[k]=v: .map(kv -&gt; { String[] ss = kv.split(\"\\\\=\", 2); return Map.of(ss[0], ss[1]); }) // 把所有Map聚合到一个Map: .reduce(new HashMap&lt;String, String&gt;(), (m, kv) -&gt; { m.putAll(kv); return m; }); // 打印结果: map.forEach((k, v) -&gt; { System.out.println(k + \" = \" + v); }); }} 小结reduce()方法将一个Stream的每个元素依次做用于BinaryOperator，并将结果合并。 reduce()是聚合方法，聚合方法会立刻对Stream进行计算。 输出集合我们介绍了Stream的几个常见操作：map()，filter()，reduce()。这些操作对Stream来说可以分为两类，一类是转换操作，即把一个Stream转换为另一个Stream，例如map()和reduce()；另一类是聚合操作，即对Stream的每个元素进行计算，得到一个确定的结果，例如reduce()。 区分这两种操作是十分重要的，因为对于Stream来说，对其进行转换操作并不会触发任何计算。因为转换操作只是保存了转换规则，无论我们对一个Stream转换多少次，都不会有实际计算发生。 而聚合操作则不一样，聚合操作会立即促使Stream输出它的每一个元素，并依次纳入计算，以获得最终结果。可见，聚合操作是真正需要从Stream请求数据的，对一个Stream做聚合计算后，结果就不再是一个Stream了，而是一个Java对象。 输出为List把Stream的每个元素收集到List的方法是调用collect()并传入Collectors.toList()对象，它实际上是一个Collector实例，通过类似reduce()的操作，把每个元素添加到一个收集器中（实际上是ArrayList）。 类似的，collect(Collectors.toSet())可以把Stream的每个元素收集到Set中。 123456789import java.util.*;import java.util.stream.*;public class Main { public static void main(String[] args) { Stream&lt;String&gt; stream = Stream.of(\"Apple\", \"\", null, \"Pear\", \" \", \"Orange\"); List&lt;String&gt; list = stream.filter(s -&gt; s != null &amp;&amp; !s.isBlank()).collect(Collectors.toList()); System.out.println(list); }} 输出为数组和把Stream的元素输出为数组类似输出为List，我们只需要调用toArray()方法，并传入数组的“构造方法”。 12List&lt;String&gt; list = List.of(\"Apple\", \"Banana\", \"Orange\");String[] array = list.stream().toArray(String[]::new); 注意到传入的构造方法是String[]::new，它的签名实际上是IntFunction&lt;String[]&gt;定义的String[] apply(int)，即传入int参数，获得Stringp[]数组的返回值。 输出为Map如果我们要把Stream的元素收集到Map中，稍微麻烦一点。因为对于每个元素，添加Map时需要key和value，因此，我们要指定两个映射函数，分别把元素映射为key和value。 1234567891011121314import java.util.*;import java.util.stream.*;public class Main { public static void main(String[] args) { Stream&lt;String&gt; stream = Stream.of(\"APPL:Apple\", \"MSFT:Microsoft\"); Map&lt;String, String&gt; map = stream .collect(Collectors.toMap( // 把元素s映射为key: s -&gt; s.substring(0, s.indexOf(':')), // 把元素s映射为value: s -&gt; s.substring(s.indexOf(':') + 1))); System.out.println(map); }} 分组输出Stream还有一个强大的分组功能，可以按组输出。 12345678910import java.util.*;import java.util.stream.*;public class Main { public static void main(String[] args) { List&lt;String&gt; list = List.of(\"Apple\", \"Banana\", \"Blackberry\", \"Coconut\", \"Avocado\", \"Cherry\", \"Apricots\"); Map&lt;String, List&lt;String&gt;&gt; groups = list.stream() .collect(Collectors.groupingBy(s -&gt; s.substring(0, 1), Collectors.toList())); System.out.println(groups); }} 分组输出使用Collectors.groupingBy()，它需要提供两个函数：一个是分组的key，这里使用s -&gt; s.substring(0, 1)，表示只要首字母相同的String分到一组，第二个是分组的value，这里直接使用Collectors.toList()，表示输出为List，上述代码运行结果如下： 12345{ A=[Apple, Avocado, Apricots], B=[Banana, Blackberry], C=[Coconut, Cherry]} 可见，结果一共有3组，按\"A\"，\"B\"，\"C\"分组，每一组都是一个List。 假设有这样一个Student类，包含学生姓名、班级和成绩： 123456class Student { int gradeId; // 年级 int classId; // 班级 String name; // 名字 int score; // 分数} 如果我们有一个Stream&lt;Student&gt;，利用分组输出，可以非常简单地按年级或班级把Student归类。 其他操作除了前面介绍的转换操作和聚合操作，Stream还提供了一系列非常有用的方法。 排序对Stream的元素进行排序非常简单，只需要调用sorted()方法。 12345List&lt;String&gt; list = List.of(\"Orange\", \"apple\", \"Banana\") .stream() .sorted() .collect(Collectors.toList());System.out.println(list); 此方法要求Stream的元素必须实现Comparable接口，如果要自定义排序，传入指定的Comparator即可。 1234List&lt;String&gt; list = List.of(\"Orange\", \"apple\", \"Banana\") .stream() .sorted(String::compareToIgnoreCase) .collect(Collectors.toList()); 注意sorted()只是一个转换操作，它会返回一个新的Stream。 去重对一个Stream的元素进行去重，没必要先转换为Set，可以直接用distinct()。 1234List.of(\"A\", \"B\", \"A\", \"C\", \"B\", \"D\") .stream() .distinct() .collect(Collectors.toList()); // [A, B, C, D] 截取截取操作常用于把一个无限Stream转换成有限Stream，skip()用于跳过当前Stream的前N个元素，limit()用于截取当前Stream最多前N个元素。 12345List.of(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\") .stream() .skip(2) // 跳过A, B .limit(3) // 截取C, D, E .collect(Collectors.toList()); // [C, D, E] 截取操作也是一个转换操作，将返回新的Stream。 合并将两个Stream合并为一个Stream可以使用Stream的静态方法concat()。 12345Stream&lt;String&gt; s1 = List.of(\"A\", \"B\", \"C\").stream();Stream&lt;String&gt; s2 = List.of(\"D\", \"E\").stream();// 合并:Stream&lt;String&gt; s = Stream.concat(s1, s2);System.out.println(s.collect(Collectors.toList())); // [A, B, C, D, E] flatMap如果Stream的元素是集合： 1234Stream&lt;List&lt;Integer&gt;&gt; s = Stream.of( Arrays.asList(1, 2, 3), Arrays.asList(4, 5, 6), Arrays.asList(7, 8, 9)); 而我们希望把上述Stream转换为Stream&lt;Integer&gt;，就可以使用flatMap()： 1Stream&lt;Integer&gt; i = s.flatMap(list -&gt; list.stream()); 所谓flatMap()是指把Stream的每个元素（这里是List）映射为Stream，然后合并为一个新的Stream。 并行通常情况下，对Stream的元素进行处理是单线程的，即一个元素一个元素处理。但是，我们希望可以并行处理Stream的元素，因为在元素数量非常大的情况，并行处理可以大大加快处理速度。 把一个普通Stream转换为可以并行处理的Stream非常简单，只需要用parallel()进行转换。 1234Stream&lt;String&gt; s = ...String[] result = s.parallel() // 变成一个可以并行处理的Stream .sorted() // 可以进行并行排序 .toArray(String[]::new); 经过parallel()转换后的Stream只要可能，就会对后续操作并行处理，我们不需要编写任何多线程的代码就可以得到并行处理带来的效率提升。 其他聚合方法除了reduce()和collect()外，Stream还有一些常用的聚合方法： count()：用于返回元素个数； max(Comparator&lt;? super T&gt; cp)：找出最大元素； min(Comparator&lt;? super T&gt; cp)：找出最小元素。 针对IntStream、LongStream和DoubleStream，还额外提供了以下聚合方法： sum()：对所有元素求和； average()：对所有元素求平均数。 还有一些方法，用来测试Stream的元素是否满足以下条件： boolean allMatch(Predicate&lt;? super T&gt;)：测试是否所有元素均满足测试条件； boolean anyMatch(Predicate&lt;? super T&gt;)：测试是否至少有一个元素满足测试条件。 最后一个常用的方法是forEach()，它可以循环处理Stream的每个元素，我们经常传入System.out::println来打印Stream的元素： 1234Stream&lt;String&gt; s = ...s.forEach(str -&gt; { System.out.println(\"Hello, \" + str);}); 小结Stream提供的常用操作有： 转换操作：map()，filter()，sorted()，distinct()； 合并操作：concat()，flatMap()； 并行处理：parallel()； 聚合操作：reduce()，collect()，count()，max()，min()，sum()，average()； 其他操作：allMatch(), anyMatch(), forEach()。","link":"/Study/Java/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"title":"网络编程","text":"网络编程是Java最擅长的方向之一，使用Java进行网络编程时，由虚拟机实现了底层复杂的网络协议，Java程序只需要调用Java标准库提供的接口，就可以简单高效的编写网络程序。本节我们详细介绍如何用Java进行网络编程。 网络编程基础在学习Java网络编程之前，我们先来了解什么是计算机网络。 计算机网络是指两台或更多的计算机组成的网络，在同一个网络中，任意两台计算机都可以直接通信，因为所有计算机都需要遵循同一种网络协议。 那什么是互联网呢？互联网是网络的网络（internet），即把很多计算机网络连接起来，形成一个全球统一的互联网。 对某个特定的计算机网络来说，它可能使用网络协议ABC，而另一个计算机网络可能使用网络协议XYZ。如果计算机网络各自的通讯协议不统一，就没法把不同的网络连接起来形成互联网。因此，为了把计算机网络接入互联网，就必须使用TCP/IP协议。 TCP/IP协议泛指互联网协议，其中最重要的两个协议是TCP协议和IP协议。只有使用TCP/IP协议的计算机才能够联入互联网，使用其他网络协议（例如NetBIOS、AppleTalk协议等）是无法联入互联网的。 IP地址在互联网中，一个IP地址用于唯一标识一个网络接口（Network Interface）。一台联入互联网的计算机肯定有一个IP地址，但也可能有多个IP地址。 IP地址分为IPv4和IPv6两种。IPv4采用32位地址，类似101.202.99.12，而IPv6采用128位地址，类似2001:0DA8:100A:0000:0000:1020:F2F3:1428。IPv4地址总共有232个（大约42亿），而IPv6地址则总共有2128个（大约340万亿亿亿亿），IPv4的地址目前已耗尽，而IPv6的地址是根本用不完的。 IP地址又分为公网IP地址和内网IP地址。公网IP地址可以直接被访问，内网IP地址只能在内网访问。内网IP地址类似于： 192.168.x.x 10.x.x.x 有一个特殊的IP地址，称之为本机地址，它总是127.0.0.1。 IPv4地址实际上是一个32位整数。例如： 123106717964 = 0x65ca630c = 65 ca 63 0c = 101.202.99.12 如果一台计算机只有一个网卡，并且接入了网络，那么，它有一个本机地址127.0.0.1，还有一个IP地址，例如101.202.99.12，可以通过这个IP地址接入网络。 如果一台计算机有两块网卡，那么除了本机地址，它可以有两个IP地址，可以分别接入两个网络。通常连接两个网络的设备是路由器或者交换机，它至少有两个IP地址，分别接入不同的网络，让网络之间连接起来。 如果两台计算机位于同一个网络，那么他们之间可以直接通信，因为他们的IP地址前段是相同的，也就是网络号是相同的。网络号是IP地址通过子网掩码过滤后得到的。例如： 某台计算机的IP是101.202.99.2，子网掩码是255.255.255.0，那么计算该计算机的网络号是： 123IP = 101.202.99.2Mask = 255.255.255.0Network = IP &amp; Mask = 101.202.99.0 每台计算机都需要正确配置IP地址和子网掩码，根据这两个就可以计算网络号，如果两台计算机计算出的网络号相同，说明两台计算机在同一个网络，可以直接通信。如果两台计算机计算出的网络号不同，那么两台计算机不在同一个网络，不能直接通信，它们之间必须通过路由器或者交换机这样的网络设备间接通信，我们把这种设备称为网关。 网关的作用就是连接多个网络，负责把来自一个网络的数据包发到另一个网络，这个过程叫路由。 所以，一台计算机的一个网卡会有3个关键配置： IP地址 子网掩码 网关的IP地址 域名因为直接记忆IP地址非常困难，所以我们通常使用域名访问某个特定的服务。域名解析服务器DNS负责把域名翻译成对应的IP，客户端再根据IP地址访问服务器。有一个特殊的本机域名localhost，它对应的IP地址总是本机地址127.0.0.1。 网络模型由于计算机网络从底层的传输到高层的软件设计十分复杂，要合理地设计计算机网络模型，必须采用分层模型，每一层负责处理自己的操作。OSI（Open System Interconnect）网络模型是ISO组织定义的一个计算机互联的标准模型，注意它只是一个定义，目的是为了简化网络各层的操作，提供标准接口便于实现和维护。这个模型从上到下依次是： 应用层，提供应用程序之间的通信； 表示层：处理数据格式，加解密等等； 会话层：负责建立和维护会话； 传输层：负责提供端到端的可靠传输； 网络层：负责根据目标地址选择路由来传输数据； 链路层和物理层负责把数据进行分片并且真正通过物理网络传输，例如，无线网、光纤等。 互联网实际使用的TCP/IP模型并不是对应到OSI的7层模型，而是大致对应OSI的5层模型。 常用协议IP协议是一个分组交换，它不保证可靠传输。而TCP协议是传输控制协议，它是面向连接的协议，支持可靠传输和双向通信。TCP协议是建立在IP协议之上的，简单地说，IP协议只负责发数据包，不保证顺序和正确性，而TCP协议负责控制数据包传输，它在传输数据之前需要先建立连接，建立连接后才能传输数据，传输完后还需要断开连接。TCP协议之所以能保证数据的可靠传输，是通过接收确认、超时重传这些机制实现的。并且，TCP协议允许双向通信，即通信双方可以同时发送和接收数据。 TCP协议也是应用最广泛的协议，许多高级协议都是建立在TCP协议之上的，例如HTTP、SMTP等。 UDP协议（User Datagram Protocol）是一种数据报文协议，它是无连接协议，不保证可靠传输。因为UDP协议在通信前不需要建立连接，因此它的传输效率比TCP高，而且UDP协议比TCP协议要简单得多。 选择UDP协议时，传输的数据通常是能容忍丢失的，例如，一些语音视频通信的应用会选择UDP协议。 TCP编程在开发网络应用程序时，我们又会遇到Socket这个概念。Socket是一个抽象概念，一个应用程序通过一个Socket来建立一个远程连接，而Socket内部通过TCP/IP协议把数据传输到网络。 Socket、TCP和部分IP的功能都是由操作系统提供的，不同的编程语言只是提供了对操作系统调用的简单的封装。 为什么需要Socket进行网络通信？因为仅仅通过IP地址进行通信是不够的，同一台计算机同一时间会运行多个网络应用程序，例如浏览器、QQ、邮件客户端等。当操作系统接收到一个数据包的时候，如果只有IP地址，它没法判断应该发给哪个应用程序，所以，操作系统抽象出Socket接口，每个应用程序需要各自对应到不同的Socket，数据包才能根据Socket正确地发到对应的应用程序。 一个Socket就是由IP地址和端口号（范围是0～65535）组成，可以把Socket简单理解为IP地址加端口号。端口号总是由操作系统分配，它是一个0～65535之间的数字，其中，小于1024的端口属于特权端口，需要管理员权限，大于1024的端口可以由任意用户的应用程序打开。 使用Socket进行网络编程时，本质上就是两个进程之间的网络通信。其中一个进程必须充当服务器端，它会主动监听某个指定的端口，另一个进程必须充当客户端，它必须主动连接服务器的IP地址和指定端口，如果连接成功，服务器端和客户端就成功地建立了一个TCP连接，双方后续就可以随时发送和接收数据。 因此，当Socket连接成功地在服务器端和客户端之间建立后： 对服务器端来说，它的Socket是指定的IP地址和指定的端口号； 对客户端来说，它的Socket是它所在计算机的IP地址和一个由操作系统分配的随机端口号。 服务器端要使用Socket编程，我们首先要编写服务器端程序。Java标准库提供了ServerSocket来实现对指定IP和指定端口的监听。ServerSocket的典型实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Server { public static void main(String[] args) throws IOException { ServerSocket ss = new ServerSocket(6666); // 监听指定端口 System.out.println(\"server is running...\"); for (;;) { Socket sock = ss.accept(); System.out.println(\"connected from \" + sock.getRemoteSocketAddress()); Thread t = new Handler(sock); t.start(); } }}class Handler extends Thread { Socket sock; public Handler(Socket sock) { this.sock = sock; } @Override public void run() { try (InputStream input = this.sock.getInputStream()) { try (OutputStream output = this.sock.getOutputStream()) { handle(input, output); } } catch (Exception e) { try { this.sock.close(); } catch (IOException ioe) { } System.out.println(\"client disconnected.\"); } } private void handle(InputStream input, OutputStream output) throws IOException { var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8)); var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8)); writer.write(\"hello\\n\"); writer.flush(); for (;;) { String s = reader.readLine(); if (s.equals(\"bye\")) { writer.write(\"bye\\n\"); writer.flush(); break; } writer.write(\"ok: \" + s + \"\\n\"); writer.flush(); } }} 服务器端通过代码： 1ServerSocket ss = new ServerSocket(6666); 在指定端口6666监听。这里我们没有指定IP地址，表示在计算机的所有网络接口上进行监听。 如果ServerSocket监听成功，我们就使用一个无限循环来处理客户端的连接： 12345for (;;) { Socket sock = ss.accept(); Thread t = new Handler(sock); t.start();} 注意到代码ss.accept()表示每当有新的客户端连接进来后，就返回一个Socket实例，这个Socket实例就是用来和刚连接的客户端进行通信的。由于客户端很多，要实现并发处理，我们就必须为每个新的Socket创建一个新线程来处理，这样，主线程的作用就是接收新的连接，每当收到新连接后，就创建一个新线程进行处理。 我们在多线程编程的章节中介绍过线程池，这里也完全可以利用线程池来处理客户端连接，能大大提高运行效率。 如果没有客户端连接进来，accept()方法会阻塞并一直等待。如果有多个客户端同时连接进来，ServerSocket会把连接扔到队列里，然后一个一个处理。对于Java程序而言，只需要通过循环不断调用accept()就可以获取新的连接。 客户端相比服务器端，客户端程序就要简单很多。一个典型的客户端程序如下： 12345678910111213141516171819202122232425262728293031public class Client { public static void main(String[] args) throws IOException { Socket sock = new Socket(\"localhost\", 6666); // 连接指定服务器和端口 try (InputStream input = sock.getInputStream()) { try (OutputStream output = sock.getOutputStream()) { handle(input, output); } } sock.close(); System.out.println(\"disconnected.\"); } private static void handle(InputStream input, OutputStream output) throws IOException { var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8)); var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8)); Scanner scanner = new Scanner(System.in); System.out.println(\"[server] \" + reader.readLine()); for (;;) { System.out.print(\"&gt;&gt;&gt; \"); // 打印提示 String s = scanner.nextLine(); // 读取一行输入 writer.write(s); writer.newLine(); writer.flush(); String resp = reader.readLine(); System.out.println(\"&lt;&lt;&lt; \" + resp); if (resp.equals(\"bye\")) { break; } } }} 客户端程序通过： 1Socket sock = new Socket(\"localhost\", 6666); 连接到服务器端，注意上述代码的服务器地址是\"localhost\"，表示本机地址，端口号是6666。如果连接成功，将返回一个Socket实例，用于后续通信。 Socket流当Socket连接创建成功后，无论是服务器端，还是客户端，我们都使用Socket实例进行网络通信。因为TCP是一种基于流的协议，因此，Java标准库使用InputStream和OutputStream来封装Socket的数据流，这样我们使用Socket的流，和普通IO流类似： 1234// 用于读取网络数据:InputStream in = sock.getInputStream();// 用于写入网络数据:OutputStream out = sock.getOutputStream(); 最后我们重点来看看，为什么写入网络数据时，要调用flush()方法。 如果不调用flush()，我们很可能会发现，客户端和服务器都收不到数据，这并不是Java标准库的设计问题，而是我们以流的形式写入数据的时候，并不是一写入就立刻发送到网络，而是先写入内存缓冲区，直到缓冲区满了以后，才会一次性真正发送到网络，这样设计的目的是为了提高传输效率。如果缓冲区的数据很少，而我们又想强制把这些数据发送到网络，就必须调用flush()强制把缓冲区数据发送出去。 小结使用Java进行TCP编程时，需要使用Socket模型： 服务器端用ServerSocket监听指定端口； 客户端使用Socket(InetAddress, port)连接服务器； 服务器端用accept()接收连接并返回Socket； 双方通过Socket打开InputStream/OutputStream读写数据； 服务器端通常使用多线程同时处理多个客户端连接，利用线程池可大幅提升效率； flush()用于强制输出缓冲区到网络。 UDP编程和TCP编程相比，UDP编程就简单的多，因为UDP没有创建连接，数据包也是一次收发一个，所以没有流的概念。在Java中使用UDP编程，仍然需要使用Socket，因为应用程序在使用UDP时必须指定网络接口（IP）和端口号。注意，UDP端口和TCP端口虽然都使用0～65535，但他们是两套独立的端口，即一个应用程序TCP占用了端口1234，不影响另一个应用程序用UDP占用端口1234。 服务器端在服务器端，使用UDP也需要监听指定的端口。Java提供了DatagramSocket来实现这个功能。 1234567891011121314DatagramSocket ds = new DatagramSocket(6666); // 监听指定端口for (;;) { // 无限循环 // 数据缓冲区: byte[] buffer = new byte[1024]; DatagramPacket packet = new DatagramPacket(buffer, buffer.length); ds.receive(packet); // 收取一个UDP数据包 // 收取到的数据存储在buffer中，由packet.getOffset(), packet.getLength()指定起始位置和长度 // 将其按UTF-8编码转换为String: String s = new String(packet.getData(), packet.getOffset(), packet.getLength(), StandardCharsets.UTF_8); // 发送数据: byte[] data = \"ACK\".getBytes(StandardCharsets.UTF_8); packet.setData(data); ds.send(packet);} 当服务器收到一个DatagramPacket后，通常必须立刻回复一个或多个UDP包。因为客户端地址在DatagramPacket中，每次收到的DatagramPacket可能是不同的客户端，如果不回复，某个客户端就收不到任何UDP包。 客户端和服务端相比，客户端使用UDP时，只需要直接向服务器端发送UDP包，然后接受返回的UDP包。 12345678910111213DatagramSocket ds = new DatagramSocket();ds.setSoTimeout(1000);ds.connect(InetAddress.getByName(\"localhost\"), 6666); // 连接指定服务器和端口// 发送:byte[] data = \"Hello\".getBytes();DatagramPacket packet = new DatagramPacket(data, data.length);ds.send(packet);// 接收:byte[] buffer = new byte[1024];packet = new DatagramPacket(buffer, buffer.length);ds.receive(packet);String resp = new String(packet.getData(), packet.getOffset(), packet.getLength());ds.disconnect(); 客户端创建DatagramSocket实例时并不需要指定端口，而是由操作系统自动指定一个当前未使用的端口。紧接着，调用setSoTimeout(1000)设定超时1秒，意思是后续接收UDP包时，等待时间最多不会超过1秒，否则在没有收到UDP包时，客户端会无限等待下去。这一点和服务器端不一样，服务器端可以无限等待，因为它本来就被设计成长时间运行。 注意到客户端的DatagramSocket还调用了一个connect()方法“连接”到指定的服务器端。不是说UDP是无连接的协议吗？为啥这里需要connect()？ 这个connect()方法不是真连接，它是为了在客户端的DatagramSocket实例中保存服务器端的IP和端口号，确保这个DatagramSocket实例只能往指定的地址和端口发送UDP包，不能往其他地址和端口发送。这么做不是UDP的限制，而是Java内置了安全检查。 如果客户端希望向两个不同的服务器发送UDP包，那么它必须创建两个DatagramSocket实例。 后续的收发数据和服务器端是一致的。通常来说，客户端必须先发UDP包，因为客户端不发UDP包，服务器端就根本不知道客户端的地址和端口号。 如果客户端认为通信结束，就可以调用disconnect()断开连接。注意到disconnect()也不是真正地断开连接，它只是清除了客户端DatagramSocket实例记录的远程服务器地址和端口号，这样，DatagramSocket实例就可以连接另一个服务器端。 小结使用UDP协议通信时，服务器和客户端双方无需建立连接： 服务器端用DatagramSocket(port)监听端口； 客户端使用DatagramSocket.connect()指定远程地址和端口； 双方通过receive()和send()读写数据； DatagramSocket没有IO流接口，数据被直接写入byte[]缓冲区。 发送EmailEmail就是电子邮件。电子邮件的应用已经有几十年的历史了，我们熟悉的邮箱地址比如abc@example.com，邮件软件比如Outlook都是用来收发邮件的。 使用Java程序也可以收发电子邮件。我们先来看一下传统的邮件是如何发送的。 传统的邮件是通过邮局投递，然后从一个邮局到另一个邮局，最终到达用户的邮箱： 123456 ┌──────────┐ ┌──────────┐ │PostOffice│ │PostOffice│ .───.┌─────┐ ├──────────┤ ├──────────┤ ( ( )│═══ ░│───&gt;│ ┌─┐ ┌┐┌┐ │───&gt;│ ┌─┐ ┌┐┌┐ │───&gt; `─┬─'└─────┘ │ │░│ └┘└┘ │ │ │░│ └┘└┘ │ │ └─┴─┴──────┘ └─┴─┴──────┘ │ 电子邮件的发送过程也是类似的，只不过是电子邮件是从用户电脑的邮件软件，例如Outlook，发送到邮件服务器上，可能经过若干个邮件服务器的中转，最终到达对方邮件服务器上，收件方就可以用软件接收邮件： 12345678 ┌─────────┐ ┌─────────┐ ┌─────────┐ │░░░░░░░░░│ │░░░░░░░░░│ │░░░░░░░░░│┌───────┐ ├─────────┤ ├─────────┤ ├─────────┤ ┌───────┐│░░░░░░░│ │░░░░░░░░░│ │░░░░░░░░░│ │░░░░░░░░░│ │░░░░░░░│├───────┤ ├─────────┤ ├─────────┤ ├─────────┤ ├───────┤│ │───&gt;│O ░░░░░░░│───&gt;│O ░░░░░░░│───&gt;│O ░░░░░░░│&lt;───│ │└───────┘ └─────────┘ └─────────┘ └─────────┘ └───────┘ MUA MTA MTA MDA MUA 我们把类似Outlook这样的邮件软件称为MUA：Mail User Agent，意思是给用户服务的邮件代理；邮件服务器则称为MTA：Mail Transfer Agent，意思是邮件中转的代理；最终到达的邮件服务器称为MDA：Mail Delivery Agent，意思是邮件到达的代理。电子邮件一旦到达MDA，就不再动了。实际上，电子邮件通常就存储在MDA服务器的硬盘上，然后等收件人通过软件或者登陆浏览器查看邮件。 MTA和MDA这样的服务器软件通常是现成的，我们不关心这些服务器内部是如何运行的。要发送邮件，我们关心的是如何编写一个MUA的软件，把邮件发送到MTA上。 MUA到MTA发送邮件的协议就是SMTP协议，它是Simple Mail Transport Protocol的缩写，使用标准端口25，也可以使用加密端口465或587。 SMTP协议是一个建立在TCP之上的协议，任何程序发送邮件都必须遵守SMTP协议。使用Java程序发送邮件时，我们无需关心SMTP协议的底层原理，只需要使用JavaMail这个标准API就可以直接发送邮件。 准备SMTP登录信息假设我们准备使用自己的邮件地址me@example.com给小明发送邮件，已知小明的邮件地址是xiaoming@somewhere.com，发送邮件前，我们首先要确定作为MTA的邮件服务器地址和端口号。邮件服务器地址通常是smtp.example.com，端口号由邮件服务商确定使用25、465还是587。以下是一些常用邮件服务商的SMTP信息： QQ邮箱：SMTP服务器是smtp.qq.com，端口是465/587； 163邮箱：SMTP服务器是smtp.163.com，端口是465； Gmail邮箱：SMTP服务器是smtp.gmail.com，端口是465/587。 有了SMTP服务器的域名和端口号，我们还需要SMTP服务器的登录信息，通常是使用自己的邮件地址作为用户名，登录口令是用户口令或者一个独立设置的SMTP口令。 我们来看看如何使用JavaMail发送邮件。 首先，我们需要创建一个Maven工程，并把JavaMail相关的两个依赖加入进来： 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.mail&lt;/groupId&gt; &lt;artifactId&gt;javax.mail-api&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.mail&lt;/groupId&gt; &lt;artifactId&gt;javax.mail&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; ... 然后，我们通过JavaMail API连接到SMTP服务器上： 1234567891011121314151617181920// 服务器地址:String smtp = \"smtp.office365.com\";// 登录用户名:String username = \"jxsmtp101@outlook.com\";// 登录口令:String password = \"********\";// 连接到SMTP服务器587端口:Properties props = new Properties();props.put(\"mail.smtp.host\", smtp); // SMTP主机名props.put(\"mail.smtp.port\", \"587\"); // 主机端口号props.put(\"mail.smtp.auth\", \"true\"); // 是否需要用户认证props.put(\"mail.smtp.starttls.enable\", \"true\"); // 启用TLS加密// 获取Session实例:Session session = Session.getInstance(props, new Authenticator() { protected PasswordAuthentication getPasswordAuthentication() { return new PasswordAuthentication(username, password); }});// 设置debug模式便于调试:session.setDebug(true); 以587端口为例，连接SMTP服务器时，需要准备一个Properties对象，填入相关信息。最后获取Session实例时，如果服务器需要认证，还需要传入一个Authenticator对象，并返回指定的用户名和口令。 当我们获取到Session实例后，打开调试模式可以看到SMTP通信的详细内容，便于调试。 发送邮件发送邮件时，我们需要构造一个Message对象，然后调用Transport.send(Message)即可完成发送： 1234567891011MimeMessage message = new MimeMessage(session);// 设置发送方地址:message.setFrom(new InternetAddress(\"me@example.com\"));// 设置接收方地址:message.setRecipient(Message.RecipientType.TO, new InternetAddress(\"xiaoming@somewhere.com\"));// 设置邮件主题:message.setSubject(\"Hello\", \"UTF-8\");// 设置邮件正文:message.setText(\"Hi Xiaoming...\", \"UTF-8\");// 发送:Transport.send(message); 绝大多数邮件服务器要求发送方地址和登录用户名必须一致，否则发送将失败。 发送HTML邮件发送HTML邮件和文本邮件是类似的，只需要把： 1message.setText(body, \"UTF-8\"); 改为： 1message.setText(body, \"UTF-8\", \"html\"); 传入的body是类似&lt;h1&gt;Hello&lt;/h1&gt;&lt;p&gt;Hi, xxx&lt;/p&gt;这样的HTML字符串即可。HTML邮件可以在邮件客户端直接显示为网页格式。 发送附件要在电子邮件中携带附件，我们就不能直接调用message.setText()方法，而是要构造一个Multipart对象： 123456789101112Multipart multipart = new MimeMultipart();// 添加text:BodyPart textpart = new MimeBodyPart();textpart.setContent(body, \"text/html;charset=utf-8\");multipart.addBodyPart(textpart);// 添加image:BodyPart imagepart = new MimeBodyPart();imagepart.setFileName(fileName);imagepart.setDataHandler(new DataHandler(new ByteArrayDataSource(input, \"application/octet-stream\")));multipart.addBodyPart(imagepart);// 设置邮件内容为multipart:message.setContent(multipart); 一个Multipart对象可以添加若干个BodyPart，其中第一个BodyPart是文本，即邮件正文，后面的BodyPart是附件。BodyPart依靠setContent()决定添加的内容，如果添加文本，用setContent(\"...\", \"text/plain;charset=utf-8\")添加纯文本，或者用setContent(\"...\", \"text/html;charset=utf-8\")添加HTML文本。如果添加附件，需要设置文件名（不一定和真实文件名一致），并且添加一个DataHandler()，传入文件的MIME类型。二进制文件可以用application/octet-stream，Word文档则是application/msword。 最后，通过setContent()把Multipart添加到Message中，即可发送。 发送内嵌图片的HTML邮件有些童鞋可能注意到，HTML邮件中可以内嵌图片，这是怎么做到的？ 如果给一个&lt;img src=\"http://example.com/test.jpg\"&gt;，这样的外部图片链接通常会被邮件客户端过滤，并提示用户显示图片并不安全。只有内嵌的图片才能正常在邮件中显示。 内嵌图片实际上也是一个附件，即邮件本身也是Multipart，但需要做一点额外的处理： 123456789101112Multipart multipart = new MimeMultipart();// 添加text:BodyPart textpart = new MimeBodyPart();textpart.setContent(\"&lt;h1&gt;Hello&lt;/h1&gt;&lt;p&gt;&lt;img src=\\\"cid:img01\\\"&gt;&lt;/p&gt;\", \"text/html;charset=utf-8\");multipart.addBodyPart(textpart);// 添加image:BodyPart imagepart = new MimeBodyPart();imagepart.setFileName(fileName);imagepart.setDataHandler(new DataHandler(new ByteArrayDataSource(input, \"image/jpeg\")));// 与HTML的&lt;img src=\"cid:img01\"&gt;关联:imagepart.setHeader(\"Content-ID\", \"&lt;img01&gt;\");multipart.addBodyPart(imagepart); 在HTML邮件中引用图片时，需要设定一个ID，用类似&lt;img src=\\\"cid:img01\\\"&gt;引用，然后，在添加图片作为BodyPart时，除了要正确设置MIME类型（根据图片类型使用image/jpeg或image/png），还需要设置一个Header： 1imagepart.setHeader(\"Content-ID\", \"&lt;img01&gt;\"); 这个ID和HTML中引用的ID对应起来，邮件客户端就可以正常显示内嵌图片。 常见问题如果用户名或口令错误，会导致535登录失败： 12DEBUG SMTP: AUTH LOGIN failedException in thread \"main\" javax.mail.AuthenticationFailedException: 535 5.7.3 Authentication unsuccessful [HK0PR03CA0105.apcprd03.prod.outlook.com] 如果登录用户和发件人不一致，会导致554拒绝发送错误： 12DEBUG SMTP: MessagingException while sending, THROW: com.sun.mail.smtp.SMTPSendFailedException: 554 5.2.0 STOREDRV.Submission.Exception:SendAsDeniedException.MapiExceptionSendAsDenied; 有些时候，如果邮件主题和正文过于简单，会导致554被识别为垃圾邮件的错误： 12DEBUG SMTP: MessagingException while sending, THROW: com.sun.mail.smtp.SMTPSendFailedException: 554 DT:SPM 接受Email邮件最终到达收件人的MDA服务器，所以，接收邮件是收件人用自己的客户端把邮件从MDA服务器上抓取到本地的过程。 接收邮件使用最广泛的协议是POP3：Post Office Protocol version 3，它也是一个建立在TCP连接之上的协议。POP3服务器的标准端口是110，如果整个回话需要加密，那么使用加密端口995。 另一种接受邮件的协议是IMAP：Internet Mail Access Protocol，它使用标准端口143和加密端口993。IMAP和POP3的区别在于，IMAP协议在本地的所有操作都会自动同步到服务器上，并且，IMAP可以允许用户在邮件服务器的收件箱中创建文件夹。 JavaMail也提供了IMAP协议的支持。因为POP3和IMAP的使用方式非常类似，因此我们只介绍POP3的用法。 首先连接到Store对象。 1234567891011121314151617181920// 准备登录信息:String host = \"pop3.example.com\";int port = 995;String username = \"bob@example.com\";String password = \"password\";Properties props = new Properties();props.setProperty(\"mail.store.protocol\", \"pop3\"); // 协议名称props.setProperty(\"mail.pop3.host\", host);// POP3主机名props.setProperty(\"mail.pop3.port\", String.valueOf(port)); // 端口号// 启动SSL:props.put(\"mail.smtp.socketFactory.class\", \"javax.net.ssl.SSLSocketFactory\");props.put(\"mail.smtp.socketFactory.port\", String.valueOf(port));// 连接到Store:URLName url = new URLName(\"pop3\", host, post, \"\", username, password);Session session = Session.getInstance(props, null);session.setDebug(true); // 显示调试信息Store store = new POP3SSLStore(session, url);store.connect(); 一个Store对象表示整个邮箱的存储，要收取邮件，我们需要通过Store访问指定的Folder（文件夹），通常是INBOX表示收件箱： 123456789101112131415// 获取收件箱:Folder folder = store.getFolder(\"INBOX\");// 以读写方式打开:folder.open(Folder.READ_WRITE);// 打印邮件总数/新邮件数量/未读数量/已删除数量:System.out.println(\"Total messages: \" + folder.getMessageCount());System.out.println(\"New messages: \" + folder.getNewMessageCount());System.out.println(\"Unread messages: \" + folder.getUnreadMessageCount());System.out.println(\"Deleted messages: \" + folder.getDeletedMessageCount());// 获取每一封邮件:Message[] messages = folder.getMessages();for (Message message : messages) { // 打印每一封邮件: printMessage((MimeMessage) message);} 当我们获取到一个Message对象时，可以强制转型为MimeMessage，然后打印出邮件主题、发件人、收件人等信息： 123456789101112void printMessage(MimeMessage msg) throws IOException, MessagingException { // 邮件主题: System.out.println(\"Subject: \" + MimeUtility.decodeText(msg.getSubject())); // 发件人: Address[] froms = msg.getFrom(); InternetAddress address = (InternetAddress) froms[0]; String personal = address.getPersonal(); String from = personal == null ? address.getAddress() : (MimeUtility.decodeText(personal) + \" &lt;\" + address.getAddress() + \"&gt;\"); System.out.println(\"From: \" + from); // 继续打印收件人: ...} 比较麻烦的是获取邮件的正文。一个MimeMessage对象也是一个Part对象，它可能只包含一个文本，也可能是一个Multipart对象，即由几个Part构成，因此，需要递归地解析出完整的正文： 12345678910111213141516171819String getBody(Part part) throws MessagingException, IOException { if (part.isMimeType(\"text/*\")) { // Part是文本: return part.getContent().toString(); } if (part.isMimeType(\"multipart/*\")) { // Part是一个Multipart对象: Multipart multipart = (Multipart) part.getContent(); // 循环解析每个子Part: for (int i = 0; i &lt; multipart.getCount(); i++) { BodyPart bodyPart = multipart.getBodyPart(i); String body = getBody(bodyPart); if (!body.isEmpty()) { return body; } } } return \"\";} 最后记得关闭Folder和Store： 12folder.close(true); // 传入true表示删除操作会同步到服务器上（即删除服务器收件箱的邮件）store.close(); 设置debug模式可以查看通信详细内容，便于排查错误。 HTTP编程什么是HTTP？HTTP就是目前使用最广泛的Web应用程序使用的基础协议，例如，浏览器访问网站，手机App访问后台服务器，都是通过HTTP协议实现的。HTTP是HyperText Transfer Protocol的缩写，翻译为超文本传输协议，它是基于TCP协议之上的一种请求-响应协议。 我们来看一下浏览器请求访问某个网站时发送的HTTP请求-响应。当浏览器希望访问某个网站时，浏览器和网站服务器之间首先建立TCP连接，且服务器总是使用80端口和加密端口443，然后，浏览器向服务器发送一个HTTP请求，服务器收到后，返回一个HTTP响应，并且在响应中包含了HTML的网页内容，这样，浏览器解析HTML后就可以给用户显示网页了。 HTTP请求的格式是固定的，它由HTTP Header和HTTP Body两部分构成。第一行总是请求方法 路径 HTTP版本，例如，GET / HTTP/1.1表示使用GET请求，路径是/，版本是HTTP/1.1。 Host：表示请求的域名，因为一台服务器上可能有多个网站，因此有必要依靠Host来识别请求是发给哪个网站的； User-Agent：表示客户端自身标识信息，不同的浏览器有不同的标识，服务器依靠User-Agent判断客户端类型是IE还是Chrome，是Firefox还是一个Python爬虫； Accept：表示客户端能处理的HTTP响应格式，*/*表示任意格式，text/*表示任意文本，image/png表示PNG格式的图片； Accept-Language：表示客户端接收的语言，多种语言按优先级排序，服务器依靠该字段给用户返回特定语言的网页版本。 如果是GET请求，那么该HTTP请求只有HTTP Header，没有HTTP Body。如果是POST请求，那么该HTTP请求带有HTTP Body，以一个空行分割。一个典型的带Body的HTTP请求如下： 123456POST /login HTTP/1.1Host: www.example.comContent-Type: application/x-www-form-urlencodedContent-Length: 30username=hello&amp;password=123456 POST请求通常要设置Content-Type表示Body类型，Content-Length表示Body的长度，这样服务器就可以请求的Header和Body做出正确的响应。 此外，GET请求的参数必须附加在URL上，并以URLEncode方式编码，例如：http://www.example.com/?a=1&amp;b=K%26R，参数分别是a=1和b=K&amp;R。因为URL的长度限制，GET请求的参数不能太多，而POST请求的参数就没有长度限制，因为POST请求的参数必须放到Body中。并且POST请求的参数不一定是URL编码，可以按任意格式编码，只需要在Content-Type中正确设置即可。常见的发送JSON的POST请求如下： 12345POST /login HTTP/1.1Content-Type: application/jsonContent-Length: 38{\"username\":\"bob\",\"password\":\"123456\"} HTTP响应也是由Header和Body两部分组成，一个典型的HTTP响应如下： 12345678HTTP/1.1 200 OKContent-Type: text/htmlContent-Length: 133251&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello&lt;/h1&gt;... 响应的第一行总是HTTP版本 响应代码 响应说明，例如，HTTP/1.1 200 OK表示版本是HTTP/1.1，响应代码是200，响应说明是OK。客户端只依赖响应代码判断HTTP响应是否成功。HTTP有固定的响应代码： 1xx：表示一个提示性响应，例如101表示将切换协议，常见于WebSocket连接； 2xx：表示一个成功的响应，例如200表示成功，206表示只发送了部分内容； 3xx：表示一个重定向的响应，例如301表示永久重定向，303表示客户端应该按指定路径重新发送请求； 4xx：表示一个因为客户端问题导致的错误响应，例如400表示因为Content-Type等各种原因导致的无效请求，404表示指定的路径不存在； 5xx：表示一个因为服务器问题导致的错误响应，例如500表示服务器内部故障，503表示服务器暂时无法响应。 当浏览器收到第一个HTTP响应后，它解析HTML后，又会发送一系列HTTP请求，例如，GET /logo.jpg HTTP/1.1请求一个图片，服务器响应图片请求后，会直接把二进制内容的图片发送给浏览器： 12345HTTP/1.1 200 OKContent-Type: image/jpegContent-Length: 18391????JFIFHH??XExifMM?i&amp;??X?...(二进制的JPEG图片) 因此，服务器总是被动地接收客户端的一个HTTP请求，然后响应它。客户端则根据需要发送若干个HTTP请求。 对于最早期的HTTP/1.0协议，每次发送一个HTTP请求，客户端都需要先创建一个新的TCP连接，然后，收到服务器响应后，关闭这个TCP连接。由于建立TCP连接就比较耗时，因此，为了提高效率，HTTP/1.1协议允许在一个TCP连接中反复发送-响应，这样就能大大提高效率。 因为HTTP协议是一个请求-响应协议，客户端在发送了一个HTTP请求后，必须等待服务器响应后，才能发送下一个请求，这样一来，如果某个响应太慢，它就会堵住后面的请求。 所以，为了进一步提速，HTTP/2.0允许客户端在没有收到响应的时候，发送多个HTTP请求，服务器返回响应的时候，不一定按顺序返回，只要双方能识别出哪个响应对应哪个请求，就可以做到并行发送和接收。 HTTP编程既然HTTP涉及到客户端和服务器端，和TCP类似，我们也需要针对客户端编程和针对服务器端编程。 本节我们不讨论服务器端的HTTP编程，因为服务器端的HTTP编程本质上就是编写Web服务器，这是一个非常复杂的体系，也是JavaEE开发的核心内容，我们在后面的章节再仔细研究。 本节我们只讨论作为客户端的HTTP编程。 因为浏览器也是一种HTTP客户端，所以，客户端的HTTP编程，它的行为本质上和浏览器是一样的，即发送一个HTTP请求，接收服务器响应后，获得响应内容。只不过浏览器进一步把响应内容解析后渲染并展示给了用户，而我们使用Java进行HTTP客户端编程仅限于获得响应内容。 我们来看一下Java如何使用HTTP客户端编程。 Java标准库提供了基于HTTP的包，但是要注意，早期的JDK版本是通过HttpURLConnection访问HTTP。 上述代码编写比较繁琐，并且需要手动处理InputStream，所以用起来很麻烦。 从Java 11开始，引入了新的HttpClient，它使用链式调用的API，能大大简化HTTP的处理。 我们来看一下如何使用新版的HttpClient。首先需要创建一个全局HttpClient实例，因为HttpClient内部使用线程池优化多个HTTP连接，可以复用： 1static HttpClient httpClient = HttpClient.newBuilder().build(); 使用GET请求获取文本内容代码如下： 12345678910111213141516171819202122232425262728import java.net.URI;import java.net.http.*;import java.net.http.HttpClient.Version;import java.time.Duration;import java.util.*;public class Main { // 全局HttpClient: static HttpClient httpClient = HttpClient.newBuilder().build(); public static void main(String[] args) throws Exception { String url = \"https://www.sina.com.cn/\"; HttpRequest request = HttpRequest.newBuilder(new URI(url)) // 设置Header: .header(\"User-Agent\", \"Java HttpClient\").header(\"Accept\", \"*/*\") // 设置超时: .timeout(Duration.ofSeconds(5)) // 设置版本: .version(Version.HTTP_2).build(); HttpResponse&lt;String&gt; response = httpClient.send(request, HttpResponse.BodyHandlers.ofString()); // HTTP允许重复的Header，因此一个Header可对应多个Value: Map&lt;String, List&lt;String&gt;&gt; headers = response.headers().map(); for (String header : headers.keySet()) { System.out.println(header + \": \" + headers.get(header).get(0)); } System.out.println(response.body().substring(0, 1024) + \"...\"); }} 如果我们要获取图片这样的二进制内容，只需要把HttpResponse.BodyHandlers.ofString()换成HttpResponse.BodyHandlers.ofByteArray()，就可以获得一个HttpResponse&lt;byte[]&gt;对象。如果响应的内容很大，不希望一次性全部加载到内存，可以使用HttpResponse.BodyHandlers.ofInputStream()获取一个InputStream流。 要使用POST请求，我们要准备好发送的Body数据并正确设置Content-Type： 1234567891011121314String url = \"http://www.example.com/login\";String body = \"username=bob&amp;password=123456\";HttpRequest request = HttpRequest.newBuilder(new URI(url)) // 设置Header: .header(\"Accept\", \"*/*\") .header(\"Content-Type\", \"application/x-www-form-urlencoded\") // 设置超时: .timeout(Duration.ofSeconds(5)) // 设置版本: .version(Version.HTTP_2) // 使用POST并设置Body: .POST(BodyPublishers.ofString(body, StandardCharsets.UTF_8)).build();HttpResponse&lt;String&gt; response = httpClient.send(request, HttpResponse.BodyHandlers.ofString());String s = response.body(); 可见发送POST数据也十分简单。 RMI远程调用Java的RMI远程调用是指，一个JVM中的代码可以通过网络实现远程调用另一个JVM中的某个方法。RMI是Remote Method Invocation的缩写。提供服务的一方我们称为服务器，而实现远程调用的一方我们称为客户端。 我们先来实现一个最简单的RMI：服务器会提供一个WorldClock服务，允许客户端获取指定时区的时间，即允许客户端调用下面的方法： 1LocalDateTime getLocalDateTime(String zoneId); 要实现RMI，服务器和客户端必须共享同一个接口。我们定义一个WorldClock接口，代码如下： 123public interface WorldClock extends Remote { LocalDateTime getLocalDateTime(String zoneId) throws RemoteException;} Java的RMI规定此接口必须派生自java.rmi.Remote，并在每个方法声明抛出RemoteException。 下一步是编写服务器的实现类，因为客户端请求的调用方法getLocalDateTime()最终会通过这个实现类返回结果。实现类WorldClockService代码如下： 123456public class WorldClockService implements WorldClock { @Override public LocalDateTime getLocalDateTime(String zoneId) throws RemoteException { return LocalDateTime.now(ZoneId.of(zoneId)).withNano(0); }} 现在，服务器端的服务相关代码就编写完毕。我们需要通过Java RMI提供的一系列底层支持接口，把上面编写的服务以RMI的形式暴露在网络上，客户端才能调用： 12345678910111213public class Server { public static void main(String[] args) throws RemoteException { System.out.println(\"create World clock remote service...\"); // 实例化一个WorldClock: WorldClock worldClock = new WorldClockService(); // 将此服务转换为远程服务接口: WorldClock skeleton = (WorldClock) UnicastRemoteObject.exportObject(worldClock, 0); // 将RMI服务注册到1099端口: Registry registry = LocateRegistry.createRegistry(1099); // 注册此服务，服务名为\"WorldClock\": registry.rebind(\"WorldClock\", skeleton); }} 上述代码主要目的是通过RMI提供的相关类，将我们自己的WorldClock实例注册到RMI服务上。RMI的默认端口是1099，最后一步注册服务时通过rebind()指定服务名称为\"WorldClock\"。 下一步我们就可以编写客户端代码。RMI要求服务器和客户端共享同一个接口，因此我们要把WorldClock.java这个接口文件复制到客户端，然后在客户端实现RMI调用： 123456789101112public class Client { public static void main(String[] args) throws RemoteException, NotBoundException { // 连接到服务器localhost，端口1099: Registry registry = LocateRegistry.getRegistry(\"localhost\", 1099); // 查找名称为\"WorldClock\"的服务并强制转型为WorldClock接口: WorldClock worldClock = (WorldClock) registry.lookup(\"WorldClock\"); // 正常调用接口方法: LocalDateTime now = worldClock.getLocalDateTime(\"Asia/Shanghai\"); // 打印调用结果: System.out.println(now); }} 先运行服务器，再运行客户端。从运行结果可知，因为客户端只有接口，并没有实现类，因此，客户端获得的接口方法返回值实际上是通过网络从服务器端获取的。整个过程实际上非常简单，对客户端来说，客户端持有的WorldClock接口实际上对应了一个“实现类”，它是由Registry内部动态生成的，并负责把方法调用通过网络传递到服务器端。而服务器端接收网络调用的服务并不是我们自己编写的WorldClockService，而是Registry自动生成的代码。我们把客户端的“实现类”称为stub，而服务器端的网络服务类称为skeleton，它会真正调用服务器端的WorldClockService，获取结果，然后把结果通过网络传递给客户端。整个过程由RMI底层负责实现序列化和反序列化。 Java的RMI严重依赖序列化和反序列化，而这种情况下可能会造成严重的安全漏洞，因为Java的序列化和反序列化不但涉及到数据，还涉及到二进制的字节码，即使使用白名单机制也很难保证100%排除恶意构造的字节码。因此，使用RMI时，双方必须是内网互相信任的机器，不要把1099端口暴露在公网上作为对外服务。 此外，Java的RMI调用机制决定了双方必须是Java程序，其他语言很难调用Java的RMI。如果要使用不同语言进行RPC调用，可以选择更通用的协议，例如gRPC。","link":"/Study/Java/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"title":"集成第三方组件","text":"Spring框架不仅提供了标准的IoC容器、AOP支持、数据库支持以及WebMVC等标准功能，还可以非常方便地集成许多常用的第三方组件： 可以集成JavaMail发送邮件 可以集成JMS消息服务 可以集成Quartz实现定时任务 可以集成Redis等服务 本章我们介绍如何在Spring中简单快捷地集成这些第三方组件。 集成JavaMail在Spring中可以集成JavaMail。在服务器端，我们主要以发送邮件为主，例如在注册成功、登录时、购物付款后通知用户，基本上不会遇到接收用户邮件的情况，所以本节我们只讨论如何在Spring发送邮件。 在Spring中，发送邮件最终也是需要JavaMail，Spring只对JavaMail做了一点简单封装。为了在Spring中集成JavaMail，我们在pom.xml中添加Web相关依赖以及如下依赖： org.springframework:spring-context-support:5.2.0.RELEASE javax.mail:javax.mail-api:1.6.2 com.sun.mail:javax.mail:1.6.2 我们希望用户在注册成功后能收到注册邮件，为此，我们先定义一个JavaMailSender的Bean： 12345678910111213141516171819202122232425262728@BeanJavaMailSender createJavaMailSender( // smtp.properties: @Value(\"${smtp.host}\") String host, @Value(\"${smtp.port}\") int port, @Value(\"${smtp.auth}\") String auth, @Value(\"${smtp.username}\") String username, @Value(\"${smtp.password}\") String password, @Value(\"${smtp.debug:true}\") String debug){ var mailSender = new JavaMailSenderImpl(); mailSender.setHost(host); mailSender.setPort(port); mailSender.setUsername(username); mailSender.setPassword(password); Properties props = mailSender.getJavaMailProperties(); props.put(\"mail.transport.protocol\", \"smtp\"); props.put(\"mail.smtp.auth\", auth); if (port == 587) { props.put(\"mail.smtp.starttls.enable\", \"true\"); } if (port == 465) { props.put(\"mail.smtp.socketFactory.port\", \"465\"); props.put(\"mail.smtp.socketFactory.class\", \"javax.net.ssl.SSLSocketFactory\"); } props.put(\"mail.debug\", debug); return mailSender;} 这个JavaMailSender接口的实现类是JavaMainlSenderImpl，初始化时，传入的参数与JavaMail完全一致。另外注意到需要注入的属性是从smtp.properties中读取的，因此，AppConfig导入的就不止一个.properties文件，可以导入多个： 12345678@Configuration@ComponentScan@EnableWebMvc@EnableTransactionManagement@PropertySource({ \"classpath:/jdbc.properties\", \"classpath:/smtp.properties\" })public class AppConfig { ...} 下一步是封装一个MailService，并定义sendRegistrationMail()方法： 1234567891011121314151617181920212223@Componentpublic class MailService { @Value(\"${smtp.from}\") String from; @Autowired JavaMailSender mailSender; public void sendRegistrationMail(User user) { try { MimeMessage mimeMessage = mailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, \"utf-8\"); helper.setFrom(from); helper.setTo(user.getEmail()); helper.setSubject(\"Welcome to Java course!\"); String html = String.format(\"&lt;p&gt;Hi, %s,&lt;/p&gt;&lt;p&gt;Welcome to Java course!&lt;/p&gt;&lt;p&gt;Sent at %s&lt;/p&gt;\", user.getName(), LocalDateTime.now()); helper.setText(html, true); mailSender.send(mimeMessage); } catch (MessagingException e) { throw new RuntimeException(e); } }} 观察上述代码，MimeMessage是JavaMail的邮件对象，而MimeMessageHelper是Spring提供的用于简化设置MimeMessage的类，比如我们设置HTML邮件就可以直接调用setText(String text, boolean html)，而不必再调用比较繁琐的JavaMail接口方法。最后一步，调用JavaMailSender.send()方法把邮件发送出去。 在MVC的某个Controller某个方法中，当用户注册成功后，我们就启动一个新线程来异步来发送邮件： 123456User user = userService.register(email, password, name);logger.info(\"user registered: {}\", user.getEmail());// send registration mail:new Thread(() -&gt; { mailService.sendRegistrationMail(user);}).start(); 因为发送邮件是一种耗时的任务，从几秒到几分钟不等，因此，异步发送是保证页面能快速显示的必要措施。这里我们新起了一个线程，但实际上还有更优化的方法，我们下一节讨论。 集成JMSJMS即Java Message Service，是JavaEE的消息服务接口，JMS主要有两个版本1.1和2.0，2.0相比主要是简化了收发消息的代码。 所谓消息服务，就是两个进程之间，通过消息服务器传递消息。使用消息服务，而不是直接调用对方的API的好处是： 双方各自无需知晓对方的存在，消息可以异步处理，因为消息服务器会在Consumer离线的时候自动缓存消息 如果Producer发送的消息频率高于Consumer的处理能力，消息可以积压在消息服务器，不至于压垮Consumer 通过一个消息服务器，可以连接多个Producer和多个Consumer 因为消息服务在各类应用程序中非常有用，所以JavaEE专门定义了JMS规范。注意到JMS是一组接口定义，如果我们要使用JMS，还需要选择一个具体的JMS产品。常用的JMS服务器有开源的ActiveMQ，商业服务器如WebLogic、WebSphere等也内置了JMS支持。这里我们选择开源的ActiveMQ作为JMS服务器，在开发JMS之前，我们先安装ActiveMQ。 现在问题来了：从官网下载ActiveMQ时，蹦出一个页面，让我们选择ActiveMQ Classic或者ActiveMQ Artemis，这两个是什么关系，又有什么区别？ 实际上ActiveMQ Classic原来就叫ActiveMQ，是Apache开发的基于JMS 1.1的消息服务器，目前稳定版本号是5.x，而ActiveMQ Artemis是由RedHat捐赠的HornetQ服务器代码的基础上开发的，目前稳定版本号是2.x。和ActiveMQ Classic相比，Artemis版的代码与Classic完全不同，并且，它支持JMS 2.0，使用基于Netty的异步IO，大大提升了性能。此外，Artemis不仅提供了JMS接口，它还提供了AMQP接口，STOMP接口和物联网使用的MQTT接口。选择Artemis，相当于一鱼四吃。 所以，我们这里直接选择ActiveMQ Artemis。从官网下载最新的2.x版本，解压后设置环境变量ARTEMIS_HOME，指向Artemis根目录，例如C:\\Apps\\artemis，然后，把ARTEMIS_HOME/bin加入PATH环境变量： Windows下添加%ARTEMIS_HOME%\\bin到Path路径 Mac和Linux下添加$ARTEMIS_HOME/bin到PATH路径 Artemis有个很好的设计，就是它把程序和数据完全分离了。我们解压后的ARTEMIS_HOME目录是程序目录，要启动一个Artemis服务，还需要创建一个数据目录。我们把数据目录直接设定在项目spring-integration-jms的jms-data目录下。执行命令artemis create jms-data。 在创建过程中，会要求用户输入连接用户和口令，这里我们设定admin和password，以及是否允许匿名访问，选择N。此数据目录jms-data不仅包含消息数据、日志，还自动创建了两个启动服务器的命令bin/artemis和bin/artemis-service，前者在前台启动运行，按Ctrl+C结束，后者会一直在后台运行。 我们把目录切换到jms-data/bin，直接运行artemis run即可启动Artemis服务。启动成功后，Artemis提示可以通过URLhttp://localhost:8161/console访问管理后台，注意不要关闭命令行窗口。 在编写JMS代码前，首先得理解JMS的消息模型。JMS把生产消息的一方成为Producer，处理消息的一方称为Consumer。有两种类型的消息通道，一种是Queue： 123┌────────┐ ┌────────┐ ┌────────┐│Producer│───&gt;│ Queue │───&gt;│Consumer│└────────┘ └────────┘ └────────┘ 一种是Topic： 123456789 ┌────────┐ ┌─&gt;│Consumer│ │ └────────┘┌────────┐ ┌────────┐ │ ┌────────┐│Producer│───&gt;│ Topic │─┼─&gt;│Consumer│└────────┘ └────────┘ │ └────────┘ │ ┌────────┐ └─&gt;│Consumer│ └────────┘ 它们的区别在于，Queue是一对一的通道，如果Consumer离线无法处理消息时，Queue会把消息存起来，等Consumer连接的时候发给它。设定了持久化机制的Queue不会丢失消息。如果有多个Consumer接入同一个Queue，那么它们等效于以集群的方式处理消息。例如，发送方发送的消息是A，B，C，D，E，F，两个Consumer可能分别收到A，C，E和B，D，F，即每个消息只会交给其中一个Consumer处理。 Topic则是一种一对多的通道。一个Producer发送的消息会被多个Consumer同时接收到，即每个Consumer会收到一份完整的信息流。那么如果一个Consumer暂时离线，一段时间后又重新上线，那么在离线期间产生的消息还能不能收到？这取决于消息服务器对Topic类型消息的持久化机制，如果消息服务器不存储Topic消息，那么离线的Consumer会丢失部分离线时期的消息；如果消息服务器存储了Topic消息，那么离线的Consumer可以收到自上次离线后产生的所有消息。JMS规范通过Consumer指定一个持久化订阅可以在上线后收取所有离线期间的消息，如果指定的是非持久化订阅，那么离线期间的消息会全部丢失。 细心的朋友可能发现了，如果一个Topic的消息全部被持久化了，并且只有一个Consumer，那么它和Queue其实是一样的。实际上，很多消息服务器内部只有Topic类型的消息架构，Queue可以通过Topic“模拟”出来。 无论是Queue还是Topic，对Producer没什么要求。多个Producer也可以写入同一个Queue或Topic，此时消息服务器内部会自动排序确保消息总是有序的。 以上是消息服务的基本模型。具体到某个消息服务器时，Producer和Consumer通常是通过TCP协议连接消息服务器的。编写JMS程序时，又会遇到ConnectionFactory、Connection、Session等概念，其实这和JDBC连接是类似的： ConnectionFactory：代表一个到消息服务器的连接池，类似JDBC的DataSource Connection：代表一个到消息服务器的连接，类似JDBC的Connection Session：代表一个经过认证后的连接会话 Message：代表一个消息对象 在JMS 1.1中，发送消息的典型代码如下： 12345678910111213141516171819202122try { Connection connection = null; try { // 创建连接: connection = connectionFactory.createConnection(); // 创建会话: Session session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE); // 创建一个Producer并关联到某个Queue: MessageProducer messageProducer = session.createProducer(queue); // 创建一个文本消息: TextMessage textMessage = session.createTextMessage(text); // 发送消息: messageProducer.send(textMessage); } finally { // 关闭连接: if (connection != null) { connection.close(); } }} catch (JMSException ex) { // 处理JMS异常} JMS 2.0改进了一些API接口，其中，JMSContext实现了AutoCloseable接口，可以使用try(resource)语法，代码更简单。发送消息变得更简单： 123try (JMSContext context = connectionFactory.createContext()) { context.createProducer().send(queue, text);} 有了以上预备知识，我们就可以开发开发JMS应用了。 首先，在pom.xml中添加依赖： org.springframework:spring-jms:5.2.0.RELEASE javax.jms:javax.jms-api:2.0.1 org.apache.activemq:artemis-jms-client:2.13.0 io.netty:netty-handler-proxy:4.1.45.Final 在AppConfig上添加@EnableJms让Spring自动扫描JMS相关的Bean，并加载JMS配置文件jms.properties： 123456789@Configuration@ComponentScan@EnableWebMvc@EnableJms // 启用JMS@EnableTransactionManagement@PropertySource({ \"classpath:/jdbc.properties\", \"classpath:/jms.properties\" })public class AppConfig { ...} 首先创建的Bean是ConnectionFactory，即连接消息服务器的连接池： 12345678@BeanConnectionFactory createJMSConnectionFactory( @Value(\"${jms.uri:tcp://localhost:61616}\") String uri, @Value(\"${jms.username:admin}\") String username, @Value(\"${jms.password:password}\") String password){ return new ActiveMQJMSConnectionFactory(uri, username, password);} 因为我们使用的消息服务器是ActiveMQ Artemis，所以ConnectionFactory的实现类就是消息服务器提供的ActiveMQJMSConnectionFactory，它需要的参数均由配置文件读取后传入，并设置默认值。 我们再创建一个JmsTemplate，它是Spring提供的一个工具类，和JdbcTemplate类似，可以简化发送消息的代码： 1234@BeanJmsTemplate createJmsTemplate(@Autowired ConnectionFactory connectionFactory) { return new JmsTemplate(connectionFactory);} 下一步要创建的是JmsListenerContainerFactory， 123456@Bean(\"jmsListenerContainerFactory\")DefaultJmsListenerContainerFactory createJmsListenerContainerFactory(@Autowired ConnectionFactory connectionFactory) { var factory = new DefaultJmsListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); return factory;} 除了必须指定Bean的名称是jmsListenerContainerFactory外，这个Bean的作用是处理和Consumer相关的Bean。我们先跳过它的原理，继续编写MessagingService来发送消息： 1234567891011121314@Componentpublic class MessagingService { @Autowired ObjectMapper objectMapper; @Autowired JmsTemplate jmsTemplate; public void sendMailMessage(MailMessage msg) throws Exception { String text = objectMapper.writeValueAsString(msg); jmsTemplate.send(\"jms/queue/mail\", new MessageCreator() { public Message createMessage(Session session) throws JMSException { return session.createTextMessage(text); } }); }} JMS的消息类型支持以下几种： TextMessage：文本消息 BytesMessage：二进制消息 MapMessage：包含多个Key-Value对的消息 ObjectMessage：直接序列化Java对象的消息 StreamMessage：一个包含基本类型序列的消息 最常用的是发送基于JSON的文本消息，上述代码通过JmsTemplate创建一个TextMessage并发送到名称为jms/queue/mail的Queue。 注意：Artemis消息服务器默认配置下会自动创建Queue，因此不必手动创建一个名为jms/queue/mail的Queue，但不是所有的消息服务器都会自动创建Queue，生产环境的消息服务器通常会关闭自动创建功能，需要手动创建Queue。 注意到MailMessage是我们自定义的一个JavaBean，真正的JMS消息是创建的TextMessage，它的内容是JSON。 当用户注册成功后，我们就调用MessagingService.sendMailMessage()发送一条JMS消息，代码十分简单。 下面我们详细讨论如何处理消息，即编写Consumer。从理论上讲，可以创建另一个Java进程来处理消息，但对于我们这个简单的Web程序来说没有必要，直接在同一个Web应用中接收并处理消息即可。 处理消息的核心代码是编写一个Bean，并在处理方法上标注@JmsListener： 12345678910111213141516171819@Componentpublic class MailMessageListener { final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired ObjectMapper objectMapper; @Autowired MailService mailService; @JmsListener(destination = \"jms/queue/mail\", concurrency = \"10\") public void onMailMessageReceived(Message message) throws Exception { logger.info(\"received message: \" + message); if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); MailMessage mm = objectMapper.readValue(text, MailMessage.class); mailService.sendRegistrationMail(mm); } else { logger.error(\"unable to process non-text message!\"); } }} 注意到@JmsListener指定了Queue的名称，因此，凡是发送到此Queue的消息都会被这个onMessageReceived()方法处理，方法参数是JMS的Message接口，我们通过强制转型为TextMessage并提取JSON，反序列化后获得自定义的JavaBean，也就获得了发送邮件所需要的信息。 Spring处理JMS消息的流程是什么？ 如果我们直接调用JMS的API来处理消息，那么编写的代码大致如下： 1234567891011121314// 创建JMS连接:Connection connection = connectionFactory.createConnection();// 创建会话:Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);// 创建一个Consumer:MessageConsumer consumer = session.createConsumer(queue);// 为Consumer指定一个消息处理器:consumer.setMessageListener(new MessageListener() { public void onMessage(Message message) { // 在此处理消息... }});// 启动接收消息的循环:connection.start(); 我们自己编写的MailMessageListener.onMailMessageReceived()相当于消息处理器： 12345consumer.setMessageListener(new MessageListener() { public void onMessage(Message message) { mailMessageListener.onMailMessageReceived(message); }}); 所以，Spring根据AppConfig的注解@EnableJms自动扫描带有@JmsListener的Bean方法，并为其创建一个MessageListener把它包装起来。 注意到前面我们还创建了一个JmsListenerContainerFactory的Bean，它的作用就是为每个MessageListener创建MessageConsumer并启动消息接收循环。 再注意到@JmsListener还有一个concurrency参数，10表示可以最多同时并发处理10个消息，5-10表示并发处理的线程可以在5~10之间调整。 因此，Spring在通过MessageListener接收到消息后，并不是直接调用mailMessageListener.onMailMessageReceived()，而是用线程池调用，因此，要时刻牢记，onMailMessageReceived()方法可能被多线程并发执行，一定要保证线程安全。 我们总结一下Spring接收消息的步骤： 通过JmsListenerContainerFactory配合@EnableJms扫描所有@JmsListener方法，自动创建MessageConsumer、MessageListener以及线程池，启动消息循环接收处理消息，最终由我们自己编写的@JmsListener方法处理消息，可能会由多线程同时并发处理。 要验证消息发送和处理，我们注册一个新用户，可以看到如下日志输出： 12342020-06-02 08:04:27 INFO c.i.learnjava.web.UserController - user registered: bob@example.com2020-06-02 08:04:27 INFO c.i.l.service.MailMessageListener - received message: ActiveMQMessage[ID:9fc5...]:PERSISTENT/ClientMessageImpl[messageID=983, durable=true, address=jms/queue/mail, ...]]2020-06-02 08:04:27 INFO c.i.learnjava.service.MailService - [send mail] sending registration mail to bob@example.com...2020-06-02 08:04:30 INFO c.i.learnjava.service.MailService - [send mail] registration mail was sent to bob@example.com. 可见，消息被成功发送到Artemis，然后在很短的时间内被接收处理了。 使用消息服务对发送Email进行改造的好处是，发送Email的能力通常是有限的，通过JMS消息服务，如果短时间内需要给大量用户发送Email，可以先把消息堆积在JMS服务器上慢慢发送，对于批量发送邮件、短信等尤其有用。 小结JMS是Java的消息服务，可以通过JMS服务器实现消息的异步处理。消息服务主要解决Producer和Consumer生产和处理速度不匹配的问题。 使用Scheduler在许多应用程序中，经常需要执行定时任务。例如，每天或每月给用户发送账户汇总报表，定期检查并发送系统状态报告等等。Java本身就提供了定时执行任务的功能，在Spring中，使用定时任务更简单，不需要手写线程池相关代码，只需要两个注解。 我们还是以实际代码为例，建立工程spring-integration-schedule，无需额外的依赖，我们可以直接在AppConfig中加上@EnableScheduling就开启了定时任务的支持： 123456789@Configuration@ComponentScan@EnableWebMvc@EnableScheduling // 开启定时任务@EnableTransactionManagement@PropertySource({ \"classpath:/jdbc.properties\", \"classpath:/task.properties\" })public class AppConfig { ...} 然后，我们可以直接在一个Bean中编写一个public void无参数方法，然后加上@Scheduled注解： 123456789@Componentpublic class TaskService { final Logger logger = LoggerFactory.getLogger(getClass()); @Scheduled(initialDelay = 60_000, fixedRate = 60_000) public void checkSystemStatusEveryMinute() { logger.info(\"Start check system status...\"); }} 上述注解指定了启动延时60s，并以60s为间隔执行任务。直接运行应用程序，就可以在控制台看到定时任务打印的日志。如果没有看到定时任务的日志，需要检查： 是否忘记了在AppConfig中标注@EnableScheduling 是否忘记了在定时任务的方法所在的class标注@Component 除了可以使用fixedRate外，还可以使用fixedDelay。FixedRate是指任务总是以固定的时间间隔触发，不管任务执行多长时间，而FixedDelay是指上一次任务执行完毕后，等待固定的时间间隔，再执行下一次任务。 有的童鞋在实际开发中会遇到一个问题，因为Java的注解全部是常量，写死了fixedDelay=30000，如果根据实际情况要改成60秒怎么办，只能重新编译？ 我们可以把定时任务的配置放到配置文件中，例如task.properties： 1task.checkDiskSpace=30000 这样就可以随时修改配置文件而无需动代码。但是在代码中，我们需要用fixedDelayString取代fixedDelay： 123456789@Componentpublic class TaskService { ... @Scheduled(initialDelay = 30_000, fixedDelayString = \"${task.checkDiskSpace:30000}\") public void checkDiskSpaceEveryMinute() { logger.info(\"Start check disk space...\"); }} 注意到上述代码的注解参数fixedDelayString是一个属性占位符，并配有默认值30000，Spring在处理@Scheduled注解时，如果遇到String，会根据占位符自动用配置项替换，这样就可以灵活地修改定时任务的配置。 此外，fixedDelayString还可以使用更易读的Duration，例如： 1@Scheduled(initialDelay = 30_000, fixedDelayString = \"${task.checkDiskSpace:PT2M30S}\") 以字符串PT2M30S表示的Duration就是2分30秒，请参考LocalDateTime一节的Duration相关部分。多个@Scheduled方法完全可以放到一个Bean中，这样便于统一管理各类定时任务。 使用Cron任务还有一类定时任务，它不是简单地重复，而是按时间触发，我们把这类任务称为定时任务，比如： 每天凌晨2:15执行报表任务 每个工作日12:00执行特定任务 Cron源自Unix/Linux系统自带的crond守护进程，以一个简洁的表达式定义任务触发时间。在Spring中，也可以使用Cron表达式来执行Cron任务。Cron表达式详解指路。 在Spring中，我们定义一个每天凌晨2:15执行的任务： 123456789@Componentpublic class TaskService { ... @Scheduled(cron = \"${task.report:0 15 2 * * *}\") public void cronDailyReport() { logger.info(\"Start daily report task...\"); }} Cron任务同样可以使用属性占位符，这样修改起来更加方便。实际上它可以取代fixedRate类型的定时任务。 集成Quartz在Spring中使用定时任务和Cron任务都非常简单，但是要注意到，这些任务的调度都是在每个JVM进程中的。如果本机启动两个进程，或者多台机器上启动应用，这些进程的定时任务和Cron任务都是独立运行互不影响的。 如果一些定时任务要以集群的方式运行，例如每天23:00检查任务，只需要集群中一台运行即可，这时可以考虑使用Quartz。Quartz可以配置一个JDBC数据源，以便存储所有的任务调度计划以及任务执行状态。也可以使用内存来调度任务，但这样配置就和使用Spring的调度没啥区别了，额外集成Quartz的意义就不大。 Quartz的JDBC配置比较复杂，Spring对其也有一定的支持。要详细了解Quartz的集成，请参考Spring的文档。思考：如果不使用Quartz的JDBC配置，多个Spring应用同时运行时，如何保证某个任务只在某一台机器执行？ 集成JMX什么是JMX？JMX是Java Management Extensions，它是一个Java平台的管理和监控接口。为什么要搞JMX？因为在所有应用程序中，对运行中的程序进行监控是非常重要的，Java应用程序也不例外。我们肯定希望知道Java应用程序当前的状态，例如，占用了多少内存，分配了多少内存，当前有多少活动线程，有多少休眠线程等。 为了标准化管理和监控，Java平台使用JMX作为管理和监控的标准接口，任何程序，只要按JMX规范访问这个接口，就可以获取所有管理和监控信息。实际上，常用的运维监控如Zabbix、Nagios等工具对JVM本身的监控都是通过JMX获取信息。 因为JMX是一个标准接口，不但可以用于管理JVM，还可以管理应用程序自身，下图是JMX的架构： 1234567891011121314 ┌─────────┐ ┌─────────┐ │jconsole │ │ Web │ └─────────┘ └─────────┘ │ │┌ ─ ─ ─ ─│─ ─ ─ ─ ─ ─ ┼ ─ ─ ─ ─ JVM ▼ ▼ ││ ┌─────────┐ ┌─────────┐ ┌─┤Connector├──┤ Adaptor ├─┐ ││ │ └─────────┘ └─────────┘ │ │ MBeanServer │ ││ │ ┌──────┐┌──────┐┌──────┐ │ └─┤MBean1├┤MBean2├┤MBean3├─┘ ││ └──────┘└──────┘└──────┘ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ JMX把所有被管理的资源称为MBean（Managed Bean），这些MBean全部由MBeanServer管理，如果要访问MBean，可以通过MBeanServer对外提供的访问接口，例如通过RMI或HTTP访问。注意到使用JMX不需要安装任何额外组件，也不需要第三方库，因为MBeanServer已经内置在JavaSE标准库中了。JavaSE还提供了一个jconsole程序，用于通过RMI连接到MBeanServer，这样就可以管理整个Java进程。 除了JVM会把自身的各种资源以MBean注册到JMX，我们自己的配置、监控信息也可以作为MBean注册到JMX，这样，管理程序就可以直接控制我们暴露的MBean。因此，应用程序使用JMX，只需要两步： 编写MBean提供管理接口和监控数据 注册MBean 在Spring应用程序中，使用JMX只需要一步： 编写MBean提供管理接口和监控数据 第二步注册的过程由Spring自动完成。我们以实际工程为例，首先在AppConfig中加上@EnableMBeanExport注解，告诉Spring自动注册MBean： 123456789@Configuration@ComponentScan@EnableWebMvc@EnableMBeanExport // 自动注册MBean@EnableTransactionManagement@PropertySource({ \"classpath:/jdbc.properties\" })public class AppConfig { ...} 剩下的全部工作就是编写MBean。例如，假设我们希望给应用程序添加一个IP黑名单功能，在黑名单中的IP禁止访问，传统的做法是定义一个配置文件，启动的时候读取。如果要修改黑名单怎么办？修改配置文件，然后重启应用程序。但是每次都重启应用程序实在太麻烦了，能不能不重启应用程序？答案是可以的，可以写一个定时读取配置文件的功能，检测到文件改动时自动重新读取。 上述需求的本质是在应用程序运行期间对参数、配置等进行热更新并要求尽快生效。如果以JMX的方式实现，我们不必自己编写自动重新读取等任何代码，只需要提供一个符合JMX标准的MBean来存储配置即可。还是以IP黑名单功能为例，JMX的MBean通常以MBean结尾，我们遵循标准命名规范，首先编写一个BlacklistMBean： 12345678910111213141516171819public class BlacklistMBean { private Set&lt;String&gt; ips = new HashSet&lt;&gt;(); public String[] getBlacklist() { return ips.toArray(String[]::new); } public void addBlacklist(String ip) { ips.add(ip); } public void removeBlacklist(String ip) { ips.remove(ip); } public boolean shouldBlock(String ip) { return ips.contains(ip); }} 这个MBean没什么特殊的，和普通Java类没有任何区别。 接下来，我们要使用JMX的客户端来实时热更新这个MBean，要给它加上一些注解，让Spring能根据注解自动把相关方法注册到MBeanServer中： 1234567891011121314151617181920212223242526@Component@ManagedResource(objectName = \"sample:name=blacklist\", description = \"Blacklist of IP addresses\")public class BlacklistMBean { private Set&lt;String&gt; ips = new HashSet&lt;&gt;(); @ManagedAttribute(description = \"Get IP addresses in blacklist\") public String[] getBlacklist() { return ips.toArray(String[]::new); } @ManagedOperation @ManagedOperationParameter(name = \"ip\", description = \"Target IP address that will be added to blacklist\") public void addBlacklist(String ip) { ips.add(ip); } @ManagedOperation @ManagedOperationParameter(name = \"ip\", description = \"Target IP address that will be removed from blacklist\") public void removeBlacklist(String ip) { ips.remove(ip); } public boolean shouldBlock(String ip) { return ips.contains(ip); }} 观察上述代码，BlacklistMBean首先是一个标准的Spring管理的Bean。其次，添加了@ManagedResource表示这是一个MBean，将要被注册到JMX。objectName指定了这个MBean的名字，通常以company:name=Xxx来分类MBean。 对于属性，使用@ManagedAttribute注解标注。上述MBean只有get属性，没有set属性，说明是一个只读属性。对于操作，使用@ManagedOperation注解标注。上述MBean定义了两个操作：addBlacklist()和removeBlacklist()，其他方法如shouldBlock()不会被暴露给JMX。 使用MBean和普通Bean是完全一样的。例如，我们在BlacklistInterceptor对IP黑名单进行拦截： 1234567891011121314151617181920212223@Order(1)@Componentpublic class BlacklistInterceptor implements HandlerInterceptor { final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired BlacklistMBean blacklistMBean; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String ip = request.getRemoteAddr(); logger.info(\"check ip address {}...\", ip); // 是否在黑名单中: if (blacklistMBean.shouldBlock(ip)) { logger.warn(\"will block ip {} for it is in blacklist.\", ip); // 发送403错误响应: response.sendError(403); return false; } return true; }} 最后正常启动Web应用程序，不要关闭它，我们打开另一个命令行窗口，输入jconsole启动JavaSE自带的一个JMX客户端程序。 通过jconsole连接到一个Java进程最简单的方法是直接在Local Process中找到正在运行的AppConfig，点击Connect即可连接当前正在运行的Web应用，在jconsole中可直接看到内存、CPU等资源的监控。点击MBean，左侧按分类列出了所有MBean，可以在java.lang查看内存信息。 在sample中看到我们自己的MBean，单击可查看属性blacklist。点击Operations-addBlacklist，可以填入127.0.0.1并点击addBlacklist按钮，相当于jconsole通过JMX接口，调用了我们自己的BlacklistMBean的addBlacklist()方法，传入的参数就是填入的127.0.0.1。再次查看属性blacklist，就可以看到结果更新了。 使用jconsole连接直接通过Local Process连接JVM有个限制，就是jconsole和正在运行的JVM必须在同一台机器。如果要远程连接，首先要打开JMX端口。我们在启动AppConfig时需要传入以下JVM启动参数： -Dcom.sun.management.jmxremote.port=19999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false 第一个参数表示在19999端口监听JMX连接，第二个和第三个参数表示无需验证，不使用SSL连接，在开发测试阶段比较方便，生产环境必须指定验证方式并启用SSL，详细参数可参考Oracle官方文档。这样jconsole可以用ip:19999的远程方式连接JMX，连接后的操作是完全一样的。许多JavaEE服务器如JBoss的管理后台都是通过JMX提供管理接口，并由Web方式访问，对用户更加友好。","link":"/Study/Java/Spring/%E9%9B%86%E6%88%90%E7%AC%AC%E4%B8%89%E6%96%B9%E7%BB%84%E4%BB%B6/"},{"title":"开发Web应用","text":"在Web开发一章，我们学习了JavaEE中Web开发的基础：Servlet，总结来说： Servlet规范定义了几种标准组件：Servlet、JSP、Filter和Listener Servlet的标准组件总是运行在Servlet容器中，如Tomcat、Jetty、WebLogic等 直接使用Servlet进行Web开发好比直接在JDBC上操作数据库，比较繁琐。更好的方法是在Servlet基础上封装MVC框架，基于MVC开发Web应用，大部分时候，不需要接触Servlet API，省时省力。我们已经介绍过了如何编写MVC框架，当然自己写MVC主要是理解原理，要实现一个功能全面的MVC需要大量的工作和广泛的测试。所以，开发Web应用，首先要选择一个优秀的MVC框架。Spring框架虽然可以集成任何Web框架，但是Spring本身开发的Spring MVC已经足够优秀，甚至已经不需要再集成其他MVC框架了。本章我们详细介绍如何基于Spring MVC开发Web应用。 使用Spring MVCServlet容器会为每个Web应用程序自动创建一个唯一的ServletContext实例，这个实例就代表了Web应用程序本身。如果直接使用Spring MVC，我们写出来的代码类似于： 12345678910111213@Controllerpublic class UserController { @GetMapping(\"/register\") public ModelAndView register() { ... } @PostMapping(\"/signin\") public ModelAndView signin(@RequestParam(\"email\") String email, @RequestParam(\"password\") String password) { ... } ...} 但是，Spring提供的是一个IoC容器，所有的Bean，包括Controller，都在Spring IoC容器中被初始化。而Servlet容器由JavaEE服务器提供（如Tomcat），Servlet容器对IoC容器一无所知，它们之间依靠什么进行联系，又以何种顺序初始化？ 在理解上述问题前，我们先把基于Spring MVC开发的项目结构搭起来，这个标准的Maven Web项目结构如下： 123456789101112131415161718192021222324252627282930313233spring-web-mvc├── pom.xml└── src └── main ├── java │ └── com │ └── itranswarp │ └── learnjava │ ├── AppConfig.java │ ├── DatabaseInitializer.java │ ├── entity │ │ └── User.java │ ├── service │ │ └── UserService.java │ └── web │ └── UserController.java ├── resources │ ├── jdbc.properties │ └── logback.xml └── webapp ├── WEB-INF │ ├── templates │ │ ├── _base.html │ │ ├── index.html │ │ ├── profile.html │ │ ├── register.html │ │ └── signin.html │ └── web.xml └── static ├── css │ └── bootstrap.css └── js └── jquery.js 其中，src/main/webapp是标准Web目录，WEB-INF存放web.xml、编译的class、第三方jar，以及不允许浏览器直接访问的View模板和static目录（存放所有的静态文件）。 在src/main/resources目录存放的是Java程序读取的classpath资源文件，除了JDBC的配置文件jdbc.properties外，我们新增了一个logback.xml，这是Logback默认查找的配置文件。 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;Pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;logger name=\"com.itranswarp.learnjava\" level=\"info\" additivity=\"false\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;/logger&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;/root&gt;&lt;/configuration&gt; 上面给出了一个写入到标准输出的Logback配置，可以基于上述配置添加写入到文件的配置。 目录src/main/java就是我们编写Java代码的地方了。 配置Spring MVC和普通Spring配置一样，编写正常的AppConfig后，只需加上@EnableWebMvc注解，就激活了Spring MVC。 12345678@Configuration@ComponentScan@EnableWebMvc // 启用Spring MVC@EnableTransactionManagement@PropertySource(\"classpath:/jdbc.properties\")public class AppConfig { ...} 除了创建DataSource、JdbcTemplate、PlatformTransactionManager外，AppConfig需要额外创建几个用于Spring MVC的Bean： 123456789@BeanWebMvcConfigurer createWebMvcConfigurer() { return new WebMvcConfigurer() { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/static/**\").addResourceLocations(\"/static/\"); } };} WebMvcConfigurer并不是必须的，但我们在这里创建一个默认的WebMvcConfigurer，只覆写addResourceHandlers()，目的是让Spring MVC自动处理静态文件，并且映射路径为/static/**。 另一个必须创建的Bean是ViewResolver，因为Spring MVC允许集成任何模板引擎，使用哪一个模板引擎就实例化一个对应的ViewResolver： 12345678910111213@BeanViewResolver createViewResolver(@Autowired ServletContext servletContext) { PebbleEngine engine = new PebbleEngine.Builder().autoEscaping(true) .cacheActive(false) .loader(new ServletLoader(servletContext)) .extension(new SpringExtension()) .build(); PebbleViewResolver viewResolver = new PebbleViewResolver(); viewResolver.setPrefix(\"/WEB-INF/templates/\"); viewResolver.setSuffix(\"\"); viewResolver.setPebbleEngine(engine); return viewResolver;} ViewResolver通过指定prefix和suffix来确定如何查找View。上述配置使用Pebble引擎，指定模板文件存放在/WEB-INF/templates/目录下。 剩下的Bean都是普通的@Component，但Controller必须被标记为@Controller。 如果是普通的Java应用程序，我们通过main()方法可以很简单的创建一个Spring容器实例： 123public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);} 但现在是Web应用程序，而Web应用程序总是由Servlet容器创建，那么Springo容器应该由谁创建呢，在什么时候创建，Spring容器中的Controller又是如何通过Servlet调用的？ 在Web应用中启动Spring容器有很多种方法，可以通过Listener启动，也可以通过Servlet启动，可以使用XML配置，也可以使用注解配置，这里我们介绍一种最简单的启动Spring容器的方式。 第一步，我们在web.xml中配置Spring MVC提供的DispatcherServlet： 123456789101112131415161718192021222324&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt;org.springframework.web.context.support.AnnotationConfigWebApplicationContext&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;com.itranswarp.learnjava.AppConfig&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;0&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 初始化参数contextClass指定使用注解配置的AnnotationConfigWebApplicationContext，配置文件的位置参数contextConfigLocation指向AppConfig的完整类名，最后把这个Servlet映射到/*，即处理所有URL。 有了这个配置，Servlet容器会首先初始化Spring MVC的DispatcherServlet，在DispatcherServlet启动时，它根据配置AppConfig创建了一个类型是WebApplicationContext的IoC容器，完成所有Bean的初始化，并将容器绑到ServletContext上。 因为DispatcherServlet持有IoC容器，能从IoC容器中获取所有@Controller的Bean，因此，DispatcherServlet接收到所有HTTP请求后，根据Controller方法配置的路径，就可以正确地把请求转发到指定方法，并根据返回的ModelAndView决定如何渲染页面。 最后，我们在AppConfig中通过main()启动嵌入式Tomcat： 123456789101112public static void main(String[] args) throws Exception { Tomcat tomcat = new Tomcat(); tomcat.setPort(Integer.getInteger(\"port\", 8080)); tomcat.getConnector(); Context ctx = tomcat.addWebapp(\"\", new File(\"src/main/webapp\").getAbsolutePath()); WebResourceRoot resources = new StandardRoot(ctx); resources.addPreResources( new DirResourceSet(resources, \"/WEB-INF/classes\", new File(\"target/classes\").getAbsolutePath(), \"/\")); ctx.setResources(resources); tomcat.start(); tomcat.getServer().await();} 上述Web应用程序就是我们使用Spring MVC时的一个最小启动功能集。 编写Controller有了Web应用程序的基本结构，我们的重点就可以放在如何编写Controller上了。Spring MVC对Controller没有固定要求，也不需要实现特定接口。以UserController为例，编写Controller只需要遵循以下要点。 总是标记@Controller，而不是@Component： 1234@Controllerpublic class UserController { ...} 一个方法对应一个HTTP请求路径，用@GetMapping或@PostMapping表示GET或POST请求： 1234567@PostMapping(\"/signin\")public ModelAndView doSignin( @RequestParam(\"email\") String email, @RequestParam(\"password\") String password, HttpSession session) { ...} 需要接收HTTP参数以@RequestParam()标注，可以设置默认值。如果方法参数需要传入HttpServletRequest、HttpServletResponse或者HttpSession，直接添加这个类型的参数即可，Spring MVC会自动按类型传入。 返回的ModelAndView通常包含View的路径和一个Map作为Model，但也可以没有Model，例如： 1return new ModelAndView(\"signin.html\"); // 仅View，没有Model 返回重定向时既可以写new ModelAndView(\"redirect:/signin\")，也可以直接返回String： 1234567public String index() { if (...) { return \"redirect:/signin\"; } else { return \"redirect:/profile\"; }} 如果在方法内部直接操作HttpServletResponse发送响应，返回null表示无需进一步处理： 12345678public ModelAndView download(HttpServletResponse response) { byte[] data = ... response.setContentType(\"application/octet-stream\"); OutputStream output = response.getOutputStream(); output.write(data); output.flush(); return null;} 对URL进行分组，每组对应一个Controller是很好的组织形式，并可以在Controller的class定义出添加URL前缀，例如： 123456789101112131415@Controller@RequestMapping(\"/user\")public class UserController { // 注意实际URL映射是/user/profile @GetMapping(\"/profile\") public ModelAndView profile() { ... } // 注意实际URL映射是/user/changePassword @GetMapping(\"/changePassword\") public ModelAndView changePassword() { ... }} 实际方法的URL映射总是前缀+路径，这种形式还可以有效避免不小心导致的重复URL映射。 可见，Spring MVC帮助我们编写既简单又灵活的Controller实现。 小结使用Spring MVC时，整个Web应用程序按如下顺序启动： 启动Tomcat服务器 Tomcat读取web.xml并初始化DispatcherServlet DispatcherServlet创建IoC容器并自动注册到ServletContext中 启动后，浏览器发送的HTTP请求全部由DispathcerServlet接收，并根据配置转发到指定的Controller的指定方法处理。 使用REST使用Spring MVC开发Web应用程序的主要工作就是编写Controller。在Web应用中，除了需要使用MVC给用户显示页面外，还有一类API接口，我们称之为REST，通常输入输出都是JSON，便于第三方调用或者使用页面JavaScript与之交互。 直接在Controller中处理JSON是可以的，因为Spring MVC的@GetMapping和@PostMapping都支持指定输入和输出的格式。如果我们想接收JSON，输出JSON，可以这样写： 1234567@PostMapping(value = \"/rest\", consumes = \"application/json;charset=UTF-8\", produces = \"application/json;charset=UTF-8\")@ResponseBodypublic String rest(@RequestBody User user) { return \"{\\\"restSupport\\\":true}\";} 对应的Maven功程需要引入Jackson这个依赖。注意到@PostMapping使用consumes声明能接收的类型，使用produces声明输出的类型，并且额外加了@ResponseBody表示返回的String无需额外处理，直接作为输出内容写入HttpServletResponse。输入的JSON则根据注解@RequestBody直接被Spring反序列化为User这个Bean。 直接用Spring的Controller配合一大堆注解写REST太麻烦了，因此，Spring还额外提供了一个@RestController注解。使用@RestController替代@Controller后，每个方法自动变成API接口方法，例如： 12345678910111213141516171819202122232425262728293031@RestController@RequestMapping(\"/api\")public class ApiController { @Autowired UserService userService; @GetMapping(\"/users\") public List&lt;User&gt; users() { return userService.getUsers(); } @GetMapping(\"/users/{id}\") public User user(@PathVariable(\"id\") long id) { return userService.getUserById(id); } @PostMapping(\"/signin\") public Map&lt;String, Object&gt; signin(@RequestBody SignInRequest signinRequest) { try { User user = userService.signin(signinRequest.email, signinRequest.password); return Map.of(\"user\", user); } catch (Exception e) { return Map.of(\"error\", \"SIGNIN_FAILED\", \"message\", e.getMessage()); } } public static class SignInRequest { public String email; public String password; }} 编写REST接口只需要定义@RestController，然后，每个方法都是一个API接口，输入和输出只要能被Jackson序列化或反序列化为JSON。我们用浏览器测试GET请求，可直接显示JSON响应。 使用curl命令可以测试到JSON的输出，User能被正确序列化为JSON，但暴露了password属性，这是我们不愿意的。要避免输出password属性，可以把User复制到另一个UserBean对象，该对象只持有必要的属性，但这样做比较繁琐。另一种简单的方法是直接在User的password属性定义处加上@JsonIgnore表示完全忽略该属性。 12345678910public class User { ... @JsonIgnore public String getPassword() { return password; } ...} 但是这样一来，如果写一个register(User user)方法，那么该方法的User对象也拿不到注册时用户传入的密码了。如果要允许输入password，但不允许输出password，即在JSON序列化和反序列化时，允许写属性，禁用读属性，可以更精细地控制如下： 12345678910public class User { ... @JsonProperty(access = Access.WRITE_ONLY) public String getPassword() { return password; } ...} 同样地，可以使用@JsonProperty(access = Access.READ_ONLY)允许输出，不允许输入。 集成Filter在Servlet规范中，我们还可以使用Filter，如果要在Spring MVC中使用Filter，应该怎么做？ 有同学可能发现了，Servlet默认按非UTF-8编码读取参数，为了修复这一问题，我们可以用一个EndoingFilter，在全局范围类给HttpServletRequest和HttpServletResponse强制设置为UTF-8。可以自己编写一个EncodingFilter，也可以直接使用Spring MVC自带的一个CharacterEncodingFilter。配置Filter时，只需在web.xml中声明即可： 1234567891011121314151617181920&lt;web-app&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; ...&lt;/web-app&gt; 因为这种Filter和我们业务关系不大，注意到CharacterEncodingFilter其实和Spring的IoC容器没有任何关系，两者均不知道互相的存在，所以配置Filter非常简单。 我们再考虑这样一个问题：如果允许用户使用Basic模式进行用户验证，即在HTTP请求中添加头Authorization: Basic email:password，这个需求如何实现？ 编写一个AuthFilter是最简单的实现方式： 1234567891011121314151617181920212223@Componentpublic class AuthFilter implements Filter { @Autowired UserService userService; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; // 获取Authorization头: String authHeader = req.getHeader(\"Authorization\"); if (authHeader != null &amp;&amp; authHeader.startsWith(\"Basic \")) { // 从Header中提取email和password: String email = prefixFrom(authHeader); String password = suffixFrom(authHeader); // 登录: User user = userService.signin(email, password); // 放入Session: req.getSession().setAttribute(UserController.KEY_USER, user); } // 继续处理请求: chain.doFilter(request, response); }} 在Spring中创建的这个AuthFilter是一个普通Bean，Servlet容器并不知道，所以它不起作用。如果我们直接在web.xml中声明这个AuthFilter，但AuthFilter的实例是有Servlet容器而不是Spring容器（也就是IoC容器）初始化，因此@AutoWired不生效，用于登录的UserService成员变量将永远是null。 所以，得通过一种方式，让Servlet容器实例化的Filter，间接引用Spring容器实例化的AuthFilter。Spring MVC提供了一个DelegatingFilterProxy来做这件事： 123456789101112&lt;web-app&gt; &lt;filter&gt; &lt;filter-name&gt;authFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;authFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; ...&lt;/web-app&gt; 我们来看实现原理： Servlet容器从web.xml读取配置，实例化DelegatingFilterProxy，注意命名是authFilter Spring容器扫描@Component实例化AuthFilter 当DelegatingFilterProxy生效后，它会自动查找注册在ServletContext上的Spring容器，再试图从容器中查找名为authFilter的Bean，也就是我们用@Component声明的AuthFilter。 DelegatingFilterProxy将请求代理给AuthFilter，核心代码如下： 123456789public class DelegatingFilterProxy implements Filter { private Filter delegate; public void doFilter(...) throws ... { if (delegate == null) { delegate = findBeanFromSpringContainer(); } delegate.doFilter(req, resp, chain); }} 这是一个代理模式的简单应用，我们用图表表示它们之间的引用关系如下： 12345678910┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┌─────────────────────┐ ┌───────────┐ ││ │DelegatingFilterProxy│─│─│─ ─&gt;│AuthFilter │ └─────────────────────┘ └───────────┘ ││ ┌─────────────────────┐ │ │ ┌───────────┐ │ DispatcherServlet │─ ─ ─ ─&gt;│Controllers│ ││ └─────────────────────┘ │ │ └───────────┘ ││ Servlet Container │ │ Spring Container ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ 如果在web.xml中配置的Filter名称和Spring容器的Bean的名字不一致，那么需要指定Bean的名字： 123456789&lt;filter&gt; &lt;filter-name&gt;basicAuthFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;!-- 指定Bean的名字 --&gt; &lt;init-param&gt; &lt;param-name&gt;targetBeanName&lt;/param-name&gt; &lt;param-value&gt;authFilter&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; 实际应用时，尽量保持名字一致，以减少不必要的配置。 注意：Basic认证模式并不安全，本节只用来作为使用Filter的示例。 使用Interceptor在Web应用程序中，注意到使用Filter时，Filter由Servlet容器管理，它在Spring MVC的Web应用程序中作用范围如下： 123456789101112131415161718192021222324252627 │ ▲ ▼ │ ┌───────┐ │Filter1│ └───────┘ │ ▲ ▼ │ ┌───────┐┌ ─ ─ ─│Filter2│─ ─ ─ ─ ─ ─ ─ ─ ┐ └───────┘│ │ ▲ │ ▼ ││ ┌─────────────────┐ │ │DispatcherServlet│&lt;───┐│ └─────────────────┘ │ │ │ ┌────────────┐│ │ │ModelAndView││ │ └────────────┘│ │ ▲ │ │ ┌───────────┐ ││ ├───&gt;│Controller1│────┤ │ │ └───────────┘ ││ │ │ │ │ ┌───────────┐ ││ └───&gt;│Controller2│────┘ │ └───────────┘└ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ 上图虚线框就是Filter2的拦截范围，Filter实际上不知道后续处理是通过Spring MVC提供的DispathcerServlet还是其他Servlet组件，因为Filter是Servlet规范定义的标准组件，它可以应用在任何基于Servlet的程序中。 如果只基于Spring MVC开发应用程序，还可以使用Spring MVC提供的一种功能类似Filter的拦截器：Interceptor。和Filter相比，Interceptor拦截范围不是后续整个处理流程，而是仅针对Controller的拦截。 123456789101112131415161718192021222324252627 │ ▲ ▼ │ ┌───────┐ │Filter1│ └───────┘ │ ▲ ▼ │ ┌───────┐ │Filter2│ └───────┘ │ ▲ ▼ │┌─────────────────┐│DispatcherServlet│&lt;───┐└─────────────────┘ │ │ ┌────────────┐ │ │ModelAndView│ │ └────────────┘ │ ┌ ─ ─ ─ ─ ─ ─ ─ ─ ┐ ▲ │ ┌───────────┐ │ ├─┼─&gt;│Controller1│──┼─┤ │ └───────────┘ │ │ │ │ │ │ ┌───────────┐ │ └─┼─&gt;│Controller2│──┼─┘ └───────────┘ └ ─ ─ ─ ─ ─ ─ ─ ─ ┘ 上图虚线框就是Interceptor的拦截范围。注意到Controller的处理方法一般都类似这样： 1234567@Controllerpublic class Controller1 { @GetMapping(\"/path/to/hello\") ModelAndView hello() { ... }} 所以，Interceptor的拦截范围其实就是Controller方法，实际上相当于基于AOP的方法拦截。因为Interceptor只拦截Controller方法，所以要注意，返回ModelAndView后，后续对View的渲染就脱离了Interceptor的拦截范围。 使用Interceptor的好处是Interceptor本身是Spring管理的Bean，因此注入任意的Bean都非常简单，此外可以应用多个Interceptor，并通过简单的@Order指定顺序。 我们先写一个LoggerInterceptor： 12345678910111213141516171819202122232425262728293031@Order(1)@Componentpublic class LoggerInterceptor implements HandlerInterceptor { final Logger logger = LoggerFactory.getLogger(getClass()); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { logger.info(\"preHandle {}...\", request.getRequestURI()); if (request.getParameter(\"debug\") != null) { PrintWriter pw = response.getWriter(); pw.write(\"&lt;p&gt;DEBUG MODE&lt;/p&gt;\"); pw.flush(); return false; } return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { logger.info(\"postHandle {}.\", request.getRequestURI()); if (modelAndView != null) { modelAndView.addObject(\"__time__\", LocalDateTime.now()); } } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { logger.info(\"afterCompletion {}: exception = {}\", request.getRequestURI(), ex); }} 一个Interceptor必须实现HandlerInterceptor接口，可以选择实现preHandle()、postHandle()和afterCompletion()方法。preHandle()是Controller方法调用前执行，postHandle()是Controller方法争藏返回后执行，而afterCompletion()无论Controller方法是否抛异常都会执行，参数ex就是Controller方法抛出的异常（未抛出异常是null）。 在preHandle()中也可以直接处理响应，然后返回false标识无需调用Controller方法继续处理了，通常在认证或者安全检查失败时直接返回错误响应。在postHandle()中，因为捕获了Controller方法返回的ModelAndView，所以可以继续在ModelAndView中添加一些通用数据，很多页面需要的全局数据如CopyRight信息都可以放到这里，无需在每个Controller方法中重复添加。 我们添加一个AuthInterceptor，用于替代上一节使用的AuthFilter进行Basic认证的功能： 12345678910111213141516171819202122232425262728293031323334353637@Order(2)@Componentpublic class AuthInterceptor implements HandlerInterceptor { final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired UserService userService; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { logger.info(\"pre authenticate {}...\", request.getRequestURI()); try { authenticateByHeader(request); } catch (RuntimeException e) { logger.warn(\"login by authorization header failed.\", e); } return true; } private void authenticateByHeader(HttpServletRequest req) { String authHeader = req.getHeader(\"Authorization\"); if (authHeader != null &amp;&amp; authHeader.startsWith(\"Basic \")) { logger.info(\"try authenticate by authorization header...\"); String up = new String(Base64.getDecoder().decode(authHeader.substring(6)), StandardCharsets.UTF_8); int pos = up.indexOf(':'); if (pos &gt; 0) { String email = URLDecoder.decode(up.substring(0, pos), StandardCharsets.UTF_8); String password = URLDecoder.decode(up.substring(pos + 1), StandardCharsets.UTF_8); User user = userService.signin(email, password); req.getSession().setAttribute(UserController.KEY_USER, user); logger.info(\"user {} login by authorization header ok.\", email); } } }} 这个AuthInterceptor是由Spring容器直接管理的，因此注入UserService非常方便。 最后，要让拦截器生效，我们在WebMvcConfigurer中注册所有的Interceptor： 1234567891011@BeanWebMvcConfigurer createWebMvcConfigurer(@Autowired HandlerInterceptor[] interceptors) { return new WebMvcConfigurer() { public void addInterceptors(InterceptorRegistry registry) { for (var interceptor : interceptors) { registry.addInterceptor(interceptor); } } ... };} 如果拦截器没有生效，请检查是否忘记了在WebMvcConfigurer中注册。 处理异常在Controller中，Spring MVC还允许定义基于@ExceptionHandler注解的异常处理方法，我们来看示例代码： 12345678@Controllerpublic class UserController { @ExceptionHandler(RuntimeException.class) public ModelAndView handleUnknowException(Exception ex) { return new ModelAndView(\"500.html\", Map.of(\"error\", ex.getClass().getSimpleName(), \"message\", ex.getMessage())); } ...} 异常处理方法没有固定的方法签名，可以传入Exception、HttpServletRequest等，返回值可以是void，也可以是ModelAndView，上述代码通过@ExceptionHandler(RuntimeException.class)表示当发生RuntimeException的时候，就自动调用此方法处理。 注意到我们返回了一个新的ModelAndView，这样在应用程序内部发生了预料之外的异常，可以给用户显示一个出错页面，而不是简单的500 Internal Server Error或404 Not Found。 可以编写多个错误处理方法，每个方法针对特定的异常，例如，处理LoginException使得页面可以自动跳转到登录页。使用ExceptionHandler时，要注意它仅作用于当前的Controller，即ControllerA中定义的ExceptionHander方法对ControllerB不起作用。那如果我们有很多Controller，每个Controller都需要处理一些通用异常，应该怎么避免重复代码？ 处理CORS在开发REST应用时，很多时候是通过页面的JavaScript和后端的REST API交互。在JavaScript与REST API交互的时候，有很多安全限制。默认情况下，浏览器按同源策略放行JavaScript调用API，即： 如果A站在域名a.com页面的JavaScript调用A站自己的API时，没有问题 如果A站在域名a.com页面的JavaScript调用B站b.com的API时，将被浏览器拒绝访问，因为不满足同源策略 同源要求域名完全相同（a.com和www.a.com不同），协议要相同（http和https不同），端口要相同。 那么，在域名a.com页面的JavaScript要调用b.com的API时，还有没有办法？ 有的，那就是CORS，全称叫Cross-Origin Resource Sharing，是HTML5规范定义的如何跨域访问资源。如果A站的JavaScript访问B站API时，B站能够返回响应头Access-Control-Allow-Origin: http://a.com，那么浏览器就允许A站的JavaScript访问B站的API。注意到跨域访问能否成功，取决于B站是否愿意给A站返回一个正确的Access-Control-Allow-Origin响应头，所以决定权永远在提供API的服务方手中。 使用Spring的@RestController开发REST应用时，同样会面对跨域问题。如果我们允许指定的网站通过页面JavaScript访问这些REST API，就必须正确地设置CORS。我们一一介绍设置CORS的几种方法。 使用@CrossOrigin在@RestController的class级别或method级别定义一个@CrossOrigin，例如： 123456@CrossOrigin(origins = \"http://local.liaoxuefeng.com:8080\")@RestController@RequestMapping(\"/api\")public class ApiController { ...} 上述定义在ApiController处的@CrossOrigin指定了只允许来自local.liaoxuefeng.com跨域访问，允许多个域名访问需要写成数组形式，例如origins = {\"http://a.com\", \"https://www.b.com\"}。如果允许任何域名访问，写成origins = \"*\"即可。 如果有多个REST Controller都需要使用CORS，那么每个Controller都必须标注@CrossOrigin注解。 使用CorsRegistry在WebMvcConfigurer中定义一个全局CORS配置，下面是一个示例： 1234567891011121314@BeanWebMvcConfigurer createWebMvcConfigurer() { return new WebMvcConfigurer() { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/api/**\") .allowedOrigins(\"http://local.liaoxuefeng.com:8080\") .allowedMethods(\"GET\", \"POST\") .maxAge(3600); // 可以继续添加其他URL规则: // registry.addMapping(\"/rest/v2/**\")... } };} 这种方式可以创建一个全局CORS配置，如果仔细地设计URL结构，那么可以一目了然地看到各个URL的CORS规则，推荐使用这种方式配置CORS。 使用CorsFilter使用Spring提供的CorsFilter，我们在[集成Filter中详细介绍了将Spring容器内置的Bean暴露为Servlet容器的Filter的方法，由于这种配置方式需要修改web.xml，也比较繁琐，所以推荐使用第二种方式。 国际化在开发应用程序时，经常会遇到支持多语言的需求，这种支持多语言的功能称之为国际化，英文名是internationalization，缩写为i18n（因为首字母i和末字母n之间有18个字母）。还有针对特定地区的本地化功能，英文是localization，缩写为l10n，本地化是指根据地区调整类似姓名、日期的显示等。也有把上述两者合称为全球化，英文是globalization，缩写为g11n。 在Java中，支持多语言和本地化是通过MessageFormat配合Locale实现的。 1234567891011121314import java.text.MessageFormat;import java.util.Locale;public class Time { public static void main(String[] args) { double price = 123.5; int number = 10; Object[] arguments = { price, number }; MessageFormat mfUS = new MessageFormat(\"Pay {0,number,currency} for {1} books.\", Locale.US); // Pay $123.50 for 10 books. System.out.println(mfUS.format(arguments)); MessageFormat mfZH = new MessageFormat(\"{1}本书一共{0,number,currency}。\", Locale.CHINA); // 10本书一共¥123.50。 System.out.println(mfZH.format(arguments)); }} 对于Web应用程序，要实现国际化功能，主要是渲染View的时候，要把各种语言的资源文件提出来，这样，不同的用户访问同一个页面时，显示的语言就是不同的。 我们来看看在Spring MVC应用程序中如何实现国际货。 获取Locale第一步获取用户的Locale。在Web应用程序中，HTTP规范规定了浏览器会在请求中携带Accept-Language头，用来指示用户浏览器设定的语言顺序，如： 1Accept-Language: zh-CN,zh;q=0.8,en;q=0.2 上述HTTP请求头表示优先选择简体中文，其次选择中文，最后选择英文。q表示权重，解析后我们可获得一个根据优先级排序的语言列表，把它转换为Java的Locale，即获得了用户的Locale。大多数框架通常只返回权重最高的Locale。 Spring MVC通过LocaleResolver来自动从HttpServletRequest中获取Locale。有多种LocaleResolver的实现类，其中最常用的是CookieLocaleResolver： 1234567@BeanLocaleResolver createLocaleResolver() { var clr = new CookieLocaleResolver(); clr.setDefaultLocale(Locale.ENGLISH); clr.setDefaultTimeZone(TimeZone.getDefault()); return clr;} CookieLocaleResolver从HttpServletRequest中获取Locale时，首先根据一个特定的Cookie判断是否指定了Locale，如果没有，就从HTTP头获取，如果还没有，就返回默认的Locale。 当用户第一次访问网站时，CookieLocaleResolver只能从HTTP头获取Locale，即使用浏览器的默认语言。通常网站也允许用户自己选择语言，此时，CookieLocaleResolver就会把用户选择的语言存放到Cookie中，下一次访问时，就会返回用户上次选择的语言而不是浏览器默认语言。 提取资源文件第二步是把写死在模板中的字符串以资源文件的形式存储在外部。 对于多语言，主文件名如果命名为messages，那么资源文件必须按如下方式命名并放入classpath中： 默认语言，文件名必须为messages.properties 简体中文，Locale是zh_CN，文件名必须为messages_zh_CN.properties 日文，Locale是ja_JP，文件名必须为messages_ja_JP.properties 其它更多语言…… 每个资源文件都有相同的key，例如，默认语言是英文，文件messages.properties内容如下： 1234language.select=Languagehome=Homesignin=Sign Incopyright=Copyright©{0,number,#} 文件messages_zh_CN.properties内容如下： 1234language.select=语言home=首页signin=登录copyright=版权所有©{0,number,#} 创建MessageSource第三步是创建一个Spring提供的MessageSource实例，它自动读取所有的.properties文件，并提供一个统一接口来实现“翻译”： 12// code, arguments, locale:String text = messageSource.getMessage(\"signin\", null, locale); 其中，signin是我们在.properties文件中定义的key，第二个参数是Object[]数组作为格式化时传入的参数，最后一个参数就是获取的用户Locale实例。 创建MessageSource如下： 123456789@Bean(\"i18n\")MessageSource createMessageSource() { var messageSource = new ResourceBundleMessageSource(); // 指定文件是UTF-8编码: messageSource.setDefaultEncoding(\"UTF-8\"); // 指定主文件名: messageSource.setBasename(\"messages\"); return messageSource;} 注意到ResourceBundleMessageSource会自动根据主文件名自动把所有相关语言的资源文件都读进来。 再注意到Spring容器会创建不只一个MessageSource实例，我们自己创建的这个MessageSource是专门给页面国际化使用的，因此命名为i18n，不会与其它MessageSource实例冲突。 实现多语言要在View中实现MessageSource加上Locale输出多语言，我们编写一个Interceptor，把相关资源注入到ModelAndView中： 1234567891011121314151617181920@Componentpublic class MvcInterceptor implements HandlerInterceptor { @Autowired LocaleResolver localeResolver; // 注意注入的MessageSource名称是i18n: @Autowired @Qualifier(\"i18n\") MessageSource messageSource; public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { if (modelAndView != null) { // 解析用户的Locale: Locale locale = localeResolver.resolveLocale(request); // 放入Model: modelAndView.addObject(\"__messageSource__\", messageSource); modelAndView.addObject(\"__locale__\", locale); } }} 不要忘了在WebMvcConfigurer中注册MvcInterceptor。现在，就可以在View中调用MessageSource.getMessage()方法来实现多语言： 1&lt;a href=\"/signin\"&gt;{{ __messageSource__.getMessage('signin', null, __locale__) }}&lt;/a&gt; 上述这种写法虽然可行，但格式太复杂了。使用View时，要根据每个特定的View引擎定制国际化函数。在Pebble中，我们可以封装一个国际化函数，名称就是下划线_，改造一下创建ViewResolver的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@BeanViewResolver createViewResolver(@Autowired ServletContext servletContext, @Autowired @Qualifier(\"i18n\") MessageSource messageSource) { PebbleEngine engine = new PebbleEngine.Builder() .autoEscaping(true) .cacheActive(false) .loader(new ServletLoader(servletContext)) // 添加扩展: .extension(createExtension(messageSource)) .build(); PebbleViewResolver viewResolver = new PebbleViewResolver(); viewResolver.setPrefix(\"/WEB-INF/templates/\"); viewResolver.setSuffix(\"\"); viewResolver.setPebbleEngine(engine); return viewResolver;}private Extension createExtension(MessageSource messageSource) { return new AbstractExtension() { @Override public Map&lt;String, Function&gt; getFunctions() { return Map.of(\"_\", new Function() { public Object execute(Map&lt;String, Object&gt; args, PebbleTemplate self, EvaluationContext context, int lineNumber) { String key = (String) args.get(\"0\"); List&lt;Object&gt; arguments = this.extractArguments(args); Locale locale = (Locale) context.getVariable(\"__locale__\"); return messageSource.getMessage(key, arguments.toArray(), \"???\" + key + \"???\", locale); } private List&lt;Object&gt; extractArguments(Map&lt;String, Object&gt; args) { int i = 1; List&lt;Object&gt; arguments = new ArrayList&lt;&gt;(); while (args.containsKey(String.valueOf(i))) { Object param = args.get(String.valueOf(i)); arguments.add(param); i++; } return arguments; } public List&lt;String&gt; getArgumentNames() { return null; } }); } };} 这样，我们可以把多语言页面改写为： 1&lt;a href=\"/signin\"&gt;{{ _('signin') }}&lt;/a&gt; 如果是带参数的多语言，需要把参数传进去： 1&lt;h5&gt;{{ _('copyright', 2020) }}&lt;/h5&gt; 使用其它View引擎时，也应当根据引擎接口实现更方便的语法。 切换Locale最后，我们需要允许用户手动切换Locale，编写一个LocaleController来实现该功能： 123456789101112131415161718192021222324252627@Controllerpublic class LocaleController { final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired LocaleResolver localeResolver; @GetMapping(\"/locale/{lo}\") public String setLocale(@PathVariable(\"lo\") String lo, HttpServletRequest request, HttpServletResponse response) { // 根据传入的lo创建Locale实例: Locale locale = null; int pos = lo.indexOf('_'); if (pos &gt; 0) { String lang = lo.substring(0, pos); String country = lo.substring(pos + 1); locale = new Locale(lang, country); } else { locale = new Locale(lo); } // 设定此Locale: localeResolver.setLocale(request, response, locale); logger.info(\"locale is set to {}.\", locale); // 刷新页面: String referer = request.getHeader(\"Referer\"); return \"redirect:\" + (referer == null ? \"/\" : referer); }} 在页面设计中，通常在右上角给用户提供一个语言选择列表。 小结多语言支持需要从HTTP请求中解析用户的Locale，然后针对不同Locale显示不同的语言。Spring MVC应用程序通过MessageSource和LocaleResolver，配合View实现国际化。 异步处理在Servlet模型中，每个请求都是由某个线程处理，然后，将响应写入IO流，发送给客户端。从开始处理请求，到写入响应完成，都是在同一个线程中处理的。 实现Servlet容器时，只要每处理一个请求，就创建一个新线程处理它，就能保证正确实现了Servlet线程模型。在实际产品中，例如Tomcat，总是通过线程池来处理请求，仍然符合一个请求从头到尾都由某一个线程处理。 这种线程模型非常重要，因为Spring的JDBC事务是基于ThreadLocal实现的，如果在处理过程中，一会由线程A处理，一会由线程B处理，那事务就乱套了。此外，很多安全认证也是基于ThreadLocal实现的，可以保证在处理请求的过程中，各个线程互不影响。 但是，如果一个请求处理的时间比较长，例如有几秒钟甚至更长，这种基于线程池的同步模型很快就把所有的线程耗尽，导致服务器无法响应新的请求。如果把长时间处理的请求改为异步处理，那么线程池的利用率会大大提高。Servlet从3.0规范开始添加了异步支持，允许对一个请求进行异步处理。 我们先来看看在Spring MVC中实现对请求进行异步处理的逻辑。首先建立一个Web工程，然后编辑web.xml文件如下： 1234567891011121314151617181920212223242526&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\"&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextClass&lt;/param-name&gt; &lt;param-value&gt;org.springframework.web.context.support.AnnotationConfigWebApplicationContext&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;com.itranswarp.learnjava.AppConfig&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;0&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 和前面普通的MVC程序相比，这个web.xml主要有几点不同： 不能再使用&lt;!DOCTYPE ...web-app_2_3.dtd\"&gt;的DTD声明，必须用新的支持Servlet 3.1规范的XSD声明，照抄即可 对DispatcherServlet的配置多了一个&lt;async-supported&gt;，默认值是false，必须明确写成true，这样Servlet容器才会支持async处理 然后在Controller中编写async处理逻辑。我们以ApiController为例，演示如何异步处理请求。 第一种async处理方式是返回一个Callable，Spring MVC自动把返回的Callable放入线程池执行，等待结果返回后再写入响应： 1234567891011@GetMapping(\"/users\")public Callable&lt;List&lt;User&gt;&gt; users() { return () -&gt; { // 模拟3秒耗时: try { Thread.sleep(3000); } catch (InterruptedException e) { } return userService.getUsers(); };} 第二种async处理方式是返回一个DeferredResult对象，然后在另一个线程中设置此对象的值并写入响应： 1234567891011121314151617181920@GetMapping(\"/users/{id}\")public DeferredResult&lt;User&gt; user(@PathVariable(\"id\") long id) { DeferredResult&lt;User&gt; result = new DeferredResult&lt;&gt;(3000L); // 3秒超时 new Thread(() -&gt; { // 等待1秒: try { Thread.sleep(1000); } catch (InterruptedException e) { } try { User user = userService.getUserById(id); // 设置正常结果并由Spring MVC写入Response: result.setResult(user); } catch (Exception e) { // 设置错误结果并由Spring MVC写入Response: result.setErrorResult(Map.of(\"error\", e.getClass().getSimpleName(), \"message\", e.getMessage())); } }).start(); return result;} 使用DeferredResult时，可以设置超时，超时会自动返回超时错误响应。在另一个线程中，可以调用setResult()写入结果，也可以调用setErrorResult()写入一个错误结果。 使用Filter当我们使用async模式处理请求时，原有的Filter也可以工作，但必须在web.xml中添加&lt;async-supported&gt;并设置为true。我们用两个Filter：SyncFilter和AsyncFilter分别测试： 123456789101112131415161718192021222324&lt;web-app ...&gt; ... &lt;filter&gt; &lt;filter-name&gt;sync-filter&lt;/filter-name&gt; &lt;filter-class&gt;com.itranswarp.learnjava.web.SyncFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter&gt; &lt;filter-name&gt;async-filter&lt;/filter-name&gt; &lt;filter-class&gt;com.itranswarp.learnjava.web.AsyncFilter&lt;/filter-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;sync-filter&lt;/filter-name&gt; &lt;url-pattern&gt;/api/version&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;async-filter&lt;/filter-name&gt; &lt;url-pattern&gt;/api/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; ...&lt;/web-app&gt; 一个声明为支持&lt;async-supported&gt;的Filter既可以过滤async请求，也可以过滤正常的同步请求，而未声明&lt;async-supported&gt;的Filter无法支持async请求。如果一个普通的Filter遇到async请求时，会直接报错，因此，务必注意普通Filter的&lt;url-pattern&gt;不要匹配async请求路径。 在logback.xml配置文件中，我们输出格式加上[%thread]，可以输出当前线程的名称： 123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;Pattern&gt;%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n&lt;/Pattern&gt; &lt;/layout&gt; &lt;/appender&gt; ...&lt;/configuration&gt; 对于同步请求，每个Filter和ApiController都是由同一个线程执行。对于异步请求，AsyncFilter和ApiController是由同一个线程执行的，但是，返回响应的是另一个线程。 实际中，经常使用到的就是DeferredResult，因为返回DeferredResult时，可以设置超时、正常结果和错误结果，易于编写比较灵活的逻辑。使用async异步处理响应时，要时刻牢记，在另一个异步线程中的事务和Controller方法中执行的事务不是同一个事务，在Controller中绑定的ThreadLocal信息也无法在异步线程中获取。 此外，Servlet 3.0规范添加的异步支持是针对同步模型打了一个“补丁”，虽然可以异步处理请求，但高并发异步请求时，它的处理效率并不高，因为这种异步模型并没有用到真正的“原生”异步。Java标准库提供了封装操作系统的异步IO包java.nio，是真正的多路复用IO模型，可以用少量线程支持大量并发。使用NIO编程复杂度比同步IO高很多，因此我们很少直接使用NIO。相反，大部分需要高性能异步IO的应用程序会选择Netty这样的框架，它基于NIO提供了更易于使用的API，方便开发异步应用程序。 使用WebSocketWebSocket是一种基于HTTP的长链接技术。传统的HTTP协议是一种请求-响应模型，如果浏览器不发送请求，那么服务器无法主动给浏览器推送数据。如果要定期给浏览器推送数据，例如股票行情，或者不定期给浏览器推送数据，例如在线聊天，基于HTTP协议实现这类需求，只能依靠浏览器的定时轮询，效率低且实时性不高。 因为HTTP本身是基于TCP连接的，所以，WebSocket在HTTP协议的基础上做了一个简单的升级，即建立TCP连接后，浏览器发送请求时，附带几个头： 1234GET /chat HTTP/1.1Host: www.example.comUpgrade: websocketConnection: Upgrade 就表示客户端希望升级连接，变成长连接的WebSocket，服务器返回升级成功的响应： 123HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: Upgrade 收到成功响应时表示WebSocket“握手”成功，这样，代表WebSocket的这个TCP连接将不会被服务器关闭，而是一直保持，服务器可随时向浏览器推送消息，浏览器也可以随时向服务器推送消息。双方推送消息既可以是文本消息，也可以是二进制消息，一般来说，绝大部分应用程序都会推送基于JSON的文本消息。 现代浏览器都已经支持WebSocket协议，服务器则需要底层框架支持。Java的Servelt规范从3.1开始支持WebSocket，所以，必须选择支持Servlet3.1或更高规范的Servlet容器，才能支持WebSocket。最新版本的Tomcat、Jetty等开源服务器均支持WebSocket。 我们以实际代码演示如何在Spring MVC中实现对WebSocket的支持。首先，我们需要在pom.xml中加入以下依赖： org.apache.tomcat.embed:tomcat-embed-websocket:9.0.26 org.springframework:spring-websocket:5.2.0.RELEASE 第一项是嵌入式Tomcat支持WebSocket的组件，第二项是Spring封装的支持WebSocket的接口。 接下来，我们要在AppConfig中加入Spring Web对WebSocket的配置，此处我们要创建一个WebSocketConfigurer实例。 123456789101112@BeanWebSocketConfigurer createWebSocketConfigurer( @Autowired ChatHandler chatHandler, @Autowired ChatHandshakeInterceptor chatInterceptor){ return new WebSocketConfigurer() { public void registerWebSocketHandlers(WebSocketHandlerRegistry registry) { // 把URL与指定的WebSocketHandler关联，可关联多个: registry.addHandler(chatHandler, \"/chat\").addInterceptors(chatInterceptor); } };} 此实例在内部通过WebSocketHandlerRegistry注册能处理WebSocket的WebSocketHandler，以及可选的WebSocket拦截器HandshakeInterceptor。我们注入的这两个类都是自己编写的业务逻辑，后面我们详细讨论如何编写它们，这里只需关注浏览器连接到WebSocket的URL是/chat。 处理WebSocket连接和处理普通HTTP请求不同，没法用一个方法处理一个URL。Spring提供了TextWebSocketHandler和BinaryWebSocketHandler分别处理文本消息和二进制消息，这里我们选择文本消息作为聊天室的协议，因此，ChatHandler需要继承自TextWebSocketHandler： 1234@Componentpublic class ChatHandler extends TextWebSocketHandler { ...} 当浏览器请求一个WebSocket连接后，如果成功建立连接，Spring会自动调用afterConnectionEstablished()方法，任何原因导致WebSocket中断，Spring会自动调用afterConnectionClosed()方法，因此，覆写这两个方法即可处理连接成功和结束后的业务逻辑。 1234567891011121314151617@Componentpublic class ChatHandler extends TextWebSocketHandler { // 保存所有Client的WebSocket会话实例: private Map&lt;String, WebSocketSession&gt; clients = new ConcurrentHashMap&lt;&gt;(); @Override public void afterConnectionEstablished(WebSocketSession session) throws Exception { // 新会话根据ID放入Map: clients.put(session.getId(), session); session.getAttributes().put(\"name\", \"Guest1\"); } @Override public void afterConnectionClosed(WebSocketSession session, CloseStatus status) throws Exception { clients.remove(session.getId()); }} 每个WebSocket会话以WebSocketSession表示，且已分配唯一ID。和WebSocket相关的数据，例如用户名称等，均可放入关联的getAttributes()中。 用实例变量clients持有当前所有的WebSocketSession是为了广播，即向所有用户推送同一消息时，可以这么写： 123456String json = ...TextMessage message = new TextMessage(json);for (String id : clients.keySet()) { WebSocketSession session = clients.get(id); session.sendMessage(message);} 我们发送的消息是序列化后的JSON，可以用ChatMessage表示： 12345public class ChatMessage { public long timestamp; public String name; public String text;} 每收到一个用户的消息后，我们就需要广播给所有用户： 12345678910@Componentpublic class ChatHandler extends TextWebSocketHandler { ... @Override protected void handleTextMessage(WebSocketSession session, TextMessage message) throws Exception { String s = message.getPayload(); String r = ... // 根据输入消息构造待发送消息 broadcastMessage(r); // 推送给所有用户 }} 如果要推送给指定的几个用户，那就需要在clients中根据条件查找出某些WebSocketSession，然后发送消息。 注意到我们在注册WebSocket时还传入了一个ChatHandshakeInterceptor，这个类实际上可以从HttpSessionHandshakeInterceptor继承，它的主要作用是在WebSocket建立连接后，把HttpSession的一些属性复制到WebSocketSession，例如，用户的登录信息等： 1234567@Componentpublic class ChatHandshakeInterceptor extends HttpSessionHandshakeInterceptor { public ChatHandshakeInterceptor() { // 指定从HttpSession复制属性到WebSocketSession: super(List.of(UserController.KEY_USER)); }} 这样，在ChatHandler中，可以从WebSocketSession.getAttributes()中获取到复制过来的属性。 客户端开发在完成了服务器端的开发后，我们还需要在页面编写一点JavaScript逻辑： 123456789101112131415161718// 创建WebSocket连接:var ws = new WebSocket('ws://' + location.host + '/chat');// 连接成功时:ws.addEventListener('open', function (event) { console.log('websocket connected.');});// 收到消息时:ws.addEventListener('message', function (event) { console.log('message: ' + event.data); var msgs = JSON.parse(event.data); // TODO:});// 连接关闭时:ws.addEventListener('close', function () { console.log('websocket closed.');});// 绑定到全局变量:window.chatWs = ws; 用户可以在连接成功后任何时候给服务器发送消息： 12var inputText = 'Hello, WebSocket.';window.chatWs.send(JSON.stringify({text: inputText})); 最后，连调浏览器和服务器端，如果一切无误，可以开多个不同的浏览器测试WebSocket的推送和广播。 和上一节我们介绍的异步处理类似，Servlet的线程模型并不适合大规模的长链接。基于NIO的Netty等框架更适合处理WebSocket长链接，我们将在后面介绍。 通过spring-websocket可以简化WebSocket的开发。","link":"/Study/Java/Spring/%E5%BC%80%E5%8F%91Web%E5%BA%94%E7%94%A8/"},{"title":"设计模式","text":"设计模式，即Design Patterns，是指在软件设计中，被反复使用的代码设计经验。使用设计模式的目的是为了可重用代码，提高代码的可扩展性和可维护性。 概述为什么要使用设计模式？根本原因还是软件开发要实现可维护、可扩展，就必须尽量复用代码，并且降低代码耦合度。设计模式主要是基于OOP编程提炼的，它基于以下几个原则： 开闭原则。开闭原则（Open Closed Principle）是指，软件应该对扩展开放，而对修改关闭。这里的意思是，在增加新功能时，能不改代码就尽量不要改，如果只增加代码就完成了新功能，那是最好的。 里氏替换原则。里氏替换原则是一种面向对象的设计原则，即如果我们调用一个父类的方法可以成功，那么替换成子类调用也应该完全可以运行。 设计模式是把一些常用的设计模式提炼出一个个模式，然后给每个模式命名，这样在使用的时候更方便交流。GoF（提出设计模式这个术语的四个人）把23个常用模式分为创建型模式、结构型模式和行为型模式三类。学习设计模式，关键的是学习设计思想，不能简单地生搬硬套，也不能为了使用设计模式而过度设计，要合理平衡设计的复杂性和灵活性，并意识到设计模式也不是万能的。 创建型模式创建型模式关注点是如何创建对象，其核心思想是把对象的创建和使用相分离，这样使得两者能相对独立地变换。 工厂方法定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method使一个类的实例化延迟到其子类。工厂方法即Factory Method，是一种对象创建型模式。工厂方法的目的是使得创建对象和使用对象是想分离的，并且客户端总是引用抽象工厂和抽象产品。 我们来举个例子，假设我们希望实现一个解析字符串到Number的Factory，可以这么定义。 1234567891011public interface NumberFactory { // 创建方法: Number parse(String s); // 获取工厂实例: static NumberFactory getFactory() { return impl; } static NumberFactory impl = new NumberFactoryImpl();} 客户端如何创建NumberFactoryImpl呢？通常我们会在接口Factory中定义一个静态方法getFactory()来返回真正的子类。 有了工厂接口，再编写一个工厂的实现类。 12345public class NumberFactoryImpl implements NumberFactory { public Number parse(String s) { return new BigDecimal(s); }} 产品接口是Number，NumberFactoryImpl返回的实际产品是BigDecimal。 在客户端中，我们只需要和工厂接口NumberFactory以及抽象产品Number打交道。 12NumberFactory factory = NumberFactory.getFactory();Number result = factory.parse(\"123.456\"); 调用方可以完全忽略真正的工厂NumberFactoryImpl和实际产品BigDecimal，这样做的好处是允许创建产品的代码独立地变化，而不会影响到调用方。 有的同学就会问了：一个简单的parse()需要写这么复杂的工厂吗？实际上，大多数情况下，我们并不需要抽象工厂，而是通过静态方法直接返回产品，即： 12345public class NumberFactory { public static Number parse(String s) { return new BigDecimal(s); }} 这种简化的使用静态方法创建产品的方式，称为静态工厂方法（Static Factory Method）。静态工厂方法广泛应用在Java标准库中，例如： 1Integer n = Integer.valueOf(100); Integer既是产品也是静态工厂。它提供了静态方法valueOf()来创建Integer，那么，这种方式和直接使用new操作符有何区别？使用静态方法的好处在于，valueOf()内部可能会使用new创建一个新的Integer实例，也可能直接返回一个缓存的Integer实例，此时会减少内存消耗提升速度。对调用方来说没必要在意这些细节。而如果调用方直接使用new操作符，那么就失去了使用缓存优化的可能性。 我们经常使用的另一个静态工厂方法是List.of()，这个静态工厂方法可以接收可变参数，然后返回List接口。需要注意的是，调用方获取的产品总是List接口，而且并不关心它的实际类型。即使调用方知道List产品的实际类型是java.util.ImmutableCollections$ListN，也不要去强制转型为子类，因为静态工厂方法List.of()保证返回List，但也完全可以修改为返回java.util.ArrayList。 总是引用接口而非实现类，能允许变换子类而不影响调用方，即尽可能面向对象编程 小结工厂方法是指定义工厂接口和产品接口，但如何创建实际工厂和实际产品被推迟到子类实现，从而使调用方只和抽象工厂与抽象产品打交道。 实际更常用的是更简单的静态工厂方法，它允许工厂内部对创建产品进行优化。 调用方尽量持有接口或抽象类，避免持有具体类型的子类，以便工厂方法能随时切换不同的子类返回，却不影响调用方代码。 抽象工厂抽象工厂模式（Abstract Factory）是一个比较复杂的创建型模式。抽象工厂模式和工厂方法不太一样，它要解决的问题比较复杂，不但工厂是抽象的，产品是抽象的，而且有多个产品需要创建，因此，这个抽象工厂会对应到多个实际工厂，每个实际工厂负责创建多个实际产品。 这类似于多个供应商提供相类似产品。我们举个例子：假设我们希望为用户提供一个Markdown文本转换为HTML和Word的服务，它的接口定义如下： 123456public interface AbstractFactory { // 创建Html文档: HtmlDocument createHtml(String md); // 创建Word文档: WordDocument createWord(String md);} 上面的抽象工厂仅仅是一个接口，没有任何代码。同样的，因为HtmlDocument和WordDocument都比较复杂，现在我们并不知道如何实现它们，所以只有接口： 12345678910// Html文档接口:public interface HtmlDocument { String toHtml(); void save(Path path) throws IOException;}// Word文档接口:public interface WordDocument { void save(Path path) throws IOException;} 这样，我们就定义好了抽象工厂AbstractFactory和两个抽象产品HtmlDocument和WordDocument。实现它们比较困难，我们决定让供应商来完成。 现在市场上有两家供应商：FastDoc Soft的产品便宜，并且转换速度快，而GoodDoc Soft的产品贵，但转换效果好。我们决定同时使用这两家供应商的产品，以便给免费用户和付费用户提供不同的服务。 我们先看看FastDoc Soft的产品是如何实现的。首先，FastDoc Soft必须要有实际的产品，即FastHtmlDocument和FastWordDocument： 1234567891011121314public class FastHtmlDocument implements HtmlDocument { public String toHtml() { ... } public void save(Path path) throws IOException { ... }}public class FastWordDocument implements WordDocument { public void save(Path path) throws IOException { ... }} 然后，FastDoc Soft必须提供一个实际的工厂来生产这两种产品，即FastFactory： 12345678public class FastFactory implements AbstractFactory { public HtmlDocument createHtml(String md) { return new FastHtmlDocument(md); } public WordDocument createWord(String md) { return new FastWordDocument(md); }} 这样，我们就可以使用FastDoc Soft的服务了。客户端编写代码如下： 12345678// 创建AbstractFactory，实际类型是FastFactory:AbstractFactory factory = new FastFactory();// 生成Html文档:HtmlDocument html = factory.createHtml(\"#Hello\\nHello, world!\");html.save(Paths.get(\".\", \"fast.html\"));// 生成Word文档:WordDocument word = factory.createWord(\"#Hello\\nHello, world!\");word.save(Paths.get(\".\", \"fast.doc\")); 如果我们要同时使用GoodDoc Soft的服务怎么办？因为用了抽象工厂模式，GoodDoc Soft只需要根据我们定义的抽象工厂和抽象产品接口，实现自己的实际工厂和实际产品即可： 123456789101112131415161718// 实际工厂:public class GoodFactory implements AbstractFactory { public HtmlDocument createHtml(String md) { return new GoodHtmlDocument(md); } public WordDocument createWord(String md) { return new GoodWordDocument(md); }}// 实际产品:public class GoodHtmlDocument implements HtmlDocument { ...}public class GoodWordDocument implements HtmlDocument { ...} 客户端要使用GoodDoc Soft的服务，只需要把原来的new FastFactory()切换为new GoodFactory()。 注意到，客户端代码除了通过new创建了FastFactory和GoodFactory外，其余代码只引用了产品接口，并未引用任何实际产品。如果把创建工厂的代码放到AbstractFactory中，就可以连实际工厂也屏蔽了。 1234567891011public interface AbstractFactory { public static AbstractFactory createFactory(String name) { if (name.equalsIgnoreCase(\"fast\")) { return new FastFactory(); } else if (name.equalsIgnoreCase(\"good\")) { return new GoodFactory(); } else { throw new IllegalArgumentException(\"Invalid factory name\"); } }} 生成器生成器模式（Builder）是使用多个“小型工厂”来最终创建出一个完整对象。当我们使用Builder时，一般来说，是因为创建这个对象的步骤比较多，每个步骤都需要一个零部件，最终组合成一个完整的对象。 我们仍然以Markdown转HTML为例，因为直接编写一个完整的转换器比较困难，但如果针对类似下面的一行文本： 1# this is a heading 转换成HTML就很简单： 1&lt;h1&gt;this is a heading&lt;/h1&gt; 因此，我们把Markdown转HTML看作一行一行转换，每一行根据语法，使用不同的转换器： 如果以#开头，使用HeadingBuilder转换 如果以&gt;开头，使用QuoteBuilder转换 如果以---开头，使用HrBuilder转换 其余使用ParagraphBuilder转换 这个HtmlBuilder写出来如下： 12345678910111213141516171819202122public class HtmlBuilder { private HeadingBuilder headingBuilder = new HeadingBuilder(); private HrBuilder hrBuilder = new HrBuilder(); private ParagraphBuilder paragraphBuilder = new ParagraphBuilder(); private QuoteBuilder quoteBuilder = new QuoteBuilder(); public String toHtml(String markdown) { StringBuilder buffer = new StringBuilder(); markdown.lines().forEach(line -&gt; { if (line.startsWith(\"#\")) { buffer.append(headingBuilder.buildHeading(line)).append('\\n'); } else if (line.startsWith(\"&gt;\")) { buffer.append(quoteBuilder.buildQuote(line)).append('\\n'); } else if (line.startsWith(\"---\")) { buffer.append(hrBuilder.buildHr(line)).append('\\n'); } else { buffer.append(paragraphBuilder.buildParagraph(line)).append('\\n'); } }); return buffer.toString(); }} 注意观察上述代码，HtmlBuilder并不是一次性把整个Markdown转换为HTML，而是一行一行转换，而且它自己并不会将某一行转换为特定的HTML，而是根据特性把每一行都“委托”给一个XxxBuilder去转换。最后，把所有转换的结果组合起来，返回给客户端。 这样一来，我们只需要针对每一种类型编写不同的Builder。例如，针对以#开头的行，需要HeadingBuilder： 12345678910public class HeadingBuilder { public String buildHeading(String line) { int n = 0; while (line.charAt(0) == '#') { n++; line = line.substring(1); } return String.format(\"&lt;h%d&gt;%s&lt;/h%d&gt;\", n, line.strip(), n); }} 注意：实际解析Markdown是带有状态的，即下一行的语义可能与上一行相关。这里我们做了简化，认为每一行可以独立转换。 可见，使用Builder模式时，适用于创建的对象比较复杂，最好一步一步创建出“零件”，最后再装配起来。 JavaMail的MimeMessage就可以看作是一个Builder模式，只不过Builder和最终产品合二为一，都是MimeMessage： 1234567891011121314151617181920Multipart multipart = new MimeMultipart();// 添加text:BodyPart textpart = new MimeBodyPart();textpart.setContent(body, \"text/html;charset=utf-8\");multipart.addBodyPart(textpart);// 添加image:BodyPart imagepart = new MimeBodyPart();imagepart.setFileName(fileName);imagepart.setDataHandler(new DataHandler(new ByteArrayDataSource(input, \"application/octet-stream\")));multipart.addBodyPart(imagepart);MimeMessage message = new MimeMessage(session);// 设置发送方地址:message.setFrom(new InternetAddress(\"me@example.com\"));// 设置接收方地址:message.setRecipient(Message.RecipientType.TO, new InternetAddress(\"xiaoming@somewhere.com\"));// 设置邮件主题:message.setSubject(\"Hello\", \"UTF-8\");// 设置邮件内容为multipart:message.setContent(multipart); 很多时候，我们可以简化Builder模式，以链式调用的方式来创建对象。例如，我们经常这样编写代码： 123456StringBuilder builder = new StringBuilder();builder.append(secure ? \"https://\" : \"http://\") .append(\"www.liaoxuefeng.com\") .append(\"/\") .append(\"?t=0\");String url = builder.toString(); 由于我们经常需要构造URL字符串，可以使用Builder模式编写一个URLBuilder，调用方式如下： 123456String url = URLBuilder.builder() // 创建Builder .setDomain(\"www.liaoxuefeng.com\") // 设置domain .setScheme(\"https\") // 设置scheme .setPath(\"/\") // 设置路径 .setQuery(Map.of(\"a\", \"123\", \"q\", \"K&amp;R\")) // 设置query .build(); // 完成build 原型原型模式，即Prototype，指创建新对象的时候，根据现有的一个原型创建。 我们举个例子：如果我们已经有了一个String[]数组，想再创建一个一模一样的String[]数组，怎么写？实际上创建过程很简单，就是把现有数组的元素复制到新数组。如果我们把这个创建过程封装一下，就成了原型模式。用代码实现如下： 1234// 原型:String[] original = { \"Apple\", \"Pear\", \"Banana\" };// 新对象:String[] copy = Arrays.copyOf(original, original.length); 对于普通类，我们如何实现原型拷贝？Java的Object提供了一个clone()方法，它的意图就是复制一个新的对象出来，我们需要实现一个Cloneable接口，来标识一个对象是“可复制”的。 1234567891011121314public class Student implements Cloneable { private int id; private String name; private int score; // 复制新对象并返回: public Object clone() { Student std = new Student(); std.id = this.id; std.name = this.name; std.score = this.score; return std; }} 使用的时候，因为clone()的方法签名定义在Object中，返回类型也是Object，所以强制转型，比较麻烦。 123456Student std1 = new Student();std1.setId(123);std1.setName(\"Bob\");std1.setScore(88);// 复制新对象:Student std2 = (Student) std1.clone(); 实际上，使用原型模式更好的方式是定义一个copy()方法，返回明确的类型。 12345678910111213public class Student { private int id; private String name; private int score; public Student copy() { Student std = new Student(); std.id = this.id; std.name = this.name; std.score = this.score; return std; }} 原型模式应用不是很广泛，因为很多实例会持有类似文件、Socket这样的资源，而这些资源是无法复制给另一个对象共享的，只有存储简单类型的“值”对象可以复制。 单例单例模式，即Singleton，是为了保证在一个进程中，某个类有且仅有一个实例。因为这个类只有一个实例，因此，自然不能让调用方使用new Xyz()来创建实例了。所以，单例的构造方法必须是private，这样就防止了调用方自己创建实例。但在类的内部，可以用一个静态字段来引用唯一创建的实例。 12345678public class Singleton { // 静态字段引用唯一实例: private static final Singleton INSTANCE = new Singleton(); // private构造方法保证外部无法实例化: private Singleton() { }} 那么，外部调用方如何获取这唯一的实例呢？提供一个静态方法返回这个实例。 12345678910111213public class Singleton { // 静态字段引用唯一实例: private static final Singleton INSTANCE = new Singleton(); // 通过静态方法返回实例: public static Singleton getInstance() { return INSTANCE; } // private构造方法保证外部无法实例化: private Singleton() { }} 或者直接把static变量暴露出去。 12345678public class Singleton { // 静态字段引用唯一实例: public static final Singleton INSTANCE = new Singleton(); // private构造方法保证外部无法实例化: private Singleton() { }} 所以，单例模式的实现方式很简单： 只有private构造方法，确保外部无法实例化； 通过private static变量持有唯一实例，保证全局唯一性； 通过public static方法返回此唯一实例，使外部调用方能获取到实例。 Java标准库有一些类就是单例，例如Runtime这个类： 1Runtime runtime = Runtime.getRuntime(); 有些童鞋可能听说过延迟加载，即在调用方第一次调用getInstance()时才初始化全局唯一实例，类似这样： 12345678910111213public class Singleton { private static Singleton INSTANCE = null; public static Singleton getInstance() { if (INSTANCE == null) { INSTANCE = new Singleton(); } return INSTANCE; } private Singleton() { }} 遗憾的是，这种写法在多线程中是错误的，在竞争条件下会创建出多个实例。必须对整个方法进行加锁： 123456public synchronized static Singleton getInstance() { if (INSTANCE == null) { INSTANCE = new Singleton(); } return INSTANCE;} 但加锁会严重影响并发性能。还有些童鞋听说过双重检查，类似这样： 12345678910public static Singleton getInstance() { if (INSTANCE == null) { synchronized (Singleton.class) { if (INSTANCE == null) { INSTANCE = new Singleton(); } } } return INSTANCE;} 然而，由于Java的内存模型，双重检查在这里不成立。要真正实现延迟加载，只能通过Java的ClassLoader机制完成。如果没有特殊的需求，使用Singleton模式的时候，最好不要延迟加载，这样会使代码更简单。 另一种实现Singleton的方式是利用Java的enum，因为Java保证枚举类的每个枚举都是单例，所以我们只需要编写一个只有一个枚举的类即可： 1234567891011121314public enum World { // 唯一枚举: INSTANCE; private String name = \"world\"; public String getName() { return this.name; } public void setName(String name) { this.name = name; }} 枚举类也完全可以像其他类那样定义自己的字段、方法，这样上面这个World类在调用方看来就可以这么用： 1String name = World.INSTANCE.getName(); 使用枚举实现Singleton还避免了第一种方式实现Singleton的一个潜在问题：即序列化和反序列化会绕过普通类的private构造方法从而创建出多个实例，而枚举类就没有这个问题。 那我们什么时候应该用Singleton呢？实际上，很多程序，尤其是Web程序，大部分服务类都应该被视作Singleton，如果全部按Singleton的写法写，会非常麻烦，所以，通常是通过约定让框架（例如Spring）来实例化这些类，保证只有一个实例，调用方自觉通过框架获取实例而不是new操作符： 1234@Component // 表示一个单例组件public class MyService { ...} 因此，除非确有必要，否则Singleton模式一般以“约定”为主，不会刻意实现它。 小结Singleton模式是为了保证一个程序的运行期间，某个类有且只有一个全局唯一实例； Singleton模式既可以严格实现，也可以以约定的方式把普通类视作单例。 结构型模式结构型模式主要涉及如何组合各种对象一遍获得更好、更灵活的结构。虽然面向对象的继承机制提供了最基本的子类扩展父类的功能，但结构型模式不仅仅简单地使用继承，而更多地通过组合和运行期的动态组合来实现更灵活的功能。 适配器适配器模式是Adapter，也称Wrapper，是指如果一个接口需要B结构，但是待传入的对象却是A接口，怎么办？ 如果去美国，我们随身带的电器是无法直接使用的，因为美国的插座标准和中国不同，所以，我们需要一个适配器 在程序设计中，适配器也是类似的。我们已经有一个Task类，实现了Callable接口： 123456789101112131415public class Task implements Callable&lt;Long&gt; { private long num; public Task(long num) { this.num = num; } public Long call() throws Exception { long r = 0; for (long n = 1; n &lt;= this.num; n++) { r = r + n; } System.out.println(\"Result: \" + r); return r; }} 现在，我们想通过一个线程去执行它： 123Callable&lt;Long&gt; callable = new Task(123450000L);Thread thread = new Thread(callable); // compile error!thread.start(); 发现编译不过！因为Thread接收Runnable接口，但不接收Callable接口，怎么办？一个办法是改写Task类，把实现的Callable改为Runnable，但这样做不好，因为Task很可能在其他地方作为Callable被调用，改写Task的接口，会导致其他正常工作的代码无法编译。 另一个办法不用改写Task类，而是用一个Adapter，把这个Callable接口“变成”Runnable接口，这样，就可以正常编译： 123Callable&lt;Long&gt; callable = new Task(123450000L);Thread thread = new Thread(new RunnableAdapter(callable));thread.start(); 这个RunnableAdapter类就是Adapter，它接收一个Callable，输出一个Runnable。怎么实现这个RunnableAdapter呢？我们先看完整的代码： 123456789101112131415161718public class RunnableAdapter implements Runnable { // 引用待转换接口: private Callable&lt;?&gt; callable; public RunnableAdapter(Callable&lt;?&gt; callable) { this.callable = callable; } // 实现指定接口: public void run() { // 将指定接口调用委托给转换接口调用: try { callable.call(); } catch (Exception e) { throw new RuntimeException(e); } }} 编写一个Adapter的步骤如下： 实现目标接口，这里是Runnable 内部持有一个待转换接口的引用，这里是通过字段持有Callable接口 在目标接口的实现方法内部，调用待转换接口的方法 这样一来，Thread就可以接收这个RunnableAdapter，因为它实现了Runnable接口。Thread作为调用方，它会调用RunnableAdapter的run()方法，在这个run()方法内部，又调用了Callable的call()方法，相当于Thread通过一层转换，间接调用了Callable的call()方法。 适配器模式在Java标准库中有广泛应用。比如我们持有数据类型是String[]，但是需要List接口时，可以用一个Adapter： 12String[] exist = new String[] {\"Good\", \"morning\", \"Bob\", \"and\", \"Alice\"};Set&lt;String&gt; set = new HashSet&lt;&gt;(Arrays.asList(exist)); 注意到List&lt;T&gt; Arrays.asList(T[])就相当于一个转换器，它可以把数组转换为List。 我们再看一个例子：假设我们持有一个InputStream，希望调用readText(Reader)方法，但它的参数类型是Reader而不是InputStream，怎么办？ 当然是使用适配器，把InputStream“变成”Reader： 123InputStream input = Files.newInputStream(Paths.get(\"/path/to/file\"));Reader reader = new InputStreamReader(input, \"UTF-8\");readText(reader); InputStreamReader就是Java标准库提供的Adapter，它负责把一个InputStream适配为Reader。类似的还有OutputStreamWriter。 如果我们把readText(Reader)方法参数从Reader改为FileReader，会有什么问题？这个时候，因为我们需要一个FileReader类型，就必须把InputStream适配为FileReader： 1FileReader reader = new InputStreamReader(input, \"UTF-8\"); // compile error! 直接使用InputStreamReader这个Adapter是不行的，因为它只能转换出Reader接口。事实上，要把InputStream转换为FileReader也不是不可能，但需要花费十倍以上的功夫。这时，面向抽象编程这一原则就体现出了威力：持有高层接口不但代码更灵活，而且把各种接口组合起来也更容易。一旦持有某个具体的子类类型，要想做一些改动就非常困难。 小结Adapter模式可以将一个A接口转换为B接口。编写Adapter实际上就是编写了一个实现了B接口，并且内部持有A接口的类，在Adapter内部将B接口的调用“转换”为A接口的调用。只有A、B接口均是抽象接口时，才能非常简单地实现Adapter模式。 桥接桥接模式的定义非常玄乎，直接理解不太容易，所以我们还是举例子。 假设某个汽车厂商生产三种品牌的汽车：Big、Tiny和Boss，每种品牌又可以选择燃油、纯电和混合动力。如果用传统的继承来表示各个最终车型，一共有3个抽象类加9个最终子类。如果要新增一个品牌，或者加一个新的引擎（比如核动力），那么子类的数量增长更快。所以，桥接模式就是为了避免直接继承带来的子类爆炸。 我们来看看桥接模式如何解决上述问题。 在桥接模式中，首先把Car按品牌进行子类化，但是，每个品牌选择什么发动机，不再使用子类扩充，而是通过一个抽象的“修正”类，以组合的形式引入。我们来看看具体的实现。 首先定义抽象类Car，它引用一个Engine： 12345678910public abstract class Car { // 引用Engine: protected Engine engine; public Car(Engine engine) { this.engine = engine; } public abstract void drive();} Engine的定义如下： 123public interface Engine { void start();} 紧接着，在一个“修正”的抽象类RefinedCar中定义一些额外操作： 123456789101112public abstract class RefinedCar extends Car { public RefinedCar(Engine engine) { super(engine); } public void drive() { this.engine.start(); System.out.println(\"Drive \" + getBrand() + \" car...\"); } public abstract String getBrand();} 这样一来，最终的不同品牌继承自RefinedCar，例如BossCar： 123456789public class BossCar extends RefinedCar { public BossCar(Engine engine) { super(engine); } public String getBrand() { return \"Boss\"; }} 而针对每一种引擎，继承自Engine，例如HybridEngine： 12345public class HybridEngine implements Engine { public void start() { System.out.println(\"Start Hybrid Engine...\"); }} 客户端通过自己选择一个品牌，再配合一种引擎，得到最终的Car： 12RefinedCar car = new BossCar(new HybridEngine());car.drive(); 使用桥接模式的好处在于，如果要增加一种引擎，只需要针对Engine派生一个新的子类，如果要增加一个品牌，只需要针对RefinedCar派生一个子类，任何RefinedCar的子类都可以和任何一种Engine自由组合，即一辆汽车的两个维度：品牌和引擎都可以独立地变化。 桥接模式实现比较复杂，实际应用也非常少，但它提供的设计思想值得借鉴，即不要过度使用继承，而是优先拆分某些部件，使用组合的方式来扩展功能。 桥接模式通过分离一个抽象接口和它的实现部分，使得设计可以按两个维度独立扩展。 组合组合模式（Composite）经常用于树形结构，为了简化代码，使用Composite可以把一个叶节点和父节点统一起来处理。举个例子，在XML和HTML中，从根结点开始，每个节点都可能包含任意个其他节点，这些层层嵌套的节点就构成了一棵树。 要以树的结构表示XML，我们可以先抽象出节点类型Node。对于一个&lt;abc&gt;这样的节点，我们称之为ElementNode，他可以包含任意个子节点。而对于普通文本，我们把它看作TextNode，它没有子节点。此外，还可以有注释节点。 通过ElementNode、TextNode和CommentNode，我们就可以构造出一棵树。 类似地，像文件夹和文件、GUI窗口的各种组件，都符合Composite模式的定义。 装饰器装饰器模式（Decorator），是一种在运行期动态给某个对象的实例增加功能的方法。 我们在IO的Filter模式一节中其实已经讲过装饰器模式了。在Java标准库中，InputStream是抽象类，FileInputStream、ServletInputStream、Socket.getInputStream()这些InputStream都是最终数据源。 现在，如果要给不同的最终数据源增加缓冲功能、计算签名功能、加密解密功能，那么，3个最终数据源、3种功能一共需要9个子类。如果继续增加最终数据源，或者增加新功能，子类会爆炸式增长，这种设计方式显然是不可取的。 Decorator模式的目的就是把一个一个的附加功能，用Decorator的方式给一层一层地累加到原始数据源上，最终，通过组合获得我们想要的功能。 例如：给FileInputStream增加缓冲和解压缩功能，用Decorator模式写出来如下： 123456// 创建原始的数据源:InputStream fis = new FileInputStream(\"test.gz\");// 增加缓冲功能:InputStream bis = new BufferedInputStream(fis);// 增加解压缩功能:InputStream gis = new GZIPInputStream(bis); 或者一次性写成这样： 1234InputStream input = new GZIPInputStream( // 第二层装饰 new BufferedInputStream( // 第一层装饰 new FileInputStream(\"test.gz\") // 核心功能 )); 观察BufferedInputStream和GZIPInputStream，它们实际上都是从FilterInputStream继承的，这个FilterInputStream就是一个抽象的Decorator。Decorator是用于实现各个附加功能的抽象装饰器，对应到IO的就是FilterInputStream。而从Decorator派生的就是一个一个的装饰器，它们每个都有独立的功能，对应到IO的就是BufferedInputStream、GZIPInputStream等。 Decorator模式有什么好处？它实际上把核心功能和附加功能给分开了。核心功能指FileInputStream这些真正读数据的源头，附加功能指加缓冲、压缩、解密这些功能。如果我们要新增核心功能，就增加Component的子类，例如ByteInputStream。如果我们要增加附加功能，就增加Decorator的子类，例如CipherInputStream。两部分都可以独立地扩展，而具体如何附加功能，由调用方自由组合，从而极大地增强了灵活性。 外观外观模式，即Facade，它的基本思想是：如果客户端要跟许多子系统打交道，那么客户端需要了解各个子系统的接口，比较麻烦。如果有一个统一的“中介”，让客户端只跟中介打交道，中介再去跟各个子系统打交道，对客户端来说就比较简单。所以Facade就相当于搞了一个中介。 很多Web程序，内部有多个子系统提供服务，经常使用一个统一的Facade入口，例如一个RestApiController，使得外部用户调用的时候，只关心Facade提供的接口，不用管内部到底是哪个子系统处理的。 更复杂的Web程序，会有多个Web服务，这个时候，经常会使用一个统一的网关入口来自动转发到不同的Web服务，这种提供统一入口的网关就是Gateway，它本质上也是一个Facade，但可以附加一些用户认证、限流限速的额外服务。 享元享元（Flyweight）的核心思想很简单，如果一个对象实例一经创建就不可变，那么反复创建相同的实例就没有必要，直接向调用方返回一个共享的实例就行，这样即节省内存，又可以减少创建对象的过程，提高运行速度。 享元模式在Java标准库中有很多应用。我们知道，包装类型如Byte、Integer都是不变类，因此，反复创建同一个值相同的包装类型是没有必要的。以Integer为例，如果我们通过Integer.valueOf()这个静态工厂方法创建Integer实例，当传入的int范围在-128~`+127之间时，会直接返回缓存的Integer实例。对于Byte来说，因为它一共只有256个状态，所以，通过Byte.valueOf()创建的Byte`实例，全部都是缓存对象。 因此，享元模式就是通过工厂方法创建对象，在工厂方法内部，很可能返回缓存的实例，而不是新创建实例，从而实现不可变实例的复用。 在实际应用中，享元模式主要应用于缓存，即客户端如果重复请求某些对象，不必每次查询数据库或者读取文件，而是直接返回内存中缓存的数据。 在实际应用中，我们经常使用成熟的缓存库，例如Guava的Cache，因为它提供了最大缓存数量限制、定时过期等实用功能。 代理代理模式，即Proxy，它和Adapter模式很相似。Adapter模式用于把A接口转换为B接口，而Proxy模式把A接口转为A接口，Proxy就是给A接口再包一层。 123456789101112public AProxy implements A { private A a; public AProxy(A a) { this.a = a; } public void a() { if (getCurrentUser().isRoot()) { this.a.a(); } else { throw new SecurityException(\"Forbidden\"); }} 我们在调用this.a.a()的前后，加了一些额外代码。这样一来，我们就可以实现权限检查，只有复合要求的用户，才会真正调用目标方法，否则会直接抛出异常。 为啥不把权限检查的功能直接写到目标实例A的内部？ 因为我们编写代码的原则有： 职责清晰：一个类只负责一件事； 易于测试：一次只测一个功能。 用Proxy实现这个权限检查，我们可以获得更清晰、更简洁的代码： A接口：只定义接口； ABusiness类：只实现A接口的业务逻辑； APermissionProxy类：只实现A接口的权限检查代理。 如果我们希望编写其他类型的代理，可以继续增加类似ALogProxy，而不必对现有的A接口、ABusiness类进行修改。 实际上权限检查只是代理模式的一种应用。Proxy还广泛应用在： 远程代理远程代理即Remote Proxy，本地的调用者持有的接口实际上是一个代理，这个代理负责把对接口的方法访问转换成远程调用，然后返回结果。Java内置的RMI机制就是一个完整的远程代理模式。 虚代理虚代理即Virtual Proxy，它让调用者先持有一个代理对象，但真正的对象尚未创建。如果没有必要，这个真正的对象是不会被创建的，直到客户端需要真的必须调用时，才创建真正的对象。JDBC的连接池返回的JDBC连接（Connection对象）就可以是一个虚代理，即获取连接时根本没有任何实际的数据库连接，直到第一次执行JDBC查询或更新操作时，才真正创建实际的JDBC连接。 保护代理保护代理即Protection Proxy，它用代理对象控制对原始对象的访问，常用于鉴权。 智能引用智能引用即Smart Reference，它也是一种代理对象，如果有很多客户端对它进行访问，通过内部的计数器可以在外部调用者都不使用后自动释放它。 小结有的童鞋会发现Proxy模式和Decorator模式有些类似。确实，这两者看起来很像，但区别在于：Decorator模式让调用者自己创建核心类，然后组合各种功能，而Proxy模式决不能让调用者自己创建再组合，否则就失去了代理的功能。Proxy模式让调用者认为获取到的是核心类接口，但实际上是代理类。 代理模式通过封装一个已有接口，并向调用方返回相同的接口类型，能让调用方在不改变任何代码的前提下增强某些功能（例如，鉴权、延迟加载、连接池复用等）。使用Proxy模式要求调用方持有接口，作为Proxy的类也必须实现相同的接口类型。 行为型模式行为型模式主要涉及算法和对象间的职责分配。通过使用对象组合，行为型模式可以描述一组对象应该如何协作来完成一个整体任务。 责任链责任链模式（Chain of Responsibility）是一种处理请求的模式，它让多个处理器都有机会处理该请求，直到其中某个处理成功为止。责任链模式把多个处理器串成链，然后让请求在链上传递。 在实际场景中，财务审批就是一个责任链模式。假设某个员工需要报销一笔费用，审核者可以分为： Manager：只能审核1000元以下的报销； Director：只能审核10000元以下的报销； CEO：可以审核任意额度。 用责任链模式设计此报销流程时，每个审核者只关心自己责任范围内的请求，并且处理它。对于超出自己责任范围的，扔给下一个审核者处理，这样，将来继续添加审核者的时候，不用改动现有逻辑。 责任链模式很容易理解，但需要注意的是，Handler的添加顺序很重要，如果顺序不对，处理的结果可能就是不符合要求的。 此外，责任链模式有很多变种。有些责任链的实现方式是通过某个Handler手动调用下一个Handler来传递Request。还有一些责任链模式，每个Handler都有机会处理Request，通常这种责任链被称为拦截器（Interceptor）或者过滤器（Filter），它的目的不是找到某个Handler处理掉Request，而是每个Handler都做一些工作，比如：记录日志，检查权限，准备相关资源……。 例如，JavaEE的Servlet规范定义的Filter就是一种责任链模式，它不但允许每个Filter都有机会处理请求，还允许每个Filter决定是否将请求“放行”给下一个Filter。这种模式不但允许一个Filter自行决定处理ServletRequest和ServletResponse，还可以“伪造”ServletRequest和ServletResponse以便让下一个Filter处理，能实现非常复杂的功能。 命令命令模式（Command）是指，把请求封装成一个命令，然后执行该命令。 我们用一个StringBuilder模拟一个文本编辑器，它支持copy()、paste()、add()、delete()等方法。 正常情况，我们像这样调用TextEditor： 12345TextEditor editor = new TextEditor();editor.add(\"Command pattern in text editor.\\n\");editor.copy();editor.paste();System.out.println(editor.getState()); 这是直接调用方法，调用方需要了解TextEditor的所有接口信息。 如果改用命令模式，我们就要把调用方发送命令和执行方执行命令分开。怎么分？ 解决方案是引入一个Command接口： 123public interface Command { void execute();} 调用方创建一个对应的Command，然后执行，并不关心内部是如何具体执行的。 为了支持CopyCommand和PasteCommand这两个命令，我们从Command接口派生： 123456789101112131415161718192021222324public class CopyCommand implements Command { // 持有执行者对象: private TextEditor receiver; public CopyCommand(TextEditor receiver) { this.receiver = receiver; } public void execute() { receiver.copy(); }}public class PasteCommand implements Command { private TextEditor receiver; public PasteCommand(TextEditor receiver) { this.receiver = receiver; } public void execute() { receiver.paste(); }} 最后我们把Command和TextEditor组装一下，客户端这么写： 12345678910TextEditor editor = new TextEditor();editor.add(\"Command pattern in text editor.\\n\");// 执行一个CopyCommand:Command copy = new CopyCommand(editor);copy.execute();editor.add(\"----\\n\");// 执行一个PasteCommand:Command paste = new PasteCommand(editor);paste.execute();System.out.println(editor.getState()); 有同学会问了：写了一大堆Command，多了好多个类，还不如直接写方便。实际上，使用命令模式，确实增加了系统的复杂度。如果需求很简单，那么直接调用显然更直观且更简单。那么我们还需要命令模式吗？答案是视需求而定。如果TextEditor复杂到一定程度，并且需要支持Undo、Redo的功能时，就需要使用命令模式，因为我们可以给每个命令增加undo()： 1234public interface Command { void execute(); void undo();} 然后把执行的一系列命令用List保存起来，就既能支持Undo，又能支持Redo。这个时候，我们又需要一个Invoker对象，负责执行命令并保存历史命令. 可见，模式带来的设计复杂度的增加是随着需求而增加的，它减少的是系统各组件的耦合度。 命令模式的设计思想是把命令的创建和执行想分离，使得调用者无需关心具体的执行过程。 解释器解释器模式（Interpreter）是一种针对特定问题设计的一种解决方案。例如，匹配字符串的时候，由于匹配条件非常灵活，使得通过代码来实现非常不灵活。举个例子，针对以下的匹配条件： 以+开头的数字表示的区号和电话号码，如+861012345678； 以英文开头，后接英文和数字，并以.分隔的域名，如www.liaoxuefeng.com； 以/开头的文件路径，如/path/to/file.txt； … 因此，需要一种通用的表示方法——正则表达式来进行匹配。正则表达式就是一个字符串，但要把正则表达式解析为语法树，然后再匹配指定的字符串，就需要一个解释器。 实现一个完整的正则表达式的解释器非常复杂，但是使用解释器模式却很简单： 12String s = \"+861012345678\";System.out.println(s.matches(\"^\\\\+\\\\d+$\")); 类似的，当我们使用JDBC时，执行的SQL语句虽然是字符串，但最终需要数据库服务器的SQL解释器来把SQL“翻译”成数据库服务器能执行的代码，这个执行引擎也非常复杂，但对于使用者来说，仅仅需要写出SQL字符串即可。 解释器模式通过抽象语法树实现对用户输入的解释执行，解释器模式的实现通常非常复杂，且一般只能解决一类特定问题。 迭代器迭代器模式（Iterator）实际上在Java的集合类中已经广泛使用了。我们以List为例，要遍历ArrayList，即使我们知道它的内部存储了一个Object[]数组，也不应该直接使用数组索引去遍历，因为这样需要了解集合内部的存储结构。如果使用Iterator遍历，那么，ArrayList和LinkedList都可以以一种统一的接口来遍历： 1234List&lt;String&gt; list = ...for (Iterator&lt;String&gt; it = list.iterator(); it.hasNext(); ) { String s = it.next();} 实际上，Iterator模式十分有用，因此，Java允许我们直接把任何支持Iterator的集合对象用foreach循环写出来： 1234List&lt;String&gt; list = ...for (String s : list) { ...} 然后由Java编译器完成Iterator模式的所有循环代码。 虽然我们对如何使用Iterator有了一定了解，但是如何实现一个Iterator模式呢？我们以一个自定义集合为例，通过Iterator模式实现倒序遍历。 123456789101112public class ReverseArrayCollection&lt;T&gt; implements Iterable&lt;T&gt; { // 以数组形式持有集合: private T[] array; public ReverseArrayCollection(T... objs) { this.array = Arrays.copyOfRange(objs, 0, objs.length); } public Iterator&lt;T&gt; iterator() { return ???; }} 实现Iterator模式的关键是返回一个Iterator对象，该对象知道集合的内部结构，因为它可以实现倒序遍历。我们使用Java的内部类实现这个Iterator： 1234567891011121314151617181920212223242526272829303132public class ReverseArrayCollection&lt;T&gt; implements Iterable&lt;T&gt; { private T[] array; public ReverseArrayCollection(T... objs) { this.array = Arrays.copyOfRange(objs, 0, objs.length); } public Iterator&lt;T&gt; iterator() { return new ReverseIterator(); } class ReverseIterator implements Iterator&lt;T&gt; { // 索引位置: int index; public ReverseIterator() { // 创建Iterator时,索引在数组末尾: this.index = ReverseArrayCollection.this.array.length; } public boolean hasNext() { // 如果索引大于0,那么可以移动到下一个元素(倒序往前移动): return index &gt; 0; } public T next() { // 将索引移动到下一个元素并返回(倒序往前移动): index--; return array[index]; } }} 使用内部类的好处是内部类隐含地持有一个它所在对象的this引用，可以通过ReverseArrayCollection.this引用到它所在的集合。上述代码实现的逻辑非常简单，但是实际应用时，如果考虑到多线程访问，当一个线程正在迭代某个集合，而另一个线程修改了集合的内容时，是否能继续安全地迭代，还是抛出ConcurrentModificationException，就需要更仔细地设计。 中介中介模式（Mediator）又称调停者模式，它的目的是把多方会谈变成双方会谈，从而实现多方的松耦合。 比如考虑一个简单的点餐输入。复选框有汉堡、鸡块、薯条、咖啡，按钮有全选、反选、取消所有。它的复杂性在于，当复选框变化时，它会影响三个按钮的是否可点击的状态。所以这是一个多方会谈，逻辑写起来很复杂。如果我们引入一个中介，把多方会谈变成多个双方会谈，虽然多了一个对象，但对象之间的关系变简单了。 12345678910111213141516171819202122232425┌─────────────────┐ ┌─────────────────┐│ CheckBox List │&lt;───&gt;│SelectAll Button │└─────────────────┘ └─────────────────┘ ▲ ▲ ▲ │ └─────────────────────┤ ▼ │┌─────────────────┐ ┌────────┴────────┐│SelectNone Button│&lt;────│ Inverse Button │└─────────────────┘ └─────────────────┘ ┌─────────────────┐ ┌─────&gt;│ CheckBox List │ │ └─────────────────┘ │ ┌─────────────────┐ │ ┌───&gt;│SelectAll Button │ ▼ ▼ └─────────────────┘┌─────────┐│Mediator │└─────────┘ ▲ ▲ ┌─────────────────┐ │ └───&gt;│SelectNone Button│ │ └─────────────────┘ │ ┌─────────────────┐ └─────&gt;│ Inverse Button │ └─────────────────┘ 使用Mediator模式后，我们得到了以下好处： 各个UI组件互不引用，这样就减少了组件之间的耦合关系； Mediator用于当一个组件发生状态变化时，根据当前所有组件的状态决定更新某些组件； 如果新增一个UI组件，我们只需要修改Mediator更新状态的逻辑，现有的其他UI组件代码不变。 Mediator模式经常用在有众多交互组件的UI上。为了简化UI程序，MVC模式以及MVVM模式都可以看作是Mediator模式的扩展。 备忘录备忘录模式（Memento），主要用于捕获一个对象的内部状态，以便在将来的某个时候恢复此状态。 其实我们使用的几乎所有软件都用到了备忘录模式。最简单的备忘录模式就是保存到文件，打开文件。对于文本编辑器来说，保存就是把TextEditor类的字符串存储到文件，打开就是恢复TextEditor类的状态。对于图像编辑器来说，原理是一样的，只是保存和恢复的数据格式比较复杂而已。Java的序列化也可以看作备忘录模式。 在使用文本编辑器时，我们还经常使用Undo、Redo这些功能。这些功能也可以由备忘录模式实现，即不定期地把TextEditor类的字符串复制一份存起来，这样就可以Undo或Redo。 标准的备忘录模式有这么几种角色： Memento：存储的内部状态 Originator：创建一个备忘录并设置其状态 Caretaker：负责保存备忘录 实际上我们在使用备忘录模式时，不必设计地这么复杂，只需要对类似TextEditor的类，添加getState()和setState()即可。 我们以一个文本编辑器TextEditor为例，它内部使用StringBuilder允许用户增删字符： 12345678910111213141516171819202122232425262728public class TextEditor { private StringBuilder buffer = new StringBuilder(); public void add(char ch) { buffer.append(ch); } public void add(String s) { buffer.append(s); } public void delete() { if (buffer.length() &gt; 0) { buffer.deleteCharAt(buffer.length() - 1); } } // 获取状态: public String getState() { return buffer.toString(); } // 恢复状态: public void setState(String state) { this.buffer.delete(0, this.buffer.length()); this.buffer.append(state); }} 对这个简单的文本编辑器，用一个String就可以表示其状态，对于复杂的对象模型，通常我们会用JSON、XML等更复杂的格式。 观察者观察者模式（Observer）又称发布-订阅模式（Publish-Subscribe：Pub/Sub）。它是一种通知机制，让发送通知的一方和接收通知的一方能彼此分离，互不影响。 广义的观察者模式包括所有消息系统。所谓消息系统，就是把观察者和被观察者完全分离，通过消息系统本身来通知。消息发送方称为Producer，消息接收方称为Consumer。Producer发送消息的时候，必须选择发送到哪个Topic；Consumer可以订阅自己感兴趣的Topic，从而只获得特定类型的消息。 使用消息系统时，Producer和Consumer经常不在一台机器上，并且互相对对方一无所知。因为注册观察者这个动作本身都在消息系统中完成，而不是在Producer内部完成。 状态状态模式（State）经常用在带有状态的对象中。 什么是状态？以QQ为例，一个用户有离线、登录、在线、忙等状态。我们用一个enum就可以表示不同的状态，但不同的状态要对应不同的行为，比如收到消息时： 12345if (state == ONLINE) { // 闪烁图标} else if (state == BUSY) { reply(\"现在忙，稍后回复\");} else if ... 状态模式的目的就是为了把上述一大串if...else...的逻辑拆分到不同的状态类中，使得将来增加状态类比较容易。 例如，我们设计一个聊天机器人，它有两个状态： 未连线； 已连线。 对于未连线状态，我们收到消息也不回复： 123456789public class DisconnectedState implements State { public String init() { return \"Bye!\"; } public String reply(String input) { return \"\"; }} 对于已连线状态，我们回应收到的消息： 123456789101112131415public class ConnectedState implements State { public String init() { return \"Hello, I'm Bob.\"; } public String reply(String input) { if (input.endsWith(\"?\")) { return \"Yes. \" + input.substring(0, input.length() - 1) + \"!\"; } if (input.endsWith(\".\")) { return input.substring(0, input.length() - 1) + \"!\"; } return input.substring(0, input.length() - 1) + \"?\"; }} 状态模式的关键设计思想在于状态切换，我们引入一个BotContext完成状态切换。 12345678910111213141516public class BotContext { private State state = new DisconnectedState(); public String chat(String input) { if (\"hello\".equalsIgnoreCase(input)) { // 收到hello切换到在线状态: state = new ConnectedState(); return state.init(); } else if (\"bye\".equalsIgnoreCase(input)) { / 收到bye切换到离线状态: state = new DisconnectedState(); return state.init(); } return state.reply(input); }} 策略策略模式（Strategy）指定义一组算法，并封装到一个对象中，在运行时，可以灵活地使用其中的一个算法。策略模式在Java标准库中应用非常广泛，我们以排序为例，看看如何通过Arrays.sort()实现忽略大小写排序。 如果我们想忽略大小写排序，就传入String::compareToIgnoreCase，如果我们想倒序排序，就传入(s1, s2) -&gt; -s1.compareTo(s2)，这个比较两个元素大小的算法就是策略。 我们观察Arrays.sort(T[] a, Comparator&lt;? super T&gt; c)这个排序方法，它在内部实现了TimSort排序，但是，排序算法在比较两个元素大小的时候，需要借助我们传入的Comparator对象，才能完成比较。因此，这里的策略是指比较两个元素大小的策略，可以是忽略大小写比较，可以是倒序比较，也可以根据字符串长度比较。 因此，上述排序使用到了策略模式，它实际上指，在一个方法中，流程是确定的，但是，某些关键步骤的算法依赖调用方传入的策略，这样，传入不同的策略，即可获得不同的结果，大大增强了系统的灵活性。 策略模式的核心思想是在一个计算方法中把容易变换的算法抽出来作为“策略”参数传进去，从而使得新增策略不必修改原有逻辑。 模板方法模板方法（Template Method）是一个比较简单的模式。它的主要思想是，定义一个操作的一系列步骤，对于某些暂时确定不下来的步骤，就留给子类去实现好了，这样不同的子类就可以定义出不同的步骤。因此，模板方法的核心在于定义一个骨架。 假设我们开发了一个从数据库读取设置的类： 12345678910public class Setting { public final String getSetting(String key) { String value = readFromDatabase(key); return value; } private String readFromDatabase(String key) { // TODO: 从数据库读取 }} 由于从数据库读取数据较慢，我们可以考虑把读取的设置缓存起来，这样下一次读取同样的key就不必再访问数据库了。但是怎么实现缓存，暂时没想好，但不妨碍我们先写出使用缓存的代码： 12345678910111213141516public class Setting { public final String getSetting(String key) { // 先从缓存读取: String value = lookupCache(key); if (value == null) { // 在缓存中未找到,从数据库读取: value = readFromDatabase(key); System.out.println(\"[DEBUG] load from db: \" + key + \" = \" + value); // 放入缓存: putIntoCache(key, value); } else { System.out.println(\"[DEBUG] load from cache: \" + key + \" = \" + value); } return value; }} 整个流程没有问题，但是，lookupCache(key)和putIntoCache(key, value)这两个方法还根本没实现，怎么编译通过？这个不要紧，我们声明抽象方法就可以： 1234567891011121314public abstract class AbstractSetting { public final String getSetting(String key) { String value = lookupCache(key); if (value == null) { value = readFromDatabase(key); putIntoCache(key, value); } return value; } protected abstract String lookupCache(String key); protected abstract void putIntoCache(String key, String value);} 因为声明了抽象方法，自然整个类也必须是抽象类。如何实现lookupCache(key)和putIntoCache(key, value)这两个方法就交给子类了。子类其实并不关心核心代码getSetting(key)的逻辑，它只需要关心如何完成两个小小的子任务就可以了。 假设我们希望用一个Map做缓存，那么可以写一个LocalSetting： 1234567891011public class LocalSetting extends AbstractSetting { private Map&lt;String, String&gt; cache = new HashMap&lt;&gt;(); protected String lookupCache(String key) { return cache.get(key); } protected void putIntoCache(String key, String value) { cache.put(key, value); }} 如果我们要使用Redis做缓存，那么可以再写一个RedisSetting： 1234567891011121314151617public class RedisSetting extends AbstractSetting { private RedisClient client = RedisClient.create(\"redis://localhost:6379\"); protected String lookupCache(String key) { try (StatefulRedisConnection&lt;String, String&gt; connection = client.connect()) { RedisCommands&lt;String, String&gt; commands = connection.sync(); return commands.get(key); } } protected void putIntoCache(String key, String value) { try (StatefulRedisConnection&lt;String, String&gt; connection = client.connect()) { RedisCommands&lt;String, String&gt; commands = connection.sync(); commands.set(key, value); } }} 客户端代码使用本地缓存的代码这么写： 123AbstractSetting setting1 = new LocalSetting();System.out.println(\"test = \" + setting1.getSetting(\"test\"));System.out.println(\"test = \" + setting1.getSetting(\"test\")); 要改成Redis缓存，只需要把LocalSetting替换为RedisSetting： 123AbstractSetting setting2 = new RedisSetting();System.out.println(\"autosave = \" + setting2.getSetting(\"autosave\"));System.out.println(\"autosave = \" + setting2.getSetting(\"autosave\")); 可见，模板方法的核心思想是：父类定义骨架，子类实现某些细节。 为了防止子类复写父类的骨架方法，可以在父类中对骨架方法使用final。对于需要子类实现的抽象方法，一般声明为protected，使得这些方法对外部客户端不可见。 Java标准库也有很多模板方法的应用。在集合类中，AbstractList和AbstractQueuedSynchronizer都定义了很多通用操作，子类只需要实现某些必要方法。 访问者访问者模式（Visitor）是一种操作一组对象的操作，它的目的是不改变对象的定义，但允许新增不同的访问者，来定义新的操作。 这里我们只介绍简化的访问者模式。假设我们要递归遍历某个文件夹的所有子文件夹和文件，然后找出.java文件，正常的做法是写个递归： 12345678910void scan(File dir, List&lt;File&gt; collector) { for (File file : dir.listFiles()) { if (file.isFile() &amp;&amp; file.getName().endsWith(\".java\")) { collector.add(file); } else if (file.isDir()) { // 递归调用: scan(file, collector); } }} 上述代码的问题在于，扫描目录的逻辑和处理.java文件的逻辑混在了一起。如果下次需要增加一个清理.class文件的功能，就必须再重复写扫描逻辑。 因此，访问者模式先把数据结构和其对应的操作分离开，以后如果要新增操作，只需要新增访问者，不需要改变现有逻辑。 用访问者模式改写上述代码步骤如下： 首先，我们需要定义访问者接口，即该访问者能够干的事情： 123456public interface Visitor { // 访问文件夹: void visitDir(File dir); // 访问文件: void visitFile(File file);} 紧接着，我们要定义能持有文件夹和文件的数据结构FileStructure： 1234567public class FileStructure { // 根目录: private File path; public FileStructure(File path) { this.path = path; }} 然后，我们给FileStructure增加一个handle()方法，传入一个访问者： 123456789101112131415161718192021public class FileStructure { ... public void handle(Visitor visitor) { scan(this.path, visitor); } private void scan(File file, Visitor visitor) { if (file.isDirectory()) { // 让访问者处理文件夹: visitor.visitDir(file); for (File sub : file.listFiles()) { // 递归处理子文件夹: scan(sub, visitor); } } else if (file.isFile()) { // 让访问者处理文件: visitor.visitFile(file); } }} 这样，我们就把访问者的行为抽象出来了。如果我们要实现一种操作，例如，查找.java文件，就传入JavaFileVisitor： 12FileStructure fs = new FileStructure(new File(\".\"));fs.handle(new JavaFileVisitor()); 这个JavaFileVisitor实现如下： 1234567891011public class JavaFileVisitor implements Visitor { public void visitDir(File dir) { System.out.println(\"Visit dir: \" + dir); } public void visitFile(File file) { if (file.getName().endsWith(\".java\")) { System.out.println(\"Found java file: \" + file); } }} 类似的，如果要清理.class文件，可以再写一个ClassFileClearnerVisitor： 12345678910public class ClassFileCleanerVisitor implements Visitor { public void visitDir(File dir) { } public void visitFile(File file) { if (file.getName().endsWith(\".class\")) { System.out.println(\"Will clean class file: \" + file); } }} 可见，访问者模式的核心是为了访问比较复杂的数据结构，不去改变数据结构，而是把对数据的操作抽象出来，在“访问”的过程中以回调函数形式在访问者中处理操作逻辑。如果要新增一组操作，那么只需要增加一个新的访问者。","link":"/Study/Java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"集合","text":"本节我们介绍Java的集合类型。集合类型也是Java标准库中被使用最多的类型。 Java集合简介什么是集合（Collection）？集合就是由若干个确定的元素所构成的整体。为什么要在计算机中引入集合呢？这是为了便于处理一组类似的数据。 在Java中，如果一个Java对象可以在内部持有若干其他Java对象，并对外提供访问接口，我们把这种Java对象称为集合。很显然，Java的数组可以看作是一种集合。既然Java提供了数组这种数据类型，可以充当集合，那么我们为什么还需要其他集合类？这是因为数组有如下限制： 数组初始化后大小不可变 数组只能按索引顺序存取 因此，我们需要各种不同类型的集合类来处理不同的数据，例如： 可变大小的顺序链表 保证无重复元素的集合 … CollectionJava标准库自带的java.util包提供了集合类：Collection，它是除Map外所有其他集合类的根接口。Java的java.util包主要提供了以下三种类型的集合： List：一种有序列表的集合 Set：一种保证没有重复元素的集合 Map：一种通过键值（key-value）查找的映射表集合 Java的集合设计有几个特点：一是实现了接口和实现类相分离，例如，有序表的接口是List，具体的实现类有ArrayList，LinkedList等；二是支持泛型，我们可以限制在一个集合中只能放入同一数据类型的元素，例如，List&lt;String&gt; list = new ArrayList&lt;&gt;(); // 只能放入String类型；最后，Java访问集合总是通过统一的方式—-迭代器（Iterator）来实现，它最明显的好处在于无需知道集合内部元素是按什么方式存储的。 由于Java的集合设计非常久远，中间经历过大规模改进，我们要注意到有一小部分集合类是遗留类，不应该继续使用： Hashtable：一种线程安全的Map实现 Vector：一种线程安全的List实现 Stack：基于Vector实现的LIFO的栈 还有一小部分接口是遗留接口，也不应该继续使用： Enumeration：已被Iterator取代 使用List在集合类中，List是最基础的一种集合，它是一种有序列表。List的行为和数组几乎完全相同，List内部按照放入元素的先后顺序存放，每个元素都可以通过索引确定自己的位置，List的索引和数组一样，都是从0开始。但在添加和删除元素的时候，使用数组实现会非常麻烦。在实际应用中，需要增删元素的有序列表，我们使用最多的是ArrayList。实际上，ArrayList在内部使用了数组来存储所有的元素。 例如，一个ArrayList拥有5个元素，实际数组大小为6（即有一个空位）。当添加一个元素并指定索引到ArrayList时，ArrayList自动移动需要移动的元素。然后，往内部指定索引的数组位置添加一个元素，然后把size加1。继续添加元素，但是数组已满，没有空闲位置的时候，ArrayList先创建一个更大的新数组，然后把旧数组的所有元素复制到新数组，紧接着用新数组取代旧数组。现在，新数组就有了空位，可以继续添加一个元素到数组末尾，同时size加1。 可见，ArrayList把添加和删除的操作封装起来，让我们操作List类似于操作数组，却不用关心内部元素如何移动。 我们考察List接口，可以看到几个主要的接口方法： 在末尾添加一个元素：boolean add(E e) 在指定索引处添加一个元素：boolean add(int index, E e) 删除指定索引的元素：E remove(int index) 删除某个元素：boolean remove(Object e) 获取指定索引的元素：E get(int index) 获取链表大小：int size() 但是，实现List接口并非只能通过数组来实现，另一种LinkedList通过“链表”也实现了List接口。在LinkedList中，它的内部元素都指向下一个元素。 通常情况下，我们总是优先使用ArrayList。 List的特点使用List时，我们要关注List接口的规范。List接口允许我们添加重复的元素，即List内部的元素可以重复。List还允许添加null。 创建List除了使用ArrayList和LinkedList，我们还可以通过List接口提供的of()方法，根据给定元素快速创建List。 1List&lt;Integer&gt; list = List.of(1, 2, 5); 但是List.of()方法不接受null值，如果传入null，会抛出NullPointerException异常。 遍历List和数组类型一样，我们要遍历一个List，完全可以用for循环根据索引配合get(int)方法遍历。但不推荐这种方式，一是代码复杂，二是get(int)方法只有ArrayList的实现是高效的，换成LinkedList后，索引越大，访问速度越慢。 所以我们要始终坚持使用迭代器Iterator来访问List。Iterator本身也是一个对象，但它是由List的实例调用iterator()方法的时候创建的。Iterator对象知道如何遍历一个List，并且不同的List类型，返回的Iterator对象实现也是不同的，但总是具有最高访问效率。 Iterator对象有两个方法：boolean hasNext()判断是否有下一个元素，E next()返回下一个元素。因此，使用Iterator遍历List代码如下： 12345List&lt;String&gt; list = List.of(\"apple\", \"pear\", \"banana\"); for (Iterator&lt;String&gt; it = list.iterator(); it.hasNext(); ) { String s = it.next(); System.out.println(s);} 有同学可能觉得使用Iterator访问List的代码比使用索引更复杂。但是，要记住，通过Iterator遍历List永远是最高效的方式。并且，由于Iterator遍历是如此常用，所以Java的for each循环本身就可以帮我们使用Iterator遍历。 1234List&lt;String&gt; list = List.of(\"apple\", \"pear\", \"banana\"); for (String s : list) { System.out.println(s);} 上述代码就是我们编写遍历List的常见代码。 实际上，只要实现了Iterator接口的集合类都可以直接用for each循环来遍历，Java编译器本身并不知道如何遍历集合对象，但它会自动把for each循环变成Iterator的调用，原因就在于Iterator接口定义了一个Iterator iterator()方法，强迫集合类必须返回一个Iterator实例。 List和Array转换把List变为Array有三种方法，第一种是调用toArray()方法直接返回一个Object[]数组，这种方法会丢失类型信息，所以实际应用很少。 第二种是给toArray(T[])传入一个类型相同的array，List自动把元素复制到传入的array中。但是如果我们传入的数组大小和List实际的元素个数不一致怎么半？根据List接口的文档，我们知道：如果传入的数组不够大，那么List内部会创建一个新的刚好够大的数组，填充后返回；如果传入的数组比List元素还要多，那么填充完元素后，剩下的数组元素一律填充null。实际上，最常用的是传入一个恰好大小的数组。 最后一种更简洁的写法是通过List接口定义的T[] toArray(IntFunction&lt;T[]&gt; generator)方法。这种函数式的写法我们会在后续讲到。 12345678910111213141516// 第一种List&lt;String&gt; list = List.of(\"apple\", \"pear\", \"banana\");Object[] array = list.toArray();for (Object s : array) { System.out.println(s);}// 第二种List&lt;Integer&gt; list = List.of(12, 34, 56);Integer[] array = list.toArray(new Integer[3]);for (Integer n : array) { System.out.println(n);}// 第二种 改进Integer[] array = list.toArray(new Integer[list.size()]);// 第三种Integer[] array = list.toArray(Integer[]::new); 反过来，把Array变成List就简单多了。通过List.of(T...)方法最简单。 12Integer[] array = { 1, 2, 3 };List&lt;Integer&gt; list = List.of(array); 对于JDK 11以前的版本，可以使用Array.asList(T...)方法把数组转换为List。 要注意的是，返回的List不一定就是ArrayList或者LinkedList，因为List只是一个接口，如果我们调用List.of()，它返回的是一个只读List。对只读List调用add()，remove()方法会抛出UnsupportedOperationException。 编写equals方法我们知道List是一种有序链表：List内部按照放入元素的先后顺序存放，并且每个元素都可以通过索引确定自己的位置。 List还提供了boolean contains(Object o)方法来判断List是否包含某个指定元素。此外，int indexOf(Object o)方法可以返回某个元素的索引，如果元素不存在，就返回-1。 这里我们注意一个问题，我们往List里添加的”C”和调用contains(“C”)传入的”C”是不是同一个实例？ 123List&lt;String&gt; list = List.of(\"A\", \"B\", \"C\");System.out.println(list.contains(new String(\"C\"))); // true or false? trueSystem.out.println(list.indexOf(new String(\"C\"))); // 2 or -1? 2 我们传入的是new String(\"C\")，所以一定是不同的实例。结果仍然是true，这是为什么呢？因为List内部并不是通过==判断两个元素是否相等，而是使用equals()方法判断两个元素是否相等。对于引用字段比较，我们使用equals()，对于基本类型字段的比较，我们使用==。 因此，要正确使用List的contains()，indexOf()这些方法，放入的实例必须正确覆写equals()方法，否则查不到放进去的实例。我们之所以能正常放入String，Integer这些对象，是因为Java标准库定义的这些类已经正确实现了equals()方法。我们来测试一下。 123456789101112131415161718import java.util.List;public class Main { public static void main(String[] args) { List&lt;Person&gt; list = List.of( new Person(\"Xiao Ming\"), new Person(\"Xiao Hong\"), new Person(\"Bob\") ); System.out.println(list.contains(new Person(\"Bob\"))); // false }}class Person { String name; public Person(String name) { this.name = name; }} 编写equals如何正确编写equals()方法？equals()方法要求必须满足以下条件： 自反性（Reflexive）：对于非null的x来说，x.equals(x)必须返回true； 对称性（Symmetric）：对于非null的x和y来说，如果x.equals(y)为true，则y.equals(x)也必须为true； 传递性（Transitive）：对于非null的x、y和z来说，如果x.equals(y)为true，y.equals(z)也为true，那么x.equals(z)也必须为true； 一致性（Consistent）：对于非null的x和y来说，只要x和y状态不变，则x.equals(y)总是一致地返回true或者false； 对null的比较：即x.equals(null)永远返回false。 上述规则看上去很复杂，但其实代码实现equals()方法是很简单的，以Person类为例。首先我们要定义“相等”的逻辑含义。对于Person类，如果name相等，并且age相等，我们就认为两个Person实例相等。 123456789101112public class Person { public String name; public int age; public boolean equals(Object o) { if (o instanceof Person) { Person p = (Person) o; return this.name.equals(p.name) &amp;&amp; this.age == p.age; } return false; }} 如果this.name为null，那么equals()方法会报错，因此需要改写。 1234567891011121314public boolean equals(Object o) { if (o instanceof Person) { Person p = (Person) o; boolean nameEquals = false; if (this.name == null &amp;&amp; p.name == null) { nameEquals = true; } if (this.name != null) { nameEquals = this.name.equals(p.name); } return nameEquals &amp;&amp; this.age == p.age; } return false;} 如果Person有好几个引用类型的字段，上面的写法就太复杂了。要简化引用类型的比较，我们使用Objects.equals()静态方法。 1234567public boolean equals(Object o) { if (o instanceof Person) { Person p = (Person) o; return Objects.equals(this.name, p.name) &amp;&amp; this.age == p.age; } return false;} 因此，我们总结一下equals()的正确编写方法： 先确定实例“相等”的逻辑，即哪些字段相等，就认为实例相等； 用instanceof判断传入的待比较的Object是不是当前类型，如果是，继续比较，否则，返回false； 对引用类型用Objects.equals()比较，对基本类型直接用==比较。 使用Objects.equals()比较两个引用类型是否相等的目的是省去了判断null的麻烦。两个引用类型都是null时它们也是相等的。 如果不在List种查找元素，即不调用List的contains()、indexOf()这些方法，那么放入的元素就不需要实现equals()方法。 使用Map我们知道，List是一种顺序列表，如果有一个存储学生Student实例的List，要在List种根据name查找某个指定的Student分数，应该怎么办？最简单的方法是遍历List并判断name是否相等，然后返回指定元素。 这种需求其实非常常见，即通过一个键去查询对应的值。使用List来实现存在效率非常低的问题，因为平均需要扫描一半的元素才能确定。而Map这种键值（key-value）映射表的数据结构，作用就是能高校通过keyu快速查找value（元素）。 用Map来实现根据name查询某个student的代码如下。 1234567891011121314151617181920212223import java.util.HashMap;import java.util.Map;public class Main { public static void main(String[] args) { Student s = new Student(\"Xiao Ming\", 99); Map&lt;String, Student&gt; map = new HashMap&lt;&gt;(); map.put(\"Xiao Ming\", s); // 将\"Xiao Ming\"和Student实例映射并关联 Student target = map.get(\"Xiao Ming\"); // 通过key查找并返回映射的Student实例 System.out.println(target == s); // true，同一个实例 System.out.println(target.score); // 99 Student another = map.get(\"Bob\"); // 通过另一个key查找 System.out.println(another); // 未找到返回null }}class Student { public String name; public int score; public Student(String name, int score) { this.name = name; this.score = score; }} 通过上述代码可知：Map&lt;K, V&gt;是一种键值映射表，当我们调用put(K key, V value)方法时，就把key和value做了映射并放入Map。当我们调用V get(K key)时，就可以通过key获取对应的value。如果key不存在，则返回null。和List类似，Map也是一个接口，最常用的实现类是HashMap。 如果想查询某个key是否存在，可以调用boolean containsKey(K key)方法。 如果我们在存储Map映射关系的时候，对同一个key调用两次put()方法，分别放入不同的value，会出现什么问题呢？答：重复放入key-value并不会有任何问题，但是一个key只能关联一个value。实际上，put()方法的签名是V put(K key, V value)，如果放入的key已经存在，put()方法会返回被删除的旧的value，否则，返回null。始终牢记：Map中不存在重复的key，因为放入相同的key，只会把原有的key-value对应的value给替换掉。 此外，在一个Map中，虽然key不能重复，但value是可以重复的。 遍历Map对Map来说，要遍历key可以使用for each循环，遍历Map实例的keySet()方法返回的Set集合，它是包含不重复key的集合。 12345678Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(\"apple\", 123);map.put(\"pear\", 456);map.put(\"banana\", 789);for (String key : map.keySet()) { Integer value = map.get(key); System.out.println(key + \" = \" + value);} 同时遍历key和value可以遍历Map实例的entrySet()集合，它包含每一个key-value实例。 123456789Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(\"apple\", 123);map.put(\"pear\", 456);map.put(\"banana\", 789);for (Map.Entry&lt;String, Integer&gt; entry : map.entrySet()) { String key = entry.getKey(); Integer value = entry.getValue(); System.out.println(key + \" = \" + value);} Map和List不同的是，Map存储的是key-value的映射关系，并且，它不保证顺序。在遍历的时候，遍历的顺序既不一定是put()时放入的key的顺序，也不一定是key的排序顺序。使用Map时，任何依赖顺序的逻辑都是不可靠的。以HashMap为例，假设我们放入”A”，”B”，”C”这3个key，遍历的时候，每个key会保证被遍历一次且仅遍历一次，但顺序完全没有保证，甚至对于不同的JDK版本，相同的代码遍历的输出顺序都是不同的！ 遍历Map时，不可假设输出的key是有序的！ 编写equals和hashCode我们知道Map是一种键值映射表，可以通过key快速查找对应的value。以HashMap为例，HashMap之所以能根据key直接拿到value，原因是它内部通过空间换时间的方法，用一个大数组存储所有value，并根据key直接计算出value应该存储在哪个索引。 1234567Map&lt;String, Person&gt; map = new HashMap&lt;&gt;();map.put(\"a\", new Person(\"Xiao Ming\"));map.put(\"b\", new Person(\"Xiao Hong\"));map.put(\"c\", new Person(\"Xiao Jun\"));map.get(\"a\"); // Person(\"Xiao Ming\")map.get(\"x\"); // null 如果key的值为”a”，计算得到的索引总是1，因此返回value为Person(“Xiao Ming”)，如果key的值为”b”，计算得到的索引总是5，因此返回value为Person(“Xiao Hong”)，这样，就不必遍历整个数组，即可直接读取key对应的value。 当我们使用key存取value的时候，就会引出一个问题：我们放入Map的key是字符串”a”，但是，当我们获取Map的value时，传入的变量不一定就是放入的那个key对象。换句话讲，两个key应该是内容相同，但不一定是同一个对象。 123456789String key1 = \"a\";Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(key1, 123);String key2 = new String(\"a\");map.get(key2); // 123System.out.println(key1 == key2); // falseSystem.out.println(key1.equals(key2)); // true 因为在Map内部，对key作比较是通过equals()实现的，这一点和List查找元素需要正确覆写equals()是一样的。即正确使用Map必须保证：作为key的对象必须正确覆写了equals()方法。 我们经常使用String作为key，因为String已经正确覆写了equals()。但如果我们放入的key是一个自己写的类，就必须保证正确覆写了equals()。 我们再思考一下HashMap为什么能通过key直接计算出value存储的索引。相同的key对象必须要计算出相同的索引，否则，相同的key每次取出的value就不一定对。通过key计算索引的方式就是调用key对象的hashCode()方法，它返回一个int整数。HashMap正是通过这个方法直接定位key对应的value的索引，继而直接返回value。 因此，正确使用Map必须保证： 作为key的对象必须正确覆写equals()方法，相等的两个key实例调用equals()必须返回true 作为key的对象必须正确覆写hashCode()方法，且hashCode()方法要严格遵循以下规范： 如果两个对象相等，则两个对象的hashCode()必须相等 如果两个对象不相等，则两个对象的hashCode()尽量不要相等 上述第一条规范是正确性，必须保证实现，否则HashMap不能正常工作。第二条规范尽量满足，这样可以保证查询效率。因为不同的对象，如果返回相同的hashCode()，会造成Map内部存储冲突，使存储效率下降。 正确编写equals()的方法我们在上两节讲过了，以Person类为例，首先，把需要比较的字段找出来；然后，引用类型使用Objects.equals()比较，基本类型使用==比较。在正确实现equals()的基础上，我们还需要正确实现hashCode()，即上述字段分别相同的实例，hashCode()返回的int必须相同。 1234567891011121314public class Person { String firstName; String lastName; int age; @Override int hashCode() { int h = 0; h = 31 * h + firstName.hashCode(); h = 31 * h + lastName.hashCode(); h = 31 * h + age; return h; }} 主要到String类已经正确实现了hashCode()方法，我们在计算Person的hashCode()时，反复使用31*h，这样做的目的是为了尽量把不同的Person实例的hashCode()均匀分布在整个int范围。 和实现equals()方法遇到的问题类似，如果firstName或lastName为null，上述代码工作起来就会抛NullPointerException。为了解决这个问题，我们在计算hashCode()的时候，经常借助Objects.hash()来计算。 123int hashCode() { return Objects.hash(firstName, lastName, age);} 所以，编写equals()和hashCode()遵循的原则是：equals()用到的用于比较的每一字段，都必须在hashCode()中用于计算；equals()中没有使用到的字段，绝不可放在hashCode()中计算。 另外注意，对于放入HashMap的value对象，没有任何要求。 延伸阅读既然HashMap内部使用了数组，通过计算key的hashCode()直接定位value所在的索引，那么第一个问题来了：hashCode()返回的int范围高达±21亿，先不考虑负数，HashMap内部使用的数组得有多大？ 实际上，HashMap初始化时默认的数组大小只有16，任何key，无论它的hashCode()有多大，都可以简单通过： 1int index = key.hashCode() &amp; 0xf; // 0xf = 15 把索引确定再0~15，即永远不会超出数组范围，上述算法只是一种最简单的实现。 第二个问题：如果添加超过16个key-value到HashMap，数组不够用了怎么办？添加超过一定数量的key-value时，HashMap会在内部自动扩容，每次扩容一倍，即数组的长度从16扩展为32，相应的，需要重新确定hashCode()计算的索引位置。例如，对长度为32的数组计算hashCode()对应的索引，计算方式要改为： 1int index = key.hashCode() &amp; 0x1f; // 0x1f = 31 由于扩容会导致重新分布已有的key-value，所以频繁扩容对HashMap的性能影响很大。如果我们确定要使用一个容量为10000个key-value的HashMap，更好的方式是创建HashMap时就指定容量： 1Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(10000); 虽然指定容量是10000，但HashMap内部的数组长度总是2^n，因此实际数组长度被初始化为2^14=16384&gt;10000。 最后一个问题：如果不同的两个key，他们的hashCode()恰好是相同的，那后面放的value会不会把前面的value覆盖了？当然不会！使用Map的时候，只要key不相同，它们映射的value就互不干扰。但是，在HashMap内部，确实可能存在不同的key，映射到相同的hashCode()，即相同的数组索引上，肿么办？ 我们假设”a”和”b”这两个key最终计算出的索引都是5，那么在HashMap的数组中，实际存储的不是一个Person实例，而是一个包含两个Entry的List，一个是”a”的映射，一个是”b”的映射。在查找的时候，Person p = map.get(\"a\")，HashMap内部通过”a”找到的实际上是List&lt;Entry&lt;String, Person&gt;&gt;，它还需要遍历这个List，并找到key字段是”a”的Entry，再返回对应的Person实例。 我们把不同的key具有相同hashCode()的情况称为哈希冲突。在冲突的时候，一种最简单的解决办法是用List存储hashCode()相同的key-value。显然，如果冲突的概率越大，这个List就越长，Map的get()方法效率就越低，这就解释了为什么要尽量满足第二条规范。 hashCode()方法编写的越好，HashMap工作的效率越高。实现hashCode()方法可以通过Objects.hashCode()辅助方法实现。 使用EnumMap我们知道，HashMap通过对key计算hashCode()，通过空间换时间的方式，直接定位到value所在的内部数组的索引，因此查询效率非常高。 如果作为key的对象是enum类型，那么还可以使用Java集合库提供的一种EnumMap，它在内部以一个非常紧凑的数组存储value，并且根据enum类型的key直接定位到内部数组的索引，并不需要计算hashCode()，不但效率最高，而且没有额外的空间浪费。 使用EnumMap的时候，我们总是用Map接口来引用它。因此，实际上把HashMap和EnumMap互换，在客户端没有任何差别。 使用TreeMap我们知道，HashMap是一种以空间换时间的映射表，它的实现原理决定了内部的key是无序的，即遍历HashMap的key时，其顺序是不可预测的，但每个key都会且仅遍历一次。 还有一种Map，它在内部会对key进行排序，这种Map就是SortedMap，注意SortedMap是接口，其最常用的实现类是TreeMap。 SortedMap保证遍历时以key的顺序来进行排序。例如，放入的Key是”apple”、”pear”、”orange”，遍历的顺序一定是”apple”、”orange”、”pear”，因为String默认按字母排序。 使用TreeMap时，放入的key必须实现Comparable接口。String，Integer这些类已经实现了Comparable接口，因此可以直接作为key使用，作为value的对象则没有任何要求。 如果作为key的class没有实现Comparable接口，那么，必须在创建TreeMap时指定一个自定义排序算法。 12345678910111213141516171819202122232425262728import java.util.*;public class Main { public static void main(String[] args) { Map&lt;Person, Integer&gt; map = new TreeMap&lt;&gt;(new Comparator&lt;Person&gt;() { public int compare(Person p1, Person p2) { return p1.name.compareTo(p2.name); } }); map.put(new Person(\"Tom\"), 1); map.put(new Person(\"Bob\"), 2); map.put(new Person(\"Lily\"), 3); for (Person key : map.keySet()) { System.out.println(key); } // {Person: Bob}, {Person: Lily}, {Person: Tom} System.out.println(map.get(new Person(\"Bob\"))); // 2 }}class Person { public String name; Person(String name) { this.name = name; } public String toString() { return \"{Person: \" + name + \"}\"; }} 注意到Comparator接口要求实现一个比较方法，它负责比较传入的两个元素a和b，如果a&lt;b，则返回负数，通常是-1，如果a==b，则返回0，如果a&gt;b，则返回正数，通常是1。TreeMap内部根据比较结果对Key进行排序。 如果要根据Key查找Value，我们可以传入一个new Person(\"Bob\")作为Key，它会返回对应的Integer值2。 另外，注意到Person类并未覆写equals()和hashCode()，因为TreeMap不使用equals()和hashCode()。 我们来看一个稍微复杂的例子，这次我们定义了Student类，并用分数score进行排序。 1234567891011121314151617181920212223242526272829import java.util.*;public class Main { public static void main(String[] args) { Map&lt;Student, Integer&gt; map = new TreeMap&lt;&gt;(new Comparator&lt;Student&gt;() { public int compare(Student p1, Student p2) { return p1.score &gt; p2.score ? -1 : 1; } }); map.put(new Student(\"Tom\", 77), 1); map.put(new Student(\"Bob\", 66), 2); map.put(new Student(\"Lily\", 99), 3); for (Student key : map.keySet()) { System.out.println(key); } System.out.println(map.get(new Student(\"Bob\", 66))); // null? }}class Student { public String name; public int score; Student(String name, int score) { this.name = name; this.score = score; } public String toString() { return String.format(\"{%s: score=%d}\", name, score); }} 在for循环中，我们确实得到了正确的顺序。但是，且慢！根据相同的Key：new Student(\"Bob\", 66)进行查找时，结果为null！这是怎么回事？在这个例子中，TreeMap出现问题，原因出在这个Comparator上。在p1.score和p2.score不相等的时候，它的返回值是正确的，但是，在p1.score和p2.score相等的时候，它并没有返回0！这就是为什么TreeMap工作不正常的原因：TreeMap在比较两个Key是否相等时，依赖Key的compareTo()方法或者Comparator.compare()方法。在两个Key相等时，必须返回0。 我们修改代码如下： 123456public int compare(Student p1, Student p2) { if (p1.score == p2.score) { return 0; } return p1.score &gt; p2.score ? -1 : 1;} 或者直接借助Integer.compare(int, int)也可以返回正确结果。 作为SortedMap的Key必须实现Comparable接口，或者传入Comparator； 要严格按照compare()规范实现比较逻辑，否则，TreeMap将不能正常工作。 使用Properties在编写应用程序时，经常需要读写配置文件。例如，用户的设置： 1234# 上次最后打开的文件:last_open_file=/data/hello.txt# 自动保存文件的时间间隔:auto_save_interval=60 配置文件的特点是，它的key-value一般都是String-String类型的，因此我们完全可以用Map&lt;String, String&gt;来表示。因为配置文件非常有用，所以Java集合库提供了一个Properties来表示一组“配置”。由于历史遗留原因，Properties内部本质上是一个Hashtable，但我们只需要用到Properties自身关于读写配置的接口。 读取配置文件用Properties读取配置文件非常简单。Java默认配置文件以.properties为扩展名，每行以key=value表示，以#开头的是注释。可以从文件系统读取上述.properties文件。 123456String f = \"setting.properties\";Properties props = new Properties();props.load(new java.io.FileInputStream(f));String filepath = props.getProperty(\"last_open_file\");String interval = props.getProperty(\"auto_save_interval\", \"120\"); 可见，用Properties读取配置文件按，一共有三步： 创建Properties实例 调用load()读取文件 调用getProperty()获取配置 调用getProperty()获取配置时，如果key不存在，将返回null。我们还可以提供一个默认值，这样，当key不存在的时候，就返回默认值。 也可以从classpath读取.properties文件，因为load(InputStream)方法接受一个InputStream实例，表示一个字节流，它不一定是文件流，也可以是从jar包读取的资源流。 12Properties props = new Properties();props.load(getClass().getResourceAsStream(\"/common/setting.properties\")); 还可以从内存中读取一个字节流。 如果有多个.properties文件，可以反复调用load()读取，后读取的key-value会覆盖已读取的key-value。 123Properties props = new Properties();props.load(getClass().getResourceAsStream(\"/common/setting.properties\"));props.load(new FileInputStream(\"C:\\\\conf\\\\setting.properties\")); 上面的代码演示了Properties的一个常用用法：可以把默认配置文件放到classpath中，然后，根据机器的环境编写另一个配置文件，覆盖某些默认的配置。 Properties设计的目的是存储String类型的key－value，但Properties实际上是从Hashtable派生的，它的设计实际上是有问题的，但是为了保持兼容性，现在已经没法修改了。除了getProperty()和setProperty()方法外，还有从Hashtable继承下来的get()和put()方法，这些方法的参数签名是Object，我们在使用Properties的时候，不要去调用这些从Hashtable继承下来的方法。 写入配置文件如果通过setProperty()修改了Properties实例，可以把配置写入文件，以便下次启动时获得最新配置。写入配置文件使用store()方法。 1234Properties props = new Properties();props.setProperty(\"url\", \"http://www.liaoxuefeng.com\");props.setProperty(\"language\", \"Java\");props.store(new FileOutputStream(\"C:\\\\conf\\\\setting.properties\"), \"这是写入的properties注释\"); 编码早期版本的Java规定.properties文件编码是ASCII编码（ISO8859-1），如果涉及到中文就必须用name=\\u4e2d\\u6587来表示，非常别扭。从JDK9开始，Java的.properties文件可以使用UTF-8编码了。 不过，需要注意的是，由于load(InputStream)默认总是以ASCII编码读取字节流，所以会导致读到乱码。我们需要用另一个重载方法load(Reader)读取： 12Properties props = new Properties();props.load(new FileReader(\"settings.properties\", StandardCharsets.UTF_8)); 就可以正常读取中文。InputStream和Reader的区别是一个是字节流，一个是字符流。字符流在内存中已经以char类型表示了，不涉及编码问题。 使用Set我们知道，Map用于存储key-value的映射，对于充当key的对象，是不能重复的，并且，不但需要正确覆写equals()方法，还要正确覆写hashCode()方法。 如果我们只需要存储不重复的key，并不需要存储映射的value，那么就可以使用Set。Set用于存储不重复元素的集合，它主要提供以下几个方法： 将元素添加进Set：boolean add(E e) 将元素从Set删除：boolean remove(Object e) 判断是否包含元素：boolean contains(Object e) Set实际上相当于只存储key，不存储value的Map。我们经常使用Set用于去除重复元素。因为放入Set的元素和Map的key类似，都要正确实现equals()和hashCode()方法，否则该元素无法正确的放入Set。最常用的Set的实现类是HashSet，实际上，HashSet仅仅是对HashMap的一个简单封装，它的核心代码如下： 12345678910111213141516171819public class HashSet&lt;E&gt; implements Set&lt;E&gt; { // 持有一个HashMap: private HashMap&lt;E, Object&gt; map = new HashMap&lt;&gt;(); // 放入HashMap的value: private static final Object PRESENT = new Object(); public boolean add(E e) { return map.put(e, PRESENT) == null; } public boolean contains(Object o) { return map.containsKey(o); } public boolean remove(Object o) { return map.remove(o) == PRESENT; }} Set接口不保证有序，而SortedSet保证元素是有序的。HashSet是无序的，因为它实现了Set接口，并没有实现SortedSet接口；TreeSet是有序的，因为它实现了SortedSet接口。 使用TreeSet和使用TreeMap的要求一样，添加的元素必须正确实现Comparable接口，如果没有实现Comparable接口，那么创建TreeSet时必须传入一个Comparator对象。 使用Queue队列（Queue）是一种经常使用的集合。Queue实际上是实现了一个先进先出的有序表。它和List的区别在于，List可以在任意位置添加和删除元素，而Queue只有两个操作： 把元素添加到队列末尾 从队列头部取出元素 在Java标准库中，队列接口Queue定义了以下几个方法： int size()，获取队列长度 boolean add(E)/boolean offer(E)，添加元素到队尾 E remove()/E poll()，获取队首元素并从队列中删除 E element()/E peek()，获取队首元素但并不从队列中删除 对于具体的实现类，有的Queue有最大队列长度限制，有的Queue没有。注意到添加、删除和获取队首元素总是有两个方法，这是因为在添加和删除失败时，这两个方法的行为是不同的。 操作 throw Exception 返回false或null 添加元素到队尾 add(E e) boolean offer(E e) 取队首元素并删除 E remove() E poll() 取队首元素但不删除 E element() E peek() 因此，两套方法可以根据需要来选择使用。注意，不要把null添加到队列中，不然很难确定是取到了null元素还是队列为空。 LinkedList即实现了List接口，又实现了Queue接口，使用时，把它当作List就获取List的引用，把它当作Queue就获取Queue的引用。始终按照面向抽象编程的原则编写代码，可以大大提高代码质量。 1234// 这是一个List:List&lt;String&gt; list = new LinkedList&lt;&gt;();// 这是一个Queue:Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); 使用PriorityQueue我们知道，Queue是一个先进先出的队列。但当我们要实现“VIP插队”的业务，用Queue就不行了，因为Queue会严格遵循FIFO的原则，这时我们就需要优先队列PriorityQueue。 PriorityQueue和Queue的区别在于，它的出队顺序与元素的优先级相关，对PriorityQueue调用remove()或poll()方法，返回的总是优先级最高的元素。因此，要使用PriorityQueue，就必须给每个元素定义优先级。 因此，放入PriorityQueue的元素，必须实现Comparable接口，PriorityQueue会根据元素的排序顺序决定出队的优先级。如果我们要放入的元素并没有实现Comparable接口怎么办？PriorityQueue允许我们提供一个Comparator对象来判断两个元素的顺序。我们以银行排队业务为例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.Comparator;import java.util.PriorityQueue;import java.util.Queue;public class Main { public static void main(String[] args) { Queue&lt;User&gt; q = new PriorityQueue&lt;&gt;(new UserComparator()); // 添加3个元素到队列: q.offer(new User(\"Bob\", \"A1\")); q.offer(new User(\"Alice\", \"A2\")); q.offer(new User(\"Boss\", \"V1\")); System.out.println(q.poll()); // Boss/V1 System.out.println(q.poll()); // Bob/A1 System.out.println(q.poll()); // Alice/A2 System.out.println(q.poll()); // null,因为队列为空 }}class UserComparator implements Comparator&lt;User&gt; { public int compare(User u1, User u2) { if (u1.number.charAt(0) == u2.number.charAt(0)) { // 如果两人的号都是A开头或者都是V开头,比较号的大小: return u1.number.compareTo(u2.number); } if (u1.number.charAt(0) == 'V') { // u1的号码是V开头,优先级高: return -1; } else { return 1; } }}class User { public final String name; public final String number; public User(String name, String number) { this.name = name; this.number = number; } public String toString() { return name + \"/\" + number; }} 实现PriorityQueue的关键在于提供的UserComparator对象，它负责比较两个元素的大小（较小的在前）。UserComparator总是把V开头的号码优先返回，只有在开头相同的时候，才比较号码大小。 使用Deque我们知道，Queue是队列，只能一头进一头出。如果把条件放松，允许两头都进两头都出，这种队列叫双端队列（Double Ended Queue），学名Deque。Java集合提供了接口Deque来实现一个双端队列，它的功能： 既可以添加到队尾，也可以添加到队首 既可以从队首获取，又可以从队尾获取 我们来比较一下Queue和Deque出队和入队的方法： Queue Deque 添加元素到队尾 add(E e) / offer(E e) addLast(E e) / offerLast(E e) 取队首元素并删除 E remove() / E poll() E removeFirst() / E pollFirst() 取队首元素但不删除 E element() / E peek() E getFirst() / E peekFirst() 添加元素到队首 无 addFirst(E e) / offerFirst(E e) 取队尾元素并删除 无 E removeLast() / E pollLast() 取队尾元素但不删除 无 E getLast() / E peekLast() 注意到Deque接口实际上扩展自Queue，因此，Queue提供的add()/offer()方法在Deque中也能用，但是使用Deque最好不要调用offer()，而是调用offerLast()。使用Deque，推荐总是明确调用offerLast()/offerFirst()或者pollFirst()/pollLast()方法。 Deque是一个接口，它的实现类有ArrayDeque和LinkedList。我们发现LinkedList真是一个全能选手，它即是List，又是Queue，还是Deque。但是我们在使用的时候，总是用特定的接口来引用它，这是因为持有接口说明代码的抽象层次更高，而且接口本身定义的方法代表了特定的用途。 123456// 不推荐的写法:LinkedList&lt;String&gt; d1 = new LinkedList&lt;&gt;();d1.offerLast(\"z\");// 推荐的写法：Deque&lt;String&gt; d2 = new LinkedList&lt;&gt;();d2.offerLast(\"z\"); 使用Stack栈（Stack）是一种后进先出的数据结构，只能不断的往Stack中压入（push）元素，最后进去的必须最早弹出（pop）来。Stack只有入栈和出栈操作： 把元素压栈，push(E) 把栈顶元素弹出，pop() 取栈顶元素但不弹出，peek() 在Java中，我们用Deque可以实现Stack的功能： 把元素压栈：push(E)/addFirst(E) 把栈顶的元素弹出：pop()/removeFirst() 取栈顶元素但不弹出：peek()/peekFirst() 为什么Java的集合类没有单独的Stack接口呢？因为有个遗留类的名字就叫Stack，出于兼容性考虑，所以没办法创建Stack接口，只能用Deque接口来模拟一个Stack了。当我们把Deque当Stack来用时，主意只调用push()/pop()/peek()方法，不要调用addFirst()/removeFirst()/peekFirst()方法，这样使代码更加清晰。 Stack的作用Stack在计算机中使用非常广泛，JVM在处理Java方法调用的时候就会通过栈这种数据结构维护方法调用的层次。JVM会创建方法调用栈，每调用一个方法时，先将参数压栈，然后执行对应的方法；当方法返回时，返回值压栈，调用方法通过出栈操作获得方法返回值。 因为方法调用栈有容量限制，嵌套调用太多会造成栈溢出，即引发StackOverflowError。 对整数进行进制转换就可以利用栈。 中缀表达式转为后缀表达式会用到栈。计算后缀表达式也会用到栈。 使用IteratorJava的集合类都可以使用for each循环，List、Set和Queue会迭代每个元素，Map会迭代每个key。 1234List&lt;String&gt; list = List.of(\"Apple\", \"Orange\", \"Pear\");for (String s : list) { System.out.println(s);} 实际上，Java编译器并不知道如何遍历List，上述代码能够编译通过，只是因为编译器把for each循环通过Iterator写成了普通的for循环： 1234for (Iterator&lt;String&gt; it = list.iterator(); it.hasNext(); ) { String s = it.next(); System.out.println(s);} 我们把这种通过Iterator对象遍历集合的模式称为迭代器。使用迭代器的好处在于，调用方总是以统一的方式遍历各种集合类型，而不必关心他们内部的存储结构。 例如，我们虽然知道ArrayList在内部是以数组形式存储元素，并且它还提供了get(int)方法。虽然我们可以用for循环遍历，但是这样一来，调用方就必须知道集合的内部存储结构。并且，如果把ArrayList换成LinkedList，get(int)方法耗时会随着index的增加而增加。如果把ArrayList换为Set，上述代码就无法编译，因为Set内部没有索引。 用Iterator遍历就没有上述问题，因为Iterator对象是集合在自己内部创建的，它自己知道如何高效遍历内部的数据集合，调用方则获得了统一的代码，编译器才能把标准的for each循环自动转换成Iterator遍历。 如果我们自己编写了一个集合类，想要使用for each循环，只需满足下面的条件： 集合类实现Iterator接口，该接口要求返回一个Iterator对象 用Iterator对象迭代集合内部数据 这里的关键在于，集合类通过调用iterator()方法，返回一个Iterator对象，这个对象必须自己知道如何遍历该集合。一个简单的Iterator示例如下，它总是以倒序遍历集合： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.*;public class Main { public static void main(String[] args) { ReverseList&lt;String&gt; rlist = new ReverseList&lt;&gt;(); rlist.add(\"Apple\"); rlist.add(\"Orange\"); rlist.add(\"Pear\"); for (String s : rlist) { System.out.println(s); } }}class ReverseList&lt;T&gt; implements Iterable&lt;T&gt; { private List&lt;T&gt; list = new ArrayList&lt;&gt;(); public void add(T t) { list.add(t); } @Override public Iterator&lt;T&gt; iterator() { return new ReverseIterator(list.size()); } class ReverseIterator implements Iterator&lt;T&gt; { int index; ReverseIterator(int index) { this.index = index; } @Override public boolean hasNext() { return index &gt; 0; } @Override public T next() { index--; return ReverseList.this.list.get(index); } }} 虽然ReverseList和ReverseIterator的实现类稍微比较复杂，但是，注意到这是底层集合库，只需编写一次。而调用方则完全按for each循环编写代码，根本不需要知道集合内部的存储逻辑和遍历逻辑。 在编写Iterator的时候，我们通常可以用一个内部类来实现Iterator接口，这个内部类可以直接访问对应的外部类的所有字段和方法。例如，上述代码中，内部类ReverseIterator可以用ReverseList.this获得当前外部类的this引用，然后，通过这个this引用就可以访问ReverseList的所有字段和方法。 使用CollectionsCollections是JDK提供的工具类，同样位于java.util包中，它提供了一系列静态方法，能更方便的操作各种集合。 我们一般看方法名和参数就可以确认Collections提供的该方法的功能。例如，对于以下静态方法： 1public static boolean addAll(Collection&lt;? super T&gt; c, T... elements) { ... } addAll()方法可以给一个Collection类型的集合添加若干元素。因为方法签名是Collection，所以我们可以传入List，Set等各种集合类型。 创建空集合Collections提供了一系列方法来创建空集合： 创建空List：List&lt;T&gt; emptyList() 创建空Map：Map&lt;K, V&gt; emptyMap() 创建空Set：Set&lt;T&gt; emptySet() 注意，返回的空集合是不可变集合，无法向其中添加或删除元素。 此外，也可以用各个集合接口提供的of(T...)方法创建空集合，以下两个创建空List的方法是等价的。 12List&lt;String&gt; list1 = List.of();List&lt;String&gt; list2 = Collections.emptyList(); 创建单元素集合Collections提供了一系列方法来创建一个单元素集合： 创建一个元素的List：List&lt;T&gt; singletonList(T o) 创建一个元素的Map：Map&lt;K, V&gt; singletonMap(K key, V value) 创建一个元素的Set：Set&lt;T&gt; singleton(T o) 要注意到返回的单元素集合也是不可变集合，无法向其中添加或删除元素。 此外，也可以用各个集合接口提供的of(T...)方法创建单元素集合。例如，以下创建单元素List的两个方法是等价的： 12List&lt;String&gt; list1 = List.of(\"apple\");List&lt;String&gt; list2 = Collections.singletonList(\"apple\"); 实际上，使用List.of(T...)更方便，因为它既可以创建空集合，也可以创建单元素集合，还可以创建任意个元素的集合： 1234List&lt;String&gt; list1 = List.of(); // empty listList&lt;String&gt; list2 = List.of(\"apple\"); // 1 elementList&lt;String&gt; list3 = List.of(\"apple\", \"pear\"); // 2 elementsList&lt;String&gt; list4 = List.of(\"apple\", \"pear\", \"orange\"); // 3 elements 排序Collections可以对List进行排序，方法是Collections.sort(List)，因为排序会直接修改List元素的位置，因此必须传入可变List。 洗牌Collections提供了洗牌算法，即传入一个有序的List，可以随机打乱List内部元素的顺序，方法是Collections.shuffle(List)，效果相当于让计算机洗牌。 不可变集合Collections还提供了一组方法把可变集合封装成不可变集合，Collections.unmodifiableList(List)。 封装成不可变List：List&lt;T&gt; unmodifiableList(List&lt;? extends T&gt; list) 封装成不可变Set：Set&lt;T&gt; unmodifiableSet(Set&lt;? extends T&gt; set) 封装成不可变Map：Map&lt;K, V&gt; unmodifiableMap(Map&lt;? extends K, ? extends V&gt; m) 这种封装实际上是通过创建一个代理对象，拦截掉所有修改方法实现的。然而，继续对原始的可变List进行增删是可以的，并且，可以直接影响到封装后“不可变的”List。因此，如果我们希望把一个可变List封装成不可变List，那么返回不可变List后，最好立刻扔掉可变List的引用，这样可以保证后续操作不会意外改变原始对象，从而造成“不可变的”List发生变化。 12345678List&lt;String&gt; mutable = new ArrayList&lt;&gt;();mutable.add(\"apple\");mutable.add(\"pear\");// 变为不可变集合:List&lt;String&gt; immutable = Collections.unmodifiableList(mutable);// 立刻扔掉mutable的引用:mutable = null;System.out.println(immutable); 线程安全集合Collections还提供了一组方法，可以把线程不安全的集合变为线程安全的集合： 变为线程安全的List：List&lt;T&gt; synchronizedList(List&lt;T&gt; list) 变为线程安全的Set：Set&lt;T&gt; synchronizedSet(Set&lt;T&gt; s) 变为线程安全的Map：Map&lt;K,V&gt; synchronizedMap(Map&lt;K,V&gt; m) 多线程的概念我们会在后面讲。因为从Java 5开始，引入了更高效的并发集合类，所以上述这几个同步方法已经没有什么用了。","link":"/Study/Java/%E9%9B%86%E5%90%88/"},{"title":"SpringBoot开发","text":"我们在前面详细介绍了Spring框架，它的主要功能包括IoC容器、AOP支持、事务支持、MVC开发以及强大的第三方集成功能等。那么SpringBoot又是什么？它和Spring是什么关系？SpringBoot是一个基于Spring的套件，它帮我们预组装了Spring的一系列组件，以便以尽可能少的代码和配置来开发基于Spring的Java应用程序，它们不是取代关系，试图跳过Spring直接学习SpringBoot是不可能的。SpringBoot的目标就是提供一个开箱即用的应用程序架构，我们基于SpringBoot的预置结构继续开发是省时省力的。本章我们详细介绍如何使用SpringBoot。 第一个SpringBoot应用我们新建一个springboot-hello的工程，创建标准的Maven目录结构如下： 1234567891011springboot-hello├── pom.xml├── src│ └── main│ ├── java│ └── resources│ ├── application.yml│ ├── logback-spring.xml│ ├── static│ └── templates└── target 其中，在src/main/resources目录下，注意到几个文件： application.yml这是SpringBoot默认的配置文件，它采用YAML格式而不是.properties格式，因为YAML格式更易读，文件名必须是application.yml而不是其他名称。 YAML是一种层级格式，它和.properties很容易互相转换，它的优点是去掉了大量重复的前缀，更加易读。SpringBoot中也可以使用application.properties作为配置文件。 使用环境变量在配置文件中，我们经常使用如下格式对某个key进行配置： 12345app: db: host: ${DB_HOST:localhost} user: ${DB_USER:root} password: ${DB_PASSWORD:password} 这种${DB_HOST:localhost}意思是，首先从环境变量查找DB_HOST，如果环境变量定义了，那么使用环境变量的值，否则，使用默认值localhost。类似地，这使得我们在开发和部署时更加方便，因为开发时无需设置任何环境变量，直接使用默认值，而实际线上运行时，只需要传入环境变量即可： 1$ DB_HOST=10.0.1.123 DB_USER=prod DB_PASSWORD=xxxx java -jar xxx.jar logback-spring.xml这是SpringBoot的logback配置文件名称（也可以使用logback.xml），一个标准的写法如下： 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;include resource=\"org/springframework/boot/logging/logback/defaults.xml\" /&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"APP_LOG\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;file&gt;app.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\"&gt; &lt;maxIndex&gt;1&lt;/maxIndex&gt; &lt;fileNamePattern&gt;app.log.%i&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;1MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"APP_LOG\" /&gt; &lt;/root&gt;&lt;/configuration&gt; 它主要通过&lt;include resource=\"...\"&gt;引入SpringBoot的缺省配置，这样我们就可以引用类似${CONSOLE_LOG_PATTERN}这样的变量。上述配置定义了一个控制台输出和文件输出，可根据需要修改。 static是静态文件目录，templates是模板文件目录。注意它们不再存放在src/main/webapp下，而是直接放到src/main/resources这个classpath目录下，因为SpringBoot已经不需要专门的webapp目录了。 以上就是SpringBoot的标准目录结构，它完全是一个基于Java应用的普通Java项目。 我们再来看源码目录结构： 1234567891011src/main/java└── com └── itranswarp └── learnjava ├── Application.java ├── entity │ └── User.java ├── service │ └── UserService.java └── web └── UserController.java 在存放源码的src/main/java目录中，SpringBoot对Java包的层级结构有一个要求。注意到我们的根package是com.itranswarp.learnjava，下面还有entity、service、web等子package。SpringBoot要求main()方法所在的启动类必须放到根package下，命名不做要求，这里我们以Application.java命名，它的内容如下： 123456@SpringBootApplicationpublic class Application { public static void main(String[] args) throws Exception { SpringApplication.run(Application.class, args); }} 启动SpringBoot应用程序只需要一行代码加上一个注解@SpringBootApplication，该注解实际上又包含了： SpringBootConfiguration Configuration EnableAutoConfiguration AutoConfigurationPackage ComponentScan 这样一个注解就相当于启动了自动配置和自动扫描。 我们再观察pom.xml，它的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;project ...&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.0.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itranswarp.learnjava&lt;/groupId&gt; &lt;artifactId&gt;springboot-hello&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;java.version&gt;11&lt;/java.version&gt; &lt;pebble.version&gt;3.1.2&lt;/pebble.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 集成Pebble View --&gt; &lt;dependency&gt; &lt;groupId&gt;io.pebbletemplates&lt;/groupId&gt; &lt;artifactId&gt;pebble-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${pebble.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JDBC驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hsqldb&lt;/groupId&gt; &lt;artifactId&gt;hsqldb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 使用SpringBoot时，强烈推荐从spring-boot-starter-parent继承，因为这样就可以引入SpringBoot的预置配置。紧接着，我们引入了依赖spring-boot-starter-web和spring-boot-starter-jdbc，它们分别引入了Spring MVC和Spring JDBC的相关依赖，无需指定版本号，因为引入的&lt;parent&gt;内已经指定了，只有我们自己引入的某些第三方jar包需要指定版本号。 这里我们引入pebble-spring-boot-starter作为View，以及hsqldb作为嵌入式数据库。hsqldb已在spring-boot-starter-jdbc中预置了版本号2.5.0，因此此处无需指定版本号。 根据pebble-spring-boot-starter的文档，加入如下配置到application.yml： 12345pebble: # 默认为\".pebble\"，改为\"\": suffix: # 开发阶段禁用模板缓存: cache: false 对Application稍作改动，添加WebMvcConfigurer这个Bean： 12345678910111213141516@SpringBootApplicationpublic class Application { ... @Bean WebMvcConfigurer createWebMvcConfigurer(@Autowired HandlerInterceptor[] interceptors) { return new WebMvcConfigurer() { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { // 映射路径`/static/`到classpath路径: registry.addResourceHandler(\"/static/**\") .addResourceLocations(\"classpath:/static/\"); } }; }} 现在就可以直接运行Application，启动后观察Spring Boot的日志。SpringBoot自动启动了嵌入式Tomcat，当看到Started Application in xxx seconds时，Spring Boot应用启动成功。现在，我们在浏览器输入localhost:8080就可以直接访问页面。 那么前面我们定义的数据源、声明式事务、JdbcTemplate在哪创建的？怎么就可以直接注入到自己编写的UserService中呢？这些自动创建的Bean就是SpringBoot的特色：AutoConfiguration。当我们引入spring-boot-starter-web后，启动时会自动扫描所有的XxxAutoConfiguration： DataSourceAutoConfiguration：自从创建一个DataSource，其中配置项从application.yml的spring.datasource读取 DataSourceTransactionManagerAutoConfiguration：自动创建一个基于JDBC的事务管理器 JdbcTemplateAutoConfiguration：自动创建了一个JdbcTemplate 因此，我们自动得到了一个DataSource、一个DataSourceTransactionManager和一个JdbcTemplate。 类似地，当我们引入spring-boot-starter-web时，自动创建了： ServletWebServerFactoryAutoConfiguration：自动创建一个嵌入式Web服务器，默认是Tomcat； DispatcherServletAutoConfiguration：自动创建一个DispatcherServlet； HttpEncodingAutoConfiguration：自动创建一个CharacterEncodingFilter； WebMvcAutoConfiguration：自动创建若干与MVC相关的Bean。 … 引入第三方pepple-spring-boot-starter时，自动创建了： PebbleAutoConfiguration：自动创建了一个PebbleViewResolver SpringBoot大量的使用XxxAutoConfiguration来使得许多组件被自动化配置并创建，而这些创建过程又大量的使用了Spring的Conditional的功能。 例如，我们观察JdbcTemplateAutoConfiguration，它的代码如下： 12345678@Configuration(proxyBeanMethods = false)@ConditionalOnClass({ DataSource.class, JdbcTemplate.class })@ConditionalOnSingleCandidate(DataSource.class)@AutoConfigureAfter(DataSourceAutoConfiguration.class)@EnableConfigurationProperties(JdbcProperties.class)@Import({ JdbcTemplateConfiguration.class, NamedParameterJdbcTemplateConfiguration.class })public class JdbcTemplateAutoConfiguration {} 当满足条件： @ConditionalOnClass：在classpath中能找到DataSource和JdbcTemplate @ConditionalOnSingleCandidate(DataSource.class)：在当前Bean的定义中能找到唯一的DataSource 该JdbcTemplateAutoConfiguration就会起作用，实际创建由导入的JdbcTemplateConfiguration完成： 12345678910111213141516@Configuration(proxyBeanMethods = false)@ConditionalOnMissingBean(JdbcOperations.class)class JdbcTemplateConfiguration { @Bean @Primary JdbcTemplate jdbcTemplate(DataSource dataSource, JdbcProperties properties) { JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); JdbcProperties.Template template = properties.getTemplate(); jdbcTemplate.setFetchSize(template.getFetchSize()); jdbcTemplate.setMaxRows(template.getMaxRows()); if (template.getQueryTimeout() != null) { jdbcTemplate.setQueryTimeout((int) template.getQueryTimeout().getSeconds()); } return jdbcTemplate; }} 创建JdbcTemplate之前，要满足@ConditionalOnMissingBean(JdbcOperations.class)，即不存在JdbcOperations的Bean。 如果我们自己创建了一个JdbcTemplate： 12345678@SpringBootApplicationpublic class Application { ... @Bean JdbcTemplate createJdbcTemplate(@Autowired DataSource dataSource) { return new JdbcTemplate(dataSource); }} 那么根据条件@ConditionalOnMissingBean(JdbcOperations.class)，SpringBoot就不会再创建一个重复的JdbcTemplate（因为JdbcOperations是JdbcTemplate的父类）。 可见，Spring Boot自动装配功能是通过自动扫描+条件装配实现的，这一套机制在默认情况下工作得很好，但是，如果我们要手动控制某个Bean的创建，就需要详细地了解Spring Boot自动创建的原理，很多时候还要跟踪XxxAutoConfiguration，以便设定条件使得某个Bean不会被自动创建。 使用开发者工具在开发阶段，我们经常需要修改代码，然后重启SpringBoot应用。经常手动停止再启动，比较麻烦。SpingBoot提供了一个开发者工具，可以监控classpath路径上的文件。只要源码或配置文件发生修改，SpringBoot应用就可以自动重启。在开发阶段，这个功能比较有用。 只需要添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;&lt;/dependency&gt; 直接启动应用程序，然后试着修改源码、保存，观察日志输出，SpringBoot会自动重新加载。默认配置下，针对/static、/public和/templates目录中的文件修改，不会自动重启，因为禁用缓存后，这些文件的修改可以实时更新。 打包SpringBoot应用我们在Maven的使用插件一节中介绍了如何使用maven-shade-plugin打包一个可执行的jar包。在SpringBoot应用中，打包更简单，因为SpringBoot自带一个更简单的spring-boot-maven-plugin插件来打包，我们只需要在pom.xml中加入以下配置： 1234567891011&lt;project ...&gt; ... &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 无需任何配置，这个插件就可以自动定位应用程序的入口Class，执行以下命令就可以打包： 1$ mvn clean package 以springboot-exec-jar项目为例，打包后在target目录可以看到以下两个jar文件： 1234567$ lsclassesgenerated-sourcesmaven-archivermaven-statusspringboot-exec-jar-1.0-SNAPSHOT.jarspringboot-exec-jar-1.0-SNAPSHOT.jar.original 其中，springboot-exec-jar-1.0-SNAPSHOT.jar.original是Maven标准打包插件打的jar包，它只包含我们自己的Class，不包含依赖，而springboot-exec-jar-1.0-SNAPSHOT.jar是Spring Boot打包插件创建的包含依赖的jar，可以直接运行： 1$ java -jar springboot-exec-jar-1.0-SNAPSHOT.jar 这样，部署一个Spring Boot应用就非常简单，无需预装任何服务器，只需要上传jar包即可。 在打包的时候，因为打包后的Spring Boot应用不会被修改，因此，默认情况下，spring-boot-devtools这个依赖不会被打包进去。但是要注意，使用早期的Spring Boot版本时，需要配置一下才能排除spring-boot-devtools这个依赖： 1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludeDevtools&gt;true&lt;/excludeDevtools&gt; &lt;/configuration&gt;&lt;/plugin&gt; 如果不喜欢默认的项目名+版本号作为文件名，可以加一个配置指定文件名： 1234567&lt;project ...&gt; ... &lt;build&gt; &lt;finalName&gt;awesome-app&lt;/finalName&gt; ... &lt;/build&gt;&lt;/project&gt; 这样打包后的文件名就是awesome-app.jar。 瘦身SpringBoot应用上一节中，我们使用SpringBoot提供的spring-boot-maven-plugin打包SpringBoot应用，可以直接获得一个完整的可运行的jar包，把它上传到服务器上再运行就极其方便。但是，这种方式最大的缺点是包太大了，动不动几十MB，在网速不给力的情况下，上传服务器非常耗时。并且，其中我们引入的Tomcat、Spring和其他第三方组件，只要版本号不变，这些jar就相当于每次都重复打进去，再重复上传了一遍。 真正经常改动的是我们自己编写的代码，如果只打包我们自己的代码，通常jar包也就几百KB。但是，运行的时候，classpath里没有依赖的包，肯定会报错。 那如何只打包我们自己编写的代码，同时又自动把依赖包下载到某处，并自动引入到classpath中？答案就是使用spring-boot-thin-launcher。 使用spring-boot-thin-launcher我们先演示如何使用，再详细介绍工作原理。 首先复制一份上一节的Maven项目，并重命名为spring-thin-jar： 123456&lt;project ...&gt; ... &lt;groupId&gt;com.itranswarp.learnjava&lt;/groupId&gt; &lt;artifactId&gt;springboot-thin-jar&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; ... 然后，修改&lt;build&gt;-&lt;plugins&gt;-&lt;plugin&gt;，给原来的spring-boot-maven-plugin增加一个dependency如下： 12345678910111213141516171819&lt;project ...&gt; ... &lt;build&gt; &lt;finalName&gt;awesome-app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot.experimental&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-thin-layout&lt;/artifactId&gt; &lt;version&gt;1.0.27.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 到此为止不再需要其他改动。接下来按照正常流程打包，执行mvn clean package，观察target目录最终生成的可执行awesome-app.jar，只占很小的体积。 直接运行java -jar awesome-app.jar，效果和上节完全一样。 实际上，spring-boot-thin-launcher这个插件改变了spring-boot-maven-plugin的默认行为。它输出的jar包只包含我们自己代码编译后的class、一个很小的ThinJarWrapper，以及解析pom.xml后得到的所有依赖jar的列表。 运行的时候，入口实际上是ThinJarWrapper，它会先在指定目录搜索看看依赖的jar包是否都存在，如果不存在，先从Maven中央仓库下载到本地，然后，再执行我们自己编写的main()入口方法。这种方式有点类似于在线安装程序：用户下载后得到的是一个很小的exe安装程序，执行安装程序时，会首先在先下载所需的若干巨大的文件，再进行安装。 这个spring-boot-thin-launcher在启动时搜索的默认目录是用户主目录的.m2，我们也可以指定下载目录，例如，将下载目录指定为当前目录： 1$ java -Dthin.root=. -jar awesome-app.jar 上述命令通过环境变量thin.root传入当前目录，执行后发现当前目录下自动生成了一个repository目录，这和Maven的默认下载目录~/.m2/repository的结构是完全一样的，只是它仅包含awesome-app.jar所需的运行期依赖项。 注意：只有首次运行时会自动下载依赖项，再次运行时由于无需下载，所以启动速度会大大加快。如果删除了repository目录，再次运行时就会再次触发下载。 预热把79KB大小的awesome-app.jar直接扔到服务器执行，上传过程就非常快。但是，第一次在服务器上运行awesome-app.jar时，仍需要从Maven中央仓库下载大量的jar包，所以，spring-boot-thin-launcher还提供了一个dryrun选项，专门用来下载依赖项而不执行实际代码： 1java -Dthin.dryrun=true -Dthin.root=. -jar awesome-app.jar 执行上述代码会在当前目录创建repository目录，并下载所有依赖项，但并不会运行我们编写的main()方法。此过程称之为“预热”（warm up）。 如果服务器由于安全限制不允许从外网下载文件，那么可以在本地预热，然后把awesome-app.jar和repository目录上传到服务器。只要依赖项没有变化，后续改动只需要上传awesome-app.jar即可。 使用Actuator在生产环境中，需要对应用程序的状态进行监控。前面我们介绍了使用JMX对程序包括JVM进行监控，我们回忆一下：使用JMX需要把一些监控信息以MBean的形式暴露给JMX Server。而SpringBoot已经内置了一个监控功能，它叫Actuator。 使用Actuator非常简单，只需要添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 然后启动应用程序，Actuator就会把它能收集到的所有信息暴露给JMX。此外，Actuator还可以通过URL/actuator/挂载一些监控点，例如，输入http://localhost:8080/actuator/health，我们可以查看应用程序当前状态： 123{ \"status\": \"UP\"} 许国网关作为反向代理需要一个URL来探测后端集群应用是否存活，这个URL就可以提供给网关使用。 Actuator默认把所有访问点暴露给JMX，但出于安全原因，只有health和info会暴露给Web。Actuator提供的所有访问点均在官方文档列出，要暴露更多的访问点给Web，需要在application.yml中加上配置： 12345management: endpoints: web: exposure: include: info, health, beans, env, metrics 要特别注意暴露URL的安全性，例如，/actuator/env可以获取当前机器的所有环境变量，不可暴露给公网。 使用ProfilesProfile本身是Spring提供的功能，我们在使用条件装配中讲到了，Profile表示一个环境，如开发、测试和生产这三个环境： native test production 或者按git分支定义的master、dev这些环境： master dev 在启动一个应用程序时，可以传入一个或多个环境，例如： 1-Dspring.profiles.active=test,master 大多数情况下，一个环境就足够了。 SpringBoot对Profiles的支持在于，可以在application.yml中为每个环境进行配置，下面是一个示例配置： 1234567891011121314151617181920212223242526272829303132333435363738394041spring: application: name: ${APP_NAME:unnamed} datasource: url: jdbc:hsqldb:file:testdb username: sa password: dirver-class-name: org.hsqldb.jdbc.JDBCDriver hikari: auto-commit: false connection-timeout: 3000 validation-timeout: 3000 max-lifetime: 60000 maximum-pool-size: 20 minimum-idle: 1pebble: suffix: cache: falseserver: port: ${APP_PORT:8080}---spring: profiles: testserver: port: 8000---spring: profiles: productionserver: port: 80pebble: cache: true 注意到分隔符---，最前面的配置是默认配置，不需要指定Profile，后面的每段配置都必须以spring.profiles: xxx开头，表示一个Profile。上述配置默认使用8080端口，但在test环境下使用8000端口，在production环境下，使用80端口，并启用Pepple的缓存。 如果我们不指定任何Profile，直接启动应用程序，那么Profile实际上就是default，可以从SpringBoot启动日志看到。 要以test环境启动，可输入以下命令： 1$ java -Dspring.profiles.active=test -jar springboot-profiles-1.0-SNAPSHOT.jar 可以在日志中看到活动的Profile是test，Tomcat的监听端口是8000。 通过Profile可以实现一套代码在不同环境启用不同的配置和功能。 我们来举个例子。 假设我们需要一个存储服务，在本地开发时，直接使用文件存储即可，但是，在测试和生产环境，需要存储到云端如S3上，如何通过Profile实现该功能？ 首先，我们要定义存储接口StorageService： 12345678public interface StorageService { // 根据URI打开InputStream: InputStream openInputStream(String uri) throws IOException; // 根据扩展名+InputStream保存并返回URI: String store(String extName, InputStream input) throws IOException;} 本地存储可通过LocalStorageService实现： 1234567891011121314151617181920212223242526272829303132@Component@Profile(\"default\")public class LocalStorageService implements StorageService { @Value(\"${storage.local:/var/static}\") String localStorageRootDir; final Logger logger = LoggerFactory.getLogger(getClass()); private File localStorageRoot; @PostConstruct public void init() { logger.info(\"Intializing local storage with root dir: {}\", this.localStorageRootDir); this.localStorageRoot = new File(this.localStorageRootDir); } @Override public InputStream openInputStream(String uri) throws IOException { File targetFile = new File(this.localStorageRoot, uri); return new BufferedInputStream(new FileInputStream(targetFile)); } @Override public String store(String extName, InputStream input) throws IOException { String fileName = UUID.randomUUID().toString() + \".\" + extName; File targetFile = new File(this.localStorageRoot, fileName); try (OutputStream output = new BufferedOutputStream(new FileOutputStream(targetFile))) { input.transferTo(output); } return fileName; }} 而云端存储可通过CloudStorageService实现： 1234567891011121314151617181920212223242526272829303132@Component@Profile(\"!default\")public class CloudStorageService implements StorageService { @Value(\"${storage.cloud.bucket:}\") String bucket; @Value(\"${storage.cloud.access-key:}\") String accessKey; @Value(\"${storage.cloud.access-secret:}\") String accessSecret; final Logger logger = LoggerFactory.getLogger(getClass()); @PostConstruct public void init() { // TODO: logger.info(\"Initializing cloud storage...\"); } @Override public InputStream openInputStream(String uri) throws IOException { // TODO: throw new IOException(\"File not found: \" + uri); } @Override public String store(String extName, InputStream input) throws IOException { // TODO: throw new IOException(\"Unable to access cloud storage.\"); }} 注意到LocalStorageService使用了条件装配@Profile(\"default\")，即默认启用LocalStorageService，而CloudStorageService使用了条件装配@Profile(\"!default\")，即非default环境时，自动启用CloudStorageService。这样，一套代码，就实现了不同环境启用不同的配置。 使用Conditional使用Profile能根据不同的Profile进行条件装配，但是Profile控制比较糙，如果想要精细控制，例如，配置本地存储、AWS存储和阿里云存储，将来很可能会增加Azure存储等，用Profile就很难实现。Spring本身提供了条件装配@Conditional，但是自己要写比较复杂的Condition来做判断，比较麻烦。SpringBoot则为我们提供了几个非常实用的条件： @ConditionalOnProperty：如果有指定的配置，条件生效 @ConditionalOnBean：如果有指定的Bean，条件生效 @ConditionalOnMissingBean：如果没有指定的Bean，条件生效 @ConditionalOnMissingClass：如果没有指定的Class，条件生效 @ConditionalOnWebApplication：在Web环境中条件生效 @ConditionalOnExpression：根据表达式判断条件是否生效 我们以最常用的@ConditionalOnProperty为例，把上一节的StorageService改写如下。首先，定义配置storage.type=xxx用作判断条件，默认为local： 12storage: type: ${STORAGE_TYPE:local} 设定为local时，启动LocalStorageService： 12345@Component@ConditionalOnProperty(value = \"storage.type\", havingValue = \"local\", matchIfMissing = true)public class LocalStorageService implements StorageService { ...} 设定为aws时，启用AwsStorageService： 12345@Component@ConditionalOnProperty(value = \"storage.type\", havingValue = \"aws\")public class AwsStorageService implements StorageService { ...} 设定为aliyun时，启用AliyunStorageService： 12345@Component@ConditionalOnProperty(value = \"storage.type\", havingValue = \"aliyun\")public class AliyunStorageService implements StorageService { ...} 注意到LocalStorageService的注解，当指定配置为local，或者配置不存在，均启用LocalStorageService。由此可见，SpringBoot提供的条件装配使得应用程序更加具有灵活性。 加载配置文件加载配置文件可以直接使用注解@Value，例如，我们定义一个最大允许上传的文件大小的配置： 123storage: local: max-size: 102400 在某个FileUploader里获取该配置： 1234567@Componentpublic class FileUploader { @Value(\"${storage.local.max-size:102400}\") int maxSize; ...} 在另一个UploadFilter中，因为要检查文件的MD5，同时也要检查输入流的大小，因此，也需要该配置： 1234567@Componentpublic class UploadFilter implements Filter { @Value(\"${storage.local.max-size:100000}\") int maxSize; ...} 多次引用同一个@Value不但麻烦，而且@Value使用字符串，缺少编译器检查，容易造成多处引用不一致。 为了更好地管理配置，SpringBoot允许创建一个Bean，持有一组配置，并由SpringBoot自动注入。 假设我们在application.yml中添加了如下配置： 12345678910storage: local: # 文件存储根目录: root-dir: ${STORAGE_LOCAL_ROOT:/var/storage} # 最大文件大小，默认100K: max-size: ${STORAGE_LOCAL_MAX_SIZE:102400} # 是否允许空文件: allow-empty: false # 允许的文件类型: allow-types: jpg, png, gif 可以首先定义一个JavaBean，持有该组配置： 123456789public class StorageConfiguration { private String rootDir; private int maxSize; private boolean allowEmpty; private List&lt;String&gt; allowTypes; // TODO: getters and setters} 保证JavaBean的属性名称和配置一致即可，然后，我们添加两个注解： 12345@Configuration@ConfigurationProperties(\"storage.local\")public class StorageConfiguration { ...} 注意@ConfigurationProperties(\"storage.local\")表示将从配置项storage.local读取该项的所有子项配置，并且，@Configuration表示StorageConfiguration也是一个Spring管理的Bean，可直接注入到其他Bean中： 1234567891011121314@Componentpublic class StorageService { final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired StorageConfiguration storageConfig; @PostConstruct public void init() { logger.info(\"Load configuration: root-dir = {}\", storageConfig.getRootDir()); logger.info(\"Load configuration: max-size = {}\", storageConfig.getMaxSize()); logger.info(\"Load configuration: allowed-types = {}\", storageConfig.getAllowTypes()); }} 这样一来，引入storage.local的相关配置就很容易了，因为只需要注入StorageConfiguration这个Bean，这样就可以由编译器检查类型，无需编写重复的@Value注解。 禁用自动配置SpringBoot大量使用自动配置和默认配置，极大地减少了代码，通常只需要加上几个注解，并按照默认规则设置一下必要的配置即可。例如，配置JDBC，默认情况下，只需要配置一个spring.datasource： 123456spring: datasource: url: jdbc:hsqldb:file:testdb username: sa password: dirver-class-name: org.hsqldb.jdbc.JDBCDriver SpringBoot就会自动创建出DataSource、JdbcTemplate、DataSourceTransactionManager，非常方便。 但是，有时候，我们必须要禁用某些自动配置。例如，系统有主从两个数据库，而SpringBoot的自动配置只能配一个，怎么办？这时，针对DataSource相关的自动配置，就必须关掉。我们需要用exclude指定需要关掉的自动配置： 123456@SpringBootApplication// 启动自动配置，但排除指定的自动配置:@EnableAutoConfiguration(exclude = DataSourceAutoConfiguration.class)public class Application { ...} 现在，SpringBoot不再给我们自动创建DataSource、JdbcTemplate和DataSourceTransactionManager了，要实现主从数据库支持，怎么办？ 首先，我们需要把主从数据库配置写到application.yml中，仍然按照SpringBoot默认的格式写，但datasource改为datasource-master和datasource-slave： 1234567891011spring: datasource-master: url: jdbc:hsqldb:file:testdb username: sa password: dirver-class-name: org.hsqldb.jdbc.JDBCDriver datasource-slave: url: jdbc:hsqldb:file:testdb username: sa password: dirver-class-name: org.hsqldb.jdbc.JDBCDriver 注意到两个数据库实际上是一个库。如果使用MySQL，可以创建一个只读用户，作为datasource-slave的用户来模拟一个从库。下一步，我们分别创建两个HikariCP的DataSource： 12345678910111213141516171819202122232425public class MasterDataSourceConfiguration { @Bean(\"masterDataSourceProperties\") @ConfigurationProperties(\"spring.datasource-master\") DataSourceProperties dataSourceProperties() { return new DataSourceProperties(); } @Bean(\"masterDataSource\") DataSource dataSource(@Autowired @Qualifier(\"masterDataSourceProperties\") DataSourceProperties props) { return props.initializeDataSourceBuilder().build(); }}public class SlaveDataSourceConfiguration { @Bean(\"slaveDataSourceProperties\") @ConfigurationProperties(\"spring.datasource-slave\") DataSourceProperties dataSourceProperties() { return new DataSourceProperties(); } @Bean(\"slaveDataSource\") DataSource dataSource(@Autowired @Qualifier(\"slaveDataSourceProperties\") DataSourceProperties props) { return props.initializeDataSourceBuilder().build(); }} 注意到上述class并未添加@Configuration和@Component，要使之生效，可是使用@Import导入： 123456@SpringBootApplication@EnableAutoConfiguration(exclude = DataSourceAutoConfiguration.class)@Import({ MasterDataSourceConfiguration.class, SlaveDataSourceConfiguration.class})public class Application { ...} 此外，上述两个DataSource的Bean名称分别为masterDataSource和slaveDataSource，我们还需要一个最终的@Primary标注的DataSource，它采用Spring提供的AbstractRoutingDataSource，代码实现如下： 1234567class RoutingDataSource extends AbstractRoutingDataSource { @Override protected Object determineCurrentLookupKey() { // 从ThreadLocal中取出key: return RoutingDataSourceContext.getDataSourceRoutingKey(); }} RoutingDataSource本身并不是真正的DataSource，它通过Map关联一组DataSource，下面的代码创建了包含两个DataSource的RoutingDataSource，关联的key分别为masterDataSource和slaveDataSource： 1234567891011121314151617181920212223242526public class RoutingDataSourceConfiguration { @Primary @Bean DataSource dataSource( @Autowired @Qualifier(\"masterDataSource\") DataSource masterDataSource, @Autowired @Qualifier(\"slaveDataSource\") DataSource slaveDataSource) { var ds = new RoutingDataSource(); // 关联两个DataSource: ds.setTargetDataSources(Map.of( \"masterDataSource\", masterDataSource, \"slaveDataSource\", slaveDataSource)); // 默认使用masterDataSource: ds.setDefaultTargetDataSource(masterDataSource); return ds; } @Bean JdbcTemplate jdbcTemplate(@Autowired DataSource dataSource) { return new JdbcTemplate(dataSource); } @Bean DataSourceTransactionManager dataSourceTransactionManager(@Autowired DataSource dataSource) { return new DataSourceTransactionManager(dataSource); }} 仍然需要自己创建JdbcTemplate和PlatformTransactionManager，注入的是标记为@Primary的RoutingDataSource。 这样，我们通过如下的代码就可以切换RoutingDataSource底层使用的真正的DataSource： 12RoutingDataSourceContext.setDataSourceRoutingKey(\"slaveDataSource\");jdbcTemplate.query(...); 只不过写代码切换DataSource即麻烦又容易出错，更好的方式是通过注解配合AOP实现自动切换，这样，客户端代码实现如下： 12345678@Controllerpublic class UserController { @RoutingWithSlave // &lt;-- 指示在此方法中使用slave数据库 @GetMapping(\"/profile\") public ModelAndView profile(HttpSession session) { ... }} 实现上述功能需要编写一个@RoutingWithSlave注解，一个AOP织入和一个ThreadLocal来保存key。由于代码比较简单，这里我们不再详述。 如果我们想要确认是否真的切换了DataSource，可以覆写determineTargetDataSource()方法并打印出DataSource的名称： 12345678910class RoutingDataSource extends AbstractRoutingDataSource { ... @Override protected DataSource determineTargetDataSource() { DataSource ds = super.determineTargetDataSource(); logger.info(\"determin target datasource: {}\", ds); return ds; }} 访问不同的URL，可以在日志中看到两个DataSource，分别是HikariPool-1和hikariPool-2： 122020-06-14 17:55:21.676 INFO 91561 --- [nio-8080-exec-7] c.i.learnjava.config.RoutingDataSource : determin target datasource: HikariDataSource (HikariPool-1)2020-06-14 17:57:08.992 INFO 91561 --- [io-8080-exec-10] c.i.learnjava.config.RoutingDataSource : determin target datasource: HikariDataSource (HikariPool-2) 我们用一个图来表示创建的DataSource以及相关Bean的关系： 12345678910┌────────────────────┐ ┌──────────────────┐│@Primary │&lt;──────│ JdbcTemplate ││RoutingDataSource │ └──────────────────┘│ ┌────────────────┐ │ ┌──────────────────┐│ │MasterDataSource│ │&lt;──────│DataSource ││ └────────────────┘ │ │TransactionManager││ ┌────────────────┐ │ └──────────────────┘│ │SlaveDataSource │ ││ └────────────────┘ │└────────────────────┘ 注意到DataSourceTransactionManager和JdbcTemplate引用的都是RoutingDataSource，所以，这种设计的一个限制就是：在一个请求中，一旦切换了内部数据源，在同一个事务中，不能再切到另一个，否则，DataSourceTransactionManager和JdbcTemplate操作的就不是同一个数据库连接。 小结可以通过@EnableAutoConfiguration(exclude = {...})指定禁用的自动配置； 可以通过@Import({...})导入自定义配置。 添加Filter我们在Spring中已经学过了集成Filter，本质上就是通过代理，把Spring管理的Bean注册到Servlet容器中，不过步骤比较繁琐，需要配置web.xml。 在SpringBoot中添加一个Filter更简单。SpringBoot会自动扫描所有的FilterRegistrationBean类型的Bean，然后，将他们返回的Filter自动注册到Servlet容器中，无需任何配置。 我们还是以AuthFilter为例，首先编写一个AuthFilterRegistrationBean，它继承自FilterRegistrationBean： 123456789101112131415@Order(10)@Componentpublic class AuthFilterRegistrationBean extends FilterRegistrationBean&lt;Filter&gt; { @Autowired UserService userService; @Override public Filter getFilter() { return new AuthFilter(); } class AuthFilter implements Filter { ... }} FilterRegistrationBean本身不是Filter，它实际上是Filter的工厂。Spring Boot会调用getFilter()，把返回的Filter注册到Servlet容器中。因为我们可以在FilterRegistrationBean中注入需要的资源，然后，在返回的AuthFilter中，这个内部类可以引用外部类的所有字段，自然也包括注入的UserService，所以，整个过程完全基于Spring的IoC容器完成。 再注意到AuthFilterRegistrationBean标记了一个@Order(10)，因为Spring Boot支持给多个Filter排序，数字小的在前面，所以，多个Filter的顺序是可以固定的。 我们再编写一个ApiFilter，专门过滤/api/*这样的URL。首先编写一个ApiFilterRegistrationBean 12345678910111213@Order(20)@Componentpublic class ApiFilterRegistrationBean extends FilterRegistrationBean&lt;Filter&gt; { @PostConstruct public void init() { setFilter(new ApiFilter()); setUrlPatterns(List.of(\"/api/*\")); } class ApiFilter implements Filter { ... }} 这个ApiFilterRegistrationBean和AuthFilterRegistrationBean又有所不同。因为我们要过滤URL，而不是针对所有URL生效，因此，在@PostConstruct方法中，通过setFilter()设置一个Filter实例后，再调用setUrlPatterns()传入要过滤的URL列表。 集成第三方组件和Spring相比，使用SpringBoot通过自动配置即成第三方组件通常来说更简单，这一节我们详细介绍如何通过SpringBoot集成常用的第三方组件。 集成Open APIOpen API是一个标准，它的主要作用是描述REST API，既可以作为文档给开发者阅读，又可以让机器根据这个文档自动生成客户端代码。在SpringBoot应用中，假设我们编写了一堆REST API，如何添加Open API的支持？ 我们只需要在pom.xml中加入以下依赖： 1org.springdoc:springdoc-openapi-ui:1.4.0 然后直接启动应用，打开浏览器输入http://localhost:8080/swagger-ui.html，立即可以看到自动生成的API文档，这里列出了3个API，来自api-controller（因为定义在ApiController这个类中），点击某个API还可以交互，即输入API参数，点“try it out”，获得运行结果。 因为我们引入springdoc-openapi-ui这个依赖后，它自动引入Swagger UI用来创建API文档。可以给API加入一些描述信息，例如： 1234567891011@RestController@RequestMapping(\"/api\")public class ApiController { ... @Operation(summary = \"Get specific user object by it's id.\") @GetMapping(\"/users/{id}\") public User user(@Parameter(description = \"id of the user.\") @PathVariable(\"id\") long id) { return userService.getUserById(id); } ...} @Operation可以对API进行描述，@Parameter可以对参数进行描述，它们的目的是用于生成API文档的描述信息。 大多数情况下，不需要任何配置，我们就直接得到了一个运行时动态生成的可交互的API文档，该API文档总是和代码保持同步，大大简化了文档的编写工作。要自定义文档的样式、控制某些API显示等，请参考springdoc文档。 配置反向代理如果在服务器上，用户访问的域名是https://example.com，但内部是通过类似Nginx这样的反向代理访问实际的Spring Boot应用，比如http://localhost:8080，这个时候，在页面https://example.com/swagger-ui.html上，显示的URL仍然是http://localhost:8080，这样一来，就无法直接在页面执行API，非常不方便。 这是因为Spring Boot内置的Tomcat默认获取的服务器名称是localhost，端口是实际监听端口，而不是对外暴露的域名和80或443端口。要让Tomcat获取到对外暴露的域名等信息，必须在Nginx配置中传入必要的HTTP Header，常用的配置如下： 123456789101112# Nginx配置server { ... location / { proxy_pass http://localhost:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ...} 然后，在Spring Boot的application.yml中，加入如下配置： 12345server: # 实际监听端口: port: 8080 # 从反向代理读取相关的HTTP Header: forward-headers-strategy: native 重启Spring Boot应用，即可在Swagger中显示正确的URL。 访问Redis在SpringBoot中，要访问Redis，可以直接引入spring-boot-starter-data-redis，它实际上是Spring Data的一个子项目–Spring Data Redis，主要用到了这几个组件： Lettuce：一个基于Netty的高性能Redis客户端 RedisTemplate：一个类似于JdbcTemplate的接口，用于简化Redis的操作 因为Spring Data Redis引入的依赖项很多，如果只是为了使用Redis，完全可以只引入Lettuce，剩下的操作由自己来完成。 本节我们稍微深入了解一下Redis的客户端，看怎么一步步把一个第三方组件引入到Spring Boot中。 首先我们添加必要的几个依赖项： io.lettuce:lettuce-core org.apache.commons:commons-pool2 注意我们并未指定版本号，因为在spring-boot-starter-parent中已经把常用组件的版本号确定下来了。第一步是在配置文件application.yml中添加Redis的相关配置： 1234567spring: redis: host: ${REDIS_HOST:localhost} port: ${REDIS_PORT:6379} password: ${REDIS_PASSWORD:} ssl: ${REDIS_SSL:false} database: ${REDIS_DATABASE:0} 然后，通过RedisConfiguration来加载它： 123456789@ConfigurationProperties(\"spring.redis\")public class RedisConfiguration { private String host; private int port; private String password; private int database; // getters and setters...} 再编写一个@Bean方法来创建RedisClient，可以直接放在RedisConfiguration中： 12345678910111213@ConfigurationProperties(\"spring.redis\")public class RedisConfiguration { ... @Bean RedisClient redisClient() { RedisURI uri = RedisURI.Builder.redis(this.host, this.port) .withPassword(this.password) .withDatabase(this.database) .build(); return RedisClient.create(uri); }} 在启动入口引入该配置： 12345@SpringBootApplication@Import(RedisConfiguration.class) // 加载Redis配置public class Application { ...} 注意：如果在RedisConfiguration上标注@Configuration，则可通过SpringBoot的自动扫描机制自动加载，否则，使用@Import手动加载。紧接着，我们用一个RedisService来封装所有Redis操作，基础代码如下： 1234567891011121314151617181920212223@Componentpublic class RedisService { @Autowired RedisClient redisClient; GenericObjectPool&lt;StatefulRedisConnection&lt;String, String&gt;&gt; redisConnectionPool; @PostConstruct public void init() { GenericObjectPoolConfig&lt;StatefulRedisConnection&lt;String, String&gt;&gt; poolConfig = new GenericObjectPoolConfig&lt;&gt;(); poolConfig.setMaxTotal(20); poolConfig.setMaxIdle(5); poolConfig.setTestOnReturn(true); poolConfig.setTestWhileIdle(true); this.redisConnectionPool = ConnectionPoolSupport.createGenericObjectPool(() -&gt; redisClient.connect(), poolConfig); } @PreDestroy public void shutdown() { this.redisConnectionPool.close(); this.redisClient.shutdown(); }} 上述代码引入Common Pool的一个对象池，用于缓存Redis连接。因为Lettuce本身是基于Netty的异步驱动，在异步访问时并不需要创建连接池，但基于Servlet模型的同步访问时，连接池是必要的。连接池在@PostConstruct方法中初始化，在@PreDestroy方法中关闭。 然后，在RedisService中添加Redis访问方法。为了简化代码，我们仿照JdbcTemplate.execute(ConnectionCallback)方法，传入回调函数，可大幅减少样板代码。首先，定义回调函数接口SyncCommandCallback： 12345@FunctionalInterfacepublic interface SyncCommandCallback&lt;T&gt; { // 在此操作Redis: T doInConnection(RedisCommands&lt;String, String&gt; commands);} 编写executeSync方法，在该方法中，获取Redis连接，利用callback操作Redis，最后释放连接，并返回操作结果： 12345678910public &lt;T&gt; T executeSync(SyncCommandCallback&lt;T&gt; callback) { try (StatefulRedisConnection&lt;String, String&gt; connection = redisConnectionPool.borrowObject()) { connection.setAutoFlushCommands(true); RedisCommands&lt;String, String&gt; commands = connection.sync(); return callback.doInConnection(commands); } catch (Exception e) { logger.warn(\"executeSync redis failed.\", e); throw new RuntimeException(e); }} 有的童鞋觉得这样访问Redis的代码太复杂了，实际上我们可以针对常用操作把它封装一下，例如set和get命令： 1234567public String set(String key, String value) { return executeSync(commands -&gt; commands.set(key, value));}public String get(String key) { return executeSync(commands -&gt; commands.get(key));} 类似的，hget和hset操作如下： 1234567891011public boolean hset(String key, String field, String value) { return executeSync(commands -&gt; commands.hset(key, field, value));}public String hget(String key, String field) { return executeSync(commands -&gt; commands.hget(key, field));}public Map&lt;String, String&gt; hgetall(String key) { return executeSync(commands -&gt; commands.hgetall(key));} 常用命令可以提供方法接口，如果要执行任意复杂的操作，就可以通过executeSync(SyncCommandCallback&lt;T&gt;)来完成。 完成了RedisService后，就可以使用Redis了。例如，，在UserController中，我们在Session中只存放登录用户的ID，用户信息存放到Redis，提供两个方法用于读写： 1234567891011121314151617181920212223242526@Controllerpublic class UserController { public static final String KEY_USER_ID = \"__userid__\"; public static final String KEY_USERS = \"__users__\"; @Autowired ObjectMapper objectMapper; @Autowired RedisService redisService; // 把User写入Redis: private void putUserIntoRedis(User user) throws Exception { redisService.hset(KEY_USERS, user.getId().toString(), objectMapper.writeValueAsString(user)); } // 从Redis读取User: private User getUserFromRedis(HttpSession session) throws Exception { Long id = (Long) session.getAttribute(KEY_USER_ID); if (id != null) { String s = redisService.hget(KEY_USERS, id.toString()); if (s != null) { return objectMapper.readValue(s, User.class); } } return null; } ...} 用户登录成功后，把ID放入Session，把User实例放入Redis： 1234567891011@PostMapping(\"/signin\")public ModelAndView doSignin(@RequestParam(\"email\") String email, @RequestParam(\"password\") String password, HttpSession session) throws Exception { try { User user = userService.signin(email, password); session.setAttribute(KEY_USER_ID, user.getId()); putUserIntoRedis(user); } catch (RuntimeException e) { return new ModelAndView(\"signin.html\", Map.of(\"email\", email, \"error\", \"Signin failed\")); } return new ModelAndView(\"redirect:/profile\");} 需要获取User时，从Redis取出： 12345678@GetMapping(\"/profile\")public ModelAndView profile(HttpSession session) throws Exception { User user = getUserFromRedis(session); if (user == null) { return new ModelAndView(\"redirect:/signin\"); } return new ModelAndView(\"profile.html\", Map.of(\"user\", user));} 在Redis读写Java对象时，序列化和反序列化是应用程序的工作，上述代码使用JSON作为序列化方案，简单可靠。也可将相关序列化操作封装到RedisService中，这样可以提供更通用的方法： 1234567public &lt;T&gt; T get(String key, Class&lt;T&gt; clazz) { ...}public &lt;T&gt; T set(String key, T value) { ...} SpringBoot默认使用Lettuce作为Redis客户端，同步使用时，应通过连接池提高效率。 集成ArtemisArctiveMQ Artemis是一个JMS服务器，在集成JMS一节中我们已经详细讨论了如何在Spring中集成Artemis，本节我们介绍在SpringBoot中集成Artemis。 还是以实际工程为例，创建一个springboot-jms工程，引入的依赖除了spring-boot-starter-web，spring-boot-starter-jdbc等以外，新增spring-boot-starter-artemis，同样无需指定版本号： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-artemis&lt;/artifactId&gt;&lt;/dependency&gt; 创建Artemis服务后，我们在application.yml中加入相关配置： 12345678910spring: artemis: # 指定连接外部Artemis服务器，而不是启动嵌入式服务: mode: native # 服务器地址和端口号: host: 127.0.0.1 port: 61616 # 连接用户名和口令由创建Artemis服务器时指定: user: admin password: password 和Spring版本的JMS代码相比，在SpringBoot中集成JMS时，只要引入了spring-boot-starter-artemis，SpringBoot会自动创建JMS相关的ConnectionFactory、JmsListenerContainerFactory、JmsTemplate等，无需我们再手动配置了。 发送消息时只需要引入JmsTemplate： 1234567891011121314@Componentpublic class MessagingService { @Autowired JmsTemplate jmsTemplate; public void sendMailMessage() throws Exception { String text = \"...\"; jmsTemplate.send(\"jms/queue/mail\", new MessageCreator() { public Message createMessage(Session session) throws JMSException { return session.createTextMessage(text); } }); }} 接收消息只需要标注@JmsListener： 123456789@Componentpublic class MailMessageListener { final Logger logger = LoggerFactory.getLogger(getClass()); @JmsListener(destination = \"jms/queue/mail\", concurrency = \"10\") public void onMailMessageReceived(Message message) throws Exception { logger.info(\"received message: \" + message); }} 可见，应用程序收发消息的逻辑和Spring中使用JMS使用完全相同，只是通过SpringBoot，我们把工程简化到只需要设定Artemis相关配置。 集成RabbitMQ前面我们讲了ArctiveMQ Artemis，它实现了JMS的消息服务协议。JMS是JavaEE的消息服务标准接口，但是，如果Java程序要和另一种语言编写的程序通过消息服务器进行通信，那么JMS就不太适合了。 AMQP是一种使用广泛的独立与语言的消息协议，它的全称是Advanced Message Queuing Protocol，即高级消息队列协议，它定义了一种二进制格式的消息流，任何编程语言都可以实现该协议。实际上，Artemis也支持AMQP，但实际应用最广泛的AMQP服务器是使用Erlang编写的RabbitMQ。 安装RabbitMQ首先从官网下载并安装RabbitMQ，安装和启动RabbitMQ请参考官方设计文档。要验证启动是否成功，可以访问RabbitMQ的管理后台http://localhost:15672，如看到登录页面就表示RabbitMQ安装成功。管理后台的默认用户名和口令都是guest。 AMQP协议AMQP协议和前面介绍过的JMS协议有所不同。我们回顾一下，在JMS中有两种类型的消息通道： 点对点的Queue，即Producer发送消息到指定的Queue，接收方从Queue收取消息 一对多的Topic，即Producer发送消息到指定的Topic，任意多个在线的接收方均可从Topic获得一份完整的消息副本 而AMQP协议比JMS要复杂一点，它只有Queue，没有Topic，并且引入了Exchange。当Producer想要发送消息时，它将消息发送给Exchange，由Exchange将消息根据某些规则投递到一个或多个Queue。 如果某个Exchange总是把消息发送到固定的Queue，那么这个消息通道就相当于JMS的Queue。如果某个Exchange把消息发送到多个Queue，那么这个消息通道就相当于JMS中的Topic。和JMS的Topic相比，Exchange的投递规则更灵活，比如一个“登录成功”的消息被投放到Queue-1和Queue-2，而“登录失败”则被投递到Queue-3。这些路由规则称之为Binding，通常都在RabbitMQ的管理后台设置。 我们以实际应用场景为例。 在RabbitMQ，首先创建3个Queue，分别用于发送邮件、短信和App通知。创建Queue时注意到可配置为持久化（Durable）和非持久化（Transient），当Consumer不在线时，持久化的Queue会暂存消息，非持久化的Queue会丢弃消息。 紧接着，我们还Exchanges中创建一个Direct类型的Exchange，命名为registration，并添加两个Binding，其规则是：凡是发送到registration这个Exchange的消息，均被发送到q_mail和q_sms这样个Queue。 我们再创建一个Direct类型的Exchange，命名为login，并添加Binding，其规则是：当消息发送给login这个Exchange时，如果消息没有指定Routing Key，则被投递到q_app和q_mail，如果消息指定了Routing Key=”login_failed”，那么消息被投递到q_sms。 配合好RabbitMQ后，我们就可以基于SpringBoot开发AMQP应用程序。 使用RabbitMQ我们首先创建Spring Boot工程springboot-rabbitmq，并添加如下依赖引入RabbitMQ： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 然后在application.yml中添加RabbitMQ相关配置： 123456spring: rabbitmq: host: localhost port: 5672 username: guest password: guest 我们还需要在Application中添加一个MessageConverter： 1234567891011import org.springframework.amqp.support.converter.MessageConverter;@SpringBootApplicationpublic class Application { ... @Bean MessageConverter createMessageConverter() { return new Jackson2JsonMessageConverter(); }} MessageConverter用于将Java对象转换为RabbitMQ的消息。默认情况下，SpringBoot使用SimpleMessageConverter，只能发送String和byte[]的消息，不太方便。使用Jackson2JsonMessageConverter，我们就可以发送JavaBean对象，由SpringBoot自动序列化为JSON并以文本消息传递。 因为引入了starter，所有RabbitMQ相关的Bean均自动装配，我们需要在Producer注入的是RabbitTemplate： 1234567891011121314@Componentpublic class MessagingService { @Autowired RabbitTemplate rabbitTemplate; public void sendRegistrationMessage(RegistrationMessage msg) { rabbitTemplate.convertAndSend(\"registration\", \"\", msg); } public void sendLoginMessage(LoginMessage msg) { String routingKey = msg.success ? \"\" : \"login_failed\"; rabbitTemplate.convertAndSend(\"login\", routingKey, msg); }} 发送消息时，使用convertAndSend(exchange, routingKey, message)可以指定Exchange、Routing Key以及消息本身。这里传入JavaBean后会自动序列化为JSON文本。上述代码将RegistrationMessage发送到registration，将LoginMessage发送到login，并根据登录是否成功来指定Routing Key。 接收消息时，需要在消息处理的方法上标注@RabbitListener： 123456789101112131415161718192021222324252627282930313233@Componentpublic class QueueMessageListener { final Logger logger = LoggerFactory.getLogger(getClass()); static final String QUEUE_MAIL = \"q_mail\"; static final String QUEUE_SMS = \"q_sms\"; static final String QUEUE_APP = \"q_app\"; @RabbitListener(queues = QUEUE_MAIL) public void onRegistrationMessageFromMailQueue(RegistrationMessage message) throws Exception { logger.info(\"queue {} received registration message: {}\", QUEUE_MAIL, message); } @RabbitListener(queues = QUEUE_SMS) public void onRegistrationMessageFromSmsQueue(RegistrationMessage message) throws Exception { logger.info(\"queue {} received registration message: {}\", QUEUE_SMS, message); } @RabbitListener(queues = QUEUE_MAIL) public void onLoginMessageFromMailQueue(LoginMessage message) throws Exception { logger.info(\"queue {} received message: {}\", QUEUE_MAIL, message); } @RabbitListener(queues = QUEUE_SMS) public void onLoginMessageFromSmsQueue(LoginMessage message) throws Exception { logger.info(\"queue {} received message: {}\", QUEUE_SMS, message); } @RabbitListener(queues = QUEUE_APP) public void onLoginMessageFromAppQueue(LoginMessage message) throws Exception { logger.info(\"queue {} received message: {}\", QUEUE_APP, message); }} 上述代码一共定义了5个Consumer，监听3个Queue。 启动应用程序，我们注册一个新用户，然后发送一条RegistrationMessage消息。此时，根据registration这个Exchange的设定，我们会在两个Queue收到消息；当我们登录失败时，发送LoginMessage并设定Routing Key为login_failed，此时，只有q_sms会收到消息：登录成功后，发送LoginMessage，此时，q_mail和q_app将收到消息。 RabbitMQ还提供了使用Topic的Exchange（此Topic指消息的标签，并非JMS的Topic的概念），可以使用*进行匹配路由。可见，掌握RabbitMQ的核心是理解其消息的路由规则。 直接指定一个Queue并投递消息也是可以的，此时指定Routing Key为Queue的名称即可，因为RabbitMQ提供了一个default exchange用于根据Routing Key查找Queue并直接投递消息到指定的Queue。但是要实现一对多的投递就必须自己配置Exchange。 Spring Boot提供了AMQP的集成，默认使用RabbitMQ作为AMQP消息服务器。 使用RabbitMQ发送消息时，理解Exchange如何路由至一个或多个Queue至关重要。 集成Kafka我们在前面已经介绍了JMS和AMQP，JMS的JavaEE的标准消息接口，Artemis是一个JMS的实现产品，同样的AMQP是一个标准消息接口，RabbitMQ是一个AMQP实现产品。Kafka也是一个消息服务器，它的特点一是快，二是有巨大的吞吐量，那么Kafka实现了什么标准消息接口呢？ Kafka没有实现任何标准的消息接口，它自己提供的API就是Kafka的接口。 Kafka本身是Scala编写的，运行在JVM之上。Producer和Consumer都通过Kafka的客户端使用网络来与之通信。从逻辑上讲，Kafka的设计非常简单，它只有一种类似于JMS的Topic的消息通道： 123456789 ┌──────────┐ ┌──&gt;│Consumer-1│ │ └──────────┘┌────────┐ ┌─────┐ │ ┌──────────┐│Producer│─────&gt;│Topic│───┼──&gt;│Consumer-2│└────────┘ └─────┘ │ └──────────┘ │ ┌──────────┐ └──&gt;│Consumer-3│ └──────────┘ 那么Kafka是如何支持十万甚至百万的并发呢？答案是分区。Kafka的一个Topic可以有一个至多个Partition，并且可以分布到多台机器上： 12345678910111213 ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ Topic │ │ ┌───────────┐ ┌──────────┐ │┌─&gt;│Partition-1│──┐│┌──&gt;│Consumer-1│ │ └───────────┘ │ │ └──────────┘┌────────┐ ││ ┌───────────┐ │││ ┌──────────┐│Producer│───┼─&gt;│Partition-2│──┼─┼──&gt;│Consumer-2│└────────┘ ││ └───────────┘ │││ └──────────┘ │ ┌───────────┐ │ │ ┌──────────┐ │└─&gt;│Partition-3│──┘│└──&gt;│Consumer-3│ └───────────┘ └──────────┘ └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ Kafka只保证在一个Partition内部，消息是有序的，但是，存在多个Partition的情况下，Producer发送的3个消息会依次发送到Partition-1、Partition-2和Partition-3，Consumer从三个Partition接收的消息并不一定是Producer发送消息的顺序。因此，多个Partition只能保证接收消息大概率是按发送时间有序，并不能完全保证按Producer的发送顺序。这一点在使用Kafka作为消息服务器时要特别注意，对发送顺序有严格要求的Topic只能有一个Partition。 Kafka的另一个特点是消息发送和接收都尽量使用批处理，一次处理几十甚至上百条消息，比一次一条效率高很多。 另外，Kafka总是将消息写入Partition对应的文件，消息保存多久取决于服务器的配置，可以按照时间删除，也可以按照文件大小删除，因此，只要Consumer在离线期内还没有被删除，再次上线仍然可以接收完整的信息流。这一功能是客户端自己实现的，客户端会存储它接收到的最后一个消息的offsetId，再次上线后按上次的offsetId查询。offsetId是Kafka标识某个Partion的每一条消息的递增整数，客户端通常将它存储在ZooKeeper中。 有了Kafka消息设计的基本概念，我们来看看如何在SpringBoot中使用Kafka。 安装Kafka首先从Kafka官网下载最新版Kafaka，解压后在bin目录找到两个文件： zookeeper-server-start.sh：启动ZooKeeper（已内置在Kafka中）； kafka-server-start.sh：启动Kafka。 先启动ZooKeeper： 1$ ./zookeeper-server-start.sh ../config/zookeeper.properties 再启动Kafka： 1./kafka-server-start.sh ../config/server.properties 看到如下输出表示启动成功： 1... INFO [KafkaServer id=0] started (kafka.server.KafkaServer) 如果要关闭Kafka和ZooKeeper，依次按Ctrl-C退出即可。注意这是在本地开发时使用Kafka的方式，线上Kafka服务推荐使用云服务厂商托管模式（AWS的MSK，阿里云的消息队列Kafka版）。 使用Kafka在SpringBoot中使用Kafka，首先引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 注意这个依赖是spring-kafka项目提供的。 然后在application.yml中添加Kafka配置： 1234567spring: kafka: bootstrap-servers: localhost:9092 consumer: auto-offset-reset: latest max-poll-records: 100 max-partition-fetch-bytes: 1000000 除了bootstrap-servers必须指定外，consumer相关的配置项均为调优选项。例如，max-poll-records表示一次最多抓取100条消息。配置名称去哪里看？IDE里定义一个KafkaProperties.Consumer的变量： 1KafkaProperties.Consumer c = null; 然后按住Ctrl查看源码即可。 发送消息Spring Boot自动为我们创建一个KafkaTemplate用于发送消息。注意到这是一个泛型类，而默认配置总是使用String作为Kafka消息的类型，所以注入KafkaTemplate&lt;String, String&gt;即可： 1234567891011121314151617181920@Componentpublic class MessagingService { @Autowired ObjectMapper objectMapper; @Autowired KafkaTemplate&lt;String, String&gt; kafkaTemplate; public void sendRegistrationMessage(RegistrationMessage msg) throws IOException { send(\"topic_registration\", msg); } public void sendLoginMessage(LoginMessage msg) throws IOException { send(\"topic_login\", msg); } private void send(String topic, Object msg) throws IOException { ProducerRecord&lt;String, String&gt; pr = new ProducerRecord&lt;&gt;(topic, objectMapper.writeValueAsString(msg)); pr.headers().add(\"type\", msg.getClass().getName().getBytes(StandardCharsets.UTF_8)); kafkaTemplate.send(pr); }} 发送消息时，需指定Topic名称，消息正文。为了发送一个JavaBean，这里我们没有使用MessageConverter来转换JavaBean，而是直接把消息类型作为Header添加到消息中，Header名称为type，值为Class全名。消息正文是序列化的JSON。 接收消息接收消息可以使用@KafkaListener注解： 1234567891011121314151617181920212223242526272829303132333435@Componentpublic class TopicMessageListener { private final Logger logger = LoggerFactory.getLogger(getClass()); @Autowired ObjectMapper objectMapper; @KafkaListener(topics = \"topic_registration\", groupId = \"group1\") public void onRegistrationMessage(@Payload String message, @Header(\"type\") String type) throws Exception { RegistrationMessage msg = objectMapper.readValue(message, getType(type)); logger.info(\"received registration message: {}\", msg); } @KafkaListener(topics = \"topic_login\", groupId = \"group1\") public void onLoginMessage(@Payload String message, @Header(\"type\") String type) throws Exception { LoginMessage msg = objectMapper.readValue(message, getType(type)); logger.info(\"received login message: {}\", msg); } @KafkaListener(topics = \"topic_login\", groupId = \"group2\") public void processLoginMessage(@Payload String message, @Header(\"type\") String type) throws Exception { LoginMessage msg = objectMapper.readValue(message, getType(type)); logger.info(\"process login message: {}\", msg); } @SuppressWarnings(\"unchecked\") private static &lt;T&gt; Class&lt;T&gt; getType(String type) { // TODO: use cache: try { return (Class&lt;T&gt;) Class.forName(type); } catch (ClassNotFoundException e) { throw new RuntimeException(e); } }} 在接收消息的方法中，使用@Payload表示传入的是消息正文，使用@Header可传入消息的指定Header，这里传入@Header(\"type\")，就是我们发送消息时指定的Class全名。接收消息时，我们需要根据Class全名来反序列化获得JavaBean。 上述代码一共定义了3个Listener，其中有两个方法监听的是同一个Topic，但它们的Group ID不同。假设Producer发送的消息流是A、B、C、D，Group ID不同表示这是两个不同的Consumer，它们将分别收取完整的消息流，即各自均收到A、B、C、D。Group ID相同的多个Consumer实际上被视作一个Consumer，即如果有两个Group ID相同的Consumer，那么它们各自收到的很可能是A、C和B、D。 因为Group ID不同，同一个消息被两个Consumer分别独立接收。如果把Group ID改为相同，那么同一个消息只会被两者之一接收。所以配置Consumer时，指定Group ID非常重要。 有细心的童鞋可能会问，在Kafka中是如何创建Topic的？又如何指定某个Topic的分区数量？ 实际上开发使用的Kafka默认允许自动创建Topic，创建Topic时默认的分区数量是2，可以通过server.properties修改默认分区数量。 在生产环境中通常会关闭自动创建功能，Topic需要由运维人员先创建好。和RabbitMQ相比，Kafka并不提供网页版管理后台，管理Topic需要使用命令行，比较繁琐，只有云服务商通常会提供更友好的管理后台。","link":"/Study/Java/SpringBoot/SpringBoot%E5%BC%80%E5%8F%91/"},{"title":"访问数据库","text":"数据库基本上是现代应用程序的标准存储，绝大多数程序都把自己的业务数据存储在关系数据库中，可见，访问数据库几乎是所有应用程序必备能力。我们在前面已经介绍了Java程序访问数据库的标准接口JDBC，它的实现方式非常简洁，即：Java标准库定义接口，各数据库厂商以“驱动”的形式实现接口。应用程序要使用哪个数据库，就把该数据库厂商的驱动以jar包形式引入进来，同时自身仅使用JDBC接口，编译期并不需要特定厂商的驱动。 使用JDBC虽然简单，但代码比较繁琐。Spring为了简化数据库访问，主要做了以下几点工作： 提供了简化的访问JDBC的模板类，不必手动释放资源 提供了一个统一的DAO类以实现Data Access Object模式 把SQLException封装为DataAccessException，这个异常是一个RuntimeException，并且让我们能区分SQL异常的原因，例如，DuplicateKeyException表示违反了一个唯一约束 能方便地集成Hibernate、JPA和MyBatis这些数据库访问框架 本章我们将详细讲解在Spring中访问数据库的最佳实践。 使用JDBCJava程序使用JDBC接口访问关系数据库的时候，需要以下几步： 创建全局DataSource实例，表示数据库连接池； 在需要读写数据库的方法内部，按如下步骤访问数据库： 从全局DataSource实例获取Connection实例； 通过Connection实例创建PreparedStatement实例； 执行SQL语句，如果是查询，则通过ResultSet读取结果集，如果是修改，则获得int结果。 正确编写JDBC代码的关键是使用try ... finally释放资源，涉及到事务的代码需要正确提交或回滚事务。 在Spring使用JDBC，首先我们通过IoC容器创建并管理一个DataSource实例，然后，Spring提供了一个JdbcTemplate，可以方便地让我们操作JDBC，因此，通常情况下，我们会实例化一个JdbcTemplate。顾名思义，这个类主要使用了Template模式。 编写示例代码或者测试代码时，我们强烈推荐使用HSQLDB这个数据库，它是一个用Java编写的关系数据库，可以以内存模式或者文件模式运行，本身只有一个jar包，非常适合演示代码或者测试代码。 我们以实际工程为例，先创建Maven工程spring-data-jdbc，然后引入以下依赖： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.annotation&lt;/groupId&gt; &lt;artifactId&gt;javax.annotation-api&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hsqldb&lt;/groupId&gt; &lt;artifactId&gt;hsqldb&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在AppConfig中，我们需要创建以下几个必须的Bean： 12345678910111213141516171819202122232425262728293031@Configuration@ComponentScan@PropertySource(\"jdbc.properties\")public class AppConfig { @Value(\"${jdbc.url}\") String jdbcUrl; @Value(\"${jdbc.username}\") String jdbcUsername; @Value(\"${jdbc.password}\") String jdbcPassword; @Bean DataSource createDataSource() { HikariConfig config = new HikariConfig(); config.setJdbcUrl(jdbcUrl); config.setUsername(jdbcUsername); config.setPassword(jdbcPassword); config.addDataSourceProperty(\"autoCommit\", \"true\"); config.addDataSourceProperty(\"connectionTimeout\", \"5\"); config.addDataSourceProperty(\"idleTimeout\", \"60\"); return new HikariDataSource(config); } @Bean JdbcTemplate createJdbcTemplate(@Autowired DataSource dataSource) { return new JdbcTemplate(dataSource); }} 在上述配置中： 通过@PropertySource(\"jdbc.properties\")读取数据库配置文件 通过@Value(\"${jdbc.url}\")注入配置文件的相关配置 创建一个DataSource实例，它的实际类型是HikariDataSource，创建时需要用到注入的配置 创建一个JdbcTemplate实例，它需要注入DataSource，这是通过方法参数完成注入的 最后，针对HSQLDB写一个配置文件jdbc.properties： 123456# 数据库文件名为testdb:jdbc.url=jdbc:hsqldb:file:testdb# Hsqldb默认的用户名是sa，口令是空字符串:jdbc.username=sajdbc.password= 可以通过HSQLDB自带的工具来初始化数据库表，这里我们写一个Bean，在Spring容器启动时自动创建一个users表： 123456789101112131415@Componentpublic class DatabaseInitializer { @Autowired JdbcTemplate jdbcTemplate; @PostConstruct public void init() { jdbcTemplate.update(\"CREATE TABLE IF NOT EXISTS users (\" // + \"id BIGINT IDENTITY NOT NULL PRIMARY KEY, \" // + \"email VARCHAR(100) NOT NULL, \" // + \"password VARCHAR(100) NOT NULL, \" // + \"name VARCHAR(100) NOT NULL, \" // + \"UNIQUE (email))\"); }} 现在，所有准备工作都已完毕。我们只需要在需要访问数据库的Bean中，注入JdbcTemplate即可： 123456@Componentpublic class UserService { @Autowired JdbcTemplate jdbcTemplate; ...} JdbcTemplate的用法Spring提供的JdbcTemplate采用Template模式，提供了一系列以回调为特点的工具方法，目的是避免繁琐的try...catch语句。 我们以具体的示例来说明JdbcTemplate的用法。 首先我们看T execute(ConnectionCallback&lt;T&gt; action)方法，它提供了Jdbc的Connection供我们使用： 1234567891011121314151617181920public User getUserById(long id) { // 注意传入的是ConnectionCallback: return jdbcTemplate.execute((Connection conn) -&gt; { // 可以直接使用conn实例，不要释放它，回调结束后JdbcTemplate自动释放: // 在内部手动创建的PreparedStatement、ResultSet必须用try(...)释放: try (var ps = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\")) { ps.setObject(1, id); try (var rs = ps.executeQuery()) { if (rs.next()) { return new User( // new User object: rs.getLong(\"id\"), // id rs.getString(\"email\"), // email rs.getString(\"password\"), // password rs.getString(\"name\")); // name } throw new RuntimeException(\"user not found by id.\"); } } });} 也就是说，上述回调方法允许获取Connection，然后做任何基于Connection的操作。 我们再看T execute(String sql, PreparedStatementCallback&lt;T&gt; action)的用法： 1234567891011121314151617public User getUserByName(String name) { // 需要传入SQL语句，以及PreparedStatementCallback: return jdbcTemplate.execute(\"SELECT * FROM users WHERE name = ?\", (PreparedStatement ps) -&gt; { // PreparedStatement实例已经由JdbcTemplate创建，并在回调后自动释放: ps.setObject(1, name); try (var rs = ps.executeQuery()) { if (rs.next()) { return new User( // new User object: rs.getLong(\"id\"), // id rs.getString(\"email\"), // email rs.getString(\"password\"), // password rs.getString(\"name\")); // name } throw new RuntimeException(\"user not found by id.\"); } });} 最后，我们看T queryForObject(String sql, Object[] args, RowMapper&lt;T&gt; rowMapper)方法： 123456789101112public User getUserByEmail(String email) { // 传入SQL，参数和RowMapper实例: return jdbcTemplate.queryForObject(\"SELECT * FROM users WHERE email = ?\", new Object[] { email }, (ResultSet rs, int rowNum) -&gt; { // 将ResultSet的当前行映射为一个JavaBean: return new User( // new User object: rs.getLong(\"id\"), // id rs.getString(\"email\"), // email rs.getString(\"password\"), // password rs.getString(\"name\")); // name });} 在queryForObject()方法中，传入SQL以及SQL参数后，JdbcTemplate会自动创建PreparedStatement，自动执行查询并返回ResultSet，我们提供的RowMapper需要做的事情就是把ResultSet的当前行映射成一个JavaBean并返回。整个过程中，使用Connection、PreparedStatement和ResultSet都不需要我们手动管理。 RowMapper不一定返回JavaBean，实际上它可以返回任何Java对象。例如，使用SELECT COUNT(*)查询时，可以返回Long： 123456public long getUsers() { return jdbcTemplate.queryForObject(\"SELECT COUNT(*) FROM users\", null, (ResultSet rs, int rowNum) -&gt; { // SELECT COUNT(*)查询只有一列，取第一列数据: return rs.getLong(1); });} 如果我们期望返回多行记录，而不是一行，可以用query()方法： 123456public List&lt;User&gt; getUsers(int pageIndex) { int limit = 100; int offset = limit * (pageIndex - 1); return jdbcTemplate.query(\"SELECT * FROM users LIMIT ? OFFSET ?\", new Object[] { limit, offset }, new BeanPropertyRowMapper&lt;&gt;(User.class));} 上述query()方法传入的参数仍然是SQL、SQL参数以及RowMapper实例。这里我们直接使用Spring提供的BeanPropertyRowMapper。如果数据库表的结构恰好和JavaBean的属性名称一致，那么BeanPropertyRowMapper就可以直接把一行记录按列名转换为JavaBean。 如果我们执行的不是查询，而是插入、更新和删除操作，那么需要使用update()方法： 123456public void updateUser(User user) { // 传入SQL，SQL参数，返回更新的行数: if (1 != jdbcTemplate.update(\"UPDATE user SET name = ? WHERE id=?\", user.getName(), user.getId())) { throw new RuntimeException(\"User not found by id\"); }} 只有一种INSERT操作比较特殊，那就是如果某一列是自增列（例如自增主键），通常，我们需要获取插入后的自增值。JdbcTemplate提供了一个KeyHolder来简化这一操作： 12345678910111213141516171819202122public User register(String email, String password, String name) { // 创建一个KeyHolder: KeyHolder holder = new GeneratedKeyHolder(); if (1 != jdbcTemplate.update( // 参数1:PreparedStatementCreator (conn) -&gt; { // 创建PreparedStatement时，必须指定RETURN_GENERATED_KEYS: var ps = conn.prepareStatement(\"INSERT INTO users(email,password,name) VALUES(?,?,?)\", Statement.RETURN_GENERATED_KEYS); ps.setObject(1, email); ps.setObject(2, password); ps.setObject(3, name); return ps; }, // 参数2:KeyHolder holder) ) { throw new RuntimeException(\"Insert failed.\"); } // 从KeyHolder中获取返回的自增值: return new User(holder.getKey().longValue(), email, password, name);} JdbcTemplate还有许多重载方法，这里我们不一一介绍。需要强调的是，JdbcTemplate只是对JDBC操作的一个简单封装，它的目的是尽量减少手动编写try(resource) {...}的代码。对于查询，主要通过RowMapper实现了JDBC结果集到Java对象的转换。 我们总结一下JdbcTemplate的用法，那就是： 针对简单查询，优选query()和queryForObject()，因为只需提供SQL语句、参数和RowMapper； 针对更新操作，优选update()，因为只需提供SQL语句和参数； 任何复杂的操作，最终也可以通过execute(ConnectionCallback)实现，因为拿到Connection就可以做任何JDBC操作。 实际上我们使用最多的仍然是各种查询。如果在设计表结构的时候，能够和JavaBean的属性一一对应，那么直接使用BeanPropertyRowMapper就很方便。如果表结构和JavaBean不一致怎么办？那就需要稍微改写一下查询，使结果集的结构和JavaBean保持一致。 例如，表的列名是office_address，而JavaBean属性是workAddress，就需要指定别名，改写查询如下： 1SELECT id, email, office_address AS workAddress, name FROM users WHERE email = ? 小结Spring提供了JdbcTemplate来简化JDBC操作； 使用JdbcTemplate时，根据需要优先选择高级方法； 任何JDBC操作都可以使用保底的execute(ConnectionCallback)方法。 使用声明式事务使用Spring操作JDBC虽然方便，但是我们在前面讨论JDBC的时候，讲到过JDBC事务，如果要在Spring中操作事务，没必要手写JDBC事务，可以使用Spring提供的高级接口来操作事务。 Spring提供了一个PlatformTransactionManager来表示事务管理器，所有的事务都由它负责管理。而事务由TransactionStatus表示。如果手写事务代码，使用try...catch如下： 1234567891011121314TransactionStatus tx = null;try { // 开启事务: tx = txManager.getTransaction(new DefaultTransactionDefinition()); // 相关JDBC操作: jdbcTemplate.update(\"...\"); jdbcTemplate.update(\"...\"); // 提交事务: txManager.commit(tx);} catch (RuntimeException e) { // 回滚事务: txManager.rollback(tx); throw e;} Spring为啥要抽象出PlatformTransactionManager和TransactionStatus？原因是JavaEE除了提供JDBC事务外，它还支持分布式事务JTA（Java Transaction API）。分布式事务是指多个数据源（比如多个数据库，多个消息系统）要在分布式环境下实现事务的时候，应该怎么实现。分布式事务实现起来非常复杂，简单地说就是通过一个分布式事务管理器实现两阶段提交，但本身数据库事务就不快，基于数据库事务实现的分布式事务就慢得难以忍受，所以使用率不高。 Spring为了同时支持JDBC和JTA两种事务模型，就抽象出PlatformTransactionManager。因为我们的代码只需要JDBC事务，因此，在AppConfig中，需要再定义一个PlatformTransactionManager对应的Bean，它的实际类型是DataSourceTransactionManager： 12345678910@Configuration@ComponentScan@PropertySource(\"jdbc.properties\")public class AppConfig { ... @Bean PlatformTransactionManager createTxManager(@Autowired DataSource dataSource) { return new DataSourceTransactionManager(dataSource); }} 使用编程的方式使用Spring事务仍然比较繁琐，更好的方式是通过声明式事务来实现。使用声明式事务非常简单，除了在AppConfig中追加一个上述定义的PlatformTransactionManager外，再加一个@EnableTransactionManagement就可以启用声明式事务： 1234567@Configuration@ComponentScan@EnableTransactionManagement // 启用声明式@PropertySource(\"jdbc.properties\")public class AppConfig { ...} 然后，对需要事务支持的方法，加一个@Transactional注解： 12345678@Componentpublic class UserService { // 此public方法自动具有事务支持: @Transactional public User register(String email, String password, String name) { ... }} 或者更简单一点，直接在Bean的class处加上，表示所有public方法都具有事务支持： 12345@Component@Transactionalpublic class UserService { ...} Spring对一个声明式事务的方法，如何开启事务支持？原理仍然是AOP代理，即通过自动创建Bean的Proxy实现： 1234567891011121314151617public class UserService$$EnhancerBySpringCGLIB extends UserService { UserService target = ... PlatformTransactionManager txManager = ... public User register(String email, String password, String name) { TransactionStatus tx = null; try { tx = txManager.getTransaction(new DefaultTransactionDefinition()); target.register(email, password, name); txManager.commit(tx); } catch (RuntimeException e) { txManager.rollback(tx); throw e; } } ...} 注意：声明了@EnableTransactionManagement后，不必额外添加@EnableAspectJAutoProxy。 回滚事务默认情况下，如果发生了RuntimeException，Spring的声明式事务将自动回滚。在一个事务方法中，如果程序判断需要回滚事务，只需抛出RuntimeException，例如： 123456789@Transactionalpublic buyProducts(long productId, int num) { ... if (store &lt; num) { // 库存不够，购买失败: throw new IllegalArgumentException(\"No enough products\"); } ...} 如果要针对Checked Exception回滚事务，需要在@Transactional注解中写出来： 1234@Transactional(rollbackFor = {RuntimeException.class, IOException.class})public buyProducts(long productId, int num) throws IOException { ...} 上述代码表示在抛出RuntimeException或IOException时，事务将回滚。 为了简化代码，我们强烈建议业务异常体系从RuntimeException派生，这样就不必声明任何特殊异常即可让Spring的声明式事务正常工作： 1234567891011public class BusinessException extends RuntimeException { ...}public class LoginException extends BusinessException { ...}public class PaymentException extends BusinessException { ...} 事务边界在使用事务的时候，明确事务边界非常重要。对于声明式事务，例如，下面的register()方法： 1234567@Componentpublic class UserService { @Transactional public User register(String email, String password, String name) { // 事务开始 ... } // 事务结束} 它的事务边界就是register()方法开始和结束。 类似的，一个负责给用户增加积分的addBonus()方法： 1234567@Componentpublic class BonusService { @Transactional public void addBonus(long userId, int bonus) { // 事务开始 ... } // 事务结束} 它的事务边界就是addBonus()方法开始和结束。 在现实世界中，问题总是要复杂一点点。用户注册后，能自动获得100积分，因此，实际代码如下： 12345678910111213@Componentpublic class UserService { @Autowired BonusService bonusService; @Transactional public User register(String email, String password, String name) { // 插入用户记录: User user = jdbcTemplate.insert(\"...\"); // 增加100积分: bonusService.addBonus(user.id, 100); }} 现在问题来了：调用方（比如RegisterController）调用UserService.register()这个事务方法，它在内部又调用了BonusService.addBonus()这个事务方法，一共有几个事务？如果addBonus()抛出了异常需要回滚事务，register()方法的事务是否也要回滚？ 问题的复杂度是不是一下子提高了10倍？ 事务传播要解决上面的问题，我们首先要定义事务的传播模型。 假设用户注册的入口是RegisterController，它本身没有事务，仅仅是调用UserService.register()这个事务方法： 1234567891011121314@Controllerpublic class RegisterController { @Autowired UserService userService; @PostMapping(\"/register\") public ModelAndView doRegister(HttpServletRequest req) { String email = req.getParameter(\"email\"); String password = req.getParameter(\"password\"); String name = req.getParameter(\"name\"); User user = userService.register(email, password, name); return ... }} 因此，UserService.register()这个事务方法的起始和结束，就是事务的范围。 我们需要关心的问题是，在UserService.register()这个事务方法内，调用BonusService.addBonus()，我们期待的事务行为是什么： 1234567@Transactionalpublic User register(String email, String password, String name) { // 事务已开启: User user = jdbcTemplate.insert(\"...\"); // ???: bonusService.addBonus(user.id, 100);} // 事务结束 对于大多数业务来说，我们期待BonusService.addBonus()的调用，和UserService.register()应当融合在一起，它的行为应该如下： UserService.register()已经开启了一个事务，那么在内部调用BonusService.addBonus()时，BonusService.addBonus()方法就没必要再开启一个新事务，直接加入到BonusService.register()的事务里就好了。 其实就相当于： UserService.register()先执行了一条INSERT语句：INSERT INTO users ... BonusService.addBonus()再执行一条INSERT语句：INSERT INTO bonus ... 因此，Spring的声明式事务为事务传播定义了几个级别，默认传播级别就是REQUIRED，它的意思是，如果当前没有事务，就创建一个新事务，如果当前有事务，就加入到当前事务中执行。 我们观察UserService.register()方法，它在RegisterController中执行，因为RegisterController没有事务，因此，UserService.register()方法会自动创建一个新事务。 在UserService.register()方法内部，调用BonusService.addBonus()方法时，因为BonusService.addBonus()检测到当前已经有事务了，因此，它会加入到当前事务中执行。 因此，整个业务流程的事务边界就清晰了：它只有一个事务，并且范围就是UserService.register()方法。 有的童鞋会问：把BonusService.addBonus()方法的@Transactional去掉，变成一个普通方法，那不就规避了复杂的传播模型吗？ 去掉BonusService.addBonus()方法的@Transactional，会引来另一个问题，即其他地方如果调用BonusService.addBonus()方法，那就没法保证事务了。例如，规定用户登录时积分+5： 1234567891011@Controllerpublic class LoginController { @Autowired BonusService bonusService; @PostMapping(\"/login\") public ModelAndView doLogin(HttpServletRequest req) { User user = ... bonusService.addBonus(user.id, 5); }} 可见，BonusService.addBonus()方法必须要有@Transactional，否则，登录后积分就无法添加了。 默认的事务传播级别是REQUIRED，它满足绝大部分的需求。还有一些其他的传播级别： SUPPORTS：表示如果有事务，就加入到当前事务，如果没有，那也不开启事务执行。这种传播级别可用于查询方法，因为SELECT语句既可以在事务内执行，也可以不需要事务； MANDATORY：表示必须要存在当前事务并加入执行，否则将抛出异常。这种传播级别可用于核心更新逻辑，比如用户余额变更，它总是被其他事务方法调用，不能直接由非事务方法调用； REQUIRES_NEW：表示不管当前有没有事务，都必须开启一个新的事务执行。如果当前已经有事务，那么当前事务会挂起，等新事务完成后，再恢复执行； NOT_SUPPORTED：表示不支持事务，如果当前有事务，那么当前事务会挂起，等这个方法执行完成后，再恢复执行； NEVER：和NOT_SUPPORTED相比，它不但不支持事务，而且在监测到当前有事务时，会抛出异常拒绝执行； NESTED：表示如果当前有事务，则开启一个嵌套级别事务，如果当前没有事务，则开启一个新事务。 上面这么多种事务的传播级别，其实默认的REQUIRED已经满足绝大部分需求，SUPPORTS和REQUIRES_NEW在少数情况下会用到，其他基本不会用到，因为把事务搞得越复杂，不仅逻辑跟着复杂，而且速度也会越慢。 定义事务的传播级别也是写在@Transactional注解里的： 1234@Transactional(propagation = Propagation.REQUIRES_NEW)public Product createProduct() { ...} 现在只剩最后一个问题了：Spring是如何传播事务的？ 我们在JDBC中使用事务的时候，是这么个写法： 123456789101112131415Connection conn = openConnection();try { // 关闭自动提交: conn.setAutoCommit(false); // 执行多条SQL语句: insert(); update(); delete(); // 提交事务: conn.commit();} catch (SQLException e) { // 回滚事务: conn.rollback();} finally { conn.setAutoCommit(true); conn.close();} Spring使用声明式事务，最终也是通过执行JDBC事务来实现功能的，那么，一个事务方法，如何获知当前是否存在事务？ 答案是使用ThreadLocal。Spring总是把JDBC相关的Connection和TransactionStatus实例绑定到ThreadLocal。如果一个事务方法从ThreadLocal未取到事务，那么它会打开一个新的JDBC连接，同时开启一个新的事务，否则，它就直接使用从ThreadLocal获取的JDBC连接以及TransactionStatus。 因此，事务能正确传播的前提是，方法调用是在一个线程内才行。如果像下面这样写： 123456789@Transactionalpublic User register(String email, String password, String name) { // BEGIN TX-A User user = jdbcTemplate.insert(\"...\"); new Thread(() -&gt; { // BEGIN TX-B: bonusService.addBonus(user.id, 100); // END TX-B }).start();} // END TX-A 在另一个线程中调用BonusService.addBonus()，它根本获取不到当前事务，因此，UserService.register()和BonusService.addBonus()两个方法，将分别开启两个完全独立的事务。 换句话说，事务只能在当前线程传播，无法跨线程传播。 那如果我们想实现跨线程传播事务呢？原理很简单，就是要想办法把当前线程绑定到ThreadLocal的Connection和TransactionStatus实例传递给新线程，但实现起来非常复杂，根据异常回滚更加复杂，不推荐自己去实现。 Spring提供的声明式事物极大地方便了在数据库中使用事务，正确使用声明式事务的关键在于确定好事务边界，理解事物传播级别。 使用DAO在传统的多层应用程序中，通常是Web层调用业务层，业务层调用数据访问层。业务层负责处理各种业务逻辑，而数据访问层只负责对数据进行增删改查。因此，实现数据访问层就是用JdbcTemplate实现对数据库的操作。 编写数据访问层的时候，可以使用DAO模式。DAO即Data Access Object的缩写，它没有什么神秘之处，实现起来基本如下： 12345678910111213141516171819202122232425public class UserDao { @Autowired JdbcTemplate jdbcTemplate; User getById(long id) { ... } List&lt;User&gt; getUsers(int page) { ... } User createUser(User user) { ... } User updateUser(User user) { ... } void deleteUser(User user) { ... }} Spring提供了一个JdbcDaoSupport类，用于简化DAO的实现。这个JdbcDaoSupport没什么复杂的，核心代码就是持有一个JdbcTemplate： 123456789101112131415public abstract class JdbcDaoSupport extends DaoSupport { private JdbcTemplate jdbcTemplate; public final void setJdbcTemplate(JdbcTemplate jdbcTemplate) { this.jdbcTemplate = jdbcTemplate; initTemplateConfig(); } public final JdbcTemplate getJdbcTemplate() { return this.jdbcTemplate; } ...} 它的意图是子类直接从JdbcDaoSupport继承后，可以随时调用getJdbcTemplate()获得JdbcTemplate的实例。那么问题来了：因为JdbcDaoSupport的jdbcTemplate字段没有标记@Autowired，所以，子类想要注入JdbcTemplate，还得自己想个办法： 1234567891011@Component@Transactionalpublic class UserDao extends JdbcDaoSupport { @Autowired JdbcTemplate jdbcTemplate; @PostConstruct public void init() { super.setJdbcTemplate(jdbcTemplate); }} 有的童鞋可能看出来了：既然UserDao都已经注入了JdbcTemplate，那再把它放到父类里，通过getJdbcTemplate()访问岂不是多此一举？ 如果使用传统的XML配置，并不需要编写@Autowired JdbcTemplate jdbcTemplate，但是考虑到现在基本上是使用注解的方式，我们可以编写一个AbstractDao，专门负责注入JdbcTemplate： 123456789public abstract class AbstractDao extends JdbcDaoSupport { @Autowired private JdbcTemplate jdbcTemplate; @PostConstruct public void init() { super.setJdbcTemplate(jdbcTemplate); }} 这样，子类的代码就非常干净，可以直接调用getJdbcTemplate()： 123456789101112@Component@Transactionalpublic class UserDao extends AbstractDao { public User getById(long id) { return getJdbcTemplate().queryForObject( \"SELECT * FROM users WHERE id = ?\", new BeanPropertyRowMapper&lt;&gt;(User.class), id ); } ...} 倘若肯再多写一点样板代码，就可以把AbstractDao改成泛型，并实现getById()，getAll()，deleteById()这样的通用方法： 1234567891011121314151617181920212223242526272829public abstract class AbstractDao&lt;T&gt; extends JdbcDaoSupport { private String table; private Class&lt;T&gt; entityClass; private RowMapper&lt;T&gt; rowMapper; public AbstractDao() { // 获取当前类型的泛型类型: this.entityClass = getParameterizedType(); this.table = this.entityClass.getSimpleName().toLowerCase() + \"s\"; this.rowMapper = new BeanPropertyRowMapper&lt;&gt;(entityClass); } public T getById(long id) { return getJdbcTemplate().queryForObject(\"SELECT * FROM \" + table + \" WHERE id = ?\", this.rowMapper, id); } public List&lt;T&gt; getAll(int pageIndex) { int limit = 100; int offset = limit * (pageIndex - 1); return getJdbcTemplate().query(\"SELECT * FROM \" + table + \" LIMIT ? OFFSET ?\", new Object[] { limit, offset }, this.rowMapper); } public void deleteById(long id) { getJdbcTemplate().update(\"DELETE FROM \" + table + \" WHERE id = ?\", id); } ...} 这样，每个子类就自动获得了这些通用方法： 1234567891011121314151617@Component@Transactionalpublic class UserDao extends AbstractDao&lt;User&gt; { // 已经有了: // User getById(long) // List&lt;User&gt; getAll(int) // void deleteById(long)}@Component@Transactionalpublic class BookDao extends AbstractDao&lt;Book&gt; { // 已经有了: // Book getById(long) // List&lt;Book&gt; getAll(int) // void deleteById(long)} 可见，DAO模式就是一个简单的数据访问模式，是否使用DAO，根据实际情况决定，因为很多时候，直接在Service层操作数据库也是完全没有问题的。 集成Hibernate使用JdbcTemplate的时候，我们用的最多的方法就是List&lt;T&gt; query(String sql, Object[] args, RowMapper rowMapper)，这个RowMapper的作用是把ResultSet的一行记录映射为Java Bean。这种把关系数据库的表记录转换为Java对象的过程就是ORM：Object Relational Mapping。ORM既可以把行记录转换成行对象，也可以把Java对象转换为行记录。 使用JdbcTemplate配合RowMapper可以看作最原始的ORM，如果要实现更自动化的ORM，可以选择更成熟的ORM框架，例如Hibernate。 我们来看看如何在Spring中集成Hibernate。 Hibernate作为ORM框架，它可以替代JdbcTemplate，但Hibernate仍然需要JDBC驱动，所以，我们需要引入JDBC驱动、连接池，以及Hibernate本身。在Maven中，我们加入以下依赖项： 1234567891011121314151617181920212223242526272829303132&lt;!-- JDBC驱动，这里使用HSQLDB --&gt;&lt;dependency&gt; &lt;groupId&gt;org.hsqldb&lt;/groupId&gt; &lt;artifactId&gt;hsqldb&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- JDBC连接池 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Hibernate --&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;5.4.2.Final&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Spring Context和Spring ORM --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;5.2.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在AppConfig中，我们仍然需要创建DataSource、引入JDBC配置文件，以及启用声明式事务： 12345678910@Configuration@ComponentScan@EnableTransactionManagement@PropertySource(\"jdbc.properties\")public class AppConfig { @Bean DataSource createDataSource() { ... }} 为了启用Hibernate，我们需要创建一个LocalSessionFactoryBean： 123456789101112131415public class AppConfig { @Bean LocalSessionFactoryBean createSessionFactory(@Autowired DataSource dataSource) { var props = new Properties(); props.setProperty(\"hibernate.hbm2ddl.auto\", \"update\"); // 生产环境不要使用 props.setProperty(\"hibernate.dialect\", \"org.hibernate.dialect.HSQLDialect\"); props.setProperty(\"hibernate.show_sql\", \"true\"); var sessionFactoryBean = new LocalSessionFactoryBean(); sessionFactoryBean.setDataSource(dataSource); // 扫描指定的package获取所有entity class: sessionFactoryBean.setPackagesToScan(\"com.itranswarp.learnjava.entity\"); sessionFactoryBean.setHibernateProperties(props); return sessionFactoryBean; }} 注意我们在定制Bean中讲到过FactoryBean，LocalSessionFactoryBean是一个FactoryBean，它会再自动创建一个SessionFactory，在Hibernate中，Session是封装了一个JDBC Connection的实例，而SessionFactory是封装了JDBC DataSource的实例，即SessionFactory持有连接池，每次需要操作数据库的时候，SessionFactory创建一个新的Session，相当于从连接池获取到一个新的Connection。SessionFactory就是Hibernate提供的最核心的一个对象，但LocalSessionFactoryBean是Spring提供的为了让我们方便创建SessionFactory的类。 注意到上面创建LocalSessionFactoryBean的代码，首先用Properties持有Hibernate初始化SessionFactory时用到的所有设置，常用的设置请参考Hibernate文档，这里我们只定义了3个设置： hibernate.hbm2ddl.auto=update：表示自动创建数据库的表结构，注意不要在生产环境中启用； hibernate.dialect=org.hibernate.dialect.HSQLDialect：指示Hibernate使用的数据库是HSQLDB。Hibernate使用一种HQL的查询语句，它和SQL类似，但真正在“翻译”成SQL时，会根据设定的数据库“方言”来生成针对数据库优化的SQL； hibernate.show_sql=true：让Hibernate打印执行的SQL，这对于调试非常有用，我们可以方便地看到Hibernate生成的SQL语句是否符合我们的预期。 除了设置DataSource和Properties之外，注意到setPackagesToScan()我们传入了一个package名称，它指示Hibernate扫描这个包下面的所有Java类，自动找出能映射为数据库表记录的JavaBean。后面我们会仔细讨论如何编写符合Hibernate要求的JavaBean。 紧接着，我们还需要创建HibernateTemplate以及HibernateTransactionManager： 1234567891011public class AppConfig { @Bean HibernateTemplate createHibernateTemplate(@Autowired SessionFactory sessionFactory) { return new HibernateTemplate(sessionFactory); } @Bean PlatformTransactionManager createTxManager(@Autowired SessionFactory sessionFactory) { return new HibernateTransactionManager(sessionFactory); }} 这两个Bean的创建都十分简单。HibernateTransactionManager是配合Hibernate使用声明式事务所必须的，而HibernateTemplate则是Spring为了便于我们使用Hibernate提供的工具类，不是非用不可，但推荐使用以简化代码。 到此为止，所有的配置都定义完毕，我们来看看如何将数据库表结构映射为Java对象。 考察如下的数据库表： 123456789CREATE TABLE user id BIGINT NOT NULL AUTO_INCREMENT, email VARCHAR(100) NOT NULL, password VARCHAR(100) NOT NULL, name VARCHAR(100) NOT NULL, createdAt BIGINT NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `email` (`email`)); 其中，id是自增主键，email、password、name是VARCHAR类型，email带唯一索引以确保唯一性，createdAt存储整型类型的时间戳。用JavaBean表示如下： 12345678910public class User { private Long id; private String email; private String password; private String name; private Long createdAt; // getters and setters ...} 这种映射关系十分易懂，但我们需要添加一些注解来告诉Hibernate如何把User类映射到表记录： 12345678910111213141516171819@Entitypublic class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(nullable = false, updatable = false) public Long getId() { ... } @Column(nullable = false, unique = true, length = 100) public String getEmail() { ... } @Column(nullable = false, length = 100) public String getPassword() { ... } @Column(nullable = false, length = 100) public String getName() { ... } @Column(nullable = false, updatable = false) public Long getCreatedAt() { ... }} 如果一个JavaBean被用于映射，我们就标记一个@Entity。默认情况下，映射的表名是user，如果实际的表名不同，例如实际表名是users，可以追加一个@Table(name=\"users\")表示： 12345@Entity@Table(name=\"users)public class User { ...} 每个属性到数据库列的映射用@Column()标识，nullable指示列是否允许为NULL，updatable指示该列是否允许被用在UPDATE语句，length指示String类型的列的长度（如果没有指定，默认是255）。 对于主键，还需要用@Id标识，自增主键再追加一个@GeneratedValue，以便Hibernate能读取到自增主键的值。 细心的童鞋可能还注意到，主键id定义的类型不是long，而是Long。这是因为Hibernate如果检测到主键为null，就不会在INSERT语句中指定主键的值，而是返回由数据库生成的自增值，否则，Hibernate认为我们的程序指定了主键的值，会在INSERT语句中直接列出。long型字段总是具有默认值0，因此，每次插入的主键值总是0，导致除第一次外后续插入都将失败。 createdAt虽然是整型，但我们并没有使用long，而是Long，这是因为使用基本类型会导致某种查询会添加意外的条件，后面我们会详细讨论，这里只需牢记，作为映射使用的JavaBean，所有属性都使用包装类型而不是基本类型。 使用Hibernate时，不要使用基本类型的属性，总是使用包装类型，如Long或Integer。 类似的，我们再定义一个Book类： 12345678910111213@Entitypublic class Book { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(nullable = false, updatable = false) public Long getId() { ... } @Column(nullable = false, length = 100) public String getTitle() { ... } @Column(nullable = false, updatable = false) public Long getCreatedAt() { ... }} 如果仔细观察User和Book，会发现它们定义的id、createdAt属性是一样的，这在数据库表结构的设计中很常见：对于每个表，通常我们会统一使用一种主键生成机制，并添加createdAt表示创建时间，updatedAt表示修改时间等通用字段。 不必在User和Book中重复定义这些通用字段，我们可以把它们提到一个抽象类中： 123456789101112131415161718192021222324@MappedSuperclasspublic abstract class AbstractEntity { private Long id; private Long createdAt; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(nullable = false, updatable = false) public Long getId() { ... } @Column(nullable = false, updatable = false) public Long getCreatedAt() { ... } @Transient public ZonedDateTime getCreatedDateTime() { return Instant.ofEpochMilli(this.createdAt).atZone(ZoneId.systemDefault()); } @PrePersist public void preInsert() { setCreatedAt(System.currentTimeMillis()); }} 对于AbstractEntity来说，我们要标注一个@MappedSuperclass表示它用于继承。此外，注意到我们定义了一个@Transient方法，它返回一个“虚拟”的属性。因为getCreatedDateTime()是计算得出的属性，而不是从数据库表读出的值，因此必须要标注@Transient，否则Hibernate会尝试从数据库读取名为createdDateTime这个不存在的字段从而出错。 再注意到@PrePersist标识的方法，它表示在我们将一个JavaBean持久化到数据库之前（即执行INSERT语句），Hibernate会先执行该方法，这样我们就可以自动设置好createdAt属性。 有了AbstractEntity，我们就可以大幅简化User和Book： 123456789101112@Entitypublic class User extends AbstractEntity { @Column(nullable = false, unique = true, length = 100) public String getEmail() { ... } @Column(nullable = false, length = 100) public String getPassword() { ... } @Column(nullable = false, length = 100) public String getName() { ... }} 注意到使用的所有注解均来自javax.persistence，它是JPA规范的一部分。这里我们只介绍使用注解的方式配置Hibernate映射关系，不再介绍传统的比较繁琐的XML配置。通过Spring集成Hibernate时，也不再需要hibernate.cfg.xml配置文件，用一句话总结： 使用Spring集成Hibernate，配合JPA注解，无需任何额外的XML配置。 类似User、Book这样的用于ORM的Java Bean，我们通常称之为Entity Bean。 最后，我们来看看如果对user表进行增删改查。因为使用了Hibernate，因此，我们要做的，实际上是对User这个JavaBean进行“增删改查”。我们编写一个UserService，注入HibernateTemplate以便简化代码： 123456@Component@Transactionalpublic class UserService { @Autowired HibernateTemplate hibernateTemplate;} Insert操作要持久化一个User实例，我们只需调用save()方法。以register()方法为例，代码如下： 1234567891011121314public User register(String email, String password, String name) { // 创建一个User对象: User user = new User(); // 设置好各个属性: user.setEmail(email); user.setPassword(password); user.setName(name); // 不要设置id，因为使用了自增主键 // 保存到数据库: hibernateTemplate.save(user); // 现在已经自动获得了id: System.out.println(user.getId()); return user;} Delete操作删除一个User相当于从表中删除对应的记录。注意Hibernate总是用id来删除记录，因此，要正确设置User的id属性才能正常删除记录： 12345678public boolean deleteUser(Long id) { User user = hibernateTemplate.get(User.class, id); if (user != null) { hibernateTemplate.delete(user); return true; } return false;} 通过主键删除记录时，一个常见的用法是先根据主键加载该记录，再删除。load()和get()都可以根据主键加载记录，它们的区别在于，当记录不存在时，get()返回null，而load()抛出异常。 Update操作更新记录相当于先更新User的指定属性，然后调用update()方法： 12345public void updateUser(Long id, String name) { User user = hibernateTemplate.load(User.class, id); user.setName(name); hibernateTemplate.update(user);} 前面我们在定义User时，对有的属性标注了@Column(updatable=false)。Hibernate在更新记录时，它只会把@Column(updatable=true)的属性加入到UPDATE语句中，这样可以提供一层额外的安全性，即如果不小心修改了User的email、createdAt等属性，执行update()时并不会更新对应的数据库列。但也必须牢记：这个功能是Hibernate提供的，如果绕过Hibernate直接通过JDBC执行UPDATE语句仍然可以更新数据库的任意列的值。 最后，我们编写的大部分方法都是各种各样的查询。根据id查询我们可以直接调用load()或get()，如果要使用条件查询，有3种方法。 假设我们想执行以下查询： 1SELECT * FROM user WHERE email = ? AND password = ? 我们来看看可以使用什么查询。 使用Example查询第一种方法是使用findByExample()，给出一个User实例，Hibernate把该实例所有非null的属性拼成WHERE条件： 1234567public User login(String email, String password) { User example = new User(); example.setEmail(email); example.setPassword(password); List&lt;User&gt; list = hibernateTemplate.findByExample(example); return list.isEmpty() ? null : list.get(0);} 因为example实例只有email和password两个属性为非null，所以最终生成的WHERE语句就是WHERE email = ? AND password = ?。 如果我们把User的createdAt的类型从Long改为long，findByExample()的查询将出问题，原因在于example实例的long类型字段有了默认值0，导致Hibernate最终生成的WHERE语句意外变成了WHERE email = ? AND password = ? AND createdAt = 0。显然，额外的查询条件将导致错误的查询结果。 使用findByExample()时，注意基本类型字段总是会加入到WHERE条件！ 使用Criteria查询第二种查询方法是使用Criteria查询，可以实现如下： 1234567public User login(String email, String password) { DetachedCriteria criteria = DetachedCriteria.forClass(User.class); criteria.add(Restrictions.eq(\"email\", email)) .add(Restrictions.eq(\"password\", password)); List&lt;User&gt; list = (List&lt;User&gt;) hibernateTemplate.findByCriteria(criteria); return list.isEmpty() ? null : list.get(0);} DetachedCriteria使用链式语句来添加多个AND条件。和findByExample()相比，findByCriteria()可以组装出更灵活的WHERE条件，例如： 1SELECT * FROM user WHERE (email = ? OR name = ?) AND password = ? 上述查询没法用findByExample()实现，但用Criteria查询可以实现如下： 12345678910DetachedCriteria criteria = DetachedCriteria.forClass(User.class);criteria.add( Restrictions.and( Restrictions.or( Restrictions.eq(\"email\", email), Restrictions.eq(\"name\", email) ), Restrictions.eq(\"password\", password) )); 只要组织好Restrictions的嵌套关系，Criteria查询可以实现任意复杂的查询。 使用HQL查询最后一种常用的查询是直接编写Hibernate内置的HQL查询： 1List&lt;User&gt; list = (List&lt;User&gt;) hibernateTemplate.find(\"FROM User WHERE email=? AND password=?\", email, password); 和SQL相比，HQL使用类名和属性名，由Hibernate自动转换为实际的表名和列名。详细的HQL语法可以参考Hibernate文档。 除了可以直接传入HQL字符串外，Hibernate还可以使用一种NamedQuery，它给查询起个名字，然后保存在注解中。使用NamedQuery时，我们要先在User类标注： 123456789101112@NamedQueries( @NamedQuery( // 查询名称: name = \"login\", // 查询语句: query = \"SELECT u FROM User u WHERE u.email=?0 AND u.password=?1\" ))@Entitypublic class User extends AbstractEntity { ...} 注意到引入的NamedQuery是javax.persistence.NamedQuery，它和直接传入HQL有点不同的是，占位符使用?0、?1，并且索引是从0开始的（真乱）。 使用NamedQuery只需要引入查询名和参数： 1234public User login(String email, String password) { List&lt;User&gt; list = (List&lt;User&gt;) hibernateTemplate.findByNamedQuery(\"login\", email, password); return list.isEmpty() ? null : list.get(0);} 直接写HQL和使用NamedQuery各有优劣。前者可以在代码中直观地看到查询语句，后者可以在User类统一管理所有相关查询。 使用Hibernate原生接口如果要使用Hibernate原生接口，但不知道怎么写，可以参考HibernateTemplate的源码。使用Hibernate的原生接口实际上总是从SessionFactory出发，它通常用全局变量存储，在HibernateTemplate中以成员变量被注入。有了SessionFactory，使用Hibernate用法如下： 123456789101112131415161718192021void operation() { Session session = null; boolean isNew = false; // 获取当前Session或者打开新的Session: try { session = this.sessionFactory.getCurrentSession(); } catch (HibernateException e) { session = this.sessionFactory.openSession(); isNew = true; } // 操作Session: try { User user = session.load(User.class, 123L); } finally { // 关闭新打开的Session: if (isNew) { session.close(); } }} 集成JPA在讨论JPA（Java Persistence API）之前，我们要注意到JavaEE早在1999年就发布了，并有Servlet、JMS等诸多标准。和其他平台不同，Java世界早期热衷于标准先行，大家先坐下来把接口定了，然后，各自回家去实现接口。这样，用户就可以在不同厂家提供的产品进行选择，还可以随意切换，因为用户编写代码时只需要引用接口，不需要引用具体的底层实现，这一点很类似JDBC。 JPA就是JavaEE的一个ORM标准，它的实现其实和Hibernate没啥本质区别，但是如果用户使用JPA，引用的就是javax.persistance这个包，而不是org.hibernate这样的第三方包。 我们使用JPA时也完全可以选择Hibernate作为底层实现，但也可以选择其他产品，比如EclipseLink。Spring内置了JPA的集成，并支持选择Hibernate或EclipseLink作为实现。这里我们仍然以主流的Hibernate作为JPA实现的例子，演示JPA的基本用法。 和使用Hibernate一样，我们只需要引入如下依赖： org.springframework:spring-context:5.2.0.RELEASE org.springframework:spring-orm:5.2.0.RELEASE javax.annotation:javax.annotation-api:1.3.2 org.hibernate:hibernate-core:5.4.2.Final com.zaxxer:HikariCP:3.4.2 org.hsqldb:hsqldb:2.5.0 然后，在AppConfig中启用声明式事务管理，创建DataSource： 12345678@Configuration@ComponentScan@EnableTransactionManagement@PropertySource(\"jdbc.properties\")public class AppConfig { @Bean DataSource createDataSource() { ... }} 使用Hibernate时，我们需要创建一个LocalSessionFactoryBean，并让它再自动创建一个SessionFactory。使用JPA也是类似的，我们需要创建一个LocalContainerEntityManagerFactoryBean，并让它再自动创建一个EntityManagerFactory： 123456789101112131415161718@BeanLocalContainerEntityManagerFactoryBean createEntityManagerFactory(@Autowired DataSource dataSource) { var entityManagerFactoryBean = new LocalContainerEntityManagerFactoryBean(); // 设置DataSource: entityManagerFactoryBean.setDataSource(dataSource); // 扫描指定的package获取所有entity class: entityManagerFactoryBean.setPackagesToScan(\"com.itranswarp.learnjava.entity\"); // 指定JPA的提供商是Hibernate: JpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter(); entityManagerFactoryBean.setJpaVendorAdapter(vendorAdapter); // 设定特定提供商自己的配置: var props = new Properties(); props.setProperty(\"hibernate.hbm2ddl.auto\", \"update\"); props.setProperty(\"hibernate.dialect\", \"org.hibernate.dialect.HSQLDialect\"); props.setProperty(\"hibernate.show_sql\", \"true\"); entityManagerFactoryBean.setJpaProperties(props); return entityManagerFactoryBean;} 观察上述代码，除了需要注入DataSource和设定自动扫描的package外，还需要指定JPA的提供商，这里使用Spring提供的一个HibernateJpaVendorAdapter，最后，针对Hibernate自己需要的配置，以Properties的形式注入。 最后，我们还需要实例化一个JpaTransactionManager，以实现声明式事务： 1234@BeanPlatformTransactionManager createTxManager(@Autowired EntityManagerFactory entityManagerFactory) { return new JpaTransactionManager(entityManagerFactory);} 这样，我们就完成了JPA的全部初始化工作。有些童鞋可能从网上搜索得知JPA需要persistence.xml配置文件，以及复杂的orm.xml文件。这里我们负责地告诉大家，使用Spring+Hibernate作为JPA实现，无需任何配置文件。 所有Entity Bean的配置和上一节完全相同，全部采用Annotation标注。我们现在只需关心具体的业务类如何通过JPA接口操作数据库。 还是以UserService为例，除了标注@Component和@Transactional外，我们需要注入一个EntityManager，但是不要使用Autowired，而是@PersistenceContext： 123456@Component@Transactionalpublic class UserService { @PersistenceContext EntityManager em;} 我们回顾一下JDBC、Hibernate和JPA提供的接口，实际上，它们的关系如下： JDBC Hibernate JPA DataSource SessionFactory EntityManagerFactory Connection Session EntityManager SessionFactory和EntityManagerFactory相当于DataSource，Session和EntityManager相当于Connection。每次需要访问数据库的时候，需要获取新的Session和EntityManager，用完后再关闭。 但是，注意到UserService注入的不是EntityManagerFactory，而是EntityManager，并且标注了@PersistenceContext。难道使用JPA可以允许多线程操作同一个EntityManager？ 实际上这里注入的并不是真正的EntityManager，而是一个EntityManager的代理类，相当于： 123public class EntityManagerProxy implements EntityManager { private EntityManagerFactory emf;} Spring遇到标注了@PersistenceContext的EntityManager会自动注入代理，该代理会在必要的时候自动打开EntityManager。换句话说，多线程引用的EntityManager虽然是同一个代理类，但该代理类内部针对不同线程会创建不同的EntityManager实例。 简单总结一下，标注了@PersistenceContext的EntityManager可以被多线程安全地共享。 因此，在UserService的每个业务方法里，直接使用EntityManager就很方便。以主键查询为例： 1234567public User getUserById(long id) { User user = this.em.find(User.class, id); if (user == null) { throw new RuntimeException(\"User not found by id: \" + id); } return user;} JPA同样支持Criteria查询，比如我们需要的查询如下： 1SELECT * FROM user WHERE email = ? 使用Criteria查询的代码如下： 12345678910111213public User fetchUserByEmail(String email) { // CriteriaBuilder: var cb = em.getCriteriaBuilder(); CriteriaQuery&lt;User&gt; q = cb.createQuery(User.class); Root&lt;User&gt; r = q.from(User.class); q.where(cb.equal(r.get(\"email\"), cb.parameter(String.class, \"e\"))); TypedQuery&lt;User&gt; query = em.createQuery(q); // 绑定参数: query.setParameter(\"e\", email); // 执行查询: List&lt;User&gt; list = query.getResultList(); return list.isEmpty() ? null : list.get(0);} 一个简单的查询用Criteria写出来就像上面那样复杂，太恐怖了，如果条件多加几个，这种写法谁读得懂？ 所以，正常人还是建议写JPQL查询，它的语法和HQL基本差不多： 12345678910public User getUserByEmail(String email) { // JPQL查询: TypedQuery&lt;User&gt; query = em.createQuery(\"SELECT u FROM User u WHERE u.email = :e\", User.class); query.setParameter(\"e\", email); List&lt;User&gt; list = query.getResultList(); if (list.isEmpty()) { throw new RuntimeException(\"User not found by email.\"); } return list.get(0);} 同样的，JPA也支持NamedQuery，即先给查询起个名字，再按名字创建查询： 1234567public User login(String email, String password) { TypedQuery&lt;User&gt; query = em.createNamedQuery(\"login\", User.class); query.setParameter(\"e\", email); query.setParameter(\"p\", password); List&lt;User&gt; list = query.getResultList(); return list.isEmpty() ? null : list.get(0);} NamedQuery通过注解标注在User类上，它的定义和上一节的User类一样： 12345678910@NamedQueries( @NamedQuery( name = \"login\", query = \"SELECT u FROM User u WHERE u.email=:e AND u.password=:p\" ))@Entitypublic class User { ...} 对数据库进行增删改的操作，可以分别使用persist()、remove()和merge()方法，参数均为Entity Bean本身，使用非常简单，这里不再多述。 集成Mybatis使用Hibernate或JPA操作数据库时，这类ORM干的主要工作就是把ResultSet的每一行变为Java Bean，或者把Java Bean自动转换到INSERT或UPDATE语句的参数中，从而实现ORM。而ORM框架之所以知道如何把行数据映射到Java Bean，是因为我们在Java Bean的属性上给了足够的注解作为元数据，ORM框架获取Java Bean的注解后，就知道如何进行双向映射。 那么，ORM是如何跟踪Java Bean的修改，以便在update()操作中更新必要的属性？ 答案是使用Proxy模式，从ORM框架读取到的是User实例实际上并不是User类，而是代理类，代理类继承自User类，但针对每个setter方法做了覆写。 12345678public class UserProxy extends User { boolean _isNameChanged; public void setName(String name) { super.setName(name); _isNameChanged = true; }} 这样，代理类就能跟踪到每个属性的变化。针对一对多或多对一关系时，代理类可以直接通过getter方法查询数据库。 12345678910111213141516171819public class UserProxy extends User { Session _session; boolean _isNameChanged; public void setName(String name) { super.setName(name); _isNameChanged = true; } /** * 获取User对象关联的Address对象: */ public Address getAddress() { Query q = _session.createQuery(\"from Address where userId = :userId\"); q.setParameter(\"userId\", this.getId()); List&lt;Address&gt; list = query.list(); return list.isEmpty() ? null : list(0); }} 为了实现这样的查询，UserProxy必须保存Hibernate的当前Session。但是，当事务提交后，Session自动关闭，此时再获取getAddress()将无法访问数据库，或者获取的不是事务一致的数据。因此，ORM框架总是引入了Attached/Detached状态，表示当前此Java Bean到底是在Session的范围内，还是脱离了Session变成了一个“游离”对象。很多初学者无法正确理解状态变化和事务边界，就会造成大量的PersistentObjectException异常。这种隐式状态使得普通Java Bean的生命周期变得复杂。 此外，Hibernate和JPA为了实现兼容多种数据库，它使用HQL或JPQL查询，经过一道转换，变成特定数据库的SQL，理论上这样可以做到无缝切换数据库，但这一层自动转换除了少许的性能开销外，给SQL级别的优化带来了麻烦。 最后，ORM框架通常提供了缓存，并且还分为一级缓存和二级缓存。一级缓存是指在一个Session范围内的缓存，常见的情景是根据主键查询时，两次查询可以返回同一实例： 12User user1 = session.load(User.class, 123);User user2 = session.load(User.class, 123); 二级缓存是指跨Session的缓存，一般默认关闭，需要手动配置。二级缓存极大的增加了数据的不一致性，原因在于SQL非常灵活，常常会导致意外的更新。例如： 12345// 线程1读取:User user1 = session1.load(User.class, 123);...// 一段时间后，线程2读取:User user2 = session2.load(User.class, 123); 当二级缓存生效的时候，两个线程读取的User实例是一样的，但是，数据库对应的行记录完全可能被修改，例如： 12-- 给老用户增加100积分:UPDATE users SET bonus = bonus + 100 WHERE createdAt &lt;= ? ORM无法判断id=123的用户是否受该UPDATE语句影响。考虑到数据库通常会支持多个应用程序，此UPDATE语句可能由其他进程执行，ORM框架就更不知道了。 我们把这种ORM框架称之为全自动ORM框架，对比Spring提供的JdbcTemplate，主要有以下几点差别： 查询后需要手动提供Mapper实例以便把ResultSet的每一行变为Java对象 增删改操作所需的参数列表，需要手动传入，即把User实例变为[user.id, user.name, user.email]这样的列表，比较麻烦 但是JdbcTemplate的优势在于它的确定性：即每次读操作一定是数据库操作而不是缓存，所执行的SQL是完全确定的，缺点是代码比较繁琐，构造INSERT INTO users VALUES (?,?,?)更是复杂。 所以，介于全自动ORM如Hibernate和手写全部如JdbcTemplate之间，还有一种半自动ORM，它只负责把ResultSet自动映射到Java Bean，或者自动填充Java Bean参数，但仍需要自己写出SQL。MyBatis就是这样一种半自动化框架。 我们来看看如何在Spring中集成MyBatis。 首先，我们要引入MyBatis本身，其次，由于Spring并没有内置对MyBatis的集成，所以，我们需要再引入MyBatis官方自己开发的一个与Spring集成的库： org.mybatis:mybatis:3.5.4 org.mybatis:mybatis-spring:2.0.4 和前面一样，先创建DataSource： 12345678@Configuration@ComponentScan@EnableTransactionManagement@PropertySource(\"jdbc.properties\")public class AppConfig { @Bean DataSource createDataSource() { ... }} 再回顾一下Hibernate和JPA的SessionFactory与EntityManagerFactory，MyBatis与之对应的是SqlSessionFactory和SqlSession： JDBC Hibernate JPA MyBatis DataSource SessionFactory EntityManagerFactory SqlSessionFactory Connection Session EntityManager SqlSession 可见，ORM的设计套路都是类似的，使用MyBatis的核心是创建SqlSessionFactory，这里我们需要创建的是SqlSessionFactoryBean： 123456@BeanSqlSessionFactoryBean createSqlSessionFactoryBean(@Autowired DataSource dataSource) { var sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource); return sqlSessionFactoryBean;} MyBatis可以直接使用Spring管理的声明式事务，因此，创建事务管理器和使用JDBC是一样的： 1234@BeanPlatformTransactionManager createTxManager(@Autowired DataSource dataSource) { return new DataSourceTransactionManager(dataSource);} 和Hibernate不同的是，MyBatis使用Mapper来实现映射，而且Mapper必须是接口。我们以User类为例，在User类和users表之间映射的UserMapper编写如下： 1234public interface UserMapper { @Select(\"SELECT * FROM users WHERE id = #{id}\") User getById(@Param(\"id\") long id);} 注意：这里的Mapper不是JdbcTemplate的RowMapper的概念，它是定义访问users表的接口方法。比如我们定义了一个User getById(long)的主键查询方法，不仅要定义接口方法本身，还要明确写出查询的SQL，这里用注解@Select标记。SQL语句的任何参数，都与方法参数按名称对应。例如，方法参数id的名字通过注解@Param()标记为id，则SQL语句里将来替换的占位符就是#{id}。 如果有多个参数，那么每个参数命名后直接在SQL中写出对应的占位符即可： 12@Select(\"SELECT * FROM users LIMIT #{offset}, #{maxResults}\")List&lt;User&gt; getAll(@Param(\"offset\") int offset, @Param(\"maxResults\") int maxResults); 注意：MyBatis执行查询后，将根据方法的返回类型自动把ResultSet的每一行转换为User实例，转换规则是按列名和属性名对应。如果列名和属性名不同，最简单的方式是编写SELECT语句的别名。 12-- 列名是created_time，属性名是createdAt:SELECT id, name, email, created_time AS createdAt FROM users 执行INSERT语句就稍微麻烦点，因为我们希望传入User实例，因此，定义的方法接口与@Insert注解如下： 12@Insert(\"INSERT INTO users (email, password, name, createdAt) VALUES (#{user.email}, #{user.password}, #{user.name}, #{user.createdAt})\")void insert(@Param(\"user\") User user); 上述方法传入的参数名称是user，参数类型是User类，在SQL中引用的时候，以#{obj.property}的方式写占位符。和Hibernate这样的全自动化ORM相比，MyBatis必须写出完整的INSERT语句。 如果users表的id是自增主键，那么，我们在SQL中不传入id，但希望获取插入后的主键，需要再加一个@Options注解： 123@Options(useGeneratedKeys = true, keyProperty = \"id\", keyColumn = \"id\")@Insert(\"INSERT INTO users (email, password, name, createdAt) VALUES (#{user.email}, #{user.password}, #{user.name}, #{user.createdAt})\")void insert(@Param(\"user\") User user); keyProperty和keyColumn分别指出JavaBean的属性和数据库的主键列名。 执行UPDATE和DELETE语句相对比较简单，我们定义方法如下： 12345@Update(\"UPDATE users SET name = #{user.name}, createdAt = #{user.createdAt} WHERE id = #{user.id}\")void update(@Param(\"user\") User user);@Delete(\"DELETE FROM users WHERE id = #{id}\")void deleteById(@Param(\"id\") long id); 有了UserMapper接口，还需要对应的实现类才能真正执行这些数据库操作的方法。虽然可以自己写实现类，但我们除了编写UserMapper接口外，还有BookMapper、BonusMapper……一个一个写太麻烦，因此，MyBatis提供了一个MapperFactoryBean来自动创建所有Mapper的实现类。可以用一个简单的注解来启用它： 12345@MapperScan(\"com.itranswarp.learnjava.mapper\")...其他注解...public class AppConfig { ...} 有了@MapperScan，就可以让MyBatis自动扫描指定包的所有Mapper并创建实现类。在真正的业务逻辑中，我们可以直接注入： 12345678910111213141516@Component@Transactionalpublic class UserService { // 注入UserMapper: @Autowired UserMapper userMapper; public User getUserById(long id) { // 调用Mapper方法: User user = userMapper.getById(id); if (user == null) { throw new RuntimeException(\"User not found by id.\"); } return user; }} 可见，业务逻辑主要就是通过XxxMapper定义的数据库方法来访问数据库。 XML配置上述Spring集成MyBatis的方式，我们只需要用到注解，并没有使用任何任何XML配置文件。MyBatis也允许使用XML配置映射关系和SQL语句，例如，更新User时根据属性值构造动态SQL： 123456789&lt;update id=\"updateUser\"&gt; UPDATE users SET &lt;set&gt; &lt;if test=\"user.name != null\"&gt; name = #{user.name} &lt;/if&gt; &lt;if test=\"user.hobby != null\"&gt; hobby = #{user.hobby} &lt;/if&gt; &lt;if test=\"user.summary != null\"&gt; summary = #{user.summary} &lt;/if&gt; &lt;/set&gt; WHERE id = #{user.id}&lt;/update&gt; 编写XML配置的优点是可以组装出动态SQL，并且把所有SQL操作集中在一起，缺点是配置起来太繁琐，调用方法时如果想查看SQL还需要定位到XML配置中。这里我们不介绍XML的配置方式，需要了解的童鞋请自行阅读官方文档。 使用MyBatis最大的问题是所有SQL都需要全部手写，优点是执行的SQL就是我们自己写的SQL，对SQL进行优化非常简单，也可以编写任意复杂的SQL，或者使用数据库的特定语法，但切换数据库可能就不太容易。好消息是大部分项目并没有切换数据库的需求，完全可以针对某个数据库编写尽可能优化的SQL。 设计ORMORM框架就是自动映射数据库表结构到Java Bean的工具，设计并实现一个简单高效的ORM框架并不难。","link":"/Study/Java/Spring/%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"Web开发","text":"从本章开始我们就进入到JavaEE的领域。JavaEE并不是一个软件产品，它更多的是一种软件架构和设计思想。我们可以把JavaEE看作是在JavaSE的基础上，开发的一系列基于服务器的组件、API标准和通用架构。 JavaEE最核心的部件是基于Servlet标准的Web服务器，开发者编写的应用程序是基于Servlet API并运行在Web服务器内部的。此外，JavaEE还有一系列技术标准： EJB：Enterprise JavaBean，企业级JavaBean，早期经常用于实现应用程序的业务逻辑，现在基本被轻量级框架如Spring所取代 JAAS：Java Authentication and Authorization Service，一个标准的认证和授权服务，常用于企业内部，Web程序通常使用更轻量级的自定义认证 JCA：JavaEE Connector Architecture，用于连接企业内部的EIS系统等 JMS：Java Message Service，用于消息服务 JTA：Java Transaction API，用于分布式事务 JAX-WS：Java API for XML Web Services，用于构建基于XML的Web服务 … 目前流行的基于Spring的轻量级JavaEE开发架构，使用最广泛的是Servlet和JMS，以及一系列开源组件。本章我们将详细介绍基于Servlet的Web开发。 Web基础今天我们访问网站、使用App时，都是基于Web这种Browser/Server模式，简称BS架构。它的特点是，客户端只需要浏览器，应用程序的逻辑和数据都存储在服务器端。浏览器只需要请求服务器，获取Web页面，并把Web页面展示给用户即可。 因为Web页面是用HTML编写的，而HTML具有强大的表现力，所以Web页面具有极强的交互性。并且，服务端升级后，客户端无需任何部署就可以使用到新版本，因此，BS架构升级非常容易。 对于Browser来说，请求页面的流程如下： 与服务器建立TCP连接 发送HTTP请求 接收HTTP相应，然后把网页在浏览器端显示出来 HTTP协议浏览器发送的HTTP请求如下： 12345GET / HTTP/1.1Host: www.sina.com.cnUser-Agent: Mozilla/5.0 xxxAccept: */*Accept-Language: zh-CN,zh;q=0.9,en-US;q=0.8 其中，第一行表示使用GET请求路径为/的资源，并使用HTTP/1.1协议。从第二行开始，每行都是以Header: Value形式表示的HTTP头，比较常用的HTTP Header包括： Host：表示请求的主机名，因为一个服务器上可能运行着多个网站，因此Host表示浏览器正在请求的域名 User-Agent：标识客户端本身，例如Chrome浏览器的标识类似Mozilla/5.0 ... Chrome/79，IE浏览器的标识类似Mozilla/5.0 (Windows NT ...) like Gecko Accept：表示浏览器能接收的资源类型，如text/*，image/*或者*/*表示所有 Accept-Language：表示浏览器偏好的语言，服务器可以根据这个返回不同语言的网页 Accept-Encoding：表示浏览器可以支持的压缩类型，例如gzip, deflate, br 服务器的响应如下： 1234567HTTP/1.1 200 OKContent-Type: text/htmlContent-Length: 21932Content-Encoding: gzipCache-Control: max-age=300&lt;html&gt;...网页数据... 服务器响应的第一行总是版本号+空格+数字+空格+文本，数字表示响应码，其中2xx表示成功，3xx表示重定向，4xx表示客户端引发的所务，5xx表示服务端引发的错误。数字是给程序识别，文本是给开发者调试使用的。常见的响应代码有： 200 OK：表示成功； 301 Moved Permanently：表示该URL已经永久重定向； 302 Found：表示该URL需要临时重定向； 304 Not Modified：表示该资源没有修改，客户端可以使用本地缓存的版本； 400 Bad Request：表示客户端发送了一个错误的请求，例如参数无效； 401 Unauthorized：表示客户端因为身份未验证而不允许访问该URL； 403 Forbidden：表示服务器因为权限问题拒绝了客户端的请求； 404 Not Found：表示客户端请求了一个不存在的资源； 500 Internal Server Error：表示服务器处理时内部出错，例如因为无法连接数据库； 503 Service Unavailable：表示服务器此刻暂时无法处理请求。 从第二行开始，服务器每一行返回一个HTTP头。服务器经常返回的HTTP Header包括： Content-Type：表示该响应内容的类型，例如text/html，image/jpeg Content-Length：表示该响应内容的长度（字节数） Content-Encoding：表示该响应压缩算法，例如gzip Cache-Control：指示客户端应如何缓存，例如max-age=300表示可以最多缓存300秒 HTTP请求和响应都由HTTP Header和HTTP Body构成，其中HTTP Header每行以\\r\\n。如果遇到连续两个\\r\\n，那么后面就是HTTP Body。浏览器读取HTTP Body，并根据Header信息中指示的Content-Type，Content-Encoding等解压后显示网页、图像或其他内容。 通常浏览器获取的第一个资源是HTTP网页，在网页中，如果嵌入了JavaScript、CSS、图片、视频等其他资源，浏览器会根据资源的URL再次向服务器请求对应的资源。 编写HTTP Server一个HTTP Server本质上是一个TCP服务器，我们先用TCP编程的知识实现服务器端的框架。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class Server { public static void main(String[] args) throws IOException { ServerSocket ss = new ServerSocket(8080); // 监听指定端口 System.out.println(\"server is running...\"); for (;;) { Socket sock = ss.accept(); System.out.println(\"connected from \" + sock.getRemoteSocketAddress()); Thread t = new Handler(sock); t.start(); } }}class Handler extends Thread { Socket sock; public Handler(Socket sock) { this.sock = sock; } public void run() { try (InputStream input = this.sock.getInputStream()) { try (OutputStream output = this.sock.getOutputStream()) { handle(input, output); } } catch (Exception e) { try { this.sock.close(); } catch (IOException ioe) { } System.out.println(\"client disconnected.\"); } } private void handle(InputStream input, OutputStream output) throws IOException { var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8)); var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8)); // TODO: 处理HTTP请求 System.out.println(\"Process new http request...\"); var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8)); var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8)); // 读取HTTP请求: boolean requestOk = false; String first = reader.readLine(); if (first.startsWith(\"GET / HTTP/1.\")) { requestOk = true; } for (;;) { String header = reader.readLine(); if (header.isEmpty()) { // 读取到空行时, HTTP Header读取完毕 break; } System.out.println(header); } System.out.println(requestOk ? \"Response OK\" : \"Response Error\"); if (!requestOk) { // 发送错误响应: writer.write(\"HTTP/1.0 404 Not Found\\r\\n\"); writer.write(\"Content-Length: 0\\r\\n\"); writer.write(\"\\r\\n\"); writer.flush(); } else { // 发送成功响应: String data = \"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello, world!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\"; int length = data.getBytes(StandardCharsets.UTF_8).length; writer.write(\"HTTP/1.0 200 OK\\r\\n\"); writer.write(\"Connection: close\\r\\n\"); writer.write(\"Content-Type: text/html\\r\\n\"); writer.write(\"Content-Length: \" + length + \"\\r\\n\"); writer.write(\"\\r\\n\"); // 空行标识Header和Body的分隔 writer.write(data); writer.flush(); }} 这里的核心代码是，先读取HTTP请求，这里我们只处理GET /的请求。当读取到空行时，表示已读到连续两个\\r\\n，说明请求结束，可以发送响应。发送响应的时候，首先发送响应代码HTTP/1.0 200 OK表示一个成功的200响应，使用HTTP/1.0协议，然后，依次发送Header，发送完Header后，再发送一个空行标识Header结束，紧接着发送HTTP Body，在浏览器输入http://localhost:8080/就可以看到响应页面。 HTTP目前有多个版本，1.0是早期版本，浏览器每次建立TCP连接后，只发送一个HTTP请求并接收一个HTTP响应，然后就关闭TCP连接。由于创建TCP连接本身就需要消耗一定的时间，因此，HTTP 1.1允许浏览器和服务器在同一个TCP连接上反复发送、接收多个HTTP请求和响应，这样就大大提高了传输效率。 我们注意到HTTP协议是一个请求-响应协议，它总是发送一个请求，然后接收一个响应。能不能一次性发送多个请求，然后再接收多个响应呢？HTTP 2.0可以支持浏览器同时发出多个请求，但每个请求需要唯一标识，服务器可以不按请求的顺序返回多个响应，由浏览器自己把收到的响应和请求对应起来。可见，HTTP 2.0进一步提高了传输效率，因为浏览器发出一个请求后，不必等待响应，就可以继续发下一个请求。 HTTP 3.0为了进一步提高速度，将抛弃TCP协议，改为使用无需创建连接的UDP协议，目前HTTP 3.0仍然处于实验阶段。 Servlet入门在上一节中我们看到，编写HTTP服务器其实是比较简单的，只需要先编写基于多线程的TCP服务，然后在一个TCP连接中去读HTTP请求，发送HTTP响应即可。但是，要编写一个完善的HTTP服务器，以HTTP/1.1为例，需要考虑： 识别正确和错误的HTTP请求； 识别正确和错误的HTTP头； 复用TCP连接； 复用线程； IO异常处理； … 这些基础的工作需要耗费大量的时间，并且经过长期测试才能稳定运行。如果我们只需要输出一个简单的HTML页面，就不得不编写上千行底层代码，那就无法做到高效而可靠的开发。 因此，在JavaEE平台上，处理TCP连接，解析HTTP协议这些底层工作统统交给现成的Web服务器去做，我们只需要把自己的应用程序跑在Web服务器上。为了实现这一目的，JavaEE提供了Servlet API，我们使用Servlet API编写自己的Servlet来处理HTTP请求，Web服务器实现Servlet API接口，实现底层功能： 1234567 ┌───────────┐ │My Servlet │ ├───────────┤ │Servlet API│┌───────┐ HTTP ├───────────┤│Browser│&lt;──────&gt;│Web Server │└───────┘ └───────────┘ 我们来实现一个最简单的Servlet： 123456789101112131415// WebServlet注解表示这是一个Servlet，并映射到地址/:@WebServlet(urlPatterns = \"/\")public class HelloServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 设置响应类型: resp.setContentType(\"text/html\"); // 获取输出流: PrintWriter pw = resp.getWriter(); // 写入响应: pw.write(\"&lt;h1&gt;Hello, world!&lt;/h1&gt;\"); // 最后不要忘记flush强制输出: pw.flush(); }} 一个Servlet总是继承自HttpServlet，然后覆写doGet()和doPost()方法。注意到doGet()方法传入了HttpServletRequest和HttpServletResponse，分别表示HTTP请求和响应。我们使用Servlet API时，并不与底层TCP交互。也不需要解析HTTP协议，因为HttpServletRequest和HttpServletResponse都已经封装好了请求和响应。以发送响应为例，我们只需要设置正确的响应类型，然后获取PrintWriter，写入响应即可。 那么Servlet API是谁提供的呢？ Servlet API是一个jar包，我们需要通过Maven来引入它，才能正常编译： 12345678910&lt;packaging&gt;war&lt;/packaging&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 注意到这个pom.xml与之前讲到的普通Java程序有点不同，打包类型是不jar而是war，表示Java Web Application Archive。注意到&lt;scope&gt;指定为provided，表示编译时使用，但不会打包到.war文件中，因为运行期Web服务器本身已经提供了Servlet API相关的jar包。 我们还需要在工程目录下创建一个web.xml描述文件，放到src/main/webapp/WEB-INF目录下（固定目录结构，不要修改路径，注意大小写）。文件内容可以固定如下： 123456&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\"&gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt;&lt;/web-app&gt; 1234567891011121314web-servlet-hello├── pom.xml└── src └── main ├── java │ └── com │ └── itranswarp │ └── learnjava │ └── servlet │ └── HelloServlet.java ├── resources └── webapp └── WEB-INF └── web.xml 运行Maven命令mvn clean package，在target目录下得到一个hello.war文件，这个文件就是我们编译打包后的Web应用程序。 普通的Java程序是通过启动JVM，然后执行main()方法开始运行。但是Web应用程序有所不同，我们无法直接运行war文件，必须先启动Web服务器，再由Web服务器加载我们编写的HelloServlet，这样就可以让HelloServlet处理浏览器发送的请求。 因此，我们首先要找一个支持Servlet API的Web服务器。常用的服务器有： Tomcat：由Apache开发的开源免费服务器； Jetty：由Eclipse开发的开源免费服务器； GlassFish：一个开源的全功能JavaEE服务器。 无论使用哪个服务器，只要它支持Servlet API 4.0（因为我们引入的Servlet版本是4.0），我们的war包都可以在上面运行。这里我们选择使用最广泛的开源免费的Tomcat服务器。 要运行我们的hello.war，首先要下载Tomcat服务器，解压后，把hello.war复制到Tomcat的webapps目录下，然后切换到bin目录，执行startup.sh或startup.bat启动Tomcat服务器。 在浏览器输入http://localhost:8080/hello/即可看到HelloServlet的输出。细心的童鞋可能会问，为啥路径是/hello/而不是/？因为一个Web服务器允许同时运行多个Web App，而我们的Web App叫hello，因此，第一级目录/hello表示Web App的名字，后面的/才是我们在HelloServlet中映射的路径。 那能不能直接使用/而不是/hello/？毕竟/比较简洁。 答案是肯定的。先关闭Tomcat（执行shutdown.sh或shutdown.bat），然后删除Tomcat的webapps目录下的所有文件夹和文件，最后把我们的hello.war复制过来，改名为ROOT.war，文件名为ROOT的应用程序将作为默认应用，启动后直接访问http://localhost:8080/即可。 实际上，类似Tomcat这样的服务器也是Java编写的，启动Tomcat服务器实际上是启动Java虚拟机，执行Tomcat的main()方法，然后由Tomcat负责加载我们的.war文件，并创建一个HelloServlet实例，最后以多线程的模式来处理HTTP请求。如果Tomcat服务器收到的请求路径是/（假定部署文件为ROOT.war），就转发到HelloServlet并传入HttpServletRequest和HttpServletResponse两个对象。 因为我们编写的Servlet并不是直接运行，而是由Web服务器加载后创建实例运行，所以，类似Tomcat这样的Web服务器也称为Servlet容器。 在Servlet容器中运行的Servlet具有如下特点： 无法在代码中直接通过new创建Servlet实例，必须由Servlet容器自动创建Servlet实例 Servlet容器只会给每个Servlet类创建唯一实例 Servlet容器会使用多线程执行doGet()或doPost()方法 复习一下Java多线程的内容，我们可以得出结论： 在Servlet中定义的实例变量会被多个线程同时访问，要注意线程安全 HttpServletRequest和HttpServletResponse实例是由Servlet容器传入的局部变量，它们只能被当前线程访问，不存在多个线程访问的问题 在doGet()或doPost()方法中，如果使用了ThreadLocal，但没有清理，那么它的状态很可能会影响到下次的某个请求，因为Servlet容器很可能用线程池实现线程复用 因此，正确编写Servlet，要清晰理解Java的多线程模型，需要同步访问的必须同步。 Servlet开发在上一节中我们看到，一个完整的Web应用程序开发流程如下： 编写Servlet 打包为war文件 复制到Tomcat的webapps目录下 启动Tomcat 这个过程有点繁琐，比如我们想在IDE中断点调试，还需要打开Tomcat的远程调试窗口并连接上去。因此，我们需要一种简单可靠，能直接在IDE中启动并调试webapp的方法。我们先来看看Tomcat的启动流程： 启动JVM并执行Tomcat的main()方法 加载war并初始化Servlet 正常服务 启动Tomcat无非就是设置好classpath并执行Tomcat某个jar包的main()方法，我们完全可以把Tomcat的jar包全部引入进来，然后自己编写main()方法，让它先启动Tomcat，再加载我们的webapp就行。 我们新建一个web-servlet-embedded工程，编写pom.xml如下： 12345678910111213141516171819202122232425262728293031323334&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itranswarp.learnjava&lt;/groupId&gt; &lt;artifactId&gt;web-servlet-embedded&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt; &lt;java.version&gt;11&lt;/java.version&gt; &lt;tomcat.version&gt;9.0.26&lt;/tomcat.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt; &lt;version&gt;${tomcat.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;version&gt;${tomcat.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 其中，&lt;packaging&gt;类型仍然为war，引入依赖tomcat-embed-core和tomcat-embed-jasper。不必再引入Servlet API，因为引入的Tomcat依赖启动后自动引入了Servlet API，我们正常编写Servlet如下： 12345678910111213@WebServlet(urlPatterns = \"/\")public class HelloServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.setContentType(\"text/html\"); String name = req.getParameter(\"name\"); if (name == null) { name = \"world\"; } PrintWriter pw = resp.getWriter(); pw.write(\"&lt;h1&gt;Hello, \" + name + \"!&lt;/h1&gt;\"); pw.flush(); }} 然后，我们编写一个main()方法，启动Tomcat服务器： 12345678910111213141516public class Main { public static void main(String[] args) throws Exception { // 启动Tomcat: Tomcat tomcat = new Tomcat(); tomcat.setPort(Integer.getInteger(\"port\", 8080)); tomcat.getConnector(); // 创建webapp: Context ctx = tomcat.addWebapp(\"\", new File(\"src/main/webapp\").getAbsolutePath()); WebResourceRoot resources = new StandardRoot(ctx); resources.addPreResources( new DirResourceSet(resources, \"/WEB-INF/classes\", new File(\"target/classes\").getAbsolutePath(), \"/\")); ctx.setResources(resources); tomcat.start(); tomcat.getServer().await(); }} 这样，我们运行main()方法，即可启动嵌入式Tomcat服务器，然后，通过预设的tomcat.addWebapp(\"\", new File(\"src/main/webapp\"))，Tomcat会自动加载当前工程为根webapp，可直接在浏览器访问http://localhost:8080/。 通过main()方法启动Tomcat服务器并加载我们自己的webapp有如下好处： 启动简单，无需下载Tomcat或安装任何IDE插件 调试方便，可在IDE中使用断点调试 使用Maven创建war包后，也可以正常部署到独立的Tomcar应用服务器 对SpringBoot有所了解的童鞋可能知道，SpringBoot也支持在main()方法中一行代码直接启动Tomcat，并且还能方便地更换成Jetty等其他服务器。它的启动方式和我们介绍的是基本一样的，后续涉及到SpringBoot的部分我们还会详细讲解。 开发Servlet时，推荐使用main()方法启动嵌入式Tomcat服务器并加载当前工程的webapp，便于开发调试，且不影响打包部署，能提升开发效率。 Servlet进阶一个Web App是由一个或多个Servlet组成，每个Servlet通过注解说明自己能处理的路径。比如： 12345678@WebServlet(urlPatterns = \"/hello\")public class HelloServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { ... } ...} 上述HelloServlet能处理/hello这个路径的请求。早期的Servlet需要在web.xml中配置映射路径，但最新Servlet版本只需要通过注解就可以完成映射。 浏览器发送请求时，还会有请求方法（HTTP Method）：即GET、POST、PUT等不同类型的请求，因此要处理GET请求必须覆写doGet()方法。类似地，要处理POST请求，就需要覆写doPost()方法。如果没有覆写doPost()方法，那么HelloServlet能不能处理POST/hello请求呢？ 我们查看HttpServlet的doPost()：它会直接返回405或400错误。因此，如果一个Servlet映射到/hello，那么这个路径下的所有请求方法都会由这个Servlet来处理，至于能不能返回200成功响应，要看有没有覆写对应的请求方法。 一个WebApp完全可以有多个Servlet，分别映射不同的路径。浏览器发送的HTTP请求总是由Web Server先接收，然后根据Servlet配置的映射，不同的路径转发到不同的Servlet。这种根据路径转发的功能一般称为Dispatch。映射到/的Servlet比较特殊，它会接收所有未匹配的路径。 一、HttpServletRequest封装了一个HTTP请求，通过HttpServletRequest的接口几乎可以拿到HTTP请求的全部信息。 getMethod()：返回请求方法，例如，\"GET\"，\"POST\" getRequestURI()：返回请求路径，但不包括请求参数，例如，\"/hello\" getQueryString()：返回请求参数，例如，\"name=Bob&amp;a=1&amp;b=2\" getParameter(name)：返回请求参数，GET请求从URL读取参数，POST请求从Body中读取参数 getContentType()：获取请求Body的类型，例如，\"application/x-www-form-urlencoded\" getContextPath()：获取当前Webapp挂载的路径，对于ROOT来说，总是返回空字符串\"\" getCookies()：返回请求携带的所有Cookie getHeader(name)：获取指定的Header，对Header名称不区分大小写 getHeaderNames()：返回所有Header名称 getInputStream()：如果该请求带有HTTP Body，该方法将打开一个输入流用于读取Body getReader()：和getInputStream()类似，但打开的是Reader getRemoteAddr()：返回客户端的IP地址 getScheme()：返回协议类型，例如，\"http\"，\"https\" 此外，HttpServletRequest还有两个方法：setAttribute()和getAttribute()，可以给当前HttpServletRequest对象附加多个Key-Value，相当于把HttpServletRequest当作一个Map&lt;String, Object&gt;使用。调用HttpServletRequest的方法时，注意务必阅读接口方法的文档说明，因为有的方法会返回null。 二、HttpServletResponse封装了一个HTTP响应。由于HTTP响应必须先发送Header，再发送Body，所以，操作HttpServletResponse对象时，必须先调用设置Header的方法，最后调用发送Body的方法。 常用的设置Header的方法有： setStatus(sc)：设置响应代码，默认是200 setContentType(type)：设置Body的类型，例如，\"text/html\" setCharacterEncoding(charset)：设置字符编码，例如，\"UTF-8\" setHeader(name, value)：设置一个Header的值 addCookie(cookie)：给响应添加一个Cookie addHeader(name, value)：给响应添加一个Header，因为HTTP协议允许有多个相同的Header 写入响应时，需要通过getOutputStream()获取写入流，或者通过getWriter()获取字符流，二者只能获取其中一个。写入响应前，无需设置setContentLength()，因为底层服务器会根据写入的字节数自动设置，如果写入的数据量很小，实际上会写入缓冲区，如果写入的数据量很大，服务器会自动采用Chunked编码让浏览器能识别数据结束符而不需要设置Content-Length。 但是写完后调用flush()是必须的，因为大部分Web服务器都基于HTTP/1.1协议，会复用TCP连接。如果没有调用flush()会导致缓冲区的内容无法及时发送到客户端。此外，写入完毕后千万不要调用close()，因为会有复用TCP连接，如果关闭写入流，将关闭TCP连接，使得Web服务器无法复用此连接。 有了HttpServletRequest和HttpServletResponse这两个高级接口，我们就不需要直接处理HTTP协议，注意到具体的实现类是由各服务器提供的，而我们编写的Web应用程序只关心接口方法，不需要关心具体的实现子类。 三、一个Servlet类在服务器中只有一个实例，但对于每个HTTP请求，Web服务器会使用多线程执行请求。因此，一个Servlet的doGet()、doPost()等处理请求是多线程并发执行的。如果Servlet中定义了字段，要注意多线程并发访问的问题。 12345678public class HelloServlet extends HttpServlet { private Map&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;(); protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 注意读写map字段是多线程并发的: this.map.put(key, value); }} 对于每个请求，Web服务器会创建唯一的HttpServletRequest和HttpServletResponse实例，因此，HttpServletRequest和HttpServletResponse实例只有在当前处理线程中有效，它们总是局部变量，不存在多线程共享的问题。 重定向与转发Redirect重定向是指浏览器请求一个URL时，浏览器返会一个重定向指令，告诉浏览器地址已经变了，请使用新的URL发送新的请求。 例如，我们已经编写了一个能处理/hello的HelloServlet，如果收到的路径为/hi，希望能重定向到/hello，可以再编写一个RedirectServlet： 12345678910@WebServlet(urlPatterns = \"/hi\")public class RedirectServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 构造重定向的路径: String name = req.getParameter(\"name\"); String redirectToUrl = \"/hello\" + (name == null ? \"\" : \"?name=\" + name); // 发送重定向响应: resp.sendRedirect(redirectToUrl); }} 使用浏览器发送GET /hi请求，RedirectServlet将处理此请求，RedirectServlet内部又发送了重定向响应，因此浏览器会收到如下响应： 12HTTP/1.1 302 FoundLocation: /hello 当浏览器收到302响应时，它会立刻根据Location的提示发送一个新的GET /hello请求，这个过程就是重定向。观察Chrome浏览器的网络请求，可以看到两次HTTP请求。 重定向有两种：一种是302响应，称为临时重定向；一种是301响应，称为永久重定向。两者的区别是，如果服务器发301永久重定向响应，浏览器会缓存/hi到/hello这个重定向的关联，下次请求/hi的时候，浏览器就直接发送/hello请求。 重定向有什么作用？重定向的目的是当Web应用升级时，如果请求路径发生了变化，可以将原来的路径重定向到新路径，避免浏览器请求原路径找不到资源。 HttpServletResponse提供了快捷的redirect()方法实现302重定向。如果要实现301永久重定向，可以这么写： 12resp.setStatus(HttpServletResponse.SC_MOVED_PERMANENTLY); // 301resp.setHeader(\"Location\", \"/hello\"); ForwardForward是指内部转发。当一个Servlet处理请求时，它可以自己决定不处理，而是转发给另一个Servlet处理。 例如，我们编写一个能处理/hello的HelloServlet，继续编写一个能处理/morning的ForwardServlet： 123456@WebServlet(urlPatterns = \"/morning\")public class ForwardServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { req.getRequestDispatcher(\"/hello\").forward(req, resp); }} ForwardServlet在收到请求后，它并不自己发送响应，而是把请求和响应都转发给路径为/hello的Servlet。后续请求的处理实际上是由HelloServlet完成的。这种处理方式称为转发（Forward）。 转发和重定向的区别在于，转发是在Web服务器内部完成的，对浏览器来说它只发送了一个HTTP请求，浏览器并不知道请求在Web服务器内部做了一次转发。 使用Session和Cookie在Web应用程序中，我们经常需要跟踪用户身份。当一个用户登录成功后，如果用户继续访问其他页面，Web程序如何才能识别用户身份？而HTTP协议是无状态的，即Web应用程序无法区分收到的两个HTTP请求是否是同一个浏览器发出的。为了跟踪用户状态，服务器可以向浏览器分配一个唯一ID，并以Cookie的形式发送到浏览器，浏览器在后续访问时总附带此Cookie，这样，服务器就可以识别用户身份。 Session我们把这种基于唯一ID识别用户身份的机制称为Session。每个用户第一次访问服务器后，会自动获得一个Session ID。如果用户一段时间内没有访问服务器，那么Session就会自动失效，下次即使带着上次分配的Session ID访问，服务器也会认为是一个新用户，会分配新的Session ID。 JavaEE的Servlet机制内建了对Session的支持。我们以登录为例，当一个用户登录成功后，我们就可以把这个用户的名字放入一个HttpSession对象，以便后续访问其他页面时，能直接从HttpSession取出用户名。 1234567891011121314151617181920212223242526272829303132@WebServlet(urlPatterns = \"/signin\")public class SignInServlet extends HttpServlet { // 模拟一个数据库: private Map&lt;String, String&gt; users = Map.of(\"bob\", \"bob123\", \"alice\", \"alice123\", \"tom\", \"tomcat\"); // GET请求时显示登录页: protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.setContentType(\"text/html\"); PrintWriter pw = resp.getWriter(); pw.write(\"&lt;h1&gt;Sign In&lt;/h1&gt;\"); pw.write(\"&lt;form action=\\\"/signin\\\" method=\\\"post\\\"&gt;\"); pw.write(\"&lt;p&gt;Username: &lt;input name=\\\"username\\\"&gt;&lt;/p&gt;\"); pw.write(\"&lt;p&gt;Password: &lt;input name=\\\"password\\\" type=\\\"password\\\"&gt;&lt;/p&gt;\"); pw.write(\"&lt;p&gt;&lt;button type=\\\"submit\\\"&gt;Sign In&lt;/button&gt; &lt;a href=\\\"/\\\"&gt;Cancel&lt;/a&gt;&lt;/p&gt;\"); pw.write(\"&lt;/form&gt;\"); pw.flush(); } // POST请求时处理用户登录: protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String name = req.getParameter(\"username\"); String password = req.getParameter(\"password\"); String expectedPassword = users.get(name.toLowerCase()); if (expectedPassword != null &amp;&amp; expectedPassword.equals(password)) { // 登录成功: req.getSession().setAttribute(\"user\", name); resp.sendRedirect(\"/\"); } else { resp.sendError(HttpServletResponse.SC_FORBIDDEN); } }} 在IndexServlet中，可以从HttpSession取出用户名： 1234567891011121314151617181920@WebServlet(urlPatterns = \"/\")public class IndexServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 从HttpSession获取当前用户名: String user = (String) req.getSession().getAttribute(\"user\"); resp.setContentType(\"text/html\"); resp.setCharacterEncoding(\"UTF-8\"); resp.setHeader(\"X-Powered-By\", \"JavaEE Servlet\"); PrintWriter pw = resp.getWriter(); pw.write(\"&lt;h1&gt;Welcome, \" + (user != null ? user : \"Guest\") + \"&lt;/h1&gt;\"); if (user == null) { // 未登录，显示登录链接: pw.write(\"&lt;p&gt;&lt;a href=\\\"/signin\\\"&gt;Sign In&lt;/a&gt;&lt;/p&gt;\"); } else { // 已登录，显示登出链接: pw.write(\"&lt;p&gt;&lt;a href=\\\"/signout\\\"&gt;Sign Out&lt;/a&gt;&lt;/p&gt;\"); } pw.flush(); }} 如果用户已登录，可以通过访问/signout登出。登出逻辑就是从HttpSession中移除用户相关信息： 12345678@WebServlet(urlPatterns = \"/signout\")public class SignOutServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 从HttpSession移除用户名: req.getSession().removeAttribute(\"user\"); resp.sendRedirect(\"/\"); }} 对于Web应用程序来说，我们总是通过HttpSession这个高级接口访问当前Session。要深入理解Session原理，可以任务Web服务器在内存中自动维护了一个ID到HttpSession的映射表。而服务器识别Session的关键是依靠一个名为JSESSIONID的Cookie。在Servlet中第一次调用req.getSession()时，Servlet容器自动创建一个Session ID，然后通过一个名为JSESSIONID的Cookie发送给浏览器。 这里要注意的几点是： JSESSIONID是由Servlet容器自动创建的，目的是维护一个浏览器回话，它和我们的登录逻辑没有关系 登录和登出的业务逻辑是我们自己根据HttpSession是否存在一个“user”的Key判断的，登出后，Session ID并不会改变 即使没有登录功能，仍然可以使用HttpSession追踪用户，例如，放入一些用户配置信息 除了使用Cookie机制实现Session之外，还可以通过隐藏表单、URL末尾附加ID来追踪Session。这些机制很少使用，最常用的Session机制仍然是Cookie。 使用Session时，由于服务器把所有用户的Session都存储在内存中，如果遇到内存不足的情况，就需要把部分不活动的Session序列化到磁盘上，这会大大降低服务器的运行效率。因此，放入Session的对象要小，通常我们放入一个简单的User对象就够了。 12345public class User { public long id; // 唯一标识 public String email; public String name;} 在使用多台服务器构建集群时，使用Session会遇到一些额外的问题。通常，多台服务器集群使用反向代理作为网站入口。 123456789 ┌────────────┐ ┌───&gt;│Web Server 1│ │ └────────────┘┌───────┐ ┌─────────────┐ │ ┌────────────┐│Browser│────&gt;│Reverse Proxy│───┼───&gt;│Web Server 2│└───────┘ └─────────────┘ │ └────────────┘ │ ┌────────────┐ └───&gt;│Web Server 3│ └────────────┘ 如果多台Web Server采用无状态集群，那么反向代理总是以轮询的方式将请求依此转发给每台Web Server，这回造成一个用户在Web Server1存储的Session信息，在Web Server2和3上并不存在。即从Web Server1登录后，如果后续请求被转发到Web Server2和3，那么依然会是无登录状态。 要解决这个问题，方案一是在所有Web Server之间进行Session复制，但这样会严重消耗网络带宽。并且，每台Web Server的内存都存储了所有用户的Session，内存使用率很低。 另一个方案是采用粘滞会话（Sticky Session）机制，即反向代理在转发请求时，总是根据JSESSIONID的值判断，相同的JSESSIONID总是转发到固定的Web Server，但这需要反向代理的支持。 无论采用哪种方案，使用Session机制会使得Web Server的集群很难扩展，因此，Session适用于中小型Web应用程序。对于大型Web应用程序来说，通常需要避免采用Session机制。 Cookie实际上，Servlet提供的HttpSession本质上就是通过一个名为JSESSIONID的Cookie来跟踪用户会话的。除了这个名称外，其他名称的Cookie我们可以任意使用。 如果我们想要设置一个Cookie，例如记录用户选择的语言，可以编写一个LanguageServlet： 1234567891011121314151617181920@WebServlet(urlPatterns = \"/pref\")public class LanguageServlet extends HttpServlet { private static final Set&lt;String&gt; LANGUAGES = Set.of(\"en\", \"zh\"); protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String lang = req.getParameter(\"lang\"); if (LANGUAGES.contains(lang)) { // 创建一个新的Cookie: Cookie cookie = new Cookie(\"lang\", lang); // 该Cookie生效的路径范围: cookie.setPath(\"/\"); // 该Cookie有效期: cookie.setMaxAge(8640000); // 8640000秒=100天 // 将该Cookie添加到响应: resp.addCookie(cookie); } resp.sendRedirect(\"/\"); }} 创建一个Cookie时，除了指定名称和值以外，通常需要设置setPath(\"/\")，浏览器根据此前缀决定是否发送Cookie。如果一个Cookie调用了setPath(\"/user/\")，那么浏览器只有在请求以/user/开头的路径时才会附加此Cookie。通过setMaxAge()设置Cookie的有效期，单位为秒，最后通过resp.addCookie()把它添加到响应。如果访问的是https网页，还需要调用setSecure(true)，否则浏览器不会发送该Cookie。 因此，务必注意：浏览器在请求某个URL时，是否携带指定的Cookie，取决于Cookie是否满足以下所有要求： URL前缀是设置Cookie时的Path； Cookie在有效期内； Cookie设置了secure时必须以https访问。 我们可以在浏览器看到服务器发送的Cookie。 如果我们要读取Cookie，例如，在IndexServlet中，读取名为lang的Cookie以获取用户设置的语言，可以写一个方法如下： 1234567891011121314151617private String parseLanguageFromCookie(HttpServletRequest req) { // 获取请求附带的所有Cookie: Cookie[] cookies = req.getCookies(); // 如果获取到Cookie: if (cookies != null) { // 循环每个Cookie: for (Cookie cookie : cookies) { // 如果Cookie名称为lang: if (cookie.getName().equals(\"lang\")) { // 返回Cookie的值: return cookie.getValue(); } } } // 返回默认值: return \"en\";} 可见，读取Cookie主要依靠遍历HttpServletRequest附带的所有Cookie。 JSP开发从前面的章节中可以看到，Servlet就是一个能处理HTTP请求、发送HTTP响应的小程序，而发送响应无非就是获取PrintWriter，然后输出HTML。 1234567PrintWriter pw = resp.getWriter();pw.write(\"&lt;html&gt;\");pw.write(\"&lt;body&gt;\");pw.write(\"&lt;h1&gt;Welcome, \" + name + \"!&lt;/h1&gt;\");pw.write(\"&lt;/body&gt;\");pw.write(\"&lt;/html&gt;\");pw.flush(); 只不过，用PrintWriter输出HTML比较痛苦，因为不但要正确编写HTML，还需要插入各种变量。如果想在Servlet中输出一个类似新浪首页的HTML，写对HTML基本不可能。那么有没有更简单的输出HTML的方法？ 有！ 我们可以使用JSP，JSP是Java Server Pages的缩写，它的文件必须放到/src/main/webapp下，文件名必须以.jsp结尾，整个文件与HTML无太大差别。但需要插入变量，或者动态输出的地方，使用特殊指令&lt;%...%&gt;。我们来编写一个hello.jsp，内容如下： 1234567891011121314151617&lt;html&gt;&lt;head&gt; &lt;title&gt;Hello World - JSP&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%-- JSP Comment --%&gt; &lt;h1&gt;Hello World!&lt;/h1&gt; &lt;p&gt; &lt;% out.println(\"Your IP address is \"); %&gt; &lt;span style=\"color:red\"&gt; &lt;%= request.getRemoteAddr() %&gt; &lt;/span&gt; &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 包含在&lt;%--和--%&gt;之间的是JSP的注释，它们会被完全忽略 包含在&lt;%和%&gt;之间的是Java代码，可以编写任意Java代码 如果使用&lt;%= xxx %&gt;则可以快捷输出一个变量的值 JSP页面内置了几个变量，这几个变量可以直接使用： out：表示HttpServletResponse的PrintWriter session：表示当前HttpSession对象 request：表示HttpServletRequest对象 访问JSP时，直接指定完整路径，例如，http://localhost:8080/hello.jsp。 JSP和Servlet有什么区别？其实它们没有区别，因为JSP在执行前会被编译为一个Servlet。在Tomcat的临时目录下，可以找到一个hello_jsp.java的源文件，这个文件就是Tomcat把JSP自动转换为Servlet源码： 123456789101112131415161718192021package org.apache.jsp;import ...public final class hello_jsp extends org.apache.jasper.runtime.HttpJspBase implements org.apache.jasper.runtime.JspSourceDependent, org.apache.jasper.runtime.JspSourceImports { ... public void _jspService(final javax.servlet.http.HttpServletRequest request, final javax.servlet.http.HttpServletResponse response) throws java.io.IOException, javax.servlet.ServletException { ... out.write(\"&lt;html&gt;\\n\"); out.write(\"&lt;head&gt;\\n\"); out.write(\" &lt;title&gt;Hello World - JSP&lt;/title&gt;\\n\"); out.write(\"&lt;/head&gt;\\n\"); out.write(\"&lt;body&gt;\\n\"); ... } ...} 可见JSP本质上就是一个Servlet，只不过无需配置映射路径，Web Server会根据路径查找对应的.jsp文件，如果找到了，就自动编译成Servlet再执行。在服务器运行过程中，如果修改了JSP的内容，那么服务器会自动重新编译。 JSP高级功能JSP的指令非常复杂，除了&lt;% ... %&gt;外，JSP页面本身可以通过page指令引入Java类： 12&lt;%@ page import=\"java.io.*\" %&gt;&lt;%@ page import=\"java.util.*\" %&gt; 这样后续的Java代码才能引用简单类名而不是完整类名。 使用include指令可以引入另一个JSP文件： 123456&lt;html&gt;&lt;body&gt; &lt;%@ include file=\"header.jsp\"%&gt; &lt;h1&gt;Index Page&lt;/h1&gt; &lt;%@ include file=\"footer.jsp\"%&gt;&lt;/body&gt; JSP TagJSP还允许自定义输出的tag，例如： 1&lt;c:out value = \"${sessionScope.user.name}\"/&gt; JSP Tag需要正确引入taglib的jar包，并且还需要正确声明，使用起来非常复杂，对于页面开发来说，不推荐使用JSP Tag，因为我们后续会介绍更简单的模板引擎，这里我们不再介绍如何使用taglib。 小结JSP是一种在HTML中嵌入动态输出的文件，它和Servlet正好相反，Servlet是在Java代码中嵌入输出的HTML。JSP可以引用并使用JSP Tag，但由于其语法复杂，不推荐使用。JSP目前已很少使用，我们只需要了解其基本用法即可。 MVC开发通过前面的章节可以看到： Servlet适合编写Java代码，实现各种复杂的业务逻辑，但不适合输出复杂的HTML JSP适合编写HTML，并在其中插入动态内容，但不适合编写复杂的Java代码 能否将两者结合起来，发挥各自的优点？答案是肯定的，这就是MVC，MVC模式是一种分离业务逻辑和显示逻辑的设计模式，广泛应用在Web和桌面应用程序。我们来看一个例子。 假设我们已经编写了几个JavaBean： 12345678910public class User { public long id; public String name; public School school;}public class School { public String name; public String address;} 在UserServlet中，我们可以从数据库读取User、School等信息，然后，把读取到的JavaBean先放到HttpServletRequest中，再通过forward()传给user.jsp处理： 123456789101112@WebServlet(urlPatterns = \"/user\")public class UserServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 假装从数据库读取: School school = new School(\"No.1 Middle School\", \"101 South Street\"); User user = new User(123, \"Bob\", school); // 放入Request中: req.setAttribute(\"user\", user); // forward给user.jsp: req.getRequestDispatcher(\"/WEB-INF/user.jsp\").forward(req, resp); }} 在user.jsp中，我们只负责展示相关JavaBean的信息，不需要编写访问数据库等复杂逻辑： 12345678910111213141516171819202122&lt;%@ page import=\"com.itranswarp.learnjava.bean.*\"%&gt;&lt;% User user = (User) request.getAttribute(\"user\");%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Hello World - JSP&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Hello &lt;%= user.name %&gt;!&lt;/h1&gt; &lt;p&gt;School Name: &lt;span style=\"color:red\"&gt; &lt;%= user.school.name %&gt; &lt;/span&gt; &lt;/p&gt; &lt;p&gt;School Address: &lt;span style=\"color:red\"&gt; &lt;%= user.school.address %&gt; &lt;/span&gt; &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 请注意几点： 需要展示的User被放入HttpServletRequest中以便传递给JSP，因为一个请求对应一个HttpServletRequest，我们也无需清理它，处理完该请求后HttpServletRequest实例将被丢弃 把user.jsp放到/WEB-INF/目录下，是因为WEB-INF是一个特殊目录，Web Server会阻止浏览器对WEB-INF目录下任何资源的访问，这样就防止用户通过/user.jsp路径直接访问到JSP页面 JSP页面首先从request变量获取User实例，然后在页面中直接输出，此处未考虑HTML的转义问题，有潜在安全风险 我们在浏览器访问http://localhost:8080/user，请求首先由UserServlet处理，然后交给user.jsp渲染。 我们把UserServlet看作业务逻辑处理，把User看作模型，把user.jsp看作渲染，这种设计模式通常称为MVC：Model-View-Controller。即User作为模型Model，user.jsp作为视图View，UserServlet作为控制器Controller。整个MVC架构如下： 123456789101112 ┌───────────────────────┐ ┌────&gt;│Controller: UserServlet│ │ └───────────────────────┘ │ │┌───────┐ │ ┌─────┴─────┐│Browser│────┘ │Model: User││ │&lt;───┐ └─────┬─────┘└───────┘ │ │ │ ▼ │ ┌───────────────────────┐ └─────│ View: user.jsp │ └───────────────────────┘ 使用MVC模式的好处是，Controller专注于业务处理，它的处理结果是Model。Model可以是一个JavaBean，也可以是一个包含多个对象的Map，Controller只负责把Model传递给View，View只负责把Model给渲染出来。这样，三者职责明确且开发更简单。但它还不够简洁和灵活，后续我们会介绍更简单的Spring MVC开发。 MVC高级开发通过结合Servlet和JSP的MVC模式，我们可以发挥二者各自的优点。但是，直接把MVC搭在Servlet和JSP上还是不太好，因为： Servlet提供的接口仍然偏底层，需要实现Servlet调用相关的接口 JSP对页面开发不太友好，更好的替代品是模板引擎 业务逻辑最好用纯粹的Java类实现，而不是强迫继承自Servlet 能不能通过普通的Java类实现MVC的Controller？类似下面的代码： 12345678910111213141516public class UserController { @GetMapping(\"/signin\") public ModelAndView signin() { ... } @PostMapping(\"/signin\") public ModelAndView doSignin(SignInBean bean) { ... } @GetMapping(\"/signout\") public ModelAndView signout(HttpSession session) { ... }} 上面的这个Java类每个方法都对应一个GET或POST请求，方法返回值是ModelAndView，它包含一个View的路径以及一个Model，这样，再由MVC框架处理后返回给浏览器。 如果是GET请求，我们希望MVC框架能直接把URL参数按方法参数对应起来然后传入： 1234@GetMapping(\"/hello\")public ModelAndView hello(String name) { ...} 如果是POST请求，我们希望MVC框架能直接把Post参数变成一个JavaBean后通过方法参数传入： 1234@PostMapping(\"/signin\")public ModelAndView doSignin(SignInBean bean) { ...} 为了增加灵活性，如果Controller方法在处理请求时需要访问HttpServletRequest、HttpServletResponse、HttpSession这些实例时，只要方法参数有定义，就可以自动传入： 1234@GetMapping(\"/signout\")public ModelAndView signout(HttpSession session) { ...} 设计MVC框架如何设计一个MVC框架？在上文中，我们已经定义了上层代码编写Controller的一切接口信息，并且并不需要实现特定接口，只需返回ModelAndView对象，该对象包含一个View和Model。实际上View就是模板的路径，而Model可以用一个Map&lt;String, Object&gt;表示，因此ModelAndView的定义非常简单： 1234public class ModelAndView { Map&lt;String, Object&gt; model; String view;} 比较复杂的是我们需要在MVC框架创建一个接收所有请求的Servlet，通常我们把它命名为DispatcherServlet，它总是映射到/。然后，根据不同的Controller的方法定义的@Get和@Post的Path决定调用哪个方法。最后，获得方法返回的ModelAndView后，渲染模板，写入HttpServletResponse，即完成了整个MVC的处理。 这个MVC的框架如下： 123456789101112131415 HTTP Request ┌─────────────────┐──────────────────&gt;│DispatcherServlet│ └─────────────────┘ │ ┌────────────┼────────────┐ ▼ ▼ ▼ ┌───────────┐┌───────────┐┌───────────┐ │Controller1││Controller2││Controller3│ └───────────┘└───────────┘└───────────┘ │ │ │ └────────────┼────────────┘ ▼ HTTP Response ┌────────────────────┐&lt;────────────────│render(ModelAndView)│ └────────────────────┘ 其中，DispatcherServlet以及如何渲染均由MVC框架实现，在MVC框架之上只需要编写每一个Controller。 我们来看看如何编写最复杂的DispatcherServlet。首先，我们需要存储请求路径到某个具体方法的映射： 12345@WebServlet(urlPatterns = \"/\")public class DispatcherServlet extends HttpServlet { private Map&lt;String, GetDispatcher&gt; getMappings = new HashMap&lt;&gt;(); private Map&lt;String, PostDispatcher&gt; postMappings = new HashMap&lt;&gt;();} 处理一个GET请求是通过GetDispather对象完成的，它需要如下信息： 123456class GetDispatcher { Object instance; // Controller实例 Method method; // Controller方法 String[] parameterNames; // 方法参数名称 Class&lt;?&gt;[] parameterClasses; // 方法参数类型} 有了以上信息，就可以定义invoke()来处理真正的请求： 123456789101112131415161718192021222324252627282930313233class GetDispatcher { ... public ModelAndView invoke(HttpServletRequest request, HttpServletResponse response) { Object[] arguments = new Object[parameterClasses.length]; for (int i = 0; i &lt; parameterClasses.length; i++) { String parameterName = parameterNames[i]; Class&lt;?&gt; parameterClass = parameterClasses[i]; if (parameterClass == HttpServletRequest.class) { arguments[i] = request; } else if (parameterClass == HttpServletResponse.class) { arguments[i] = response; } else if (parameterClass == HttpSession.class) { arguments[i] = request.getSession(); } else if (parameterClass == int.class) { arguments[i] = Integer.valueOf(getOrDefault(request, parameterName, \"0\")); } else if (parameterClass == long.class) { arguments[i] = Long.valueOf(getOrDefault(request, parameterName, \"0\")); } else if (parameterClass == boolean.class) { arguments[i] = Boolean.valueOf(getOrDefault(request, parameterName, \"false\")); } else if (parameterClass == String.class) { arguments[i] = getOrDefault(request, parameterName, \"\"); } else { throw new RuntimeException(\"Missing handler for type: \" + parameterClass); } } return (ModelAndView) this.method.invoke(this.instance, arguments); } private String getOrDefault(HttpServletRequest request, String name, String defaultValue) { String s = request.getParameter(name); return s == null ? defaultValue : s; }} 上述代码比较繁琐，但逻辑非常简单，即通过构造某个方法需要的所有参数列表，使用反射调用该方法返回结果。类似地，PostDispatcher需要如下信息： 123456class PostDispatcher { Object instance; // Controller实例 Method method; // Controller方法 Class&lt;?&gt;[] parameterClasses; // 方法参数类型 ObjectMapper objectMapper; // JSON映射} 和GET请求不同，POST请求严格来说不能有URL参数，所有数据都应当从Post Body中读取。这里我们为了简化处理，只支持JSON格式的POST请求，这样，把Post数据转化为JavaBean就非常容易。 123456789101112131415161718192021class PostDispatcher { ... public ModelAndView invoke(HttpServletRequest request, HttpServletResponse response) { Object[] arguments = new Object[parameterClasses.length]; for (int i = 0; i &lt; parameterClasses.length; i++) { Class&lt;?&gt; parameterClass = parameterClasses[i]; if (parameterClass == HttpServletRequest.class) { arguments[i] = request; } else if (parameterClass == HttpServletResponse.class) { arguments[i] = response; } else if (parameterClass == HttpSession.class) { arguments[i] = request.getSession(); } else { // 读取JSON并解析为JavaBean: BufferedReader reader = request.getReader(); arguments[i] = this.objectMapper.readValue(reader, parameterClass); } } return (ModelAndView) this.method.invoke(instance, arguments); }} 最后，我们来实现整个DispatcherServlet的处理流程，以doGet()为例。 12345678910111213141516171819202122232425262728293031public class DispatcherServlet extends HttpServlet { ... @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.setContentType(\"text/html\"); resp.setCharacterEncoding(\"UTF-8\"); String path = req.getRequestURI().substring(req.getContextPath().length()); // 根据路径查找GetDispatcher: GetDispatcher dispatcher = this.getMappings.get(path); if (dispatcher == null) { // 未找到返回404: resp.sendError(404); return; } // 调用Controller方法获得返回值: ModelAndView mv = dispatcher.invoke(req, resp); // 允许返回null: if (mv == null) { return; } // 允许返回`redirect:`开头的view表示重定向: if (mv.view.startsWith(\"redirect:\")) { resp.sendRedirect(mv.view.substring(9)); return; } // 将模板引擎渲染的内容写入响应: PrintWriter pw = resp.getWriter(); this.viewEngine.render(mv, pw); pw.flush(); }} 这里有几个小改进： 允许Controller方法返回null，表示内部已自行处理完毕 允许Controller方法返回以redirect:开头的view名称，表示一个重定向 这样使得上层代码编写更灵活，例如，一个显示用户资料的请求可以这样写： 1234567891011121314@GetMapping(\"/user/profile\")public ModelAndView profile(HttpServletResponse response, HttpSession session) { User user = (User) session.getAttribute(\"user\"); if (user == null) { // 未登录，跳转到登录页: return new ModelAndView(\"redirect:/signin\"); } if (!user.isManager()) { // 权限不够，返回403: response.sendError(403); return null; } return new ModelAndView(\"/profile.html\", Map.of(\"user\", user));} 最后一步是在DispatcherServlet的init()方法中初始化所有Get和Post的映射，以及用于渲染的模板引擎： 12345678910111213public class DispatcherServlet extends HttpServlet { private Map&lt;String, GetDispatcher&gt; getMappings = new HashMap&lt;&gt;(); private Map&lt;String, PostDispatcher&gt; postMappings = new HashMap&lt;&gt;(); private ViewEngine viewEngine; @Override public void init() throws ServletException { this.getMappings = scanGetInControllers(); this.postMappings = scanPostInControllers(); this.viewEngine = new ViewEngine(getServletContext()); } ...} 如何扫描所有Controller以获取所有标记有@GetMapping和@PostMapping的方法？当然是使用反射了。虽然代码比较繁琐，但我们相信各位童鞋可以轻松实现。 这样，整个MVC框架就搭建完毕。 实现渲染有的童鞋对如何使用模板引擎进行渲染有疑问，即如何实现上述的ViewEngine？其实ViewEngine非常简单，只需要实现一个简单的render()方法： 12345678910public class ViewEngine { public void render(ModelAndView mv, Writer writer) throws IOException { String view = mv.view; Map&lt;String, Object&gt; model = mv.model; // 根据view找到模板文件: Template template = getTemplateByPath(view); // 渲染并写入Writer: template.write(writer, model); }} Java有很多开源的模板引擎，常用的有Thymeleaf，FreeMarker，Velocity。它们的用法都大同小异，这里我们推荐一个使用Jinja语法的模板引擎Pebble，它的特点是语法简单，支持模板继承，编写出来的模板类似： 123456789&lt;html&gt;&lt;body&gt; &lt;ul&gt; {% for user in users %} &lt;li&gt;&lt;a href=\"{{ user.url }}\"&gt;{{ user.username }}&lt;/a&gt;&lt;/li&gt; {% endfor %} &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; 即变量用{{ xxx }}表示，控制语句用{% xxx %}表示。 使用Pebble渲染只需要如下几行代码： 1234567891011121314151617181920212223242526public class ViewEngine { private final PebbleEngine engine; public ViewEngine(ServletContext servletContext) { // 定义一个ServletLoader用于加载模板: ServletLoader loader = new ServletLoader(servletContext); // 模板编码: loader.setCharset(\"UTF-8\"); // 模板前缀，这里默认模板必须放在`/WEB-INF/templates`目录: loader.setPrefix(\"/WEB-INF/templates\"); // 模板后缀: loader.setSuffix(\"\"); // 创建Pebble实例: this.engine = new PebbleEngine.Builder() .autoEscaping(true) // 默认打开HTML字符转义，防止XSS攻击 .cacheActive(false) // 禁用缓存使得每次修改模板可以立刻看到效果 .loader(loader).build(); } public void render(ModelAndView mv, Writer writer) throws IOException { // 查找模板: PebbleTemplate template = this.engine.getTemplate(mv.view); // 渲染: template.evaluate(writer, mv.model); }} 最后我们来看看整个工程的结构： 12345678910111213141516171819202122232425262728293031323334353637web-mvc├── pom.xml└── src └── main ├── java │ └── com │ └── itranswarp │ └── learnjava │ ├── Main.java │ ├── bean │ │ ├── SignInBean.java │ │ └── User.java │ ├── controller │ │ ├── IndexController.java │ │ └── UserController.java │ └── framework │ ├── DispatcherServlet.java │ ├── FileServlet.java │ ├── GetMapping.java │ ├── ModelAndView.java │ ├── PostMapping.java │ └── ViewEngine.java └── webapp ├── WEB-INF │ ├── templates │ │ ├── _base.html │ │ ├── hello.html │ │ ├── index.html │ │ ├── profile.html │ │ └── signin.html │ └── web.xml └── static ├── css │ └── bootstrap.css └── js ├── bootstrap.js └── jquery.js 其中，framework包是MVC的框架，完全可以单独编译后作为一个Maven依赖引入，controller包才是我们需要编写的业务逻辑。 我们还硬性规定模板必须放在webapp/WEB-INF/templates目录下，静态文件必须放在webapp/static目录下，因此，为了便于开发，我们还顺带实现一个FileServlet来处理静态文件： 12345678910111213141516171819202122232425262728293031323334@WebServlet(urlPatterns = { \"/favicon.ico\", \"/static/*\" })public class FileServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 读取当前请求路径: ServletContext ctx = req.getServletContext(); // RequestURI包含ContextPath,需要去掉: String urlPath = req.getRequestURI().substring(ctx.getContextPath().length()); // 获取真实文件路径: String filepath = ctx.getRealPath(urlPath); if (filepath == null) { // 无法获取到路径: resp.sendError(HttpServletResponse.SC_NOT_FOUND); return; } Path path = Paths.get(filepath); if (!path.toFile().isFile()) { // 文件不存在: resp.sendError(HttpServletResponse.SC_NOT_FOUND); return; } // 根据文件名猜测Content-Type: String mime = Files.probeContentType(path); if (mime == null) { mime = \"application/octet-stream\"; } resp.setContentType(mime); // 读取文件并写入Response: OutputStream output = resp.getOutputStream(); try (InputStream input = new BufferedInputStream(new FileInputStream(filepath))) { input.transferTo(output); } output.flush(); }} 运行代码，在浏览器中输入URLhttp://localhost:8080/hello?name=Bob即可看到渲染出来的页面。 有些用过Spring MVC的童鞋会发现，本节实现的这个MVC框架，上层代码使用的公共类如GetMapping、PostMapping和ModelAndView都和Spring MVC非常类似。实际上，我们这个MVC框架主要参考就是Spring MVC，通过实现一个“简化版”MVC，可以掌握Java Web MVC开发的核心思想与原理，对将来直接使用Spring MVC是非常有帮助的。 小结一个MVC框架是基于Servlet基础抽象出更高级的接口，使得上层基于MVC框架的开发可以不涉及Servlet相关的HttpServletRequest等接口，处理多个请求更加灵活，并且可以使用任意模板引擎，不必使用JSP。 使用Filter在一个比较复杂的Web应用程序中，通常都有很多URL映射，对应的，也会有多个Servlet来处理URL。我们考察这样一个论坛应用程序： 1234567891011121314151617181920 ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ / ┌──────────────┐ │ ┌─────────────&gt;│ IndexServlet │ │ │ └──────────────┘ │ │/signin ┌──────────────┐ │ ├─────────────&gt;│SignInServlet │ │ │ └──────────────┘ │ │/signout ┌──────────────┐┌───────┐ │ ├─────────────&gt;│SignOutServlet│ ││Browser├─────┤ └──────────────┘└───────┘ │ │/user/profile ┌──────────────┐ │ ├─────────────&gt;│ProfileServlet│ │ │ └──────────────┘ │ │/user/post ┌──────────────┐ │ ├─────────────&gt;│ PostServlet │ │ │ └──────────────┘ │ │/user/reply ┌──────────────┐ │ └─────────────&gt;│ ReplyServlet │ │ └──────────────┘ │ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ 各个Servlet设计功能如下： IndexServlet：浏览帖子 SignInServlet：登录 SignOutServlet：登出 ProfileServlet：修改用户资料 PostServlet：发帖 ReplyServlet：回复 其中ProfileServlet、PostServlet和ReplyServlet都需要用户登录后才能操作，否则应当直接跳转到登录页面。我们可以直接把登录逻辑写到这3个Servlet中，但是同样的逻辑重复3次没有必要，并且，如果后续继续加Servlet并且也需要验证登录时，还继续要重复这个登录逻辑。 为了把一些公用逻辑从各个Servlet中抽离出来，JavaEE的Servlet规范还提供了一种Filter组件，即过滤器。它的作用是在HTTP请求到达Servlet之前，可以被一个或多个Filter处理。类似打印日志、登录检查等逻辑，完全可以放到Filter中。 例如，我们编写一个最简单的EncodingFilter，它强制把输入和输出的编码设置为UTF-8： 12345678910@WebFilter(urlPatterns = \"/*\")public class EncodingFilter implements Filter { public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\"EncodingFilter:doFilter\"); request.setCharacterEncoding(\"UTF-8\"); response.setCharacterEncoding(\"UTF-8\"); chain.doFilter(request, response); }} 编写Filter时，必须实现Filter接口，在doFilter()方法内部，要继续处理请求，必须调用chain.doFilter()。最后，用@WebFilter注解标注该Filter需要过滤的URL，这里的/*表示所有路径。 添加了Filter后，整个请求的处理架构如下： 1234567891011121314151617181920 ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ / ┌──────────────┐ │ ┌─────────────&gt;│ IndexServlet │ │ │ └──────────────┘ │ │/signin ┌──────────────┐ │ ├─────────────&gt;│SignInServlet │ │ │ └──────────────┘ │ │/signout ┌──────────────┐┌───────┐ │ ┌──────────────┐ ├─────────────&gt;│SignOutServlet│ ││Browser│──────&gt;│EncodingFilter├──┤ └──────────────┘└───────┘ │ └──────────────┘ │/user/profile ┌──────────────┐ │ ├─────────────&gt;│ProfileServlet│ │ │ └──────────────┘ │ │/user/post ┌──────────────┐ │ ├─────────────&gt;│ PostServlet │ │ │ └──────────────┘ │ │/user/reply ┌──────────────┐ │ └─────────────&gt;│ ReplyServlet │ │ └──────────────┘ │ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ 还可以继续添加其他Filter，例如LogFilter： 12345678@WebFilter(\"/*\")public class LogFilter implements Filter { public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\"LogFilter: process \" + ((HttpServletRequest) request).getRequestURI()); chain.doFilter(request, response); }} 多个Filter会组成一个链，每个请求都被链上的Filter依次处理： 123456789 ┌────────┐ ┌─&gt;│ServletA│ │ └────────┘ ┌──────────────┐ ┌─────────┐ │ ┌────────┐───&gt;│EncodingFilter│───&gt;│LogFilter│──┼─&gt;│ServletB│ └──────────────┘ └─────────┘ │ └────────┘ │ ┌────────┐ └─&gt;│ServletC│ └────────┘ 那么有多个Filter时，Filter的顺序如何指定？多个Filter按不同的顺序处理会造成处理结果不同吗？答案是Filter的顺序确实对处理的结果有影响，但遗憾的是，Servlet规范并没有对@WebFilter注解标注的Filter规定顺序。如果一定要给每个Filter指定顺序，就必须在web.xml中对这些Filter再配置一遍。 注意到上述两个Filter的过滤路径都是/*，即它们会对所有请求进行过滤。也可以编写只对特定路径进行过滤的Filter，例如AuthFilter： 1234567891011121314151617@WebFilter(\"/user/*\")public class AuthFilter implements Filter { public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { System.out.println(\"AuthFilter: check authentication\"); HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; if (req.getSession().getAttribute(\"user\") == null) { // 未登录，自动跳转到登录页: System.out.println(\"AuthFilter: not signin!\"); resp.sendRedirect(\"/signin\"); } else { // 已登录，继续处理: chain.doFilter(request, response); } }} 注意到AuthFilter只过滤以/user/开头的路径，因此： 如果一个请求路径类似/user/profile，那么它会被上述3个Filter依次处理 如果一个请求路径类似/test，那么它会被上述2个Filter依次处理（不会被AuthFilter处理） 再注意观察AuthFilter，当用户没有登录时，在AuthFilter内部，直接调用resp.sendRedirect()发送重定向，且没有调用chain.doFilter()，因此，当用户没有登录时，请求到达AuthFilter后，不再继续处理，即后续的Filter和任何Servlet都没有机会处理该请求了。 可见，Filter可以针对性地拦截或放行HTTP请求。 如果一个Filter在当前请求中生效，但什么都没有做： 1234567@WebFilter(\"/*\")public class MyFilter implements Filter { public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { // TODO }} 那么，用户将看到一个空白页，因为请求没有继续处理，默认响应是200加空白输出。**如果Filter要使请求继续被处理，就一定要调用chain.doFilter()**。 总结一下，Filter是一种对HTTP请求进行预处理的组件，他可以构成一个处理链，使得公共代码能集中到一起。Filter适用于日志、登录检查、全局设置等。设计合理的URL映射可以让Filter链更清晰。 修改请求Filter可以对请求进行预处理，因此，我们可以把很多公共预处理逻辑放到Filter中完成。考察这样一种需求：我们在Web应用中经常需要处理用户上传文件，例如： 12345678910111213141516171819202122232425@WebServlet(urlPatterns = \"/upload/file\")public class UploadServlet extends HttpServlet { protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { // 读取Request Body: InputStream input = req.getInputStream(); ByteArrayOutputStream output = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; for (;;) { int len = input.read(buffer); if (len == -1) { break; } output.write(buffer, 0, len); } // TODO: 写入文件: // 显示上传结果: String uploadedText = output.toString(StandardCharsets.UTF_8); PrintWriter pw = resp.getWriter(); pw.write(\"&lt;h1&gt;Uploaded:&lt;/h1&gt;\"); pw.write(\"&lt;pre&gt;&lt;code&gt;\"); pw.write(uploadedText); pw.write(\"&lt;/code&gt;&lt;/pre&gt;\"); pw.flush(); }} 要保证文件上传的一致性，我们在上传文件时，把文件的哈希也传上去，服务端做一个验证，就可以确保用户上传的文件一定是完整的。这个验证逻辑非常适合写在ValidateUploadFilter中，因为它可以复用，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@WebFilter(\"/upload/*\")public class ValidateUploadFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; // 获取客户端传入的签名方法和签名: String digest = req.getHeader(\"Signature-Method\"); String signature = req.getHeader(\"Signature\"); if (digest == null || digest.isEmpty() || signature == null || signature.isEmpty()) { sendErrorPage(resp, \"Missing signature.\"); return; } // 读取Request的Body并验证签名: MessageDigest md = getMessageDigest(digest); InputStream input = new DigestInputStream(request.getInputStream(), md); byte[] buffer = new byte[1024]; for (;;) { int len = input.read(buffer); if (len == -1) { break; } } String actual = toHexString(md.digest()); if (!signature.equals(actual)) { sendErrorPage(resp, \"Invalid signature.\"); return; } // 验证成功后继续处理: chain.doFilter(request, response); } // 将byte[]转换为hex string: private String toHexString(byte[] digest) { StringBuilder sb = new StringBuilder(); for (byte b : digest) { sb.append(String.format(\"%02x\", b)); } return sb.toString(); } // 根据名称创建MessageDigest: private MessageDigest getMessageDigest(String name) throws ServletException { try { return MessageDigest.getInstance(name); } catch (NoSuchAlgorithmException e) { throw new ServletException(e); } } // 发送一个错误响应: private void sendErrorPage(HttpServletResponse resp, String errorMessage) throws IOException { resp.setStatus(HttpServletResponse.SC_BAD_REQUEST); PrintWriter pw = resp.getWriter(); pw.write(\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;\"); pw.write(errorMessage); pw.write(\"&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\"); pw.flush(); }} ValidateUploadFilter对签名进行验证的逻辑是没有问题的，但是UploadServlet并为读取到任何数据。这是因为对HttpServletRequest进行读取时，只能读取一次。如果Filter调用getInputStream()读取了一次数据，后续Servlet处理时，再次读取将无法读到任何数据，咋么办？这时，我们需要“伪造”一个HttpServletRequest，具体做法是使用代理模式，对getInputStream()和getReader()返回一个新的流： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class ReReadableHttpServletRequest extends HttpServletRequestWrapper { private byte[] body; private boolean open = false; public ReReadableHttpServletRequest(HttpServletRequest request, byte[] body) { super(request); this.body = body; } // 返回InputStream: public ServletInputStream getInputStream() throws IOException { if (open) { throw new IllegalStateException(\"Cannot re-open input stream!\"); } open = true; return new ServletInputStream() { private int offset = 0; public boolean isFinished() { return offset &gt;= body.length; } public boolean isReady() { return true; } public void setReadListener(ReadListener listener) { } public int read() throws IOException { if (offset &gt;= body.length) { return -1; } int n = body[offset] &amp; 0xff; offset++; return n; } }; } // 返回Reader: public BufferedReader getReader() throws IOException { if (open) { throw new IllegalStateException(\"Cannot re-open reader!\"); } open = true; return new BufferedReader(new InputStreamReader(new ByteArrayInputStream(body), \"UTF-8\")); }} 注意观察ReReadableHttpServletRequest的构造方法，它保存了ValidateUploadFilter读取的byte[]，并在调用getInputStream()时通过byte[]构造了一个新的ServletInputStream。然后，我们在ValidateUploadFilter中，把doFilter()调用时传给下一个处理者的HttpServletRequest替换成我们自己“伪造”的ReReadableHttpServletRequest。 12345public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { ... chain.doFilter(new ReReadableHttpServletRequest(req, output.toByteArray()), response);} 再注意到我们编写ReReadableHttpServletRequest时，是从HttpServletRequestWrapper继承，而不是直接实现HttpServletRequest接口。这是因为，Servlet的每个新版本都会对接口增加一些新方法，从HttpServletRequestWrapper继承可以确保新方法被正确地覆写了，因为HttpServletRequestWrapper是由Servlet的jar包提供的，目的就是为了让我们方便地实现对HttpServletRequest接口的代理。 我们总结一下对HttpServletRequest接口进行代理的步骤： 从HttpServletRequestWrapper继承一个XxxHttpServletRequest，需要传入原始的HttpServletRequest实例； 覆写某些方法，使得新的XxxHttpServletRequest实例看上去“改变”了原始的HttpServletRequest实例； 在doFilter()中传入新的XxxHttpServletRequest实例。 虽然整个Filter的代码比较复杂，但它的好处在于：这个Filter在整个处理链中实现了灵活的“可插拔”特性，即是否启用对Web应用程序的其他组件（Filter、Servlet）完全没有影响。 修改响应我们来看一下什么时候需要修改HttpServletResponse。假设我们编写了一个Servlet，但由于业务逻辑比较复杂，处理该请求需要耗费很长时间。好消息是每次返回的响应内容是固定的，因此，如果我们能把结果缓存起来，就可以大大提高Web应用程序的运行效率。 1234567891011121314@WebServlet(urlPatterns = \"/slow/hello\")public class HelloServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.setContentType(\"text/html\"); // 模拟耗时1秒: try { Thread.sleep(1000); } catch (InterruptedException e) { } PrintWriter pw = resp.getWriter(); pw.write(\"&lt;h1&gt;Hello, world!&lt;/h1&gt;\"); pw.flush(); }} 缓存逻辑最好不要在Servlet内部实现，因为我们希望能复用缓存逻辑，编写一个CacheFilter最合适。 1234567891011121314151617181920212223242526272829@WebFilter(\"/slow/*\")public class CacheFilter implements Filter { // Path到byte[]的缓存: private Map&lt;String, byte[]&gt; cache = new ConcurrentHashMap&lt;&gt;(); public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; // 获取Path: String url = req.getRequestURI(); // 获取缓存内容: byte[] data = this.cache.get(url); resp.setHeader(\"X-Cache-Hit\", data == null ? \"No\" : \"Yes\"); if (data == null) { // 缓存未找到,构造一个伪造的Response: CachedHttpServletResponse wrapper = new CachedHttpServletResponse(resp); // 让下游组件写入数据到伪造的Response: chain.doFilter(request, wrapper); // 从伪造的Response中读取写入的内容并放入缓存: data = wrapper.getContent(); cache.put(url, data); } // 写入到原始的Response: ServletOutputStream output = resp.getOutputStream(); output.write(data); output.flush(); }} 实现缓存的关键在于，调用doFilter()时，我们不能传入原始的HttpServletResponse，因为这样就会写入Socket，我们也就无法获取下游组件写入的内容。如果我们传入的是“伪造”的HttpServletResponse，让下游组件写入到我们预设的ByteArrayOutputStream，我们就“截获”了下游组件写入的内容，于是，可以把内容缓存起来，再通过原始的HttpServletResponse实例写入到网络。 这个CachedHttpServletResponse实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243class CachedHttpServletResponse extends HttpServletResponseWrapper { private boolean open = false; private ByteArrayOutputStream output = new ByteArrayOutputStream(); public CachedHttpServletResponse(HttpServletResponse response) { super(response); } // 获取Writer: public PrintWriter getWriter() throws IOException { if (open) { throw new IllegalStateException(\"Cannot re-open writer!\"); } open = true; return new PrintWriter(output, false, StandardCharsets.UTF_8); } // 获取OutputStream: public ServletOutputStream getOutputStream() throws IOException { if (open) { throw new IllegalStateException(\"Cannot re-open output stream!\"); } open = true; return new ServletOutputStream() { public boolean isReady() { return true; } public void setWriteListener(WriteListener listener) { } // 实际写入ByteArrayOutputStream: public void write(int b) throws IOException { output.write(b); } }; } // 返回写入的byte[]: public byte[] getContent() { return output.toByteArray(); }} 可见，如果我们想要修改响应，就可以通过HttpServletResponseWrapper构造一个“伪造”的HttpServletResponse，这样就能拦截到写入的数据。修改响应后，不要忘记把数据写入原始的HttpServletResponse实例。 这个CacheFilter同样是一个“可拔插”组件，它是否启用不影响Web应用程序的其他组件（Filter，Servlet）。 使用Listener除了Servlet和Filter，JavaEE的Servlet规范还提供了第三种组件：Listener。Listener叫做监听器，有好几种Listener，其中最常用的是ServletContextListener，我们编写一个实现了ServletContextListener接口的类如下： 123456789101112@WebListenerpublic class AppListener implements ServletContextListener { // 在此初始化WebApp,例如打开数据库连接池等: public void contextInitialized(ServletContextEvent sce) { System.out.println(\"WebApp initialized.\"); } // 在此清理WebApp,例如关闭数据库连接池等: public void contextDestroyed(ServletContextEvent sce) { System.out.println(\"WebApp destroyed.\"); }} 任何标注为@WebListener，且实现了特定接口的类，都会被Web服务器自动初始化。上述AppListener实现了ServletContextListener接口，它会在整个Web应用程序初始化完成后，以及Web应用程序关闭后获得回调通知。我们可以把初始化数据库连接池等工作放到contextInitialized()回调方法中，把清理资源的工作放到contextDestroyed()回调方法中，因为Web服务器保证在contextInitialized()执行后，才会接受用户的HTTP请求。 很多第三方Web框架都会通过一个ServletContextListener接口初始化自己。此外，还有几种Listener： HttpSessionListener：监听HttpSession的创建和销毁事件 ServletRequestListener：监听ServletRequest请求的创建和销毁事件 ServletRequestAttributeListener：监听ServletRequest请求的属性变化事件（即调用ServletRequest.setAttribute()方法） ServletContextAttributeListener：监听ServletContext的属性变化事件（即调用ServletContext.setAttribute()方法） ServletContext一个Web服务器可以运行一个或多个WebApp，对于每个WebApp，Web服务器都会为其创建一个全局唯一的ServletContext实例，我们在AppListener里面编写的两个回调方法，实际上对应的就是ServletContext的创建和销毁。 ServletRequest、HttpSession等很多对象也提供getServletContext()方法获取到同一个ServletContext实例，ServletContext是一个WebApp运行期的全局唯一实例。ServletContext实例最大的作用就是设置和共享全局信息。此外，ServletContext还提供了动态添加Servlet、Filter、Listener等功能，它允许应用程序在运行期间动态添加一个组件，虽然这个功能不是很常用。 部署对一个Web应用程序来说，除了Servlet、Filter这些逻辑组件，还需要JSP这样的视图文件，外加一堆静态资源文件，如CSS、JS等。 合理组织文件结构非常重要。我们以一个具体的Web应用程序为例： 123456789101112131415161718192021webapp├── pom.xml└── src └── main ├── java │ └── com │ └── itranswarp │ └── learnjava │ ├── Main.java │ ├── filter │ │ └── EncodingFilter.java │ └── servlet │ ├── FileServlet.java │ └── HelloServlet.java ├── resources └── webapp ├── WEB-INF │ └── web.xml ├── favicon.ico └── static └── bootstrap.css 我们把所有的静态资源文件放入/static/目录，在开发阶段，有些Web服务器会自动为我们加一个专门负责处理静态文件的Servlet，但如果IndexServlet映射路径为/，会屏蔽掉处理静态文件的Servlet映射。因此，我们需要自己编写一个处理静态文件的FileServlet： 123456789101112131415161718192021222324252627282930313233@WebServlet(urlPatterns = \"/static/*\")public class FileServlet extends HttpServlet { protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { ServletContext ctx = req.getServletContext(); // RequestURI包含ContextPath,需要去掉: String urlPath = req.getRequestURI().substring(ctx.getContextPath().length()); // 获取真实文件路径: String filepath = ctx.getRealPath(urlPath); if (filepath == null) { // 无法获取到路径: resp.sendError(HttpServletResponse.SC_NOT_FOUND); return; } Path path = Paths.get(filepath); if (!path.toFile().isFile()) { // 文件不存在: resp.sendError(HttpServletResponse.SC_NOT_FOUND); return; } // 根据文件名猜测Content-Type: String mime = Files.probeContentType(path); if (mime == null) { mime = \"application/octet-stream\"; } resp.setContentType(mime); // 读取文件并写入Response: OutputStream output = resp.getOutputStream(); try (InputStream input = new BufferedInputStream(new FileInputStream(filepath))) { input.transferTo(output); } output.flush(); }} 这样一来，在开发阶段，我们就可以方便地高效开发。 类似Tomcat这样的Web服务器，运行的Web应用程序通常都是业务系统，因此，这类服务器也被称为应用服务器。应用服务器并不擅长处理静态文件，也不适合直接暴露给用户。通常，我们在生产环境部署时，总是使用类似Nginx这样的服务器充当反向代理和静态服务器，只有动态请求才会放行给应用服务器，所以，部署架构如下： 123456789 ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐ │ /static/* │┌───────┐ ┌──────────&gt; file│Browser├────┼─┤ │ ┌ ─ ─ ─ ─ ─ ─ ┐└───────┘ │/ proxy_pass │ └─────────────────────┼───&gt;│ Web Server │ Nginx └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘ └ ─ ─ ─ ─ ─ ─ ┘ 实现上述功能的Nginx配置文件如下： 123456789101112131415161718192021222324252627282930313233server { listen 80; server_name www.local.liaoxuefeng.com; # 静态文件根目录: root /path/to/src/main/webapp; access_log /var/log/nginx/webapp_access_log; error_log /var/log/nginx/webapp_error_log; # 处理静态文件请求: location /static { } # 处理静态文件请求: location /favicon.ico { } # 不允许请求/WEB-INF: location /WEB-INF { return 404; } # 其他请求转发给Tomcat: location / { proxy_pass http://127.0.0.1:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; }} 使用Nginx配合Tomcat服务器，可以充分发挥Nginx作为网关的优势，既可以高效处理静态文件，也可以把https、防火墙、限速、反爬虫等功能放到Nginx中，使得我们自己的WebApp能专注于业务逻辑。 部署Web应用程序时，要设计合理的目录结构，同时考虑开发模式需要便捷性，生产模式需要高性能。","link":"/Study/Java/Web%E5%BC%80%E5%8F%91/"}],"tags":[],"categories":[{"name":"Gallery","slug":"Gallery","link":"/categories/Gallery/"},{"name":"Item","slug":"Item","link":"/categories/Item/"},{"name":"Study","slug":"Study","link":"/categories/Study/"},{"name":"Java","slug":"Study/Java","link":"/categories/Study/Java/"},{"name":"English","slug":"Study/English","link":"/categories/Study/English/"},{"name":"Diary","slug":"Diary","link":"/categories/Diary/"},{"name":"Spring","slug":"Study/Java/Spring","link":"/categories/Study/Java/Spring/"},{"name":"OpenTSDB","slug":"Study/Java/OpenTSDB","link":"/categories/Study/Java/OpenTSDB/"},{"name":"SpringBoot","slug":"Study/Java/SpringBoot","link":"/categories/Study/Java/SpringBoot/"}]}